{"config":{"lang":["en"],"prebuild_index":false,"separator":"[\\s\\-]+"},"docs":[{"location":"","text":"Welcome to Drycc \u00b6 Drycc is a community branch of the popular PaaS service deis. Since Microsoft acquired the Deis team, it has stopped updating, so it decided to work hard to build a completely new and open developer community, we invite everyone to join us and help build the next generation of PaaS cloud services. Drycc Workflow is an open source Platform as a Service (PaaS) that adds a developer-friendly layer to any Kubernetes cluster, making it easy to deploy and manage applications. Drycc Workflow includes capabilities for building and deploying from source via git push , simple application configuration, creating and rolling back releases, managing domain names and SSL certificates, providing seamless edge routing, aggregating logs, and sharing applications with teams. All of this is exposed through a simple REST API and command line interface. Getting Started \u00b6 To get started with Workflow, follow our Quick Start guide. Take a deep dive into Drycc Workflow in our Concepts , Architecture , and Components sections. Feel like contibuting some code or want to get started as a maintainer? Pick an issue tagged as an easy fix or help wanted and start contributing! Service and Support \u00b6 Coming soon.","title":"Home"},{"location":"#welcome-to-drycc","text":"Drycc is a community branch of the popular PaaS service deis. Since Microsoft acquired the Deis team, it has stopped updating, so it decided to work hard to build a completely new and open developer community, we invite everyone to join us and help build the next generation of PaaS cloud services. Drycc Workflow is an open source Platform as a Service (PaaS) that adds a developer-friendly layer to any Kubernetes cluster, making it easy to deploy and manage applications. Drycc Workflow includes capabilities for building and deploying from source via git push , simple application configuration, creating and rolling back releases, managing domain names and SSL certificates, providing seamless edge routing, aggregating logs, and sharing applications with teams. All of this is exposed through a simple REST API and command line interface.","title":"Welcome to Drycc"},{"location":"#getting-started","text":"To get started with Workflow, follow our Quick Start guide. Take a deep dive into Drycc Workflow in our Concepts , Architecture , and Components sections. Feel like contibuting some code or want to get started as a maintainer? Pick an issue tagged as an easy fix or help wanted and start contributing!","title":"Getting Started"},{"location":"#service-and-support","text":"Coming soon.","title":"Service and Support"},{"location":"_includes/install-workflow/","text":"Check Your Setup \u00b6 First check that the helm command is available and the version is v2.5.0 or newer. $ helm version Client: &version.Version{SemVer:\"v2.5.0\", GitCommit:\"012cb0ac1a1b2f888144ef5a67b8dab6c2d45be6\", GitTreeState:\"clean\"} Server: &version.Version{SemVer:\"v2.5.0\", GitCommit:\"012cb0ac1a1b2f888144ef5a67b8dab6c2d45be6\", GitTreeState:\"clean\"} Ensure the kubectl client is installed and can connect to your Kubernetes cluster. Add the Drycc Chart Repository \u00b6 The Drycc Chart Repository contains everything needed to install Drycc Workflow onto a Kubernetes cluster, with a single helm install drycc/workflow --namespace drycc command. Add this repository to Helm: $ helm repo add drycc https://charts.drycc.cc/stable Install Drycc Workflow \u00b6 Now that Helm is installed and the repository has been added, install Workflow by running: $ helm install drycc/workflow --namespace drycc Helm will install a variety of Kubernetes resources in the drycc namespace. Wait for the pods that Helm launched to be ready. Monitor their status by running: $ kubectl --namespace=drycc get pods If it's preferred to have kubectl automatically update as the pod states change, run (type Ctrl-C to stop the watch): $ kubectl --namespace=drycc get pods -w Depending on the order in which the Workflow components initialize, some pods may restart. This is common during the installation: if a component's dependencies are not yet available, that component will exit and Kubernetes will automatically restart it. Here, it can be seen that the controller, builder and registry all took a few loops before they were able to start: $ kubectl --namespace=drycc get pods NAME READY STATUS RESTARTS AGE drycc-builder-hy3xv 1/1 Running 5 5m drycc-controller-g3cu8 1/1 Running 5 5m drycc-database-rad1o 1/1 Running 0 5m drycc-logger-fluentd-1v8uk 1/1 Running 0 5m drycc-logger-fluentd-esm60 1/1 Running 0 5m drycc-logger-sm8b3 1/1 Running 0 5m drycc-minio-4ww3t 1/1 Running 0 5m drycc-registry-asozo 1/1 Running 1 5m Once all of the pods are in the READY state, Drycc Workflow is up and running!","title":"Install workflow"},{"location":"_includes/install-workflow/#check-your-setup","text":"First check that the helm command is available and the version is v2.5.0 or newer. $ helm version Client: &version.Version{SemVer:\"v2.5.0\", GitCommit:\"012cb0ac1a1b2f888144ef5a67b8dab6c2d45be6\", GitTreeState:\"clean\"} Server: &version.Version{SemVer:\"v2.5.0\", GitCommit:\"012cb0ac1a1b2f888144ef5a67b8dab6c2d45be6\", GitTreeState:\"clean\"} Ensure the kubectl client is installed and can connect to your Kubernetes cluster.","title":"Check Your Setup"},{"location":"_includes/install-workflow/#add-the-drycc-chart-repository","text":"The Drycc Chart Repository contains everything needed to install Drycc Workflow onto a Kubernetes cluster, with a single helm install drycc/workflow --namespace drycc command. Add this repository to Helm: $ helm repo add drycc https://charts.drycc.cc/stable","title":"Add the Drycc Chart Repository"},{"location":"_includes/install-workflow/#install-drycc-workflow","text":"Now that Helm is installed and the repository has been added, install Workflow by running: $ helm install drycc/workflow --namespace drycc Helm will install a variety of Kubernetes resources in the drycc namespace. Wait for the pods that Helm launched to be ready. Monitor their status by running: $ kubectl --namespace=drycc get pods If it's preferred to have kubectl automatically update as the pod states change, run (type Ctrl-C to stop the watch): $ kubectl --namespace=drycc get pods -w Depending on the order in which the Workflow components initialize, some pods may restart. This is common during the installation: if a component's dependencies are not yet available, that component will exit and Kubernetes will automatically restart it. Here, it can be seen that the controller, builder and registry all took a few loops before they were able to start: $ kubectl --namespace=drycc get pods NAME READY STATUS RESTARTS AGE drycc-builder-hy3xv 1/1 Running 5 5m drycc-controller-g3cu8 1/1 Running 5 5m drycc-database-rad1o 1/1 Running 0 5m drycc-logger-fluentd-1v8uk 1/1 Running 0 5m drycc-logger-fluentd-esm60 1/1 Running 0 5m drycc-logger-sm8b3 1/1 Running 0 5m drycc-minio-4ww3t 1/1 Running 0 5m drycc-registry-asozo 1/1 Running 1 5m Once all of the pods are in the READY state, Drycc Workflow is up and running!","title":"Install Drycc Workflow"},{"location":"applications/deploying-apps/","text":"Deploying an Application \u00b6 An Application is deployed to Drycc using git push or the drycc client. Supported Applications \u00b6 Drycc Workflow can deploy any application or service that can run inside a Docker container. In order to be scaled horizontally, applications must follow the Twelve-Factor App methodology and store any application state in external backing services. For example, if your application persists state to the local filesystem -- common with content management systems like Wordpress and Drupal -- it cannot be scaled horizontally using drycc scale . Fortunately, most modern applications feature a stateless application tier that can scale horizontally inside Drycc. Login to the Controller \u00b6 Important if you haven't yet, now is a good time to install the client and register . Before deploying an application, users must first authenticate against the Drycc Controller using the URL supplied by their Drycc administrator. $ drycc login http://drycc.example.com username: drycc password: Logged in as drycc Select a Build Process \u00b6 Drycc Workflow supports three different ways of building applications: Buildpacks \u00b6 Heroku buildpacks are useful if you want to follow Heroku's best practices for building applications or if you are porting an application from Heroku. Learn how to deploy applications using Buildpacks . Dockerfiles \u00b6 Dockerfiles are a powerful way to define a portable execution environment built on a base OS of your choosing. Learn how to deploy applications using Dockerfiles . Docker Image \u00b6 Deploying a Docker image onto Drycc allows you to take a Docker image from either a public or a private registry and copy it over bit-for-bit, ensuring that you are running the same image in development or in your CI pipeline as you are in production. Learn how to deploy applications using Docker images . Tuning Application Settings \u00b6 It is possible to configure a few of the globally tunable settings on per application basis using config:set . Setting Description DRYCC_DISABLE_CACHE if set, this will disable the slugbuilder cache (default: not set) DRYCC_DEPLOY_BATCHES the number of pods to bring up and take down sequentially during a scale (default: number of available nodes) DRYCC_DEPLOY_TIMEOUT deploy timeout in seconds per deploy batch (default: 120) IMAGE_PULL_POLICY the kubernetes [image pull policy][pull-policy] for application images (default: \"IfNotPresent\") (allowed values: \"Always\", \"IfNotPresent\") KUBERNETES_DEPLOYMENTS_REVISION_HISTORY_LIMIT how many revisions Kubernetes keeps around of a given Deployment (default: all revisions) KUBERNETES_POD_TERMINATION_GRACE_PERIOD_SECONDS how many seconds kubernetes waits for a pod to finish work after a SIGTERM before sending SIGKILL (default: 30) Deploy Timeout \u00b6 Deploy timeout in seconds - There are 2 deploy methods, Deployments (see below) and RC (versions prior to 2.4) and this setting affects those a bit differently. Deployments \u00b6 Deployments behave a little bit differently from the RC based deployment strategy. Kubernetes takes care of the entire deploy, doing rolling updates in the background. As a result, there is only an overall deployment timeout instead of a configurable per-batch timeout. The base timeout is multiplied with DRYCC_DEPLOY_BATCHES to create an overall timeout. This would be 240 (timeout) * 4 (batches) = 960 second overall timeout. RC deploy \u00b6 This deploy timeout defines how long to wait for each batch to complete in DRYCC_DEPLOY_BATCHES . Additions to the base timeout \u00b6 The base timeout is extended as well with healthchecks using initialDelaySeconds on liveness and readiness where the bigger of those two is applied. Additionally the timeout system accounts for slow image pulls by adding an additional 10 minutes when it has seen an image pull take over 1 minute. This allows the timeout values to be reasonable without having to account for image pull slowness in the base deploy timeout. Deployments \u00b6 Workflow uses Deployments for deploys. In prior versions ReplicationControllers were used with the ability to turn on Deployments via DRYCC_KUBERNETES_DEPLOYMENTS=1 . The advantage of Deployments is that rolling-updates will happen server-side in Kubernetes instead of in Drycc Workflow Controller, along with a few other Pod management related functionality. This allows a deploy to continue even when the CLI connection is interrupted. Behind the scenes your application deploy will be built up of a Deployment object per process type, each having multiple ReplicaSets (one per release) which in turn manage the Pods running your application. Drycc Workflow will behave the same way with DRYCC_KUBERNETES_DEPLOYMENTS enabled or disabled (only applicable to versions prior to 2.4). The changes are behind the scenes. Where you will see differences while using the CLI is drycc ps:list will output Pod names differently.","title":"Deploying Apps"},{"location":"applications/deploying-apps/#deploying-an-application","text":"An Application is deployed to Drycc using git push or the drycc client.","title":"Deploying an Application"},{"location":"applications/deploying-apps/#supported-applications","text":"Drycc Workflow can deploy any application or service that can run inside a Docker container. In order to be scaled horizontally, applications must follow the Twelve-Factor App methodology and store any application state in external backing services. For example, if your application persists state to the local filesystem -- common with content management systems like Wordpress and Drupal -- it cannot be scaled horizontally using drycc scale . Fortunately, most modern applications feature a stateless application tier that can scale horizontally inside Drycc.","title":"Supported Applications"},{"location":"applications/deploying-apps/#login-to-the-controller","text":"Important if you haven't yet, now is a good time to install the client and register . Before deploying an application, users must first authenticate against the Drycc Controller using the URL supplied by their Drycc administrator. $ drycc login http://drycc.example.com username: drycc password: Logged in as drycc","title":"Login to the Controller"},{"location":"applications/deploying-apps/#select-a-build-process","text":"Drycc Workflow supports three different ways of building applications:","title":"Select a Build Process"},{"location":"applications/deploying-apps/#buildpacks","text":"Heroku buildpacks are useful if you want to follow Heroku's best practices for building applications or if you are porting an application from Heroku. Learn how to deploy applications using Buildpacks .","title":"Buildpacks"},{"location":"applications/deploying-apps/#dockerfiles","text":"Dockerfiles are a powerful way to define a portable execution environment built on a base OS of your choosing. Learn how to deploy applications using Dockerfiles .","title":"Dockerfiles"},{"location":"applications/deploying-apps/#docker-image","text":"Deploying a Docker image onto Drycc allows you to take a Docker image from either a public or a private registry and copy it over bit-for-bit, ensuring that you are running the same image in development or in your CI pipeline as you are in production. Learn how to deploy applications using Docker images .","title":"Docker Image"},{"location":"applications/deploying-apps/#tuning-application-settings","text":"It is possible to configure a few of the globally tunable settings on per application basis using config:set . Setting Description DRYCC_DISABLE_CACHE if set, this will disable the slugbuilder cache (default: not set) DRYCC_DEPLOY_BATCHES the number of pods to bring up and take down sequentially during a scale (default: number of available nodes) DRYCC_DEPLOY_TIMEOUT deploy timeout in seconds per deploy batch (default: 120) IMAGE_PULL_POLICY the kubernetes [image pull policy][pull-policy] for application images (default: \"IfNotPresent\") (allowed values: \"Always\", \"IfNotPresent\") KUBERNETES_DEPLOYMENTS_REVISION_HISTORY_LIMIT how many revisions Kubernetes keeps around of a given Deployment (default: all revisions) KUBERNETES_POD_TERMINATION_GRACE_PERIOD_SECONDS how many seconds kubernetes waits for a pod to finish work after a SIGTERM before sending SIGKILL (default: 30)","title":"Tuning Application Settings"},{"location":"applications/deploying-apps/#deploy-timeout","text":"Deploy timeout in seconds - There are 2 deploy methods, Deployments (see below) and RC (versions prior to 2.4) and this setting affects those a bit differently.","title":"Deploy Timeout"},{"location":"applications/deploying-apps/#deployments","text":"Deployments behave a little bit differently from the RC based deployment strategy. Kubernetes takes care of the entire deploy, doing rolling updates in the background. As a result, there is only an overall deployment timeout instead of a configurable per-batch timeout. The base timeout is multiplied with DRYCC_DEPLOY_BATCHES to create an overall timeout. This would be 240 (timeout) * 4 (batches) = 960 second overall timeout.","title":"Deployments"},{"location":"applications/deploying-apps/#rc-deploy","text":"This deploy timeout defines how long to wait for each batch to complete in DRYCC_DEPLOY_BATCHES .","title":"RC deploy"},{"location":"applications/deploying-apps/#additions-to-the-base-timeout","text":"The base timeout is extended as well with healthchecks using initialDelaySeconds on liveness and readiness where the bigger of those two is applied. Additionally the timeout system accounts for slow image pulls by adding an additional 10 minutes when it has seen an image pull take over 1 minute. This allows the timeout values to be reasonable without having to account for image pull slowness in the base deploy timeout.","title":"Additions to the base timeout"},{"location":"applications/deploying-apps/#deployments_1","text":"Workflow uses Deployments for deploys. In prior versions ReplicationControllers were used with the ability to turn on Deployments via DRYCC_KUBERNETES_DEPLOYMENTS=1 . The advantage of Deployments is that rolling-updates will happen server-side in Kubernetes instead of in Drycc Workflow Controller, along with a few other Pod management related functionality. This allows a deploy to continue even when the CLI connection is interrupted. Behind the scenes your application deploy will be built up of a Deployment object per process type, each having multiple ReplicaSets (one per release) which in turn manage the Pods running your application. Drycc Workflow will behave the same way with DRYCC_KUBERNETES_DEPLOYMENTS enabled or disabled (only applicable to versions prior to 2.4). The changes are behind the scenes. Where you will see differences while using the CLI is drycc ps:list will output Pod names differently.","title":"Deployments"},{"location":"applications/domains-and-routing/","text":"Domains and Routing \u00b6 You can use drycc domains to add or remove custom domains to the application: $ drycc domains:add hello.bacongobbler.com Adding hello.bacongobbler.com to finest-woodshed... done Once that's done, you can go into a DNS registrar and set up a CNAME from the new appname to the old one: $ dig hello.dryccapp.com [...] ;; ANSWER SECTION: hello.bacongobbler.com. 1759 IN CNAME finest-woodshed.dryccapp.com. finest-woodshed.dryccapp.com. 270 IN A 172.17.8.100 Note Setting a CNAME for a root domain can cause issues. Setting an @ record to be a CNAME causes all traffic to go to the other domain, including mail and the SOA (\"start-of-authority\") records. It is highly recommended that you bind a subdomain to an application, however you can work around this by pointing the @ record to the address of the load balancer (if any). To add or remove the application from the routing mesh, use drycc routing : $ drycc routing:disable Disabling routing for finest-woodshed... done This will make the application unreachable through the Router , but the application is still reachable internally through its Kubernetes Service . To re-enable routing: $ drycc routing:enable Enabling routing for finest-woodshed... done","title":"Domains and Routing"},{"location":"applications/domains-and-routing/#domains-and-routing","text":"You can use drycc domains to add or remove custom domains to the application: $ drycc domains:add hello.bacongobbler.com Adding hello.bacongobbler.com to finest-woodshed... done Once that's done, you can go into a DNS registrar and set up a CNAME from the new appname to the old one: $ dig hello.dryccapp.com [...] ;; ANSWER SECTION: hello.bacongobbler.com. 1759 IN CNAME finest-woodshed.dryccapp.com. finest-woodshed.dryccapp.com. 270 IN A 172.17.8.100 Note Setting a CNAME for a root domain can cause issues. Setting an @ record to be a CNAME causes all traffic to go to the other domain, including mail and the SOA (\"start-of-authority\") records. It is highly recommended that you bind a subdomain to an application, however you can work around this by pointing the @ record to the address of the load balancer (if any). To add or remove the application from the routing mesh, use drycc routing : $ drycc routing:disable Disabling routing for finest-woodshed... done This will make the application unreachable through the Router , but the application is still reachable internally through its Kubernetes Service . To re-enable routing: $ drycc routing:enable Enabling routing for finest-woodshed... done","title":"Domains and Routing"},{"location":"applications/inter-app-communication/","text":"Inter-app Communication \u00b6 A common architecture pattern of multi-process applications is to have one process serve public requests while having multiple other processes supporting the public one to, for example, perform actions on a schedule or process work items from a queue. To implement this system of apps in Drycc Workflow, set up the apps to communicate using DNS resolution, as shown above, and hide the supporting processes from public view by removing them from the Drycc Workflow router. See Drycc Blog: Private Applications on Workflow for more details, which walks through an example of removing an app from the router. DNS Service Discovery \u00b6 Drycc Workflow supports deploying a single app composed of a system of processes. Each Drycc Workflow app communicates on a single port, so communicating with another Workflow app means finding that app's address and port. All Workflow apps are mapped to port 80 externally, so finding its IP address is the only challenge. Workflow creates a Kubernetes Service for each app, which effectively assigns a name and one cluster-internal IP address to an app. The DNS service running in the cluster adds and removes DNS records which point from the app name to its IP address as services are added and removed. Drycc Workflow apps, then, can simply send requests to the domain name given to the service, which is \"app-name.app-namespace\".","title":"Inter-app Communication"},{"location":"applications/inter-app-communication/#inter-app-communication","text":"A common architecture pattern of multi-process applications is to have one process serve public requests while having multiple other processes supporting the public one to, for example, perform actions on a schedule or process work items from a queue. To implement this system of apps in Drycc Workflow, set up the apps to communicate using DNS resolution, as shown above, and hide the supporting processes from public view by removing them from the Drycc Workflow router. See Drycc Blog: Private Applications on Workflow for more details, which walks through an example of removing an app from the router.","title":"Inter-app Communication"},{"location":"applications/inter-app-communication/#dns-service-discovery","text":"Drycc Workflow supports deploying a single app composed of a system of processes. Each Drycc Workflow app communicates on a single port, so communicating with another Workflow app means finding that app's address and port. All Workflow apps are mapped to port 80 externally, so finding its IP address is the only challenge. Workflow creates a Kubernetes Service for each app, which effectively assigns a name and one cluster-internal IP address to an app. The DNS service running in the cluster adds and removes DNS records which point from the app name to its IP address as services are added and removed. Drycc Workflow apps, then, can simply send requests to the domain name given to the service, which is \"app-name.app-namespace\".","title":"DNS Service Discovery"},{"location":"applications/managing-app-configuration/","text":"Configuring an Application \u00b6 A Drycc application stores config in environment variables . Setting Environment Variables \u00b6 Use drycc config to modify environment variables for a deployed application. $ drycc help config Valid commands for config: config:list list environment variables for an app config:set set environment variables for an app config:unset unset environment variables for an app config:pull extract environment variables to .env config:push set environment variables from .env Use `drycc help [command]` to learn more. When config is changed, a new release is created and deployed automatically. You can set multiple environment variables with one drycc config:set command, or with drycc config:push and a local .env file. $ drycc config:set FOO=1 BAR=baz && drycc config:pull $ cat .env FOO=1 BAR=baz $ echo \"TIDE=high\" >> .env $ drycc config:push Creating config... done, v4 === yuppie-earthman DRYCC_APP: yuppie-earthman FOO: 1 BAR: baz TIDE: high Attach to Backing Services \u00b6 Drycc treats backing services like databases, caches and queues as attached resources . Attachments are performed using environment variables. For example, use drycc config to set a DATABASE_URL that attaches the application to an external PostgreSQL database. $ drycc config:set DATABASE_URL=postgres://user:pass@example.com:5432/db === peachy-waxworks DATABASE_URL: postgres://user:pass@example.com:5432/db Detachments can be performed with drycc config:unset . Slugbuilder Cache \u00b6 By default, apps using the Slugbuilder will have caching turned on. This means that Drycc will persist all data being written to CACHE_DIR inside the buildpack will be persisted between deploys. When deploying applications that depend on third-party libraries that have to be fetched, this could speed up deployments a lot. In order to make use of this, the buildpack must implement the cache by writing to the cache directory. Most buildpacks already implement this, but when using custom buildpacks, it might need to be changed to make full use of the cache. Disabling and re-enabling the cache \u00b6 In some cases, cache might not speed up your application. To disable caching, you can set the DRYCC_DISABLE_CACHE variable with drycc config:set DRYCC_DISABLE_CACHE=1 . When you disable the cache, Drycc will clear up files it created to store the cache. After having it turned off, run drycc config:unset DRYCC_DISABLE_CACHE to re-enable the cache. Clearing the cache \u00b6 Use the following procedure to clear the cache: $ drycc config:set DRYCC_DISABLE_CACHE=1 $ git commit --allow-empty -m \"Clearing Drycc cache\" $ git push drycc # (if you use a different remote, you should use your remote name) $ drycc config:unset DRYCC_DISABLE_CACHE Custom Health Checks \u00b6 By default, Workflow only checks that the application starts in their Container. If it is preferred to have Kubernetes respond to application health, a health check may be added by configuring a health check probe for the application. The health checks are implemented as Kubernetes container probes . A liveness and a readiness probe can be configured, and each probe can be of type httpGet , exec , or tcpSocket depending on the type of probe the container requires. A liveness probe is useful for applications running for long periods of time, eventually transitioning to broken states and cannot recover except by restarting them. Other times, a readiness probe is useful when the container is only temporarily unable to serve, and will recover on its own. In this case, if a container fails its readiness probe, the container will not be shut down, but rather the container will stop receiving incoming requests. httpGet probes are just as it sounds: it performs a HTTP GET operation on the Container. A response code inside the 200-399 range is considered a pass. exec probes run a command inside the Container to determine its health, such as cat /var/run/myapp.pid or a script that determines when the application is ready. An exit code of zero is considered a pass, while a non-zero status code is considered a fail. tcpSocket probes attempt to open a socket in the Container. The Container is only considered healthy if the check can establish a connection. tcpSocket probes accept a port number to perform the socket connection on the Container. Health checks can be configured on a per-proctype basis for each application using drycc healthchecks:set . If no type is mentioned then the health checks are applied to default proc types, web or cmd, whichever is present. To configure a httpGet liveness probe: $ drycc healthchecks:set liveness httpGet 80 --type cmd === peachy-waxworks Healthchecks cmd: Liveness -------- Initial Delay (seconds): 50 Timeout (seconds): 50 Period (seconds): 10 Success Threshold: 1 Failure Threshold: 3 Exec Probe: N/A HTTP GET Probe: Path=\"/\" Port=80 HTTPHeaders=[] TCP Socket Probe: N/A Readiness --------- No readiness probe configured. If the application relies on certain headers being set (such as the Host header) or a specific URL path relative to the root, you can also send specific HTTP headers: $ drycc healthchecks:set liveness httpGet 80 \\ --path /welcome/index.html \\ --headers \"X-Client-Version:v1.0,X-Foo:bar\" === peachy-waxworks Healthchecks web/cmd: Liveness -------- Initial Delay (seconds): 50 Timeout (seconds): 50 Period (seconds): 10 Success Threshold: 1 Failure Threshold: 3 Exec Probe: N/A HTTP GET Probe: Path=\"/welcome/index.html\" Port=80 HTTPHeaders=[X-Client-Version=v1.0] TCP Socket Probe: N/A Readiness --------- No readiness probe configured. To configure an exec readiness probe: $ drycc healthchecks:set readiness exec -- /bin/echo -n hello --type cmd === peachy-waxworks Healthchecks cmd: Liveness -------- No liveness probe configured. Readiness --------- Initial Delay (seconds): 50 Timeout (seconds): 50 Period (seconds): 10 Success Threshold: 1 Failure Threshold: 3 Exec Probe: Command=[/bin/echo -n hello] HTTP GET Probe: N/A TCP Socket Probe: N/A You can overwrite a probe by running drycc healthchecks:set again: $ drycc healthchecks:set readiness httpGet 80 --type cmd === peachy-waxworks Healthchecks cmd: Liveness -------- No liveness probe configured. Readiness --------- Initial Delay (seconds): 50 Timeout (seconds): 50 Period (seconds): 10 Success Threshold: 1 Failure Threshold: 3 Exec Probe: N/A HTTP GET Probe: Path=\"/\" Port=80 HTTPHeaders=[] TCP Socket Probe: N/A Configured health checks also modify the default application deploy behavior. When starting a new Pod, Workflow will wait for the health check to pass before moving onto the next Pod. Isolate the Application \u00b6 Workflow supports isolating applications onto a set of nodes using drycc tags . Note In order to use tags, you must first launch your cluster with the proper node labels. If you do not, tag commands will fail. Learn more by reading \"Assigning Pods to Nodes\" . Once your nodes are configured with appropriate label selectors, use drycc tags:set to restrict the application to those nodes: $ drycc tags:set environ=prod Applying tags... done, v4 environ prod","title":"Managing App Configuration"},{"location":"applications/managing-app-configuration/#configuring-an-application","text":"A Drycc application stores config in environment variables .","title":"Configuring an Application"},{"location":"applications/managing-app-configuration/#setting-environment-variables","text":"Use drycc config to modify environment variables for a deployed application. $ drycc help config Valid commands for config: config:list list environment variables for an app config:set set environment variables for an app config:unset unset environment variables for an app config:pull extract environment variables to .env config:push set environment variables from .env Use `drycc help [command]` to learn more. When config is changed, a new release is created and deployed automatically. You can set multiple environment variables with one drycc config:set command, or with drycc config:push and a local .env file. $ drycc config:set FOO=1 BAR=baz && drycc config:pull $ cat .env FOO=1 BAR=baz $ echo \"TIDE=high\" >> .env $ drycc config:push Creating config... done, v4 === yuppie-earthman DRYCC_APP: yuppie-earthman FOO: 1 BAR: baz TIDE: high","title":"Setting Environment Variables"},{"location":"applications/managing-app-configuration/#attach-to-backing-services","text":"Drycc treats backing services like databases, caches and queues as attached resources . Attachments are performed using environment variables. For example, use drycc config to set a DATABASE_URL that attaches the application to an external PostgreSQL database. $ drycc config:set DATABASE_URL=postgres://user:pass@example.com:5432/db === peachy-waxworks DATABASE_URL: postgres://user:pass@example.com:5432/db Detachments can be performed with drycc config:unset .","title":"Attach to Backing Services"},{"location":"applications/managing-app-configuration/#slugbuilder-cache","text":"By default, apps using the Slugbuilder will have caching turned on. This means that Drycc will persist all data being written to CACHE_DIR inside the buildpack will be persisted between deploys. When deploying applications that depend on third-party libraries that have to be fetched, this could speed up deployments a lot. In order to make use of this, the buildpack must implement the cache by writing to the cache directory. Most buildpacks already implement this, but when using custom buildpacks, it might need to be changed to make full use of the cache.","title":"Slugbuilder Cache"},{"location":"applications/managing-app-configuration/#disabling-and-re-enabling-the-cache","text":"In some cases, cache might not speed up your application. To disable caching, you can set the DRYCC_DISABLE_CACHE variable with drycc config:set DRYCC_DISABLE_CACHE=1 . When you disable the cache, Drycc will clear up files it created to store the cache. After having it turned off, run drycc config:unset DRYCC_DISABLE_CACHE to re-enable the cache.","title":"Disabling and re-enabling the cache"},{"location":"applications/managing-app-configuration/#clearing-the-cache","text":"Use the following procedure to clear the cache: $ drycc config:set DRYCC_DISABLE_CACHE=1 $ git commit --allow-empty -m \"Clearing Drycc cache\" $ git push drycc # (if you use a different remote, you should use your remote name) $ drycc config:unset DRYCC_DISABLE_CACHE","title":"Clearing the cache"},{"location":"applications/managing-app-configuration/#custom-health-checks","text":"By default, Workflow only checks that the application starts in their Container. If it is preferred to have Kubernetes respond to application health, a health check may be added by configuring a health check probe for the application. The health checks are implemented as Kubernetes container probes . A liveness and a readiness probe can be configured, and each probe can be of type httpGet , exec , or tcpSocket depending on the type of probe the container requires. A liveness probe is useful for applications running for long periods of time, eventually transitioning to broken states and cannot recover except by restarting them. Other times, a readiness probe is useful when the container is only temporarily unable to serve, and will recover on its own. In this case, if a container fails its readiness probe, the container will not be shut down, but rather the container will stop receiving incoming requests. httpGet probes are just as it sounds: it performs a HTTP GET operation on the Container. A response code inside the 200-399 range is considered a pass. exec probes run a command inside the Container to determine its health, such as cat /var/run/myapp.pid or a script that determines when the application is ready. An exit code of zero is considered a pass, while a non-zero status code is considered a fail. tcpSocket probes attempt to open a socket in the Container. The Container is only considered healthy if the check can establish a connection. tcpSocket probes accept a port number to perform the socket connection on the Container. Health checks can be configured on a per-proctype basis for each application using drycc healthchecks:set . If no type is mentioned then the health checks are applied to default proc types, web or cmd, whichever is present. To configure a httpGet liveness probe: $ drycc healthchecks:set liveness httpGet 80 --type cmd === peachy-waxworks Healthchecks cmd: Liveness -------- Initial Delay (seconds): 50 Timeout (seconds): 50 Period (seconds): 10 Success Threshold: 1 Failure Threshold: 3 Exec Probe: N/A HTTP GET Probe: Path=\"/\" Port=80 HTTPHeaders=[] TCP Socket Probe: N/A Readiness --------- No readiness probe configured. If the application relies on certain headers being set (such as the Host header) or a specific URL path relative to the root, you can also send specific HTTP headers: $ drycc healthchecks:set liveness httpGet 80 \\ --path /welcome/index.html \\ --headers \"X-Client-Version:v1.0,X-Foo:bar\" === peachy-waxworks Healthchecks web/cmd: Liveness -------- Initial Delay (seconds): 50 Timeout (seconds): 50 Period (seconds): 10 Success Threshold: 1 Failure Threshold: 3 Exec Probe: N/A HTTP GET Probe: Path=\"/welcome/index.html\" Port=80 HTTPHeaders=[X-Client-Version=v1.0] TCP Socket Probe: N/A Readiness --------- No readiness probe configured. To configure an exec readiness probe: $ drycc healthchecks:set readiness exec -- /bin/echo -n hello --type cmd === peachy-waxworks Healthchecks cmd: Liveness -------- No liveness probe configured. Readiness --------- Initial Delay (seconds): 50 Timeout (seconds): 50 Period (seconds): 10 Success Threshold: 1 Failure Threshold: 3 Exec Probe: Command=[/bin/echo -n hello] HTTP GET Probe: N/A TCP Socket Probe: N/A You can overwrite a probe by running drycc healthchecks:set again: $ drycc healthchecks:set readiness httpGet 80 --type cmd === peachy-waxworks Healthchecks cmd: Liveness -------- No liveness probe configured. Readiness --------- Initial Delay (seconds): 50 Timeout (seconds): 50 Period (seconds): 10 Success Threshold: 1 Failure Threshold: 3 Exec Probe: N/A HTTP GET Probe: Path=\"/\" Port=80 HTTPHeaders=[] TCP Socket Probe: N/A Configured health checks also modify the default application deploy behavior. When starting a new Pod, Workflow will wait for the health check to pass before moving onto the next Pod.","title":"Custom Health Checks"},{"location":"applications/managing-app-configuration/#isolate-the-application","text":"Workflow supports isolating applications onto a set of nodes using drycc tags . Note In order to use tags, you must first launch your cluster with the proper node labels. If you do not, tag commands will fail. Learn more by reading \"Assigning Pods to Nodes\" . Once your nodes are configured with appropriate label selectors, use drycc tags:set to restrict the application to those nodes: $ drycc tags:set environ=prod Applying tags... done, v4 environ prod","title":"Isolate the Application"},{"location":"applications/managing-app-lifecycle/","text":"Managing an Application \u00b6 Track Application Changes \u00b6 Drycc Workflow tracks all changes to your application. Application changes are the result of either new application code pushed to the platform (via git push drycc master ), or an update to application configuration (via drycc config:set KEY=VAL ). Each time a build or config change is made to your application a new release is created. These release numbers increase monotonically. You can see a record of changes to your application using drycc releases : $ drycc releases === peachy-waxworks Releases v4 3 minutes ago gabrtv deployed d3ccc05 v3 1 hour 17 minutes ago gabrtv added DATABASE_URL v2 6 hours 2 minutes ago gabrtv deployed 7cb3321 v1 6 hours 2 minutes ago gabrtv deployed drycc/helloworld Rollback a Release \u00b6 Drycc Workflow also supports rolling back go previous releases. If buggy code or an errant configuration change is pushed to your application, you may rollback to a previously known, good release. Note All rollbacks create a new, numbered release. But will reference the build/code and configuration from the desired rollback point. In this example, the application is currently running release v4. Using drycc rollback v2 tells Workflow to deploy the build and configuration that was used for release v2. This creates a new release named v5 whose contents are the source and configuration from release v2: $ drycc releases === folksy-offshoot Releases v4 4 minutes ago gabrtv deployed d3ccc05 v3 1 hour 18 minutes ago gabrtv added DATABASE_URL v2 6 hours 2 minutes ago gabrtv deployed 7cb3321 v1 6 hours 3 minutes ago gabrtv deployed drycc/helloworld $ drycc rollback v2 Rolled back to v2 $ drycc releases === folksy-offshoot Releases v5 Just now gabrtv rolled back to v2 v4 4 minutes ago gabrtv deployed d3ccc05 v3 1 hour 18 minutes ago gabrtv added DATABASE_URL v2 6 hours 2 minutes ago gabrtv deployed 7cb3321 v1 6 hours 3 minutes ago gabrtv deployed drycc/helloworld Run One-off Administration Tasks \u00b6 Drycc applications use one-off processes for admin tasks like database migrations and other commands that must run against the live application. Use drycc run to execute commands on the deployed application. $ drycc run 'ls -l' Running `ls -l`... total 28 -rw-r--r-- 1 root root 553 Dec 2 23:59 LICENSE -rw-r--r-- 1 root root 60 Dec 2 23:59 Procfile -rw-r--r-- 1 root root 33 Dec 2 23:59 README.md -rw-r--r-- 1 root root 1622 Dec 2 23:59 pom.xml drwxr-xr-x 3 root root 4096 Dec 2 23:59 src -rw-r--r-- 1 root root 25 Dec 2 23:59 system.properties drwxr-xr-x 6 root root 4096 Dec 3 00:00 target Share an Application \u00b6 Use drycc perms:create to allow another Drycc user to collaborate on your application. $ drycc perms:create otheruser Adding otheruser to peachy-waxworks collaborators... done Use drycc perms to see who an application is currently shared with, and drycc perms:remove to remove a collaborator. Note Collaborators can do anything with an application that its owner can do, except delete the application. When working with an application that has been shared with you, clone the original repository and add Drycc' git remote entry before attempting to git push any changes to Drycc. $ git clone https://github.com/drycc/example-java-jetty.git Cloning into 'example-java-jetty'... done $ cd example-java-jetty $ git remote add -f drycc ssh://git@local3.dryccapp.com:2222/peachy-waxworks.git Updating drycc From drycc-controller.local:peachy-waxworks * [new branch] master -> drycc/master Application Troubleshooting \u00b6 Applications deployed on Drycc Workflow treat logs as event streams . Drycc Workflow aggregates stdout and stderr from every Container making it easy to troubleshoot problems with your application. Use drycc logs to view the log output from your deployed application. $ drycc logs | tail Dec 3 00:30:31 ip-10-250-15-201 peachy-waxworks[web.5]: INFO:oejsh.ContextHandler:started o.e.j.s.ServletContextHandler{/,null} Dec 3 00:30:31 ip-10-250-15-201 peachy-waxworks[web.8]: INFO:oejs.Server:jetty-7.6.0.v20120127 Dec 3 00:30:31 ip-10-250-15-201 peachy-waxworks[web.5]: INFO:oejs.AbstractConnector:Started SelectChannelConnector@0.0.0.0:10005 Dec 3 00:30:31 ip-10-250-15-201 peachy-waxworks[web.6]: INFO:oejsh.ContextHandler:started o.e.j.s.ServletContextHandler{/,null} Dec 3 00:30:31 ip-10-250-15-201 peachy-waxworks[web.7]: INFO:oejsh.ContextHandler:started o.e.j.s.ServletContextHandler{/,null} Dec 3 00:30:31 ip-10-250-15-201 peachy-waxworks[web.6]: INFO:oejs.AbstractConnector:Started SelectChannelConnector@0.0.0.0:10006 Dec 3 00:30:31 ip-10-250-15-201 peachy-waxworks[web.8]: INFO:oejsh.ContextHandler:started o.e.j.s.ServletContextHandler{/,null} Dec 3 00:30:31 ip-10-250-15-201 peachy-waxworks[web.7]: INFO:oejs.AbstractConnector:Started SelectChannelConnector@0.0.0.0:10007 Dec 3 00:30:31 ip-10-250-15-201 peachy-waxworks[web.8]: INFO:oejs.AbstractConnector:Started SelectChannelConnector@0.0.0.0:10008","title":"Managing App Lifecycle"},{"location":"applications/managing-app-lifecycle/#managing-an-application","text":"","title":"Managing an Application"},{"location":"applications/managing-app-lifecycle/#track-application-changes","text":"Drycc Workflow tracks all changes to your application. Application changes are the result of either new application code pushed to the platform (via git push drycc master ), or an update to application configuration (via drycc config:set KEY=VAL ). Each time a build or config change is made to your application a new release is created. These release numbers increase monotonically. You can see a record of changes to your application using drycc releases : $ drycc releases === peachy-waxworks Releases v4 3 minutes ago gabrtv deployed d3ccc05 v3 1 hour 17 minutes ago gabrtv added DATABASE_URL v2 6 hours 2 minutes ago gabrtv deployed 7cb3321 v1 6 hours 2 minutes ago gabrtv deployed drycc/helloworld","title":"Track Application Changes"},{"location":"applications/managing-app-lifecycle/#rollback-a-release","text":"Drycc Workflow also supports rolling back go previous releases. If buggy code or an errant configuration change is pushed to your application, you may rollback to a previously known, good release. Note All rollbacks create a new, numbered release. But will reference the build/code and configuration from the desired rollback point. In this example, the application is currently running release v4. Using drycc rollback v2 tells Workflow to deploy the build and configuration that was used for release v2. This creates a new release named v5 whose contents are the source and configuration from release v2: $ drycc releases === folksy-offshoot Releases v4 4 minutes ago gabrtv deployed d3ccc05 v3 1 hour 18 minutes ago gabrtv added DATABASE_URL v2 6 hours 2 minutes ago gabrtv deployed 7cb3321 v1 6 hours 3 minutes ago gabrtv deployed drycc/helloworld $ drycc rollback v2 Rolled back to v2 $ drycc releases === folksy-offshoot Releases v5 Just now gabrtv rolled back to v2 v4 4 minutes ago gabrtv deployed d3ccc05 v3 1 hour 18 minutes ago gabrtv added DATABASE_URL v2 6 hours 2 minutes ago gabrtv deployed 7cb3321 v1 6 hours 3 minutes ago gabrtv deployed drycc/helloworld","title":"Rollback a Release"},{"location":"applications/managing-app-lifecycle/#run-one-off-administration-tasks","text":"Drycc applications use one-off processes for admin tasks like database migrations and other commands that must run against the live application. Use drycc run to execute commands on the deployed application. $ drycc run 'ls -l' Running `ls -l`... total 28 -rw-r--r-- 1 root root 553 Dec 2 23:59 LICENSE -rw-r--r-- 1 root root 60 Dec 2 23:59 Procfile -rw-r--r-- 1 root root 33 Dec 2 23:59 README.md -rw-r--r-- 1 root root 1622 Dec 2 23:59 pom.xml drwxr-xr-x 3 root root 4096 Dec 2 23:59 src -rw-r--r-- 1 root root 25 Dec 2 23:59 system.properties drwxr-xr-x 6 root root 4096 Dec 3 00:00 target","title":"Run One-off Administration Tasks"},{"location":"applications/managing-app-lifecycle/#share-an-application","text":"Use drycc perms:create to allow another Drycc user to collaborate on your application. $ drycc perms:create otheruser Adding otheruser to peachy-waxworks collaborators... done Use drycc perms to see who an application is currently shared with, and drycc perms:remove to remove a collaborator. Note Collaborators can do anything with an application that its owner can do, except delete the application. When working with an application that has been shared with you, clone the original repository and add Drycc' git remote entry before attempting to git push any changes to Drycc. $ git clone https://github.com/drycc/example-java-jetty.git Cloning into 'example-java-jetty'... done $ cd example-java-jetty $ git remote add -f drycc ssh://git@local3.dryccapp.com:2222/peachy-waxworks.git Updating drycc From drycc-controller.local:peachy-waxworks * [new branch] master -> drycc/master","title":"Share an Application"},{"location":"applications/managing-app-lifecycle/#application-troubleshooting","text":"Applications deployed on Drycc Workflow treat logs as event streams . Drycc Workflow aggregates stdout and stderr from every Container making it easy to troubleshoot problems with your application. Use drycc logs to view the log output from your deployed application. $ drycc logs | tail Dec 3 00:30:31 ip-10-250-15-201 peachy-waxworks[web.5]: INFO:oejsh.ContextHandler:started o.e.j.s.ServletContextHandler{/,null} Dec 3 00:30:31 ip-10-250-15-201 peachy-waxworks[web.8]: INFO:oejs.Server:jetty-7.6.0.v20120127 Dec 3 00:30:31 ip-10-250-15-201 peachy-waxworks[web.5]: INFO:oejs.AbstractConnector:Started SelectChannelConnector@0.0.0.0:10005 Dec 3 00:30:31 ip-10-250-15-201 peachy-waxworks[web.6]: INFO:oejsh.ContextHandler:started o.e.j.s.ServletContextHandler{/,null} Dec 3 00:30:31 ip-10-250-15-201 peachy-waxworks[web.7]: INFO:oejsh.ContextHandler:started o.e.j.s.ServletContextHandler{/,null} Dec 3 00:30:31 ip-10-250-15-201 peachy-waxworks[web.6]: INFO:oejs.AbstractConnector:Started SelectChannelConnector@0.0.0.0:10006 Dec 3 00:30:31 ip-10-250-15-201 peachy-waxworks[web.8]: INFO:oejsh.ContextHandler:started o.e.j.s.ServletContextHandler{/,null} Dec 3 00:30:31 ip-10-250-15-201 peachy-waxworks[web.7]: INFO:oejs.AbstractConnector:Started SelectChannelConnector@0.0.0.0:10007 Dec 3 00:30:31 ip-10-250-15-201 peachy-waxworks[web.8]: INFO:oejs.AbstractConnector:Started SelectChannelConnector@0.0.0.0:10008","title":"Application Troubleshooting"},{"location":"applications/managing-app-processes/","text":"Managing Application Processes \u00b6 Drycc Workflow manages your application as a set of processes that can be named, scaled and configured according to their role. This gives you the flexibility to easily manage the different facets of your application. For example, you may have web-facing processes that handle HTTP traffic, background worker processes that do async work, and a helper process that streams from the Twitter API. By using a Procfile, either checked in to your application or provided via the CLI you can specify the name of the type and the application command that should run. To spawn other process types, use drycc scale <type>=<n> to scale those types accordingly. Default Process Types \u00b6 In the absence of a Procfile, a single, default process type is assumed for each application. Applications built using Buildpacks via git push implicitly receive a web process type, which starts the application server. Rails 4, for example, has the following process type: web: bundle exec rails server -p $PORT All applications utilizing Dockerfiles have an implied cmd process type, which runs the Dockerfile's CMD directive unmodified: $ cat Dockerfile FROM centos:latest COPY . /app WORKDIR /app CMD python -m SimpleHTTPServer 5000 EXPOSE 5000 For the above Dockerfile-based application, the cmd process type would run the Docker CMD of python -m SimpleHTTPServer 5000 . Applications utilizing remote Docker images , a cmd process type is also implied, and runs the CMD specified in the Docker image. Note The web and cmd process types are special as they\u2019re the only process types that will receive HTTP traffic from Workflow\u2019s routers. Other process types can be named arbitrarily. Declaring Process Types \u00b6 If you use Buildpack or Dockerfile builds and want to override or specify additional process types, simply include a file named Procfile in the root of your application's source tree. The format of a Procfile is one process type per line, with each line containing the command to invoke: <process type>: <command> The syntax is defined as: <process type> \u2013 a lowercase alphanumeric string, is a name for your command, such as web, worker, urgentworker, clock, etc. <command> \u2013 a command line to launch the process, such as rake jobs:work . This example Procfile specifies two types, web and sleeper . The web process launches a web server on port 5000 and a simple process which sleeps for 900 seconds and exits. $ cat Procfile web: bundle exec ruby web.rb -p ${PORT:-5000} sleeper: sleep 900 If you are using remote Docker images , you may define process types by either running drycc pull with a Procfile in your working directory, or by passing a stringified Procfile to the --procfile CLI option. For example, passing process types inline: $ drycc pull drycc/example-go:latest --procfile=\"cmd: /app/bin/boot\" Read a Procfile in another directory: $ drycc pull drycc/example-go:latest --procfile=\"$(cat deploy/Procfile)\" Or via a Procfile located in your current, working directory: $ cat Procfile cmd: /bin/boot sleeper: echo \"sleeping\"; sleep 900 $ drycc pull -a steely-mainsail drycc/example-go Creating build... done $ drycc scale sleeper=1 -a steely-mainsail Scaling processes... but first, coffee! done in 0s === steely-mainsail Processes --- cmd (started): 1 steely-mainsail-cmd-3291896318-nyrim up (v3) --- sleeper (started): 1 steely-mainsail-sleeper-3291896318-oq1jr up (v3) Note Only process types of web and cmd will be scaled to 1 automatically. If you have additional process types remember to scale the process counts after creation. To remove a process type simply scale it to 0: $ drycc scale sleeper=0 -a steely-mainsail Scaling processes... but first, coffee! done in 3s === steely-mainsail Processes --- cmd (started): 1 steely-mainsail-cmd-3291896318-nyrim up (v3) --- sleeper (started): 0 Scaling Processes \u00b6 Applications deployed on Drycc Workflow scale out via the process model . Use drycc scale to control the number of containers that power your app. $ drycc scale cmd=5 -a iciest-waggoner Scaling processes... but first, coffee! done in 3s === iciest-waggoner Processes --- cmd (started): 5 iciest-waggoner-web-3291896318-09j0o up (v2) iciest-waggoner-web-3291896318-3r7kp up (v2) iciest-waggoner-web-3291896318-gc4xv up (v2) iciest-waggoner-web-3291896318-lviwo up (v2) iciest-waggoner-web-3291896318-kt7vu up (v2) If you have multiple process types for your application you may scale the process count for each type separately. For example, this allows you to manage web process independently from background workers. For more information on process types see our documentation for Managing App Processes . In this example, we are scaling the process type web to 5 but leaving the process type background with one worker. $ drycc scale web=5 Scaling processes... but first, coffee! done in 4s === scenic-icehouse Processes --- web (started): 5 scenic-icehouse-web-3291896318-7lord up (v2) scenic-icehouse-web-3291896318-jn957 up (v2) scenic-icehouse-web-3291896318-rsekj up (v2) scenic-icehouse-web-3291896318-vwhnh up (v2) scenic-icehouse-web-3291896318-vokg7 up (v2) --- background (started): 1 scenic-icehouse-web-3291896318-background-yf8kh up (v2) Note The default process type for Dockerfile and Docker Image applications is 'cmd' rather than 'web'. Scaling a process down, by reducing the process count, sends a TERM signal to the processes, followed by a SIGKILL if they have not exited within 30 seconds. Depending on your application, scaling down may interrupt long-running HTTP client connections. For example, scaling from 5 processes to 3: $ drycc scale web=3 Scaling processes... but first, coffee! done in 1s === scenic-icehouse Processes --- background (started): 1 scenic-icehouse-web-3291896318-background-yf8kh up (v2) --- web (started): 3 scenic-icehouse-web-3291896318-7lord up (v2) scenic-icehouse-web-3291896318-rsekj up (v2) scenic-icehouse-web-3291896318-vokg7 up (v2) Stop or Start Processes \u00b6 Applications deployed on Drycc Workflow,we can stop or start processes via the process model . Use drycc ps:stop to stop the processes, and drycc ps:start to start the processes $ drycc ps -a echoed-lollipop === echoed-lollipop Processes --- background (started): 1 echoed-lollipop-background-794c749dc4-yf8kh up (v2) --- web (started): 3 echoed-lollipop-web-67cfc78bdc-7lord up (v2) echoed-lollipop-web-67cfc78bdc-rsekj up (v2) echoed-lollipop-web-67cfc78bdc-vokg7 up (v2) In this example, we are stopping the process type background and web . $ drycc ps:stop background web -a echoed-lollipop Scaling processes... but first, coffee! done in 3s === echoed-lollipop Processes --- background (stopped): 1 --- web (stopped): 3 In this example, we are starting the process web , and keep the process background stopping. $ drycc ps:start web Scaling processes... but first, coffee! done in 4s === echoed-lollipop Processes --- background (stopped): 1 --- web (started): 3 echoed-lollipop-web-67cfc78bdc-4z2hw up (v2) echoed-lollipop-web-67cfc78bdc-fdx4n up (v2) echoed-lollipop-web-67cfc78bdc-h2vxf up (v2) Autoscale \u00b6 Autoscale allows adding a minimum and maximum number of pods on a per process type basis. This is accomplished by specifying a target CPU usage across all available pods. This feature is built on top of Horizontal Pod Autoscaling in Kubernetes or HPA for short. Note This is an alpha feature. It is recommended to be on the latest Kubernetes when using this feature. $ drycc autoscale:set web --min=3 --max=8 --cpu-percent=75 Applying autoscale settings for process type web on scenic-icehouse... done And then review the scaling rule that was created for web $ drycc autoscale:list === scenic-icehouse Autoscale --- web: Min Replicas: 3 Max Replicas: 8 CPU: 75% Remove scaling rule $ drycc autoscale:unset web Removing autoscale for process type web on scenic-icehouse... done For autoscaling to work CPU requests have to be specified on each application Pod (can be done via drycc limits --cpu ). This allows the autoscale policies to do the appropriate calculations and make decisions on when to scale up and down. Scale up can only happen if there was no rescaling within the last 3 minutes. Scale down will wait for 5 minutes from the last rescaling. That information and more can be found at HPA algorithm page . Web vs Cmd Process Types \u00b6 When deploying to Drycc Workflow using a Heroku Buildpack, Workflow boots the web process type to boot the application server. When you deploy an application that has a Dockerfile or uses Docker images , Workflow boots the cmd process type. Both act similarly in that they are exposed to the router as web applications. However, the cmd process type is special because, if left undefined, it is equivalent to running the container without any additional arguments. (i.e. The process specified by the Dockerfile or Docker image's CMD directive will be used.) If migrating an application from Heroku Buildpacks to a Docker-based deployment, Workflow will not automatically convert the web process type to cmd . To do this, you'll have to manually scale down the old process type and scale the new process type up. Restarting an Application Processes \u00b6 If you need to restart an application process, you may use drycc ps:restart . Behind the scenes, Drycc Workflow instructs Kubernetes to terminate the old process and launch a new one in its place. $ drycc ps === scenic-icehouse Processes --- web (started): 3 scenic-icehouse-web-3291896318-7lord up (v2) scenic-icehouse-web-3291896318-rsekj up (v2) scenic-icehouse-web-3291896318-vokg7 up (v2) --- background (started): 1 scenic-icehouse-background-3291896318-yf8kh up (v2) $ drycc ps:restart scenic-icehouse-background-3291896318-yf8kh Restarting processes... but first, coffee! done in 6s === scenic-icehouse Processes --- background (started): 1 scenic-icehouse-background-3291896318-yd87g up (v2) Notice that the process name has changed from scenic-icehouse-background-3291896318-yf8kh to scenic-icehouse-background-3291896318-yd87g . In a multi-node Kubernetes cluster, this may also have the effect of scheduling the Pod to a new node.","title":"Managing App Processes"},{"location":"applications/managing-app-processes/#managing-application-processes","text":"Drycc Workflow manages your application as a set of processes that can be named, scaled and configured according to their role. This gives you the flexibility to easily manage the different facets of your application. For example, you may have web-facing processes that handle HTTP traffic, background worker processes that do async work, and a helper process that streams from the Twitter API. By using a Procfile, either checked in to your application or provided via the CLI you can specify the name of the type and the application command that should run. To spawn other process types, use drycc scale <type>=<n> to scale those types accordingly.","title":"Managing Application Processes"},{"location":"applications/managing-app-processes/#default-process-types","text":"In the absence of a Procfile, a single, default process type is assumed for each application. Applications built using Buildpacks via git push implicitly receive a web process type, which starts the application server. Rails 4, for example, has the following process type: web: bundle exec rails server -p $PORT All applications utilizing Dockerfiles have an implied cmd process type, which runs the Dockerfile's CMD directive unmodified: $ cat Dockerfile FROM centos:latest COPY . /app WORKDIR /app CMD python -m SimpleHTTPServer 5000 EXPOSE 5000 For the above Dockerfile-based application, the cmd process type would run the Docker CMD of python -m SimpleHTTPServer 5000 . Applications utilizing remote Docker images , a cmd process type is also implied, and runs the CMD specified in the Docker image. Note The web and cmd process types are special as they\u2019re the only process types that will receive HTTP traffic from Workflow\u2019s routers. Other process types can be named arbitrarily.","title":"Default Process Types"},{"location":"applications/managing-app-processes/#declaring-process-types","text":"If you use Buildpack or Dockerfile builds and want to override or specify additional process types, simply include a file named Procfile in the root of your application's source tree. The format of a Procfile is one process type per line, with each line containing the command to invoke: <process type>: <command> The syntax is defined as: <process type> \u2013 a lowercase alphanumeric string, is a name for your command, such as web, worker, urgentworker, clock, etc. <command> \u2013 a command line to launch the process, such as rake jobs:work . This example Procfile specifies two types, web and sleeper . The web process launches a web server on port 5000 and a simple process which sleeps for 900 seconds and exits. $ cat Procfile web: bundle exec ruby web.rb -p ${PORT:-5000} sleeper: sleep 900 If you are using remote Docker images , you may define process types by either running drycc pull with a Procfile in your working directory, or by passing a stringified Procfile to the --procfile CLI option. For example, passing process types inline: $ drycc pull drycc/example-go:latest --procfile=\"cmd: /app/bin/boot\" Read a Procfile in another directory: $ drycc pull drycc/example-go:latest --procfile=\"$(cat deploy/Procfile)\" Or via a Procfile located in your current, working directory: $ cat Procfile cmd: /bin/boot sleeper: echo \"sleeping\"; sleep 900 $ drycc pull -a steely-mainsail drycc/example-go Creating build... done $ drycc scale sleeper=1 -a steely-mainsail Scaling processes... but first, coffee! done in 0s === steely-mainsail Processes --- cmd (started): 1 steely-mainsail-cmd-3291896318-nyrim up (v3) --- sleeper (started): 1 steely-mainsail-sleeper-3291896318-oq1jr up (v3) Note Only process types of web and cmd will be scaled to 1 automatically. If you have additional process types remember to scale the process counts after creation. To remove a process type simply scale it to 0: $ drycc scale sleeper=0 -a steely-mainsail Scaling processes... but first, coffee! done in 3s === steely-mainsail Processes --- cmd (started): 1 steely-mainsail-cmd-3291896318-nyrim up (v3) --- sleeper (started): 0","title":"Declaring Process Types"},{"location":"applications/managing-app-processes/#scaling-processes","text":"Applications deployed on Drycc Workflow scale out via the process model . Use drycc scale to control the number of containers that power your app. $ drycc scale cmd=5 -a iciest-waggoner Scaling processes... but first, coffee! done in 3s === iciest-waggoner Processes --- cmd (started): 5 iciest-waggoner-web-3291896318-09j0o up (v2) iciest-waggoner-web-3291896318-3r7kp up (v2) iciest-waggoner-web-3291896318-gc4xv up (v2) iciest-waggoner-web-3291896318-lviwo up (v2) iciest-waggoner-web-3291896318-kt7vu up (v2) If you have multiple process types for your application you may scale the process count for each type separately. For example, this allows you to manage web process independently from background workers. For more information on process types see our documentation for Managing App Processes . In this example, we are scaling the process type web to 5 but leaving the process type background with one worker. $ drycc scale web=5 Scaling processes... but first, coffee! done in 4s === scenic-icehouse Processes --- web (started): 5 scenic-icehouse-web-3291896318-7lord up (v2) scenic-icehouse-web-3291896318-jn957 up (v2) scenic-icehouse-web-3291896318-rsekj up (v2) scenic-icehouse-web-3291896318-vwhnh up (v2) scenic-icehouse-web-3291896318-vokg7 up (v2) --- background (started): 1 scenic-icehouse-web-3291896318-background-yf8kh up (v2) Note The default process type for Dockerfile and Docker Image applications is 'cmd' rather than 'web'. Scaling a process down, by reducing the process count, sends a TERM signal to the processes, followed by a SIGKILL if they have not exited within 30 seconds. Depending on your application, scaling down may interrupt long-running HTTP client connections. For example, scaling from 5 processes to 3: $ drycc scale web=3 Scaling processes... but first, coffee! done in 1s === scenic-icehouse Processes --- background (started): 1 scenic-icehouse-web-3291896318-background-yf8kh up (v2) --- web (started): 3 scenic-icehouse-web-3291896318-7lord up (v2) scenic-icehouse-web-3291896318-rsekj up (v2) scenic-icehouse-web-3291896318-vokg7 up (v2)","title":"Scaling Processes"},{"location":"applications/managing-app-processes/#stop-or-start-processes","text":"Applications deployed on Drycc Workflow,we can stop or start processes via the process model . Use drycc ps:stop to stop the processes, and drycc ps:start to start the processes $ drycc ps -a echoed-lollipop === echoed-lollipop Processes --- background (started): 1 echoed-lollipop-background-794c749dc4-yf8kh up (v2) --- web (started): 3 echoed-lollipop-web-67cfc78bdc-7lord up (v2) echoed-lollipop-web-67cfc78bdc-rsekj up (v2) echoed-lollipop-web-67cfc78bdc-vokg7 up (v2) In this example, we are stopping the process type background and web . $ drycc ps:stop background web -a echoed-lollipop Scaling processes... but first, coffee! done in 3s === echoed-lollipop Processes --- background (stopped): 1 --- web (stopped): 3 In this example, we are starting the process web , and keep the process background stopping. $ drycc ps:start web Scaling processes... but first, coffee! done in 4s === echoed-lollipop Processes --- background (stopped): 1 --- web (started): 3 echoed-lollipop-web-67cfc78bdc-4z2hw up (v2) echoed-lollipop-web-67cfc78bdc-fdx4n up (v2) echoed-lollipop-web-67cfc78bdc-h2vxf up (v2)","title":"Stop or Start Processes"},{"location":"applications/managing-app-processes/#autoscale","text":"Autoscale allows adding a minimum and maximum number of pods on a per process type basis. This is accomplished by specifying a target CPU usage across all available pods. This feature is built on top of Horizontal Pod Autoscaling in Kubernetes or HPA for short. Note This is an alpha feature. It is recommended to be on the latest Kubernetes when using this feature. $ drycc autoscale:set web --min=3 --max=8 --cpu-percent=75 Applying autoscale settings for process type web on scenic-icehouse... done And then review the scaling rule that was created for web $ drycc autoscale:list === scenic-icehouse Autoscale --- web: Min Replicas: 3 Max Replicas: 8 CPU: 75% Remove scaling rule $ drycc autoscale:unset web Removing autoscale for process type web on scenic-icehouse... done For autoscaling to work CPU requests have to be specified on each application Pod (can be done via drycc limits --cpu ). This allows the autoscale policies to do the appropriate calculations and make decisions on when to scale up and down. Scale up can only happen if there was no rescaling within the last 3 minutes. Scale down will wait for 5 minutes from the last rescaling. That information and more can be found at HPA algorithm page .","title":"Autoscale"},{"location":"applications/managing-app-processes/#web-vs-cmd-process-types","text":"When deploying to Drycc Workflow using a Heroku Buildpack, Workflow boots the web process type to boot the application server. When you deploy an application that has a Dockerfile or uses Docker images , Workflow boots the cmd process type. Both act similarly in that they are exposed to the router as web applications. However, the cmd process type is special because, if left undefined, it is equivalent to running the container without any additional arguments. (i.e. The process specified by the Dockerfile or Docker image's CMD directive will be used.) If migrating an application from Heroku Buildpacks to a Docker-based deployment, Workflow will not automatically convert the web process type to cmd . To do this, you'll have to manually scale down the old process type and scale the new process type up.","title":"Web vs Cmd Process Types"},{"location":"applications/managing-app-processes/#restarting-an-application-processes","text":"If you need to restart an application process, you may use drycc ps:restart . Behind the scenes, Drycc Workflow instructs Kubernetes to terminate the old process and launch a new one in its place. $ drycc ps === scenic-icehouse Processes --- web (started): 3 scenic-icehouse-web-3291896318-7lord up (v2) scenic-icehouse-web-3291896318-rsekj up (v2) scenic-icehouse-web-3291896318-vokg7 up (v2) --- background (started): 1 scenic-icehouse-background-3291896318-yf8kh up (v2) $ drycc ps:restart scenic-icehouse-background-3291896318-yf8kh Restarting processes... but first, coffee! done in 6s === scenic-icehouse Processes --- background (started): 1 scenic-icehouse-background-3291896318-yd87g up (v2) Notice that the process name has changed from scenic-icehouse-background-3291896318-yf8kh to scenic-icehouse-background-3291896318-yd87g . In a multi-node Kubernetes cluster, this may also have the effect of scheduling the Pod to a new node.","title":"Restarting an Application Processes"},{"location":"applications/managing-app-resources/","text":"Managing resources for an Application \u00b6 We can use blow command to create resources and bind which resource is created. This command depend on service-catalog . Use drycc resources to create and bind a resource for a deployed application. $ drycc help resources Valid commands for resources: resources:create create a resource for the application resources:list list resources in the application resources:describe get a resource detail info in the application resources:update update a resource from the application resources:destroy delete a resource from the applicationa resources:bind bind a resource to servicebroker resources:unbind unbind a resource from servicebroker Use 'drycc help [command]' to learn more. Create resource in application \u00b6 You can create a resource with one drycc resources:create command $ drycc resources:create memcached:custom memcached Creating memcached to scenic-icehouse... done After resources are created, you can list the resources in this application. $ drycc resources:list === scenic-icehouse resources memcached memcached:custom Bind resources \u00b6 The resource which is named memcached is created, you can bind the memcached to the application, use the command of drycc resources:bind memcached . $ drycc resources:bind memcached Binding resource... done Describe resources \u00b6 And use drycc resources:describe show the binding detail. If the binding is successful, this command will show the information of connect to the resource. $ drycc resources:describe memcached === scenic-icehouse resource memcached plan: memcached:custom status: Ready binding: Ready HOST: 10.1.7.241 10.1.7.101 PORT: 11211 Update resources \u00b6 You can use the drycc resources:update command to upgrade a new plan. An example of how to upgrade the plan's capacity to 100MB: $ drycc resources:update memcached:100 memcached Updating memcached to scenic-icehouse... done Remove the resource \u00b6 If you don't need resources, use drycc resources:unbind to unbind the resource and then use drycc resources:destroy to delete the resource from the application. Before deleting the resource, the resource must be unbinded. $ drycc resources:unbind memcached Unbinding resource... done $ drycc resources:destroy memcached Deleting memcached from scenic-icehouse... done","title":"Managing App Resources"},{"location":"applications/managing-app-resources/#managing-resources-for-an-application","text":"We can use blow command to create resources and bind which resource is created. This command depend on service-catalog . Use drycc resources to create and bind a resource for a deployed application. $ drycc help resources Valid commands for resources: resources:create create a resource for the application resources:list list resources in the application resources:describe get a resource detail info in the application resources:update update a resource from the application resources:destroy delete a resource from the applicationa resources:bind bind a resource to servicebroker resources:unbind unbind a resource from servicebroker Use 'drycc help [command]' to learn more.","title":"Managing resources for an Application"},{"location":"applications/managing-app-resources/#create-resource-in-application","text":"You can create a resource with one drycc resources:create command $ drycc resources:create memcached:custom memcached Creating memcached to scenic-icehouse... done After resources are created, you can list the resources in this application. $ drycc resources:list === scenic-icehouse resources memcached memcached:custom","title":"Create resource in application"},{"location":"applications/managing-app-resources/#bind-resources","text":"The resource which is named memcached is created, you can bind the memcached to the application, use the command of drycc resources:bind memcached . $ drycc resources:bind memcached Binding resource... done","title":"Bind resources"},{"location":"applications/managing-app-resources/#describe-resources","text":"And use drycc resources:describe show the binding detail. If the binding is successful, this command will show the information of connect to the resource. $ drycc resources:describe memcached === scenic-icehouse resource memcached plan: memcached:custom status: Ready binding: Ready HOST: 10.1.7.241 10.1.7.101 PORT: 11211","title":"Describe resources"},{"location":"applications/managing-app-resources/#update-resources","text":"You can use the drycc resources:update command to upgrade a new plan. An example of how to upgrade the plan's capacity to 100MB: $ drycc resources:update memcached:100 memcached Updating memcached to scenic-icehouse... done","title":"Update resources"},{"location":"applications/managing-app-resources/#remove-the-resource","text":"If you don't need resources, use drycc resources:unbind to unbind the resource and then use drycc resources:destroy to delete the resource from the application. Before deleting the resource, the resource must be unbinded. $ drycc resources:unbind memcached Unbinding resource... done $ drycc resources:destroy memcached Deleting memcached from scenic-icehouse... done","title":"Remove the resource"},{"location":"applications/managing-app-volumes/","text":"Mounting volumes for an Application \u00b6 We can use the blow command to create volumes and mount the created volumes. Drycc create volume support ReadWriteMany , so before deploying drycc, you need to have a StorageClass ready which can support ReadWriteMany. Deploying drycc, set controller.app_storage_class to this StorageClass. Use drycc volumes to mount a volume for a deployed application's processes. $ drycc help volumes Valid commands for volumes: volumes:create create a volume for the application volumes:list list volumes in the application volumes:delete delete a volume from the application volumes:mount mount a volume to process of the application volumes:unmount unmount a volume from process of the application Use 'drycc help [command]' to learn more. Create a volume for the application \u00b6 You can create a volume with the drycc volumes:create command $ drycc volumes:create myvolume 200M Creating myvolumes to scenic-icehouse... done List volumes in the application \u00b6 After volume is created, you can list the volumes in this application. $ drycc volumes:list === scenic-icehouse volumes --- myvolumes 200M Mount a volume \u00b6 The volume which is named myvolumes is created, you can mount the volume with process of the application, use the command of drycc volumes:mount . When volume is mounted, a new release will be created and deployed automatically. $ drycc volumes:mount myvolumes web=/data/web Mounting volume... done And use drycc volumes:list show mount detail. $ drycc volumes:list === scenic-icehouse volumes --- myvolumes 200M web /data/web If you don't need the volume, use drycc volumes:unmount to unmount the volume and then use drycc volumes:delete to delete the volume from the application. Before deleting volume, the volume has to be unmounted. $ drycc volumes:unmount myvolumes web Unmounting volume... done $ drycc volumes:delete myvolumes Deleting myvolumes from scenic-icehouse... done","title":"Managing App Volumes"},{"location":"applications/managing-app-volumes/#mounting-volumes-for-an-application","text":"We can use the blow command to create volumes and mount the created volumes. Drycc create volume support ReadWriteMany , so before deploying drycc, you need to have a StorageClass ready which can support ReadWriteMany. Deploying drycc, set controller.app_storage_class to this StorageClass. Use drycc volumes to mount a volume for a deployed application's processes. $ drycc help volumes Valid commands for volumes: volumes:create create a volume for the application volumes:list list volumes in the application volumes:delete delete a volume from the application volumes:mount mount a volume to process of the application volumes:unmount unmount a volume from process of the application Use 'drycc help [command]' to learn more.","title":"Mounting volumes for an Application"},{"location":"applications/managing-app-volumes/#create-a-volume-for-the-application","text":"You can create a volume with the drycc volumes:create command $ drycc volumes:create myvolume 200M Creating myvolumes to scenic-icehouse... done","title":"Create a volume for the application"},{"location":"applications/managing-app-volumes/#list-volumes-in-the-application","text":"After volume is created, you can list the volumes in this application. $ drycc volumes:list === scenic-icehouse volumes --- myvolumes 200M","title":"List volumes in the application"},{"location":"applications/managing-app-volumes/#mount-a-volume","text":"The volume which is named myvolumes is created, you can mount the volume with process of the application, use the command of drycc volumes:mount . When volume is mounted, a new release will be created and deployed automatically. $ drycc volumes:mount myvolumes web=/data/web Mounting volume... done And use drycc volumes:list show mount detail. $ drycc volumes:list === scenic-icehouse volumes --- myvolumes 200M web /data/web If you don't need the volume, use drycc volumes:unmount to unmount the volume and then use drycc volumes:delete to delete the volume from the application. Before deleting volume, the volume has to be unmounted. $ drycc volumes:unmount myvolumes web Unmounting volume... done $ drycc volumes:delete myvolumes Deleting myvolumes from scenic-icehouse... done","title":"Mount a volume"},{"location":"applications/managing-resource-limits/","text":"Managing Application Resource Limits \u00b6 Drycc Workflow supports restricting memory and CPU shares of each process. Requests/Limits set on a per-process type are given to Kubernetes as a requests and limits. Which means you guarantee <requests> amount of resource for a process as well as limit the process from using more than <limits>. By default, Kubernetes will set <requests> equal to <limit> if we don't explicitly set <requests> value. Please keep in mind that 0 <= requests <= limits . Limiting Memory \u00b6 If you set a requests/limits that is out of range for your cluster, Kubernetes will be unable to schedule your application processes into the cluster! Available units for memory are: Unit Amount B Bytes K KiB (Power of 2) M MiB (Power of 2) G GiB (Power of 2) Important The minimum memory limit allowed is 4MiB. Use drycc limits:set <type>=<value> to restrict memory by process type, where value can be <limit> or <request>/<limit> format : $ drycc limits:set web=64M Applying limits... done === indoor-whitecap Limits --- Memory web 64M --- CPU Unlimited $ drycc limits:set cmd=32M/64M Applying limits... done === outdoor-whitecap Limits --- Memory cmd 32M/64M --- CPU Unlimited If you would like to remove any configured memory limits use drycc limits:unset web : $ drycc limits:unset web Applying limits... done === indoor-whitecap Limits --- Memory Unlimited --- CPU Unlimited Limiting CPU \u00b6 You can also use drycc limits:set <type>=<value> --cpu to restrict CPU shares, where value can be <limit> or <request>/<limit> format. CPU shares are tracked in milli-cores. One CPU core is equivalent to 1000 milli-cores. To dedicate half a core to your process, you would need 500 milli-cores or 500m. Unit Amount 1000m 1000 milli-cores == 100% CPU core 500m 500 milli-cores == 50% CPU core 250m 250 milli-cores == 25% CPU core 100m 100 milli-cores == 10% CPU core $ drycc limits:set web=250m --cpu Applying limits... done === indoor-whitecap Limits --- Memory web 64M --- CPU web 250m $ drycc limits:set web=1500m/2000m --cpu Applying limits... done === indoor-whitecap Limits --- Memory web 64M --- CPU web 1500m/2000m You can verify the CPU and memory limits by inspecting the application process Pod with kubectl : $ drycc ps === indoor-whitecap Processes --- web (started): 1 indoor-whitecap-v14-web-8slcj up (v14) $ kubectl --namespace=indoor-whitecap describe po indoor-whitecap-v14-web-8slcj Name: indoor-whitecap-v14-web-8slcj Containers: QoS Tier: cpu: Guaranteed memory: Guaranteed Limits: cpu: 2000m memory: 64Mi Requests: memory: 64Mi cpu: 1500m Important If you restrict resources to the point where containers do not start, the limits:set command will hang. If this happens, use CTRL-C to break out of limits:set and use limits:unset to revert. To unset a CPU limit use drycc limits:unset web --cpu : $ drycc limits:unset web --cpu Applying limits... done === indoor-whitecap Limits --- Memory Unlimited --- CPU Unlimited","title":"Resource Limits"},{"location":"applications/managing-resource-limits/#managing-application-resource-limits","text":"Drycc Workflow supports restricting memory and CPU shares of each process. Requests/Limits set on a per-process type are given to Kubernetes as a requests and limits. Which means you guarantee <requests> amount of resource for a process as well as limit the process from using more than <limits>. By default, Kubernetes will set <requests> equal to <limit> if we don't explicitly set <requests> value. Please keep in mind that 0 <= requests <= limits .","title":"Managing Application Resource Limits"},{"location":"applications/managing-resource-limits/#limiting-memory","text":"If you set a requests/limits that is out of range for your cluster, Kubernetes will be unable to schedule your application processes into the cluster! Available units for memory are: Unit Amount B Bytes K KiB (Power of 2) M MiB (Power of 2) G GiB (Power of 2) Important The minimum memory limit allowed is 4MiB. Use drycc limits:set <type>=<value> to restrict memory by process type, where value can be <limit> or <request>/<limit> format : $ drycc limits:set web=64M Applying limits... done === indoor-whitecap Limits --- Memory web 64M --- CPU Unlimited $ drycc limits:set cmd=32M/64M Applying limits... done === outdoor-whitecap Limits --- Memory cmd 32M/64M --- CPU Unlimited If you would like to remove any configured memory limits use drycc limits:unset web : $ drycc limits:unset web Applying limits... done === indoor-whitecap Limits --- Memory Unlimited --- CPU Unlimited","title":"Limiting Memory"},{"location":"applications/managing-resource-limits/#limiting-cpu","text":"You can also use drycc limits:set <type>=<value> --cpu to restrict CPU shares, where value can be <limit> or <request>/<limit> format. CPU shares are tracked in milli-cores. One CPU core is equivalent to 1000 milli-cores. To dedicate half a core to your process, you would need 500 milli-cores or 500m. Unit Amount 1000m 1000 milli-cores == 100% CPU core 500m 500 milli-cores == 50% CPU core 250m 250 milli-cores == 25% CPU core 100m 100 milli-cores == 10% CPU core $ drycc limits:set web=250m --cpu Applying limits... done === indoor-whitecap Limits --- Memory web 64M --- CPU web 250m $ drycc limits:set web=1500m/2000m --cpu Applying limits... done === indoor-whitecap Limits --- Memory web 64M --- CPU web 1500m/2000m You can verify the CPU and memory limits by inspecting the application process Pod with kubectl : $ drycc ps === indoor-whitecap Processes --- web (started): 1 indoor-whitecap-v14-web-8slcj up (v14) $ kubectl --namespace=indoor-whitecap describe po indoor-whitecap-v14-web-8slcj Name: indoor-whitecap-v14-web-8slcj Containers: QoS Tier: cpu: Guaranteed memory: Guaranteed Limits: cpu: 2000m memory: 64Mi Requests: memory: 64Mi cpu: 1500m Important If you restrict resources to the point where containers do not start, the limits:set command will hang. If this happens, use CTRL-C to break out of limits:set and use limits:unset to revert. To unset a CPU limit use drycc limits:unset web --cpu : $ drycc limits:unset web --cpu Applying limits... done === indoor-whitecap Limits --- Memory Unlimited --- CPU Unlimited","title":"Limiting CPU"},{"location":"applications/ssl-certificates/","text":"Application SSL Certificates \u00b6 SSL is a cryptographic protocol that provides end-to-end encryption and integrity for all web requests. Apps that transmit sensitive data should enable SSL to ensure all information is transmitted securely. To enable SSL on a custom domain, e.g., www.example.com , use the SSL endpoint. Note drycc certs is only useful for custom domains. Default application domains are SSL-enabled already and can be accessed simply by using https, e.g. https://foo.dryccapp.com (provided that you have installed your wildcard certificate on the routers or on the load balancer). Overview \u00b6 Because of the unique nature of SSL validation, provisioning SSL for your domain is a multi-step process that involves several third-parties. You will need to: Purchase an SSL certificate from your SSL provider Upload the cert to Drycc Acquire SSL Certificate \u00b6 Purchasing an SSL cert varies in cost and process depending on the vendor. RapidSSL offers a simple way to purchase a certificate and is a recommended solution. If you\u2019re able to use this provider, see buy an SSL certificate with RapidSSL for instructions. DNS and Domain Configuration \u00b6 Once the SSL certificate is provisioned and your cert is confirmed, you must route requests for your domain through Drycc. Unless you've already done so, add the domain specified when generating the CSR to your app with: $ drycc domains:add www.example.com -a foo Adding www.example.com to foo... done Add a Certificate \u00b6 Add your certificate, any intermediate certificates, and private key to the endpoint with the certs:add command. $ drycc certs:add example-com server.crt server.key Adding SSL endpoint... done www.example.com Note The name given to the certificate can only contain a-z (lowercase), 0-9 and hyphens The Drycc platform will investigate the certificate and extract any relevant information from it such as the Common Name, Subject Alt Names (SAN), fingerprint and more. This allows for wildcard certificates and multiple domains in the SAN without uploading duplicates. Add a Certificate Chain \u00b6 Sometimes, your certificates (such as a self-signed or a cheap certificate) need additional certificates to establish the chain of trust. What you need to do is bundle all the certificates into one file and give that to Drycc. Importantly, your site\u2019s certificate must be the first one: $ cat server.crt server.ca > server.bundle After that, you can add them to Drycc with the certs:add command: $ drycc certs:add example-com server.bundle server.key Adding SSL endpoint... done www.example.com Attach SSL certificate to a domain \u00b6 Certificates are not automagically connected up to domains, instead you will have to attach a certificate to a domain $ drycc certs:attach example-com example.com Each certificate can be connected to many domains. There is no need to upload duplicates. To remove an association $ drycc certs:detach example-com example.com Endpoint overview \u00b6 You can verify the details of your domain's SSL configuration with drycc certs . $ drycc certs Name | Common Name | SubjectAltName | Expires | Fingerprint | Domains | Updated | Created +-------------+-------------------+-------------------+-------------------------+-----------------+--------------+-------------+-------------+ example-com | example.com | blog.example.com | 31 Dec 2017 (in 1 year) | 8F:8E[...]CD:EB | example.com | 30 Jan 2016 | 29 Jan 2016 or by looking at at each certificates detailed information $ drycc certs:info example-com === bar-com Certificate Common Name(s): example.com Expires At: 2017-01-14 23:57:57 +0000 UTC Starts At: 2016-01-15 23:57:57 +0000 UTC Fingerprint: 7A:CA:B8:50:FF:8D:EB:03:3D:AC:AD:13:4F:EE:03:D5:5D:EB:5E:37:51:8C:E0:98:F8:1B:36:2B:20:83:0D:C0 Subject Alt Name: blog.example.com Issuer: /C=US/ST=CA/L=San Francisco/O=Drycc/OU=Engineering/CN=example.com/emailAddress=engineering@drycc.cc Subject: /C=US/ST=CA/L=San Francisco/O=Drycc/OU=Engineering/CN=example.com/emailAddress=engineering@drycc.cc Connected Domains: example.com Owner: admin-user Created: 2016-01-28 19:07:41 +0000 UTC Updated: 2016-01-30 00:10:02 +0000 UTC Testing SSL \u00b6 Use a command line utility like curl to test that everything is configured correctly for your secure domain. Note The -k option flag tells curl to ignore untrusted certificates. Pay attention to the output. It should print SSL certificate verify ok . If it prints something like common name: www.example.com (does not match 'www.somedomain.com') then something is not configured correctly. Enforcing SSL at the Router \u00b6 To enforce all HTTP requests be redirected to HTTPS, TLS can be enforced at the router level by running $ drycc tls:force:enable -a foo Enabling https-only requests for foo... done Users hitting the HTTP endpoint for the application will now receive a 301 redirect to the HTTPS endpoint. To disable enforced TLS, run $ drycc tls:force:disable -a foo Disabling https-only requests for foo... done Automated Certificate Management \u00b6 With Automated Certificate Management (ACM), Drycc automatically manages TLS certificates for apps with Hobby and Professional dynos on the Common Runtime, and for apps in Private Spaces that enable the feature. Certificates handled by ACM automatically renew one month before they expire, and new certificates are created automatically whenever you add or remove a custom domain. All applications with paid dynos include ACM for free. Automated Certificate Management uses Let\u2019s Encrypt, the free, automated, and open certificate authority for managing your application\u2019s TLS certificates. Let\u2019s Encrypt is run for the public benefit by the Internet Security Research Group (ISRG). To enable ACM with the following command: $ drycc tls:auto:enable -a foo To disable ACM with the following command: $ drycc tls:auto:disable -a foo Remove Certificate \u00b6 You can remove a certificate using the certs:remove command: $ drycc certs:remove my-cert Removing www.example.com... Done. Swapping out certificates \u00b6 Over the lifetime of an application an operator will have to acquire certificates with new expire dates and apply it to all relevant applications, below is the recommended way to swap out certificates. Be intentional with certificate names, name them example-com-2017 when possible, where the year signifies the expiry year. This allows for example-com-2018 when a new certificate is purchased. Assuming all applications are already using example-com-2017 the following commands can be ran, chained together or otherwise: $ drycc certs:detach example-com-2017 example.com $ drycc certs:attach example-com-2018 example.com This will take care of a singular domain which allows the operator to verify everything went as planned and slowly roll it out to any other application using the same method. Troubleshooting \u00b6 Here are some steps you can follow if your SSL endpoint is not working as you'd expect. Untrusted Certificate \u00b6 In some cases when accessing the SSL endpoint, it may list your certificate as untrusted. If this occurs, it may be because it is not trusted by Mozilla\u2019s list of root CAs . If this is the case, your certificate may be considered untrusted for many browsers. If you have uploaded a certificate that was signed by a root authority but you get the message that it is not trusted, then something is wrong with the certificate. For example, it may be missing intermediary certificates . If so, download the intermediary certificates from your SSL provider, remove the certificate from Drycc and re-run the certs:add command.","title":"SSL Certificates"},{"location":"applications/ssl-certificates/#application-ssl-certificates","text":"SSL is a cryptographic protocol that provides end-to-end encryption and integrity for all web requests. Apps that transmit sensitive data should enable SSL to ensure all information is transmitted securely. To enable SSL on a custom domain, e.g., www.example.com , use the SSL endpoint. Note drycc certs is only useful for custom domains. Default application domains are SSL-enabled already and can be accessed simply by using https, e.g. https://foo.dryccapp.com (provided that you have installed your wildcard certificate on the routers or on the load balancer).","title":"Application SSL Certificates"},{"location":"applications/ssl-certificates/#overview","text":"Because of the unique nature of SSL validation, provisioning SSL for your domain is a multi-step process that involves several third-parties. You will need to: Purchase an SSL certificate from your SSL provider Upload the cert to Drycc","title":"Overview"},{"location":"applications/ssl-certificates/#acquire-ssl-certificate","text":"Purchasing an SSL cert varies in cost and process depending on the vendor. RapidSSL offers a simple way to purchase a certificate and is a recommended solution. If you\u2019re able to use this provider, see buy an SSL certificate with RapidSSL for instructions.","title":"Acquire SSL Certificate"},{"location":"applications/ssl-certificates/#dns-and-domain-configuration","text":"Once the SSL certificate is provisioned and your cert is confirmed, you must route requests for your domain through Drycc. Unless you've already done so, add the domain specified when generating the CSR to your app with: $ drycc domains:add www.example.com -a foo Adding www.example.com to foo... done","title":"DNS and Domain Configuration"},{"location":"applications/ssl-certificates/#add-a-certificate","text":"Add your certificate, any intermediate certificates, and private key to the endpoint with the certs:add command. $ drycc certs:add example-com server.crt server.key Adding SSL endpoint... done www.example.com Note The name given to the certificate can only contain a-z (lowercase), 0-9 and hyphens The Drycc platform will investigate the certificate and extract any relevant information from it such as the Common Name, Subject Alt Names (SAN), fingerprint and more. This allows for wildcard certificates and multiple domains in the SAN without uploading duplicates.","title":"Add a Certificate"},{"location":"applications/ssl-certificates/#add-a-certificate-chain","text":"Sometimes, your certificates (such as a self-signed or a cheap certificate) need additional certificates to establish the chain of trust. What you need to do is bundle all the certificates into one file and give that to Drycc. Importantly, your site\u2019s certificate must be the first one: $ cat server.crt server.ca > server.bundle After that, you can add them to Drycc with the certs:add command: $ drycc certs:add example-com server.bundle server.key Adding SSL endpoint... done www.example.com","title":"Add a Certificate Chain"},{"location":"applications/ssl-certificates/#attach-ssl-certificate-to-a-domain","text":"Certificates are not automagically connected up to domains, instead you will have to attach a certificate to a domain $ drycc certs:attach example-com example.com Each certificate can be connected to many domains. There is no need to upload duplicates. To remove an association $ drycc certs:detach example-com example.com","title":"Attach SSL certificate to a domain"},{"location":"applications/ssl-certificates/#endpoint-overview","text":"You can verify the details of your domain's SSL configuration with drycc certs . $ drycc certs Name | Common Name | SubjectAltName | Expires | Fingerprint | Domains | Updated | Created +-------------+-------------------+-------------------+-------------------------+-----------------+--------------+-------------+-------------+ example-com | example.com | blog.example.com | 31 Dec 2017 (in 1 year) | 8F:8E[...]CD:EB | example.com | 30 Jan 2016 | 29 Jan 2016 or by looking at at each certificates detailed information $ drycc certs:info example-com === bar-com Certificate Common Name(s): example.com Expires At: 2017-01-14 23:57:57 +0000 UTC Starts At: 2016-01-15 23:57:57 +0000 UTC Fingerprint: 7A:CA:B8:50:FF:8D:EB:03:3D:AC:AD:13:4F:EE:03:D5:5D:EB:5E:37:51:8C:E0:98:F8:1B:36:2B:20:83:0D:C0 Subject Alt Name: blog.example.com Issuer: /C=US/ST=CA/L=San Francisco/O=Drycc/OU=Engineering/CN=example.com/emailAddress=engineering@drycc.cc Subject: /C=US/ST=CA/L=San Francisco/O=Drycc/OU=Engineering/CN=example.com/emailAddress=engineering@drycc.cc Connected Domains: example.com Owner: admin-user Created: 2016-01-28 19:07:41 +0000 UTC Updated: 2016-01-30 00:10:02 +0000 UTC","title":"Endpoint overview"},{"location":"applications/ssl-certificates/#testing-ssl","text":"Use a command line utility like curl to test that everything is configured correctly for your secure domain. Note The -k option flag tells curl to ignore untrusted certificates. Pay attention to the output. It should print SSL certificate verify ok . If it prints something like common name: www.example.com (does not match 'www.somedomain.com') then something is not configured correctly.","title":"Testing SSL"},{"location":"applications/ssl-certificates/#enforcing-ssl-at-the-router","text":"To enforce all HTTP requests be redirected to HTTPS, TLS can be enforced at the router level by running $ drycc tls:force:enable -a foo Enabling https-only requests for foo... done Users hitting the HTTP endpoint for the application will now receive a 301 redirect to the HTTPS endpoint. To disable enforced TLS, run $ drycc tls:force:disable -a foo Disabling https-only requests for foo... done","title":"Enforcing SSL at the Router"},{"location":"applications/ssl-certificates/#automated-certificate-management","text":"With Automated Certificate Management (ACM), Drycc automatically manages TLS certificates for apps with Hobby and Professional dynos on the Common Runtime, and for apps in Private Spaces that enable the feature. Certificates handled by ACM automatically renew one month before they expire, and new certificates are created automatically whenever you add or remove a custom domain. All applications with paid dynos include ACM for free. Automated Certificate Management uses Let\u2019s Encrypt, the free, automated, and open certificate authority for managing your application\u2019s TLS certificates. Let\u2019s Encrypt is run for the public benefit by the Internet Security Research Group (ISRG). To enable ACM with the following command: $ drycc tls:auto:enable -a foo To disable ACM with the following command: $ drycc tls:auto:disable -a foo","title":"Automated Certificate Management"},{"location":"applications/ssl-certificates/#remove-certificate","text":"You can remove a certificate using the certs:remove command: $ drycc certs:remove my-cert Removing www.example.com... Done.","title":"Remove Certificate"},{"location":"applications/ssl-certificates/#swapping-out-certificates","text":"Over the lifetime of an application an operator will have to acquire certificates with new expire dates and apply it to all relevant applications, below is the recommended way to swap out certificates. Be intentional with certificate names, name them example-com-2017 when possible, where the year signifies the expiry year. This allows for example-com-2018 when a new certificate is purchased. Assuming all applications are already using example-com-2017 the following commands can be ran, chained together or otherwise: $ drycc certs:detach example-com-2017 example.com $ drycc certs:attach example-com-2018 example.com This will take care of a singular domain which allows the operator to verify everything went as planned and slowly roll it out to any other application using the same method.","title":"Swapping out certificates"},{"location":"applications/ssl-certificates/#troubleshooting","text":"Here are some steps you can follow if your SSL endpoint is not working as you'd expect.","title":"Troubleshooting"},{"location":"applications/ssl-certificates/#untrusted-certificate","text":"In some cases when accessing the SSL endpoint, it may list your certificate as untrusted. If this occurs, it may be because it is not trusted by Mozilla\u2019s list of root CAs . If this is the case, your certificate may be considered untrusted for many browsers. If you have uploaded a certificate that was signed by a root authority but you get the message that it is not trusted, then something is wrong with the certificate. For example, it may be missing intermediary certificates . If so, download the intermediary certificates from your SSL provider, remove the certificate from Drycc and re-run the certs:add command.","title":"Untrusted Certificate"},{"location":"applications/using-buildpacks/","text":"Using Buildpacks \u00b6 Drycc supports deploying applications via Heroku Buildpacks . Buildpacks are useful if you're interested in following Heroku's best practices for building applications or if you are deploying an application that already runs on Heroku. Add SSH Key \u00b6 For Buildpack based application deploys via git push , Drycc Workflow identifies users via SSH keys. SSH keys are pushed to the platform and must be unique to each user. See this document for instructions on how to generate an SSH key. Run drycc keys:add to upload your SSH key to Drycc Workflow. $ drycc keys:add ~/.ssh/id_drycc.pub Uploading id_drycc.pub to drycc... done Read more about adding/removing SSH Keys here . Prepare an Application \u00b6 If you do not have an existing application, you can clone an example application that demonstrates the Heroku Buildpack workflow. $ git clone https://github.com/drycc/example-go.git $ cd example-go Create an Application \u00b6 Use drycc create to create an application on the Controller . $ drycc create Creating application... done, created skiing-keypunch Git remote drycc added Push to Deploy \u00b6 Use git push drycc master to deploy your application. $ git push drycc master Counting objects: 75, done. Delta compression using up to 8 threads. Compressing objects: 100% (48/48), done. Writing objects: 100% (75/75), 18.28 KiB | 0 bytes/s, done. Total 75 (delta 30), reused 58 (delta 22) Starting build... but first, coffee! -----> Go app detected -----> Checking Godeps/Godeps.json file. -----> Installing go1.4.2... done -----> Running: godep go install -tags heroku ./... -----> Discovering process types Procfile declares types -> web -----> Compiled slug size is 1.7M Build complete. Launching app. Launching... Done, skiing-keypunch:v2 deployed to Drycc Use 'drycc open' to view this application in your browser To learn more, use 'drycc help' or visit http://drycc.cc To ssh://git@drycc.staging-2.drycc.cc:2222/skiing-keypunch.git * [new branch] master -> master $ curl -s http://skiing-keypunch.example.com Powered by Drycc Release v2 on skiing-keypunch-v2-web-02zb9 Because a Heroku-style application is detected, the web process type is automatically scaled to 1 on first deploy. Use drycc scale web=3 to increase web processes to 3, for example. Scaling a process type directly changes the number of pods running that process. Included Buildpacks \u00b6 For convenience, a number of buildpacks come bundled with Drycc: Ruby Buildpack Nodejs Buildpack Java Buildpack Gradle Buildpack Grails Buildpack Play Buildpack Python Buildpack PHP Buildpack Clojure Buildpack Scala Buildpack Go Buildpack Multi Buildpack Drycc will cycle through the bin/detect script of each buildpack to match the code you are pushing. Note If you're testing against the Scala Buildpack , the Builder requires at least 512MB of free memory to execute the Scala Build Tool. Using a Custom Buildpack \u00b6 To use a custom buildpack, set the BUILDPACK_URL environment variable. $ drycc config:set BUILDPACK_URL=https://github.com/dpiddy/heroku-buildpack-ruby-minimal Creating config... done, v2 === humble-autoharp BUILDPACK_URL: https://github.com/dpiddy/heroku-buildpack-ruby-minimal Note If, however, you're unable to deploy using the latest version of the buildpack, You can set an exact version of a buildpack by using a git revision in your BUILDPACK_URL . For example: BUILDPACK_URL=https://github.com/dpiddy/heroku-buildpack-ruby-minimal#v13 On your next git push , the custom buildpack will be used. Compile Hooks \u00b6 Sometimes, an application needs a way to stop or check if a service is running before building an app, which may require notifying a service that the Builder has finished compiling the app. In order to do this, an app can provide two files in their bin/ directory: bin/pre-compile bin/post-compile The builder will run these commands before and after the build process, respectively. Using Private Repositories \u00b6 To pull code from private repositories, set the SSH_KEY environment variable to a private key which has access. Use either the path of a private key file or the raw key material: $ drycc config:set SSH_KEY=/home/user/.ssh/id_rsa $ drycc config:set SSH_KEY=\"\"\"-----BEGIN RSA PRIVATE KEY----- (...) -----END RSA PRIVATE KEY-----\"\"\" For example, to use a custom buildpack hosted at a private GitHub URL, ensure that an SSH public key exists in your GitHub settings . Then set SSH_KEY to the corresponding SSH private key and set BUILDPACK_URL to the URL: $ drycc config:set SSH_KEY=/home/user/.ssh/github_id_rsa $ drycc config:set BUILDPACK_URL=git@github.com:user/private_buildpack.git $ git push drycc master Builder selector \u00b6 Which way to build a project conforms to the following principles: If Dockerfile exists in the project, the stack uses container If Procfile exists in the project, the stack uses heroku-18 If both exist, container is used by default You can also set the DRYCC_STACK to determine which stack to use.","title":"Buildpacks"},{"location":"applications/using-buildpacks/#using-buildpacks","text":"Drycc supports deploying applications via Heroku Buildpacks . Buildpacks are useful if you're interested in following Heroku's best practices for building applications or if you are deploying an application that already runs on Heroku.","title":"Using Buildpacks"},{"location":"applications/using-buildpacks/#add-ssh-key","text":"For Buildpack based application deploys via git push , Drycc Workflow identifies users via SSH keys. SSH keys are pushed to the platform and must be unique to each user. See this document for instructions on how to generate an SSH key. Run drycc keys:add to upload your SSH key to Drycc Workflow. $ drycc keys:add ~/.ssh/id_drycc.pub Uploading id_drycc.pub to drycc... done Read more about adding/removing SSH Keys here .","title":"Add SSH Key"},{"location":"applications/using-buildpacks/#prepare-an-application","text":"If you do not have an existing application, you can clone an example application that demonstrates the Heroku Buildpack workflow. $ git clone https://github.com/drycc/example-go.git $ cd example-go","title":"Prepare an Application"},{"location":"applications/using-buildpacks/#create-an-application","text":"Use drycc create to create an application on the Controller . $ drycc create Creating application... done, created skiing-keypunch Git remote drycc added","title":"Create an Application"},{"location":"applications/using-buildpacks/#push-to-deploy","text":"Use git push drycc master to deploy your application. $ git push drycc master Counting objects: 75, done. Delta compression using up to 8 threads. Compressing objects: 100% (48/48), done. Writing objects: 100% (75/75), 18.28 KiB | 0 bytes/s, done. Total 75 (delta 30), reused 58 (delta 22) Starting build... but first, coffee! -----> Go app detected -----> Checking Godeps/Godeps.json file. -----> Installing go1.4.2... done -----> Running: godep go install -tags heroku ./... -----> Discovering process types Procfile declares types -> web -----> Compiled slug size is 1.7M Build complete. Launching app. Launching... Done, skiing-keypunch:v2 deployed to Drycc Use 'drycc open' to view this application in your browser To learn more, use 'drycc help' or visit http://drycc.cc To ssh://git@drycc.staging-2.drycc.cc:2222/skiing-keypunch.git * [new branch] master -> master $ curl -s http://skiing-keypunch.example.com Powered by Drycc Release v2 on skiing-keypunch-v2-web-02zb9 Because a Heroku-style application is detected, the web process type is automatically scaled to 1 on first deploy. Use drycc scale web=3 to increase web processes to 3, for example. Scaling a process type directly changes the number of pods running that process.","title":"Push to Deploy"},{"location":"applications/using-buildpacks/#included-buildpacks","text":"For convenience, a number of buildpacks come bundled with Drycc: Ruby Buildpack Nodejs Buildpack Java Buildpack Gradle Buildpack Grails Buildpack Play Buildpack Python Buildpack PHP Buildpack Clojure Buildpack Scala Buildpack Go Buildpack Multi Buildpack Drycc will cycle through the bin/detect script of each buildpack to match the code you are pushing. Note If you're testing against the Scala Buildpack , the Builder requires at least 512MB of free memory to execute the Scala Build Tool.","title":"Included Buildpacks"},{"location":"applications/using-buildpacks/#using-a-custom-buildpack","text":"To use a custom buildpack, set the BUILDPACK_URL environment variable. $ drycc config:set BUILDPACK_URL=https://github.com/dpiddy/heroku-buildpack-ruby-minimal Creating config... done, v2 === humble-autoharp BUILDPACK_URL: https://github.com/dpiddy/heroku-buildpack-ruby-minimal Note If, however, you're unable to deploy using the latest version of the buildpack, You can set an exact version of a buildpack by using a git revision in your BUILDPACK_URL . For example: BUILDPACK_URL=https://github.com/dpiddy/heroku-buildpack-ruby-minimal#v13 On your next git push , the custom buildpack will be used.","title":"Using a Custom Buildpack"},{"location":"applications/using-buildpacks/#compile-hooks","text":"Sometimes, an application needs a way to stop or check if a service is running before building an app, which may require notifying a service that the Builder has finished compiling the app. In order to do this, an app can provide two files in their bin/ directory: bin/pre-compile bin/post-compile The builder will run these commands before and after the build process, respectively.","title":"Compile Hooks"},{"location":"applications/using-buildpacks/#using-private-repositories","text":"To pull code from private repositories, set the SSH_KEY environment variable to a private key which has access. Use either the path of a private key file or the raw key material: $ drycc config:set SSH_KEY=/home/user/.ssh/id_rsa $ drycc config:set SSH_KEY=\"\"\"-----BEGIN RSA PRIVATE KEY----- (...) -----END RSA PRIVATE KEY-----\"\"\" For example, to use a custom buildpack hosted at a private GitHub URL, ensure that an SSH public key exists in your GitHub settings . Then set SSH_KEY to the corresponding SSH private key and set BUILDPACK_URL to the URL: $ drycc config:set SSH_KEY=/home/user/.ssh/github_id_rsa $ drycc config:set BUILDPACK_URL=git@github.com:user/private_buildpack.git $ git push drycc master","title":"Using Private Repositories"},{"location":"applications/using-buildpacks/#builder-selector","text":"Which way to build a project conforms to the following principles: If Dockerfile exists in the project, the stack uses container If Procfile exists in the project, the stack uses heroku-18 If both exist, container is used by default You can also set the DRYCC_STACK to determine which stack to use.","title":"Builder selector"},{"location":"applications/using-docker-images/","text":"Using Docker Images \u00b6 Drycc supports deploying applications via an existing Docker Image . This is useful for integrating Drycc into Docker-based CI/CD pipelines. Prepare an Application \u00b6 Start by cloning an example application: $ git clone https://github.com/drycc/example-dockerfile-http.git $ cd example-dockerfile-http Next use your local docker client to build the image and push it to DockerHub . $ docker build -t <username>/example-dockerfile-http . $ docker push <username>/example-dockerfile-http Docker Image Requirements \u00b6 In order to deploy Docker images, they must conform to the following requirements: The Dockerfile must use the EXPOSE directive to expose exactly one port. That port must be listening for an HTTP connection. The Dockerfile must use the CMD directive to define the default process that will run within the container. The Docker image must contain bash to run processes. Note Note that if you are using a private registry of any kind ( gcr or other) the application environment must include a $PORT config variable that matches the EXPOSE 'd port, example: drycc config:set PORT=5000 . See Configuring Registry for more info. Create an Application \u00b6 Use drycc create to create an application on the controller . $ mkdir -p /tmp/example-dockerfile-http && cd /tmp/example-dockerfile-http $ drycc create example-dockerfile-http --no-remote Creating application... done, created example-dockerfile-http Note For all commands except for drycc create , the drycc client uses the name of the current directory as the app name if you don't specify it explicitly with --app . Deploy the Application \u00b6 Use drycc pull to deploy your application from DockerHub or a public registry. $ drycc pull <username>/example-dockerfile-http:latest Creating build... done, v2 $ curl -s http://example-dockerfile-http.local3.dryccapp.com Powered by Drycc Because you are deploying a Docker image, the cmd process type is automatically scaled to 1 on first deploy. Use drycc scale cmd=3 to increase cmd processes to 3, for example. Scaling a process type directly changes the number of Containers running that process. Private Registry \u00b6 To deploy Docker images from a private registry or from a private repository, use drycc registry to attach credentials to your application. These credentials are the same as you'd use when running docker login at your private registry. To deploy private Docker images, take the following steps: Gather the username and password for the registry, such as a Quay.io Robot Account or a GCR.io Long Lived Token Run drycc registry:set username=<the-user> password=<secret> -a <application-name> Now perform drycc pull as normal, against an image in the private registry When using a GCR.io Long Lived Token , the JSON blob will have to be compacted first using a tool like jq and then used in the password field in drycc registry:set . For the username, use _json_key . For example: drycc registry:set username=_json_key password=\"$(cat google_cloud_cred.json | jq -c .)\" When using a private registry the docker images are no longer pulled into the Drycc Internal Registry via the Drycc Workflow Controller but rather is managed by Kubernetes. This will increase security and overall speed, however the application port information can no longer be discovered. Instead the application port information can be set via drycc config:set PORT=80 prior to setting the registry information. Note Currently GCR.io and ECR in short lived auth token mode are not supported.","title":"Docker Images"},{"location":"applications/using-docker-images/#using-docker-images","text":"Drycc supports deploying applications via an existing Docker Image . This is useful for integrating Drycc into Docker-based CI/CD pipelines.","title":"Using Docker Images"},{"location":"applications/using-docker-images/#prepare-an-application","text":"Start by cloning an example application: $ git clone https://github.com/drycc/example-dockerfile-http.git $ cd example-dockerfile-http Next use your local docker client to build the image and push it to DockerHub . $ docker build -t <username>/example-dockerfile-http . $ docker push <username>/example-dockerfile-http","title":"Prepare an Application"},{"location":"applications/using-docker-images/#docker-image-requirements","text":"In order to deploy Docker images, they must conform to the following requirements: The Dockerfile must use the EXPOSE directive to expose exactly one port. That port must be listening for an HTTP connection. The Dockerfile must use the CMD directive to define the default process that will run within the container. The Docker image must contain bash to run processes. Note Note that if you are using a private registry of any kind ( gcr or other) the application environment must include a $PORT config variable that matches the EXPOSE 'd port, example: drycc config:set PORT=5000 . See Configuring Registry for more info.","title":"Docker Image Requirements"},{"location":"applications/using-docker-images/#create-an-application","text":"Use drycc create to create an application on the controller . $ mkdir -p /tmp/example-dockerfile-http && cd /tmp/example-dockerfile-http $ drycc create example-dockerfile-http --no-remote Creating application... done, created example-dockerfile-http Note For all commands except for drycc create , the drycc client uses the name of the current directory as the app name if you don't specify it explicitly with --app .","title":"Create an Application"},{"location":"applications/using-docker-images/#deploy-the-application","text":"Use drycc pull to deploy your application from DockerHub or a public registry. $ drycc pull <username>/example-dockerfile-http:latest Creating build... done, v2 $ curl -s http://example-dockerfile-http.local3.dryccapp.com Powered by Drycc Because you are deploying a Docker image, the cmd process type is automatically scaled to 1 on first deploy. Use drycc scale cmd=3 to increase cmd processes to 3, for example. Scaling a process type directly changes the number of Containers running that process.","title":"Deploy the Application"},{"location":"applications/using-docker-images/#private-registry","text":"To deploy Docker images from a private registry or from a private repository, use drycc registry to attach credentials to your application. These credentials are the same as you'd use when running docker login at your private registry. To deploy private Docker images, take the following steps: Gather the username and password for the registry, such as a Quay.io Robot Account or a GCR.io Long Lived Token Run drycc registry:set username=<the-user> password=<secret> -a <application-name> Now perform drycc pull as normal, against an image in the private registry When using a GCR.io Long Lived Token , the JSON blob will have to be compacted first using a tool like jq and then used in the password field in drycc registry:set . For the username, use _json_key . For example: drycc registry:set username=_json_key password=\"$(cat google_cloud_cred.json | jq -c .)\" When using a private registry the docker images are no longer pulled into the Drycc Internal Registry via the Drycc Workflow Controller but rather is managed by Kubernetes. This will increase security and overall speed, however the application port information can no longer be discovered. Instead the application port information can be set via drycc config:set PORT=80 prior to setting the registry information. Note Currently GCR.io and ECR in short lived auth token mode are not supported.","title":"Private Registry"},{"location":"applications/using-dockerfiles/","text":"Using Dockerfiles \u00b6 Drycc supports deploying applications via Dockerfiles. A Dockerfile automates the steps for crafting a Docker Image . Dockerfiles are incredibly powerful but require some extra work to define your exact application runtime environment. Add SSH Key \u00b6 For Dockerfile based application deploys via git push , Drycc Workflow identifies users via SSH keys. SSH keys are pushed to the platform and must be unique to each user. See this document for instructions on how to generate an SSH key. Run drycc keys:add to upload your SSH key to Drycc Workflow. $ drycc keys:add ~/.ssh/id_drycc.pub Uploading id_drycc.pub to drycc... done Read more about adding/removing SSH Keys here . Prepare an Application \u00b6 If you do not have an existing application, you can clone an example application that demonstrates the Dockerfile workflow. $ git clone https://github.com/drycc/helloworld.git $ cd helloworld Dockerfile Requirements \u00b6 In order to deploy Dockerfile applications, they must conform to the following requirements: The Dockerfile must use the EXPOSE directive to expose exactly one port. That port must be listening for an HTTP connection. The Dockerfile must use the CMD directive to define the default process that will run within the container. The Docker image must contain bash to run processes. Note Note that if you are using a private registry of any kind ( gcr or other) the application environment must include a $PORT config variable that matches the EXPOSE 'd port, example: drycc config:set PORT=5000 . See Configuring Registry for more info. Create an Application \u00b6 Use drycc create to create an application on the Controller . $ drycc create Creating application... done, created folksy-offshoot Git remote drycc added Push to Deploy \u00b6 Use git push drycc master to deploy your application. $ git push drycc master Counting objects: 13, done. Delta compression using up to 8 threads. Compressing objects: 100% (13/13), done. Writing objects: 100% (13/13), 1.99 KiB | 0 bytes/s, done. Total 13 (delta 2), reused 0 (delta 0) -----> Building Docker image Uploading context 4.096 kB Uploading context Step 0 : FROM drycc/base:latest ---> 60024338bc63 Step 1 : RUN wget -O /tmp/go1.2.1.linux-amd64.tar.gz -q https://go.googlecode.com/files/go1.2.1.linux-amd64.tar.gz ---> Using cache ---> cf9ef8c5caa7 Step 2 : RUN tar -C /usr/local -xzf /tmp/go1.2.1.linux-amd64.tar.gz ---> Using cache ---> 515b1faf3bd8 Step 3 : RUN mkdir -p /go ---> Using cache ---> ebf4927a00e9 Step 4 : ENV GOPATH /go ---> Using cache ---> c6a276eded37 Step 5 : ENV PATH /usr/local/go/bin:/go/bin:$PATH ---> Using cache ---> 2ba6f6c9f108 Step 6 : ADD . /go/src/github.com/drycc/helloworld ---> 94ab7f4b977b Removing intermediate container 171b7d9fdb34 Step 7 : RUN cd /go/src/github.com/drycc/helloworld && go install -v . ---> Running in 0c8fbb2d2812 github.com/drycc/helloworld ---> 13b5af931393 Removing intermediate container 0c8fbb2d2812 Step 8 : ENV PORT 80 ---> Running in 9b07da36a272 ---> 2dce83167874 Removing intermediate container 9b07da36a272 Step 9 : CMD [\"/go/bin/helloworld\"] ---> Running in f7b215199940 ---> b1e55ce5195a Removing intermediate container f7b215199940 Step 10 : EXPOSE 80 ---> Running in 7eb8ec45dcb0 ---> ea1a8cc93ca3 Removing intermediate container 7eb8ec45dcb0 Successfully built ea1a8cc93ca3 -----> Pushing image to private registry Launching... done, v2 -----> folksy-offshoot deployed to Drycc http://folksy-offshoot.local3.dryccapp.com To learn more, use `drycc help` or visit http://drycc.cc To ssh://git@local3.dryccapp.com:2222/folksy-offshoot.git * [new branch] master -> master $ curl -s http://folksy-offshoot.local3.dryccapp.com Welcome to Drycc! See the documentation at http://docs.drycc.cc/ for more information. Because a Dockerfile application is detected, the cmd process type is automatically scaled to 1 on first deploy. Use drycc scale cmd=3 to increase cmd processes to 3, for example. Scaling a process type directly changes the number of containers running that process. Docker Build Arguments \u00b6 As of Workflow v2.13.0, users can inject their application config into the Docker image using Docker build arguments . To opt into this, users must add a new environment variable to their application: $ drycc config:set DRYCC_DOCKER_BUILD_ARGS_ENABLED=1 Every environment variable set with drycc config:set will then be available for use inside the user's Dockerfile. For example, if a user runs drycc config:set POWERED_BY=Workflow , the user can utilize that build argument in their Dockerfile: ARG POWERED_BY RUN echo \"Powered by $POWERED_BY\" > /etc/motd","title":"Dockerfiles"},{"location":"applications/using-dockerfiles/#using-dockerfiles","text":"Drycc supports deploying applications via Dockerfiles. A Dockerfile automates the steps for crafting a Docker Image . Dockerfiles are incredibly powerful but require some extra work to define your exact application runtime environment.","title":"Using Dockerfiles"},{"location":"applications/using-dockerfiles/#add-ssh-key","text":"For Dockerfile based application deploys via git push , Drycc Workflow identifies users via SSH keys. SSH keys are pushed to the platform and must be unique to each user. See this document for instructions on how to generate an SSH key. Run drycc keys:add to upload your SSH key to Drycc Workflow. $ drycc keys:add ~/.ssh/id_drycc.pub Uploading id_drycc.pub to drycc... done Read more about adding/removing SSH Keys here .","title":"Add SSH Key"},{"location":"applications/using-dockerfiles/#prepare-an-application","text":"If you do not have an existing application, you can clone an example application that demonstrates the Dockerfile workflow. $ git clone https://github.com/drycc/helloworld.git $ cd helloworld","title":"Prepare an Application"},{"location":"applications/using-dockerfiles/#dockerfile-requirements","text":"In order to deploy Dockerfile applications, they must conform to the following requirements: The Dockerfile must use the EXPOSE directive to expose exactly one port. That port must be listening for an HTTP connection. The Dockerfile must use the CMD directive to define the default process that will run within the container. The Docker image must contain bash to run processes. Note Note that if you are using a private registry of any kind ( gcr or other) the application environment must include a $PORT config variable that matches the EXPOSE 'd port, example: drycc config:set PORT=5000 . See Configuring Registry for more info.","title":"Dockerfile Requirements"},{"location":"applications/using-dockerfiles/#create-an-application","text":"Use drycc create to create an application on the Controller . $ drycc create Creating application... done, created folksy-offshoot Git remote drycc added","title":"Create an Application"},{"location":"applications/using-dockerfiles/#push-to-deploy","text":"Use git push drycc master to deploy your application. $ git push drycc master Counting objects: 13, done. Delta compression using up to 8 threads. Compressing objects: 100% (13/13), done. Writing objects: 100% (13/13), 1.99 KiB | 0 bytes/s, done. Total 13 (delta 2), reused 0 (delta 0) -----> Building Docker image Uploading context 4.096 kB Uploading context Step 0 : FROM drycc/base:latest ---> 60024338bc63 Step 1 : RUN wget -O /tmp/go1.2.1.linux-amd64.tar.gz -q https://go.googlecode.com/files/go1.2.1.linux-amd64.tar.gz ---> Using cache ---> cf9ef8c5caa7 Step 2 : RUN tar -C /usr/local -xzf /tmp/go1.2.1.linux-amd64.tar.gz ---> Using cache ---> 515b1faf3bd8 Step 3 : RUN mkdir -p /go ---> Using cache ---> ebf4927a00e9 Step 4 : ENV GOPATH /go ---> Using cache ---> c6a276eded37 Step 5 : ENV PATH /usr/local/go/bin:/go/bin:$PATH ---> Using cache ---> 2ba6f6c9f108 Step 6 : ADD . /go/src/github.com/drycc/helloworld ---> 94ab7f4b977b Removing intermediate container 171b7d9fdb34 Step 7 : RUN cd /go/src/github.com/drycc/helloworld && go install -v . ---> Running in 0c8fbb2d2812 github.com/drycc/helloworld ---> 13b5af931393 Removing intermediate container 0c8fbb2d2812 Step 8 : ENV PORT 80 ---> Running in 9b07da36a272 ---> 2dce83167874 Removing intermediate container 9b07da36a272 Step 9 : CMD [\"/go/bin/helloworld\"] ---> Running in f7b215199940 ---> b1e55ce5195a Removing intermediate container f7b215199940 Step 10 : EXPOSE 80 ---> Running in 7eb8ec45dcb0 ---> ea1a8cc93ca3 Removing intermediate container 7eb8ec45dcb0 Successfully built ea1a8cc93ca3 -----> Pushing image to private registry Launching... done, v2 -----> folksy-offshoot deployed to Drycc http://folksy-offshoot.local3.dryccapp.com To learn more, use `drycc help` or visit http://drycc.cc To ssh://git@local3.dryccapp.com:2222/folksy-offshoot.git * [new branch] master -> master $ curl -s http://folksy-offshoot.local3.dryccapp.com Welcome to Drycc! See the documentation at http://docs.drycc.cc/ for more information. Because a Dockerfile application is detected, the cmd process type is automatically scaled to 1 on first deploy. Use drycc scale cmd=3 to increase cmd processes to 3, for example. Scaling a process type directly changes the number of containers running that process.","title":"Push to Deploy"},{"location":"applications/using-dockerfiles/#docker-build-arguments","text":"As of Workflow v2.13.0, users can inject their application config into the Docker image using Docker build arguments . To opt into this, users must add a new environment variable to their application: $ drycc config:set DRYCC_DOCKER_BUILD_ARGS_ENABLED=1 Every environment variable set with drycc config:set will then be available for use inside the user's Dockerfile. For example, if a user runs drycc config:set POWERED_BY=Workflow , the user can utilize that build argument in their Dockerfile: ARG POWERED_BY RUN echo \"Powered by $POWERED_BY\" > /etc/motd","title":"Docker Build Arguments"},{"location":"changelogs/v1.0.1/","text":"The time has come for major release! We are proud to present Drycc Workflow 1.0.1 to the world. In this release, we've added a lot of new features. You can download one of our pre-built binaries from our downloads page - make sure to select the correct platform! For further details on how to install, follow our installation guide. We\u2019d like to thank all of our backers on Open Collective, who are helping us deliver a better piece of software. With that out of the way, here\u2019s what\u2019s new in Drycc version 1.0.1: substituting minio-mc for object-storage using wal-g instead of wal-e some scenarios use dep instead of glide minio adds gateway mode adding aliyun oss support In the future, we have many exciting plans, for example: Use kubernetes ingress instead of drycc-router Automatic certificate generation using cert-manager Replace golang's package management glide with dep Support for the latest version of the kubernetes API Coming soon...","title":"v1.0.1"},{"location":"changelogs/v1.1.0/","text":"Workflow ## v1.0.0 -> v1.1.0 \u00b6 Releases \u00b6 builder v1.0.0 -> v1.0.1 controller v1.0.0 -> v1.1.0 database v1.0.0 -> v1.0.1 monitor v1.0.0 -> v1.0.1 registry-proxy v1.0.0 -> v1.0.1 Features \u00b6 69c8e12 (controller) - docker: use python:3.7-alpine replace drycc/base 6a3e70c (controller) - gunicorn: use process replace threads e63cbb5 (controller) - ingress: Improving the configuration of ingress 76f75dc (controller) - charts: add rbac to cert-manager 6807b2c (controller) - certificate: add cert-manager certificate api Fixes \u00b6 f53d89e (controller) - controller: check_image_access only when using docker 896775a (controller) - docker: multiprocess should not be used in docker ecdaf9f (controller) - app: can't create app e00af7e (controller) - tls: add migrations for certs_auto_enabled Style \u00b6 bdbb7e6 (controller) - pep8: Use pep8-compliant code style Test case \u00b6 c5b5a9d (controller) - ingress: add tests to ingress Maintenance \u00b6 62a9b7d (builder) - workflow: change experimental_native_ingress to use_native_ingress 39e9cec (builder) - ingress: renmae use_native_ingress to use_ingress 7fa8134 (builder) - ingress: change global.use_ingress to ingress.enabled e245c31 (builder) - ingress: use ingress_class 18b330d (builder) - service: no longer dependent on ingress switches 95f4d3d (controller) - django: upgrade to django version 1.11.20 latest patch 6bcd79b (controller) - workflow: change experimental_native_ingress to use_native_ingress 781229a (controller) - ingress: renmae use_native_ingress to use_ingress b96b4db (controller) - ingress: change global.use_ingress to ingress.enabled e1b124f (controller) - ingress: use ingress_class fee0554 (controller) - ingress: delete ingress judgment 5cd10f3 (controller) - ingress: Ingress_class can be empty fa312bb (database) - postgres: set max_connections = 1024 c1ee2a4 (monitor) - monitor: remove copyrights.tar.gz e088da3 (registry-proxy) - ingress: renmae use_native_ingress to use_ingress","title":"v1.1.0"},{"location":"changelogs/v1.1.0/#workflow-v100-v110","text":"","title":"Workflow ## v1.0.0 -&gt; v1.1.0"},{"location":"changelogs/v1.1.0/#releases","text":"builder v1.0.0 -> v1.0.1 controller v1.0.0 -> v1.1.0 database v1.0.0 -> v1.0.1 monitor v1.0.0 -> v1.0.1 registry-proxy v1.0.0 -> v1.0.1","title":"Releases"},{"location":"changelogs/v1.1.0/#features","text":"69c8e12 (controller) - docker: use python:3.7-alpine replace drycc/base 6a3e70c (controller) - gunicorn: use process replace threads e63cbb5 (controller) - ingress: Improving the configuration of ingress 76f75dc (controller) - charts: add rbac to cert-manager 6807b2c (controller) - certificate: add cert-manager certificate api","title":"Features"},{"location":"changelogs/v1.1.0/#fixes","text":"f53d89e (controller) - controller: check_image_access only when using docker 896775a (controller) - docker: multiprocess should not be used in docker ecdaf9f (controller) - app: can't create app e00af7e (controller) - tls: add migrations for certs_auto_enabled","title":"Fixes"},{"location":"changelogs/v1.1.0/#style","text":"bdbb7e6 (controller) - pep8: Use pep8-compliant code style","title":"Style"},{"location":"changelogs/v1.1.0/#test-case","text":"c5b5a9d (controller) - ingress: add tests to ingress","title":"Test case"},{"location":"changelogs/v1.1.0/#maintenance","text":"62a9b7d (builder) - workflow: change experimental_native_ingress to use_native_ingress 39e9cec (builder) - ingress: renmae use_native_ingress to use_ingress 7fa8134 (builder) - ingress: change global.use_ingress to ingress.enabled e245c31 (builder) - ingress: use ingress_class 18b330d (builder) - service: no longer dependent on ingress switches 95f4d3d (controller) - django: upgrade to django version 1.11.20 latest patch 6bcd79b (controller) - workflow: change experimental_native_ingress to use_native_ingress 781229a (controller) - ingress: renmae use_native_ingress to use_ingress b96b4db (controller) - ingress: change global.use_ingress to ingress.enabled e1b124f (controller) - ingress: use ingress_class fee0554 (controller) - ingress: delete ingress judgment 5cd10f3 (controller) - ingress: Ingress_class can be empty fa312bb (database) - postgres: set max_connections = 1024 c1ee2a4 (monitor) - monitor: remove copyrights.tar.gz e088da3 (registry-proxy) - ingress: renmae use_native_ingress to use_ingress","title":"Maintenance"},{"location":"changelogs/v1.2.0/","text":"Workflow ## v1.1.0 -> v1.2.0 \u00b6 Releases \u00b6 builder v1.0.1 -> v1.0.2 slugbuilder v1.0.0 -> v1.1.0 dockerbuilder v1.0.0 -> v1.1.0 controller v1.1.0 -> v1.2.0 slugrunner v1.0.0 -> v1.1.0 registry v1.0.0 -> v1.0.1 registry-proxy v1.0.1 -> v1.0.2 Features \u00b6 e5584e3 (controller) - controller: add STACK support ad34dc1 (dockerbuilder) - kaniko: use kaniko replace docker-py b81430e (dockerbuilder) - dockerbuilder: change image to image.json format 60dde96 (slugbuilder) - slugbuilder: add STACK support fe8b6e5 (slugrunner) - slugrunner: add STACK support Maintenance \u00b6 942f050 (builder) - registry: remove env DRYCC_REGISTRY_PROXY_PORT ff7a16f (builder) - registry: remove ecr and gcr registry ad13683 (builder) - builder: change DRYCC_BUILD_TYPE to DRYCC_STACK 6def637 (builder) - registry: rename DRYCC_REGISTRY_SERVICE to DRYCC_REGISTRY_PROXY 5044e22 (builder) - registry: remove registry_secret_prefix 2ea39cc (builder) - controller-go-sdk: upgrade controller-go-sdk 6aee0d7 (builder) - registry: optimizing variable naming f9c62d9 (controller) - domain: added reserved domain check f5a135b (controller) - migrations: clean old migrations 4369b2c (controller) - registry: rename DRYCC_REGISTRY_SERVICE to DRYCC_REGISTRY_PROXY 1057ca5 (controller) - registry: remove registry_secret_prefix d114b3e (controller) - docker: update docker client edbe963 (dockerbuilder) - dockerfile: change base image to alpine fb35baf (dockerbuilder) - registry: rename DRYCC_REGISTRY_SERVICE to DRYCC_REGISTRY_PROXY 946dbf6 (dockerbuilder) - docker: remove insecure support 628d853 (dockerbuilder) - proxy: add registry proxy ff27cbd (registry) - env: remove unused env 7204d72 (registry-proxy) - registry: optimizing variable naming","title":"v1.2.0"},{"location":"changelogs/v1.2.0/#workflow-v110-v120","text":"","title":"Workflow ## v1.1.0 -&gt; v1.2.0"},{"location":"changelogs/v1.2.0/#releases","text":"builder v1.0.1 -> v1.0.2 slugbuilder v1.0.0 -> v1.1.0 dockerbuilder v1.0.0 -> v1.1.0 controller v1.1.0 -> v1.2.0 slugrunner v1.0.0 -> v1.1.0 registry v1.0.0 -> v1.0.1 registry-proxy v1.0.1 -> v1.0.2","title":"Releases"},{"location":"changelogs/v1.2.0/#features","text":"e5584e3 (controller) - controller: add STACK support ad34dc1 (dockerbuilder) - kaniko: use kaniko replace docker-py b81430e (dockerbuilder) - dockerbuilder: change image to image.json format 60dde96 (slugbuilder) - slugbuilder: add STACK support fe8b6e5 (slugrunner) - slugrunner: add STACK support","title":"Features"},{"location":"changelogs/v1.2.0/#maintenance","text":"942f050 (builder) - registry: remove env DRYCC_REGISTRY_PROXY_PORT ff7a16f (builder) - registry: remove ecr and gcr registry ad13683 (builder) - builder: change DRYCC_BUILD_TYPE to DRYCC_STACK 6def637 (builder) - registry: rename DRYCC_REGISTRY_SERVICE to DRYCC_REGISTRY_PROXY 5044e22 (builder) - registry: remove registry_secret_prefix 2ea39cc (builder) - controller-go-sdk: upgrade controller-go-sdk 6aee0d7 (builder) - registry: optimizing variable naming f9c62d9 (controller) - domain: added reserved domain check f5a135b (controller) - migrations: clean old migrations 4369b2c (controller) - registry: rename DRYCC_REGISTRY_SERVICE to DRYCC_REGISTRY_PROXY 1057ca5 (controller) - registry: remove registry_secret_prefix d114b3e (controller) - docker: update docker client edbe963 (dockerbuilder) - dockerfile: change base image to alpine fb35baf (dockerbuilder) - registry: rename DRYCC_REGISTRY_SERVICE to DRYCC_REGISTRY_PROXY 946dbf6 (dockerbuilder) - docker: remove insecure support 628d853 (dockerbuilder) - proxy: add registry proxy ff27cbd (registry) - env: remove unused env 7204d72 (registry-proxy) - registry: optimizing variable naming","title":"Maintenance"},{"location":"changelogs/v1.3.0/","text":"Workflow ## v1.2.0 -> v1.3.0 \u00b6 Releases \u00b6 builder v1.0.2 -> v1.1.0 slugbuilder v1.1.0 -> v1.1.1 dockerbuilder v1.1.0 -> v1.1.1 controller v1.2.0 -> v1.2.1 slugrunner v1.1.0 -> v1.1.1 database v1.0.0 -> v1.0.1 fluentd v1.0.0 -> v1.0.1 minio v1.0.0 -> v1.0.1 monitor v1.0.0 -> v1.0.1 registry v1.0.1 -> v1.0.2 Features \u00b6 9c7cceb (builder) - builder: add app config to env Fixes \u00b6 7fe44fa (controller) - docker: docker timeout must be an int, float or None b196550 (controller) - controller: revert release.check_image_access for now Maintenance \u00b6 ef932c4 (builder) - controller-sdk-go: upgrade controller-sdk-go 4654cf6 (controller) - django-rest-framework: upgrade to 3.9.3 14121f1 (controller) - deps: bump djangorestframework from 3.9.3 to 3.9.4 in /rootfs 385acdc (controller) - deps: bump django from 1.11.20 to 1.11.21 in /rootfs fa312bb (database) - postgres: set max_connections = 1024 7ebecdf (database) - mc: upgrade mc to RELEASE.2019-05-23T01-33-27Z b8878f6 (dockerbuilder) - mc: upgrade mc to RELEASE.2019-05-23T01-33-27Z b097451 (fluentd) - fluent: upgrade fluent to v1.4 4341f9a (minio) - mc: upgrade mc and minio c1ee2a4 (monitor) - monitor: remove copyrights.tar.gz 9854260 (registry) - mc: upgrade mc to RELEASE.2019-05-23T01-33-27Z acc5627 (slugbuilder) - slugbuilder: internal support for multi buildpack d58907e (slugbuilder) - mc: upgrade mc to RELEASE.2019-05-23T01-33-27Z b39a0c2 (slugrunner) - mc: upgrade mc to RELEASE.2019-05-23T01-33-27Z","title":"v1.3.0"},{"location":"changelogs/v1.3.0/#workflow-v120-v130","text":"","title":"Workflow ## v1.2.0 -&gt; v1.3.0"},{"location":"changelogs/v1.3.0/#releases","text":"builder v1.0.2 -> v1.1.0 slugbuilder v1.1.0 -> v1.1.1 dockerbuilder v1.1.0 -> v1.1.1 controller v1.2.0 -> v1.2.1 slugrunner v1.1.0 -> v1.1.1 database v1.0.0 -> v1.0.1 fluentd v1.0.0 -> v1.0.1 minio v1.0.0 -> v1.0.1 monitor v1.0.0 -> v1.0.1 registry v1.0.1 -> v1.0.2","title":"Releases"},{"location":"changelogs/v1.3.0/#features","text":"9c7cceb (builder) - builder: add app config to env","title":"Features"},{"location":"changelogs/v1.3.0/#fixes","text":"7fe44fa (controller) - docker: docker timeout must be an int, float or None b196550 (controller) - controller: revert release.check_image_access for now","title":"Fixes"},{"location":"changelogs/v1.3.0/#maintenance","text":"ef932c4 (builder) - controller-sdk-go: upgrade controller-sdk-go 4654cf6 (controller) - django-rest-framework: upgrade to 3.9.3 14121f1 (controller) - deps: bump djangorestframework from 3.9.3 to 3.9.4 in /rootfs 385acdc (controller) - deps: bump django from 1.11.20 to 1.11.21 in /rootfs fa312bb (database) - postgres: set max_connections = 1024 7ebecdf (database) - mc: upgrade mc to RELEASE.2019-05-23T01-33-27Z b8878f6 (dockerbuilder) - mc: upgrade mc to RELEASE.2019-05-23T01-33-27Z b097451 (fluentd) - fluent: upgrade fluent to v1.4 4341f9a (minio) - mc: upgrade mc and minio c1ee2a4 (monitor) - monitor: remove copyrights.tar.gz 9854260 (registry) - mc: upgrade mc to RELEASE.2019-05-23T01-33-27Z acc5627 (slugbuilder) - slugbuilder: internal support for multi buildpack d58907e (slugbuilder) - mc: upgrade mc to RELEASE.2019-05-23T01-33-27Z b39a0c2 (slugrunner) - mc: upgrade mc to RELEASE.2019-05-23T01-33-27Z","title":"Maintenance"},{"location":"changelogs/v1.4.0/","text":"Workflow ## v1.3.0 -> v1.4.0 \u00b6 Releases \u00b6 builder v1.1.0 -> v1.2.0 slugbuilder v1.1.1 -> v1.2.0 dockerbuilder v1.1.1 -> v1.1.2 controller v1.2.1 -> v1.3.0 slugrunner v1.1.1 -> v1.1.2 database v1.0.1 -> v1.0.2 fluentd v1.0.1 -> v1.1.0 redis v1.0.0 -> v1.1.0 logger v1.0.0 -> v1.1.0 minio v1.0.1 -> v1.1.0 monitor v1.0.1 -> v1.1.0 nsqd v1.0.0 -> v1.1.0 registry v1.0.2 -> v1.0.3 registry-proxy v1.0.0 -> v1.0.1 Features \u00b6 fc7d93f (builder) - builder: use go-dev 0c2159e (builder) - builder: fmt code and add create_bucket script 1b88340 (controller) - controller: remove deprecated api a92fdeb (controller) - routable: ingress support routable 1e3eab3 (controller) - maintenance: add maintenance support for ingress 56b9dd0 (controller) - crt: support containerd-ctr 5fc3b46 (controller) - controller: add ephemeral-storage restriction d677e52 (controller) - controller: add a volume command 5f1323a (controller) - controller:drycc run cmd add --mount para 74c36a5 (controller) - tasks: add distributed async task 139c3ca (controller) - tasks: change nsq reader to async f237d74 (controller) - controller:add drycc resource cmd 41b46d0 (controller) - controller:add drycc resource cmd improvement c26f7d8 (controller) - controller: add LimitRanges support 45b5d1b (controller) - users: add users status api 4e16f9b (controller) - ps:add ps:stop/start command c659fa9 (controller) - k8s: add k8s cluster domain 31a625d (controller) - ps:add ps:stop/start command 00a779a (fluentd) - fluentd: support containerd log format f3f1bd4 (fluentd) - nsqd: add stateless nsqd cluster support db7147c (fluentd) - mirrors: delete aliyun mirrors 689c12e (logger) - nsqd: add stateless nsqd cluster support 78ccc5d (logger) - redis: add redis client cluster support 9843f2c (logger) - k8s: add k8s cluster domain 6ba122e (minio) - minio: add pvc support 6973550 (monitor) - monitor: add ingress for monitor cd73305 (monitor) - charts: add volumeName support 4769fe9 (monitor) - nsqd: add stateless nsqd cluster support 87806df (monitor) - k8s: add k8s cluster domain 4db40c4 (nsqd) - nsqd: add stateless nsqd cluster support b6f3d4f (nsqd) - nsqd: add stateless nsqd cluster support 74b85bb (redis) - redis: change redis to statefulset ff98b50 (slugbuilder) - slugbuilder: delete build hook b201c2f (slugbuilder) - buildpacks: use drycc buildpacks Fixes \u00b6 0ec042d (builder) - test: fix test case error 4fb113b (builder) - build: base image replace by alpine 443df48 (builder) - minio: fix not bucket error 3dab5b0 (builder) - minio: create bucket error 734fca6 (controller) - autoscale: Fix for autoscale on k8s-1.9+ without breaking manual scaling a7dcd10 (controller) - controller: test pass 93f0f2e (controller) - controller: fix migrations error 4724375 (controller) - controller: fix test error 7bacf29 (controller) - charts: fix clusterrole 90957f7 (controller) - pod: sort events error 440b13e (controller) - controller: review table structure 0a470a6 (controller) - controller: bump tornado 5.1.1 e39218b (controller) - pynsq: no current event loop in thread 1d8630e (controller) - tests: fix test_task.py run error 1ff1202 (controller) - controller: fix test case d8c0da3 (controller) - settings: fix env name 6d8fd36 (database) - 003_restore_from_backup.sh: ignore script exit 1 e0394a9 (database) - minio: fix not bucket error f35f252 (database) - mc: fix create_bucket error 74d6886 (database) - postgres: recovery mode not run e50d0c1 (dockerbuilder) - caddy: fix caddy not start f3bec7a (fluentd) - influxdb: fix influxdb host and port bc19f27 (fluentd) - charts: skipped value for daemon_environment: Not a table 338d623 (logger) - logger: logger not run in alpine 7788302 (minio) - minio: bump minio version 619eed0 (minio) - fix: use go mod replace dep 3b42122 (monitor) - monitor: fix host error 67998ef (monitor) - influxdb: replace drycc-monitor-influxapi to drycc-monitor-influx-api 2cc361c (registry) - registry: fix test case 548297a (registry) - minio: fix not bucket error 5412ddb (registry) - minio: create bucket error d0d629e (slugbuilder) - slugbuilder:fix normalize_storage path d76ecbe (slugbuilder) - slugbuilder: use v3 api c505e18 (slugbuilder) - shellcheck: SC2039 Style \u00b6 c893a17 (builder) - builder: fmt code bba5795 (controller) - controller: format code d36082b (controller) - controller: fix pep8 66026f2 (controller) - resource: standardize the naming of resource 03d7e2c (controller) - servicecatalog: change servicecatalog to svcat 49dbb6d (controller) - controller: flake8 upgrade cbfc108 (monitor) - monitor: format charts and dashboard ee85954 (slugbuilder) - slugbuilder: use shellcheck 3afed2e (slugbuilder) - docker: simplify dockerfile 36b7f68 (slugrunner) - docker: simplify dockerfile Maintenance \u00b6 61bb0ef (builder) - aws: upgrade aws sdk version 0f2e074 (builder) - chore: use go mode replace dep e9a2219 (builder) - builder: delete glide up bb8c518 (builder) - registry: del quay.io fa6d02f (builder) - builder: upgrade go.sum 9d61e8d (builder) - build: upgrade go.mod d763a98 (builder) - charts: upgrade k8s newer API versions d1bc1aa (builder) - pkg: upgrade to new drycc/pkg 02b1e98 (builder) - builder: update go mod 8e17d65 (builder) - builder: change alpine repositories f32b723 (builder) - mirrors: delete aliyun mirrors e33dc61 (builder) - minio: use bin mc replace docker images 3ab4f1c (builder) - builder: update controller-sdk-go b2adfac (builder) - heroku: remove heroku-16 support f429ac8 (builder) - builder: set GIT_LOCK_TIMEOUT to 30 minutes 7197c83 (builder) - go.mod:upgrade require pkg controller-sdk-go 5f3e22d (controller) - deps: bump django from 1.11.21 to 1.11.22 in /rootfs 1db645a (controller) - deps: bump django from 1.11.22 to 1.11.23 in /rootfs fbe8067 (controller) - deps: bump django from 1.11.23 to 1.11.29 in /rootfs 537d667 (controller) - registry: del quay.io a23c65b (controller) - deps: update all deps to the latest version 546337e (controller) - charts: upgrade k8s newer API versions 06023f8 (controller) - workflow-manager: del workflow-manager bba5736 (controller) - controller: change cluster-issuer location 6c43661 (controller) - Certificatechange cluster-issuer location 39a4728 (controller) - controller:change cluster-issuer location del controller-cluster-issuer.yaml 9e96d3f (controller) - Certificate:upgrade version cert-manager.io/v1alpha2 8e68049 (controller) - docker: use INDEX_URL replace index.docker.io 8fda205 (controller) - cert_manager: change cert_manager_enabled to global 6fefb6d (controller) - charts: change platform_domain to global 064b2ad (controller) - maintenance: remove maintenance support b8797c9 (controller) - workflow: remove namespace 1b20d76 (controller) - quota: add kube quota config d780075 (controller) - pod: add pod default resources support 3d72c08 (controller) - rename: rename ingress name 0aa6ab9 (controller) - mirrors: delete aliyun mirrors 7533a65 (controller) - heroku: remove heroku-16 support e5a885d (controller) - controller:check mount volume path 9014e74 (controller) - test: optimization Dockerfile.test 0b6ebb2 (controller) - tasks: change apply_async parameters 835f009 (controller) - wsgi: add tornado 6 support 67a4ad7 (controller) - utils: use threads replace asyncio a28949b (controller) - ldap: add AUTH_LDAP_USER_FLAGS_BY_GROUP a903209 (controller) - charts: add custom controller environment variables support e0e783e (controller) - ldap: change filter style d760825 (controller) - scheduler: remove debug log a25928e (controller) - wsgi: remove a wsgi.py file 7b2696e (controller) - log: disable nsq.client info log 8d5c07b (controller) - charts: add default environment 025f4a2 (controller) - controller: change quota name ebda60e (controller) - controller: review pvc code 8832ba9 (controller) - controller: change status\\binding model type and mount path check container_types 7148d04 (controller) - controller: add overcommit cpu and ram support 4d2087c (controller) - limits: modify limits unit verification af36970 (controller) - api: check cpu/memory range for api 329355b (controller) - volumes: modify the volume size 9dfee09 (controller) - LimitRanges: modify the default limits 5205bca (controller) - controller: improve the details of certificate 7ebecdf (database) - mc: upgrade mc to RELEASE.2019-05-23T01-33-27Z 6415e2c (database) - postgres: upgrade to pg13 12e6806 (database) - charts: upgrade k8s newer API versions d294509 (database) - minio: use canary minio test 1bad02e (database) - mirrors: delete aliyun mirrors d51420b (database) - minio: use bin mc replace docker images 4133d05 (dockerbuilder) - dockerbuilder: update caddy and kaniko 6b4dd18 (dockerbuilder) - minio: use bin mc replace docker images 6df9b7c (fluentd) - deps-dev: update rake requirement from ~> 10.0 to ~> 12.3 c2490f8 (fluentd) - fluentd: upgrade fluentd be4a56a (fluentd) - fluentd: add Gemfile.lock 2237f75 (fluentd) - charts: upgrade k8s newer API versions c574065 (fluentd) - charts: upgrade k8s newer API versions 52b8084 (fluentd) - router: delete obsolete router code 3b3cceb (fluentd) - fluentd: remove manifests dir 25c6702 (fluentd) - nsqd: change var name bd571be (fluentd) - nsqd: change DRYCC_NSQD_ADDRESSES to DRYCC_NSQD_ADDRS 72aa4e6 (fluentd) - influxdb: change influxdb service name bd61903 (logger) - logger: use go mod replace dep 69c63a1 (logger) - logger: update go.mod 3aa9cd7 (logger) - registry: del quay.io f058496 (logger) - nsqd: change var name 6d9787c (logger) - nsqd: change DRYCC_NSQD_ADDRESSES to DRYCC_NSQD_ADDRS 85ed307 (logger) - logger: standard naming d88e7b6 (minio) - minio: update minio api to v7 43715d2 (minio) - minio: upgrade minio 0e1239b (minio) - minio: use docker.io replace quay.io f7f047b (minio) - registry: del quay.io afa7128 (minio) - build: upgrade go.mod aff2db5 (minio) - charts: upgrade k8s newer API versions 4547f14 (minio) - pkg: upgrade to new drycc/pkg 2769b85 (minio) - minio: use bin mc replace docker images 35dde8d (monitor) - monitor: update grafana influxdb telegraf 9e3a949 (monitor) - charts: upgrade k8s newer API versions 6af0432 (monitor) - workflow-manager: remove workflow-manager 0611c07 (monitor) - router: delete obsolete router code be04824 (monitor) - cert_manager: change cert_manager_enabled to global 3780165 (monitor) - charts: change platform_domain to global 50b04e1 (monitor) - influxdb: remove influxdb admin ui 6ab4d68 (monitor) - influxdb: remove unuse port f1510bd (monitor) - monitor: update grafana dashboard,telegraf inputs.kubernetes f36de2c (monitor) - pvc: upgrade to new format fc78a0a (monitor) - workflow: remove namespace e85890f (monitor) - monitor: monitoring nsqd and redis separately 694f6b1 (monitor) - mirrors: delete aliyun mirrors 4aea36a (monitor) - grafana: add ldap support for grafana 68fc30f (nsqd) - nsq: update nsq 16f32aa (nsqd) - charts: upgrade k8s newer API versions 04db389 (redis) - reids: update to redis 6 3f01bab (redis) - charts: upgrade k8s newer API versions 647e4be (registry) - registry: del quay.io 0bbce99 (registry) - charts: upgrade k8s newer API versions a982b50 (registry) - minio: use bin mc replace docker images e088da3 (registry-proxy) - ingress: renmae use_native_ingress to use_ingress 7e88337 (registry-proxy) - nginx: upgrade nginx to mainline 7204d72 (registry-proxy) - registry: optimizing variable naming 2eafc59 (registry-proxy) - registry-proxy: update nginx 071bd86 (registry-proxy) - charts: upgrade k8s newer API versions c72db96 (registry-proxy) - registry-proxy: change travis icon url ca9f962 (slugbuilder) - slugbuilder: del BUILDPACK_URL support 1b74dd5 (slugbuilder) - slugbuilder: add heroku-20 support 54d4ad2 (slugbuilder) - slugbuilder: del quay.io a78f37e (slugbuilder) - slugbuilder: add heroku-20 stack 94ac94a (slugbuilder) - minio: use bin mc replace docker images 53b4b8b (slugbuilder) - slugbuilder: modify stack priority 58e2bd2 (slugbuilder) - dockerfile: add WORKDIR /tmp b29cd04 (slugbuilder) - slugbuilder: add pre_build.sh 9d319f6 (slugbuilder) - slugbuilder: silent mc command output d1ec3c9 (slugbuilder) - heroku: remove heroku-16 support 5048534 (slugbuilder) - slugbuilder: use drycc stack-images a116537 (slugrunner) - slugrunner: add heroku-20 support a1196bf (slugrunner) - slugrunner: del quay.io 64c96d7 (slugrunner) - slugrunner: add heroku-20 stack cc3e226 (slugrunner) - minio: use bin mc replace docker images 9130bde (slugrunner) - shellcheck: shellcheck installer 4ea33e1 (slugrunner) - slugrunner: modify stack priority 5514e8b (slugrunner) - heroku: remove heroku-16 support be829fb (slugrunner) - slugrunner: use drycc stack-images e1e06be (slugrunner) - slugrunner: remove Dockerfile.heroku-16","title":"v1.4.0"},{"location":"changelogs/v1.4.0/#workflow-v130-v140","text":"","title":"Workflow ## v1.3.0 -&gt; v1.4.0"},{"location":"changelogs/v1.4.0/#releases","text":"builder v1.1.0 -> v1.2.0 slugbuilder v1.1.1 -> v1.2.0 dockerbuilder v1.1.1 -> v1.1.2 controller v1.2.1 -> v1.3.0 slugrunner v1.1.1 -> v1.1.2 database v1.0.1 -> v1.0.2 fluentd v1.0.1 -> v1.1.0 redis v1.0.0 -> v1.1.0 logger v1.0.0 -> v1.1.0 minio v1.0.1 -> v1.1.0 monitor v1.0.1 -> v1.1.0 nsqd v1.0.0 -> v1.1.0 registry v1.0.2 -> v1.0.3 registry-proxy v1.0.0 -> v1.0.1","title":"Releases"},{"location":"changelogs/v1.4.0/#features","text":"fc7d93f (builder) - builder: use go-dev 0c2159e (builder) - builder: fmt code and add create_bucket script 1b88340 (controller) - controller: remove deprecated api a92fdeb (controller) - routable: ingress support routable 1e3eab3 (controller) - maintenance: add maintenance support for ingress 56b9dd0 (controller) - crt: support containerd-ctr 5fc3b46 (controller) - controller: add ephemeral-storage restriction d677e52 (controller) - controller: add a volume command 5f1323a (controller) - controller:drycc run cmd add --mount para 74c36a5 (controller) - tasks: add distributed async task 139c3ca (controller) - tasks: change nsq reader to async f237d74 (controller) - controller:add drycc resource cmd 41b46d0 (controller) - controller:add drycc resource cmd improvement c26f7d8 (controller) - controller: add LimitRanges support 45b5d1b (controller) - users: add users status api 4e16f9b (controller) - ps:add ps:stop/start command c659fa9 (controller) - k8s: add k8s cluster domain 31a625d (controller) - ps:add ps:stop/start command 00a779a (fluentd) - fluentd: support containerd log format f3f1bd4 (fluentd) - nsqd: add stateless nsqd cluster support db7147c (fluentd) - mirrors: delete aliyun mirrors 689c12e (logger) - nsqd: add stateless nsqd cluster support 78ccc5d (logger) - redis: add redis client cluster support 9843f2c (logger) - k8s: add k8s cluster domain 6ba122e (minio) - minio: add pvc support 6973550 (monitor) - monitor: add ingress for monitor cd73305 (monitor) - charts: add volumeName support 4769fe9 (monitor) - nsqd: add stateless nsqd cluster support 87806df (monitor) - k8s: add k8s cluster domain 4db40c4 (nsqd) - nsqd: add stateless nsqd cluster support b6f3d4f (nsqd) - nsqd: add stateless nsqd cluster support 74b85bb (redis) - redis: change redis to statefulset ff98b50 (slugbuilder) - slugbuilder: delete build hook b201c2f (slugbuilder) - buildpacks: use drycc buildpacks","title":"Features"},{"location":"changelogs/v1.4.0/#fixes","text":"0ec042d (builder) - test: fix test case error 4fb113b (builder) - build: base image replace by alpine 443df48 (builder) - minio: fix not bucket error 3dab5b0 (builder) - minio: create bucket error 734fca6 (controller) - autoscale: Fix for autoscale on k8s-1.9+ without breaking manual scaling a7dcd10 (controller) - controller: test pass 93f0f2e (controller) - controller: fix migrations error 4724375 (controller) - controller: fix test error 7bacf29 (controller) - charts: fix clusterrole 90957f7 (controller) - pod: sort events error 440b13e (controller) - controller: review table structure 0a470a6 (controller) - controller: bump tornado 5.1.1 e39218b (controller) - pynsq: no current event loop in thread 1d8630e (controller) - tests: fix test_task.py run error 1ff1202 (controller) - controller: fix test case d8c0da3 (controller) - settings: fix env name 6d8fd36 (database) - 003_restore_from_backup.sh: ignore script exit 1 e0394a9 (database) - minio: fix not bucket error f35f252 (database) - mc: fix create_bucket error 74d6886 (database) - postgres: recovery mode not run e50d0c1 (dockerbuilder) - caddy: fix caddy not start f3bec7a (fluentd) - influxdb: fix influxdb host and port bc19f27 (fluentd) - charts: skipped value for daemon_environment: Not a table 338d623 (logger) - logger: logger not run in alpine 7788302 (minio) - minio: bump minio version 619eed0 (minio) - fix: use go mod replace dep 3b42122 (monitor) - monitor: fix host error 67998ef (monitor) - influxdb: replace drycc-monitor-influxapi to drycc-monitor-influx-api 2cc361c (registry) - registry: fix test case 548297a (registry) - minio: fix not bucket error 5412ddb (registry) - minio: create bucket error d0d629e (slugbuilder) - slugbuilder:fix normalize_storage path d76ecbe (slugbuilder) - slugbuilder: use v3 api c505e18 (slugbuilder) - shellcheck: SC2039","title":"Fixes"},{"location":"changelogs/v1.4.0/#style","text":"c893a17 (builder) - builder: fmt code bba5795 (controller) - controller: format code d36082b (controller) - controller: fix pep8 66026f2 (controller) - resource: standardize the naming of resource 03d7e2c (controller) - servicecatalog: change servicecatalog to svcat 49dbb6d (controller) - controller: flake8 upgrade cbfc108 (monitor) - monitor: format charts and dashboard ee85954 (slugbuilder) - slugbuilder: use shellcheck 3afed2e (slugbuilder) - docker: simplify dockerfile 36b7f68 (slugrunner) - docker: simplify dockerfile","title":"Style"},{"location":"changelogs/v1.4.0/#maintenance","text":"61bb0ef (builder) - aws: upgrade aws sdk version 0f2e074 (builder) - chore: use go mode replace dep e9a2219 (builder) - builder: delete glide up bb8c518 (builder) - registry: del quay.io fa6d02f (builder) - builder: upgrade go.sum 9d61e8d (builder) - build: upgrade go.mod d763a98 (builder) - charts: upgrade k8s newer API versions d1bc1aa (builder) - pkg: upgrade to new drycc/pkg 02b1e98 (builder) - builder: update go mod 8e17d65 (builder) - builder: change alpine repositories f32b723 (builder) - mirrors: delete aliyun mirrors e33dc61 (builder) - minio: use bin mc replace docker images 3ab4f1c (builder) - builder: update controller-sdk-go b2adfac (builder) - heroku: remove heroku-16 support f429ac8 (builder) - builder: set GIT_LOCK_TIMEOUT to 30 minutes 7197c83 (builder) - go.mod:upgrade require pkg controller-sdk-go 5f3e22d (controller) - deps: bump django from 1.11.21 to 1.11.22 in /rootfs 1db645a (controller) - deps: bump django from 1.11.22 to 1.11.23 in /rootfs fbe8067 (controller) - deps: bump django from 1.11.23 to 1.11.29 in /rootfs 537d667 (controller) - registry: del quay.io a23c65b (controller) - deps: update all deps to the latest version 546337e (controller) - charts: upgrade k8s newer API versions 06023f8 (controller) - workflow-manager: del workflow-manager bba5736 (controller) - controller: change cluster-issuer location 6c43661 (controller) - Certificatechange cluster-issuer location 39a4728 (controller) - controller:change cluster-issuer location del controller-cluster-issuer.yaml 9e96d3f (controller) - Certificate:upgrade version cert-manager.io/v1alpha2 8e68049 (controller) - docker: use INDEX_URL replace index.docker.io 8fda205 (controller) - cert_manager: change cert_manager_enabled to global 6fefb6d (controller) - charts: change platform_domain to global 064b2ad (controller) - maintenance: remove maintenance support b8797c9 (controller) - workflow: remove namespace 1b20d76 (controller) - quota: add kube quota config d780075 (controller) - pod: add pod default resources support 3d72c08 (controller) - rename: rename ingress name 0aa6ab9 (controller) - mirrors: delete aliyun mirrors 7533a65 (controller) - heroku: remove heroku-16 support e5a885d (controller) - controller:check mount volume path 9014e74 (controller) - test: optimization Dockerfile.test 0b6ebb2 (controller) - tasks: change apply_async parameters 835f009 (controller) - wsgi: add tornado 6 support 67a4ad7 (controller) - utils: use threads replace asyncio a28949b (controller) - ldap: add AUTH_LDAP_USER_FLAGS_BY_GROUP a903209 (controller) - charts: add custom controller environment variables support e0e783e (controller) - ldap: change filter style d760825 (controller) - scheduler: remove debug log a25928e (controller) - wsgi: remove a wsgi.py file 7b2696e (controller) - log: disable nsq.client info log 8d5c07b (controller) - charts: add default environment 025f4a2 (controller) - controller: change quota name ebda60e (controller) - controller: review pvc code 8832ba9 (controller) - controller: change status\\binding model type and mount path check container_types 7148d04 (controller) - controller: add overcommit cpu and ram support 4d2087c (controller) - limits: modify limits unit verification af36970 (controller) - api: check cpu/memory range for api 329355b (controller) - volumes: modify the volume size 9dfee09 (controller) - LimitRanges: modify the default limits 5205bca (controller) - controller: improve the details of certificate 7ebecdf (database) - mc: upgrade mc to RELEASE.2019-05-23T01-33-27Z 6415e2c (database) - postgres: upgrade to pg13 12e6806 (database) - charts: upgrade k8s newer API versions d294509 (database) - minio: use canary minio test 1bad02e (database) - mirrors: delete aliyun mirrors d51420b (database) - minio: use bin mc replace docker images 4133d05 (dockerbuilder) - dockerbuilder: update caddy and kaniko 6b4dd18 (dockerbuilder) - minio: use bin mc replace docker images 6df9b7c (fluentd) - deps-dev: update rake requirement from ~> 10.0 to ~> 12.3 c2490f8 (fluentd) - fluentd: upgrade fluentd be4a56a (fluentd) - fluentd: add Gemfile.lock 2237f75 (fluentd) - charts: upgrade k8s newer API versions c574065 (fluentd) - charts: upgrade k8s newer API versions 52b8084 (fluentd) - router: delete obsolete router code 3b3cceb (fluentd) - fluentd: remove manifests dir 25c6702 (fluentd) - nsqd: change var name bd571be (fluentd) - nsqd: change DRYCC_NSQD_ADDRESSES to DRYCC_NSQD_ADDRS 72aa4e6 (fluentd) - influxdb: change influxdb service name bd61903 (logger) - logger: use go mod replace dep 69c63a1 (logger) - logger: update go.mod 3aa9cd7 (logger) - registry: del quay.io f058496 (logger) - nsqd: change var name 6d9787c (logger) - nsqd: change DRYCC_NSQD_ADDRESSES to DRYCC_NSQD_ADDRS 85ed307 (logger) - logger: standard naming d88e7b6 (minio) - minio: update minio api to v7 43715d2 (minio) - minio: upgrade minio 0e1239b (minio) - minio: use docker.io replace quay.io f7f047b (minio) - registry: del quay.io afa7128 (minio) - build: upgrade go.mod aff2db5 (minio) - charts: upgrade k8s newer API versions 4547f14 (minio) - pkg: upgrade to new drycc/pkg 2769b85 (minio) - minio: use bin mc replace docker images 35dde8d (monitor) - monitor: update grafana influxdb telegraf 9e3a949 (monitor) - charts: upgrade k8s newer API versions 6af0432 (monitor) - workflow-manager: remove workflow-manager 0611c07 (monitor) - router: delete obsolete router code be04824 (monitor) - cert_manager: change cert_manager_enabled to global 3780165 (monitor) - charts: change platform_domain to global 50b04e1 (monitor) - influxdb: remove influxdb admin ui 6ab4d68 (monitor) - influxdb: remove unuse port f1510bd (monitor) - monitor: update grafana dashboard,telegraf inputs.kubernetes f36de2c (monitor) - pvc: upgrade to new format fc78a0a (monitor) - workflow: remove namespace e85890f (monitor) - monitor: monitoring nsqd and redis separately 694f6b1 (monitor) - mirrors: delete aliyun mirrors 4aea36a (monitor) - grafana: add ldap support for grafana 68fc30f (nsqd) - nsq: update nsq 16f32aa (nsqd) - charts: upgrade k8s newer API versions 04db389 (redis) - reids: update to redis 6 3f01bab (redis) - charts: upgrade k8s newer API versions 647e4be (registry) - registry: del quay.io 0bbce99 (registry) - charts: upgrade k8s newer API versions a982b50 (registry) - minio: use bin mc replace docker images e088da3 (registry-proxy) - ingress: renmae use_native_ingress to use_ingress 7e88337 (registry-proxy) - nginx: upgrade nginx to mainline 7204d72 (registry-proxy) - registry: optimizing variable naming 2eafc59 (registry-proxy) - registry-proxy: update nginx 071bd86 (registry-proxy) - charts: upgrade k8s newer API versions c72db96 (registry-proxy) - registry-proxy: change travis icon url ca9f962 (slugbuilder) - slugbuilder: del BUILDPACK_URL support 1b74dd5 (slugbuilder) - slugbuilder: add heroku-20 support 54d4ad2 (slugbuilder) - slugbuilder: del quay.io a78f37e (slugbuilder) - slugbuilder: add heroku-20 stack 94ac94a (slugbuilder) - minio: use bin mc replace docker images 53b4b8b (slugbuilder) - slugbuilder: modify stack priority 58e2bd2 (slugbuilder) - dockerfile: add WORKDIR /tmp b29cd04 (slugbuilder) - slugbuilder: add pre_build.sh 9d319f6 (slugbuilder) - slugbuilder: silent mc command output d1ec3c9 (slugbuilder) - heroku: remove heroku-16 support 5048534 (slugbuilder) - slugbuilder: use drycc stack-images a116537 (slugrunner) - slugrunner: add heroku-20 support a1196bf (slugrunner) - slugrunner: del quay.io 64c96d7 (slugrunner) - slugrunner: add heroku-20 stack cc3e226 (slugrunner) - minio: use bin mc replace docker images 9130bde (slugrunner) - shellcheck: shellcheck installer 4ea33e1 (slugrunner) - slugrunner: modify stack priority 5514e8b (slugrunner) - heroku: remove heroku-16 support be829fb (slugrunner) - slugrunner: use drycc stack-images e1e06be (slugrunner) - slugrunner: remove Dockerfile.heroku-16","title":"Maintenance"},{"location":"contributing/community/","text":"Community \u00b6 Drycc software is fully open source. As such, the \"Drycc community\" consists of anyone who uses the Drycc software and participates in its evolution, whether by answering questions, finding bugs, suggesting enhancements, or writing documentation or code. Drycc development is coordinated through numerous project repositories on GitHub . Anyone can check out the source code for any Drycc component, fork it, make improvements, and create a pull request to offer those changes back to the Drycc community. Engine Yard maintains the numerous Drycc projects, and as such, decides what ends up in the official GitHub repositories. Drycc depends on the contributions of the community; the maintainers will not ignore pull requests or issues. Drycc uses the timeless, highly efficient, and totally unfair system known as \"Benevolent Dictator for Life\" ( BDFL ). Gabriel Monroy , the creator of Drycc, is our BDFL and has final say over all decisions related to Drycc. Open Source Bounties \u00b6 Drycc projects are bounty-friendly. We believe open source bounty sites can be constructive tools in the development of open source software. Community members are encouraged to a) offer bounties and b) receive bounties for open source contributions that benefit everyone. The Drycc maintainers, however, will not accept bounties on this project but are more than happy to help community members attempting bounties.","title":"Community"},{"location":"contributing/community/#community","text":"Drycc software is fully open source. As such, the \"Drycc community\" consists of anyone who uses the Drycc software and participates in its evolution, whether by answering questions, finding bugs, suggesting enhancements, or writing documentation or code. Drycc development is coordinated through numerous project repositories on GitHub . Anyone can check out the source code for any Drycc component, fork it, make improvements, and create a pull request to offer those changes back to the Drycc community. Engine Yard maintains the numerous Drycc projects, and as such, decides what ends up in the official GitHub repositories. Drycc depends on the contributions of the community; the maintainers will not ignore pull requests or issues. Drycc uses the timeless, highly efficient, and totally unfair system known as \"Benevolent Dictator for Life\" ( BDFL ). Gabriel Monroy , the creator of Drycc, is our BDFL and has final say over all decisions related to Drycc.","title":"Community"},{"location":"contributing/community/#open-source-bounties","text":"Drycc projects are bounty-friendly. We believe open source bounty sites can be constructive tools in the development of open source software. Community members are encouraged to a) offer bounties and b) receive bounties for open source contributions that benefit everyone. The Drycc maintainers, however, will not accept bounties on this project but are more than happy to help community members attempting bounties.","title":"Open Source Bounties"},{"location":"contributing/conduct/","text":"Conduct \u00b6 The Drycc community welcomes and encourages participation by everyone . No matter how you identify yourself or how others perceive you: we welcome you. We welcome contributions from everyone as long as they interact constructively with our community. The Drycc developer community continues to grow, and it is inevitable that disagreements and conflict will arise. We ask that participants conduct themselves according to these principles: Be welcoming, friendly, and patient. Be considerate. Your work will be used by other people, and you in turn will depend on the work of others. Any decision you take will affect users and colleagues, and you should take those consequences into account when making decisions. Remember that we're a world-wide community, so you might not be communicating in someone else's primary language. Be respectful. Not all of us will agree all the time, but disagreement is no excuse for poor behavior and bad manners. We might all experience some frustration now and then, but we cannot allow that frustration to turn into a personal attack. It\u2019s important to remember that a community where people feel uncomfortable or threatened is not a productive one. Be careful in the words that you choose. Be kind to others. Do not insult or put down other participants. Behave professionally. Remember that harassment and sexist, racist, or exclusionary jokes are never appropriate for the community. (Thanks to the Debian and Django communities for their text and their inspiration.)","title":"Conduct"},{"location":"contributing/conduct/#conduct","text":"The Drycc community welcomes and encourages participation by everyone . No matter how you identify yourself or how others perceive you: we welcome you. We welcome contributions from everyone as long as they interact constructively with our community. The Drycc developer community continues to grow, and it is inevitable that disagreements and conflict will arise. We ask that participants conduct themselves according to these principles: Be welcoming, friendly, and patient. Be considerate. Your work will be used by other people, and you in turn will depend on the work of others. Any decision you take will affect users and colleagues, and you should take those consequences into account when making decisions. Remember that we're a world-wide community, so you might not be communicating in someone else's primary language. Be respectful. Not all of us will agree all the time, but disagreement is no excuse for poor behavior and bad manners. We might all experience some frustration now and then, but we cannot allow that frustration to turn into a personal attack. It\u2019s important to remember that a community where people feel uncomfortable or threatened is not a productive one. Be careful in the words that you choose. Be kind to others. Do not insult or put down other participants. Behave professionally. Remember that harassment and sexist, racist, or exclusionary jokes are never appropriate for the community. (Thanks to the Debian and Django communities for their text and their inspiration.)","title":"Conduct"},{"location":"contributing/design-documents/","text":"Design Documents \u00b6 Before submitting a pull request which will significantly alter the behavior of any Drycc component, such as a new feature or major refactoring, contributors should first open an issue representing a design document. Goals \u00b6 Design documents help ensure project contributors: Involve stakeholders as early as possible in a feature's development Ensure code changes accomplish the original motivations and design goals Establish clear acceptance criteria for a feature or change Enforce test-driven design methodology and automated test coverage Contents \u00b6 Design document issues should be named Design Doc: <change description> and contain the following sections: Goal \u00b6 This section should briefly describe the proposed change and the motivations behind it. Tests will be written to ensure this design goal is met by the change. This section should also reference a separate GitHub issue tracking the feature or change, which will typically be assigned to a release milestone. Code Changes \u00b6 This section should detail the code changes necessary to accomplish the change, as well as the proposed implementation. This should be as detailed as necessary to help reviewers understand the change. Tests \u00b6 All changes should be covered by automated tests, either unit or integration tests (ideally both). This section should detail how tests will be written to validate that the change accomplishes the design goals and doesn't introduce any regressions. If a change cannot be sufficiently covered by automated testing, the design should be reconsidered. If there is no test coverage whatsoever for an affected section of code, a separate issue should be filed to integrate automated testing with that section of the codebase. The tests described here also form the acceptance criteria for the change, so that when it's completed maintainers can merge the pull request after confirming the tests pass CI. Approval \u00b6 A design document follows the same merge approval review process as final pull requests do, and maintainers will take extra care to ensure that any stakeholders for the change are included in the discussion and review of the design document. Once the design is accepted, the author can complete the change and submit a pull request for review. The pull request should close both the design document for the change as well as any issues that either track the issue or are closed as a result of the change. See Submitting a Pull Request for more information on pull request and commit message formatting.","title":"Design Documents"},{"location":"contributing/design-documents/#design-documents","text":"Before submitting a pull request which will significantly alter the behavior of any Drycc component, such as a new feature or major refactoring, contributors should first open an issue representing a design document.","title":"Design Documents"},{"location":"contributing/design-documents/#goals","text":"Design documents help ensure project contributors: Involve stakeholders as early as possible in a feature's development Ensure code changes accomplish the original motivations and design goals Establish clear acceptance criteria for a feature or change Enforce test-driven design methodology and automated test coverage","title":"Goals"},{"location":"contributing/design-documents/#contents","text":"Design document issues should be named Design Doc: <change description> and contain the following sections:","title":"Contents"},{"location":"contributing/design-documents/#goal","text":"This section should briefly describe the proposed change and the motivations behind it. Tests will be written to ensure this design goal is met by the change. This section should also reference a separate GitHub issue tracking the feature or change, which will typically be assigned to a release milestone.","title":"Goal"},{"location":"contributing/design-documents/#code-changes","text":"This section should detail the code changes necessary to accomplish the change, as well as the proposed implementation. This should be as detailed as necessary to help reviewers understand the change.","title":"Code Changes"},{"location":"contributing/design-documents/#tests","text":"All changes should be covered by automated tests, either unit or integration tests (ideally both). This section should detail how tests will be written to validate that the change accomplishes the design goals and doesn't introduce any regressions. If a change cannot be sufficiently covered by automated testing, the design should be reconsidered. If there is no test coverage whatsoever for an affected section of code, a separate issue should be filed to integrate automated testing with that section of the codebase. The tests described here also form the acceptance criteria for the change, so that when it's completed maintainers can merge the pull request after confirming the tests pass CI.","title":"Tests"},{"location":"contributing/design-documents/#approval","text":"A design document follows the same merge approval review process as final pull requests do, and maintainers will take extra care to ensure that any stakeholders for the change are included in the discussion and review of the design document. Once the design is accepted, the author can complete the change and submit a pull request for review. The pull request should close both the design document for the change as well as any issues that either track the issue or are closed as a result of the change. See Submitting a Pull Request for more information on pull request and commit message formatting.","title":"Approval"},{"location":"contributing/development-environment/","text":"Development Environment \u00b6 This document is for developers who are interested in working directly on the Drycc codebase. In this guide, we walk you through the process of setting up a development environment that is suitable for hacking on most Drycc components. We try to make it simple to hack on Drycc components. However, there are necessarily several moving pieces and some setup required. We welcome any suggestions for automating or simplifying this process. Note The Drycc team is actively engaged in containerizing Go and Python based development environments tailored specifically for Drycc development in order to minimize the setup required. This work is ongoing. Refer to the drycc/router project for a working example of a fully containerized development environment. If you're just getting into the Drycc codebase, look for GitHub issues with the label easy-fix . These are more straightforward or low-risk issues and are a great way to become more familiar with Drycc. Prerequisites \u00b6 In order to successfully compile and test Drycc binaries and build Docker images of Drycc components, the following are required: git Go 1.5 or later, with support for compiling to linux/amd64 glide golint shellcheck Docker (in a non-Linux environment, you will additionally want Docker Machine ) For drycc/controller , in particular, you will also need: Python 2.7 or later (with pip ) virtualenv ( sudo pip install virtualenv ) In most cases, you should simply install according to the instructions. There are a few special cases, though. We cover these below. Configuring Go \u00b6 If your local workstation does not support the linux/amd64 target environment, you will have to install Go from source with cross-compile support for that environment. This is because some of the components are built on your local machine and then injected into a Docker container. Homebrew users can just install with cross compiling support: $ brew install go --with-cc-common It is also straightforward to build Go from source: $ sudo su $ curl -sSL https://golang.org/dl/go1.5.src.tar.gz | tar -v -C /usr/local -xz $ cd /usr/local/go/src $ # compile Go for our default platform first, then add cross-compile support $ ./make.bash --no-clean $ GOOS=linux GOARCH=amd64 ./make.bash --no-clean Once you can compile to linux/amd64 , you should be able to compile Drycc components as normal. Configuring Docker Machine (Mac) \u00b6 Drycc needs Docker for building images. Docker utilizes a client/server architecture, and while the Docker client is available for Mac OS, the Docker server is dependent upon the Linux kernel. Therefore, in order to use Docker on Mac OS, Docker Machine is used to facilitate running the Docker server within a VirtualBox VM. Install Docker Machine according to the normal installation instructions, then use it to create a new VM: $ docker-machine create drycc-docker \\ --driver=virtualbox \\ --virtualbox-disk-size=100000 \\ --engine-insecure-registry 10.0.0.0/8 \\ --engine-insecure-registry 172.16.0.0/12 \\ --engine-insecure-registry 192.168.0.0/16 \\ --engine-insecure-registry 100.64.0.0/10 This will create a new virtual machine named drycc-docker that will take up as much as 100,000 MB of disk space. The images you build may be large, so allocating a big disk is a good idea. Once the drycc-docker machine exists, source its values into your environment so your docker client knows how to use the new machine. You may even choose to add this to your bash profile or similar. $ eval \"$(docker-machine env drycc-docker)\" After following these steps, some Docker Machine users report a slight delay (30 - 60 seconds) before the Docker server is ready. Note In subsequent steps, you may run a Docker registry within the drycc-docker VM. Such a registry will not have a valid SSL certificate and will use HTTP instead of HTTPS. Such registries are implicitly untrusted by the Docker server (which is also running on the drycc-docker VM). In order for the Docker server to trust the insecure registry, drycc-docker is explicitly created to trust all registries in the IP ranges that that are reserved for use by private networks. The VM (and therefore the registry) will exist within such a range. This will effectively permit Docker pulls and pushes to such a registry. Fork the Repository \u00b6 Once the prerequisites have been met, we can begin to work with Drycc components. Begin at Github by forking whichever Drycc project you would like to contribute to, then clone that fork locally. Since Drycc is predominantly written in Go, the best place to put it is under $GOPATH/src/github.com/drycc/ . $ mkdir -p $GOPATH/src/github.com/drycc $ cd $GOPATH/src/github.com/drycc $ git clone git@github.com:<username>/<component>.git $ cd <component> Note By checking out the forked copy into the namespace github.com/drycc/<component> , we are tricking the Go toolchain into seeing our fork as the \"official\" source tree. If you are going to be issuing pull requests to the upstream repository from which you forked, we suggest configuring Git such that you can easily rebase your code to the upstream repository's master branch. There are various strategies for doing this, but the most common is to add an upstream remote: $ git remote add upstream https://github.com/drycc/<component>.git For the sake of simplicity, you may want to point an environment variable to your Drycc code - the directory containing one or more Drycc components: $ export DRYCC=$GOPATH/src/github.com/drycc Throughout the rest of this document, $DRYCC refers to that location. Alternative: Forking with a Pushurl \u00b6 A number of Drycc contributors prefer to pull directly from drycc/<component> , but push to <username>/<component> . If that workflow suits you better, you can set it up this way: $ git clone git@github.com:drycc/<component>.git $ cd drycc $ git config remote.origin.pushurl git@github.com:<username>/<component>.git In this setup, fetching and pulling code will work directly with the upstream repository, while pushing code will send changes to your fork. This makes it easy to stay up to date, but also make changes and then issue pull requests. Make Your Changes \u00b6 With your development environment set up and the code you wish to work on forked and cloned, you can begin making your changes. Test Your Changes \u00b6 Drycc components each include a comprehensive suite of automated tests, mostly written in Go. See testing for instructions on running the tests. Deploying Your Changes \u00b6 Although writing and executing tests are critical to ensuring code quality, most contributors will also want to deploy their changes to a live environment, whether to make use of those changes or to test them further. The remainder of this section documents the procedure for running officially released Drycc components in a development cluster and replacing any one of those with your customizations. Running a Kubernetes Cluster for Development \u00b6 To run a Kubernetes cluster locally or elsewhere to support your development activities, refer to Drycc installation instructions here . Using a Development Registry \u00b6 To facilitate deploying Docker images containing your changes to your Kubernetes cluster, you will need to make use of a Docker registry. This is a location to where you can push your custom-built images and from where your Kubernetes cluster can retrieve those same images. If your development cluster runs locally (in Minikube, for instance), the most efficient and economical means of achieving this is to run a Docker registry locally as a Docker container. To facilitate this, most Drycc components provide a make target to create such a registry: $ make dev-registry In a Linux environment, to begin using the registry: export DRYCC_REGISTRY=<IP of the host machine>:5000 In non-Linux environments: export DRYCC_REGISTRY=<IP of the drycc-docker Docker Machine VM>:5000/ If your development cluster runs on a cloud provider such as Google Container Engine, a local registry such as the one above will not be accessible to your Kubernetes nodes. In such cases, a public registry such as DockerHub or quay.io will suffice. To use DockerHub for this purpose, for instance: $ export DRYCC_REGISTRY=\"\" $ export IMAGE_PREFIX=<your DockerHub username> To use quay.io: $ export DRYCC_REGISTRY=quay.io/ $ export IMAGE_PREFIX=<your quay.io username> Note the importance of the trailing slash. Dev / Deployment Workflow \u00b6 With a functioning Kubernetes cluster and the officially released Drycc components installed onto it, deployment and further testing of any Drycc component you have made changes to is facilitated by replacing the officially released component with a custom built image that contains your changes. Most Drycc components include Makefiles with targets specifically intended to facilitate this workflow with minimal friction. In the general case, this workflow looks like this: Update source code and commit your changes using git Use make build to build a new Docker image Use make dev-release to generate Kubernetes manifest(s) Use make deploy to restart the component using the updated manifest This can be shortened to a one-liner using just the deploy target: $ make deploy Useful Commands \u00b6 Once your customized Drycc component has been deployed, here are some helpful commands that will allow you to inspect your cluster and to troubleshoot, if necessary: See All Drycc Pods \u00b6 $ kubectl --namespace=drycc get pods Describe a Pod \u00b6 This is often useful for troubleshooting pods that are in pending or crashed states: $ kubectl --namespace=drycc describe -f <pod name> Tail Logs \u00b6 $ kubectl --namespace=drycc logs -f <pod name> Django Shell \u00b6 Specific to drycc/controller $ kubectl --namespace=drycc exec -it <pod name> -- python manage.py shell Have commands other Drycc contributors might find useful? Send us a PR! Pull Requests \u00b6 Satisfied with your changes? Share them! Please read Submitting a Pull Request . It contains a checklist of things you should do when proposing a change to any Drycc component.","title":"Development Environment"},{"location":"contributing/development-environment/#development-environment","text":"This document is for developers who are interested in working directly on the Drycc codebase. In this guide, we walk you through the process of setting up a development environment that is suitable for hacking on most Drycc components. We try to make it simple to hack on Drycc components. However, there are necessarily several moving pieces and some setup required. We welcome any suggestions for automating or simplifying this process. Note The Drycc team is actively engaged in containerizing Go and Python based development environments tailored specifically for Drycc development in order to minimize the setup required. This work is ongoing. Refer to the drycc/router project for a working example of a fully containerized development environment. If you're just getting into the Drycc codebase, look for GitHub issues with the label easy-fix . These are more straightforward or low-risk issues and are a great way to become more familiar with Drycc.","title":"Development Environment"},{"location":"contributing/development-environment/#prerequisites","text":"In order to successfully compile and test Drycc binaries and build Docker images of Drycc components, the following are required: git Go 1.5 or later, with support for compiling to linux/amd64 glide golint shellcheck Docker (in a non-Linux environment, you will additionally want Docker Machine ) For drycc/controller , in particular, you will also need: Python 2.7 or later (with pip ) virtualenv ( sudo pip install virtualenv ) In most cases, you should simply install according to the instructions. There are a few special cases, though. We cover these below.","title":"Prerequisites"},{"location":"contributing/development-environment/#configuring-go","text":"If your local workstation does not support the linux/amd64 target environment, you will have to install Go from source with cross-compile support for that environment. This is because some of the components are built on your local machine and then injected into a Docker container. Homebrew users can just install with cross compiling support: $ brew install go --with-cc-common It is also straightforward to build Go from source: $ sudo su $ curl -sSL https://golang.org/dl/go1.5.src.tar.gz | tar -v -C /usr/local -xz $ cd /usr/local/go/src $ # compile Go for our default platform first, then add cross-compile support $ ./make.bash --no-clean $ GOOS=linux GOARCH=amd64 ./make.bash --no-clean Once you can compile to linux/amd64 , you should be able to compile Drycc components as normal.","title":"Configuring Go"},{"location":"contributing/development-environment/#configuring-docker-machine-mac","text":"Drycc needs Docker for building images. Docker utilizes a client/server architecture, and while the Docker client is available for Mac OS, the Docker server is dependent upon the Linux kernel. Therefore, in order to use Docker on Mac OS, Docker Machine is used to facilitate running the Docker server within a VirtualBox VM. Install Docker Machine according to the normal installation instructions, then use it to create a new VM: $ docker-machine create drycc-docker \\ --driver=virtualbox \\ --virtualbox-disk-size=100000 \\ --engine-insecure-registry 10.0.0.0/8 \\ --engine-insecure-registry 172.16.0.0/12 \\ --engine-insecure-registry 192.168.0.0/16 \\ --engine-insecure-registry 100.64.0.0/10 This will create a new virtual machine named drycc-docker that will take up as much as 100,000 MB of disk space. The images you build may be large, so allocating a big disk is a good idea. Once the drycc-docker machine exists, source its values into your environment so your docker client knows how to use the new machine. You may even choose to add this to your bash profile or similar. $ eval \"$(docker-machine env drycc-docker)\" After following these steps, some Docker Machine users report a slight delay (30 - 60 seconds) before the Docker server is ready. Note In subsequent steps, you may run a Docker registry within the drycc-docker VM. Such a registry will not have a valid SSL certificate and will use HTTP instead of HTTPS. Such registries are implicitly untrusted by the Docker server (which is also running on the drycc-docker VM). In order for the Docker server to trust the insecure registry, drycc-docker is explicitly created to trust all registries in the IP ranges that that are reserved for use by private networks. The VM (and therefore the registry) will exist within such a range. This will effectively permit Docker pulls and pushes to such a registry.","title":"Configuring Docker Machine (Mac)"},{"location":"contributing/development-environment/#fork-the-repository","text":"Once the prerequisites have been met, we can begin to work with Drycc components. Begin at Github by forking whichever Drycc project you would like to contribute to, then clone that fork locally. Since Drycc is predominantly written in Go, the best place to put it is under $GOPATH/src/github.com/drycc/ . $ mkdir -p $GOPATH/src/github.com/drycc $ cd $GOPATH/src/github.com/drycc $ git clone git@github.com:<username>/<component>.git $ cd <component> Note By checking out the forked copy into the namespace github.com/drycc/<component> , we are tricking the Go toolchain into seeing our fork as the \"official\" source tree. If you are going to be issuing pull requests to the upstream repository from which you forked, we suggest configuring Git such that you can easily rebase your code to the upstream repository's master branch. There are various strategies for doing this, but the most common is to add an upstream remote: $ git remote add upstream https://github.com/drycc/<component>.git For the sake of simplicity, you may want to point an environment variable to your Drycc code - the directory containing one or more Drycc components: $ export DRYCC=$GOPATH/src/github.com/drycc Throughout the rest of this document, $DRYCC refers to that location.","title":"Fork the Repository"},{"location":"contributing/development-environment/#alternative-forking-with-a-pushurl","text":"A number of Drycc contributors prefer to pull directly from drycc/<component> , but push to <username>/<component> . If that workflow suits you better, you can set it up this way: $ git clone git@github.com:drycc/<component>.git $ cd drycc $ git config remote.origin.pushurl git@github.com:<username>/<component>.git In this setup, fetching and pulling code will work directly with the upstream repository, while pushing code will send changes to your fork. This makes it easy to stay up to date, but also make changes and then issue pull requests.","title":"Alternative: Forking with a Pushurl"},{"location":"contributing/development-environment/#make-your-changes","text":"With your development environment set up and the code you wish to work on forked and cloned, you can begin making your changes.","title":"Make Your Changes"},{"location":"contributing/development-environment/#test-your-changes","text":"Drycc components each include a comprehensive suite of automated tests, mostly written in Go. See testing for instructions on running the tests.","title":"Test Your Changes"},{"location":"contributing/development-environment/#deploying-your-changes","text":"Although writing and executing tests are critical to ensuring code quality, most contributors will also want to deploy their changes to a live environment, whether to make use of those changes or to test them further. The remainder of this section documents the procedure for running officially released Drycc components in a development cluster and replacing any one of those with your customizations.","title":"Deploying Your Changes"},{"location":"contributing/development-environment/#running-a-kubernetes-cluster-for-development","text":"To run a Kubernetes cluster locally or elsewhere to support your development activities, refer to Drycc installation instructions here .","title":"Running a Kubernetes Cluster for Development"},{"location":"contributing/development-environment/#using-a-development-registry","text":"To facilitate deploying Docker images containing your changes to your Kubernetes cluster, you will need to make use of a Docker registry. This is a location to where you can push your custom-built images and from where your Kubernetes cluster can retrieve those same images. If your development cluster runs locally (in Minikube, for instance), the most efficient and economical means of achieving this is to run a Docker registry locally as a Docker container. To facilitate this, most Drycc components provide a make target to create such a registry: $ make dev-registry In a Linux environment, to begin using the registry: export DRYCC_REGISTRY=<IP of the host machine>:5000 In non-Linux environments: export DRYCC_REGISTRY=<IP of the drycc-docker Docker Machine VM>:5000/ If your development cluster runs on a cloud provider such as Google Container Engine, a local registry such as the one above will not be accessible to your Kubernetes nodes. In such cases, a public registry such as DockerHub or quay.io will suffice. To use DockerHub for this purpose, for instance: $ export DRYCC_REGISTRY=\"\" $ export IMAGE_PREFIX=<your DockerHub username> To use quay.io: $ export DRYCC_REGISTRY=quay.io/ $ export IMAGE_PREFIX=<your quay.io username> Note the importance of the trailing slash.","title":"Using a Development Registry"},{"location":"contributing/development-environment/#dev-deployment-workflow","text":"With a functioning Kubernetes cluster and the officially released Drycc components installed onto it, deployment and further testing of any Drycc component you have made changes to is facilitated by replacing the officially released component with a custom built image that contains your changes. Most Drycc components include Makefiles with targets specifically intended to facilitate this workflow with minimal friction. In the general case, this workflow looks like this: Update source code and commit your changes using git Use make build to build a new Docker image Use make dev-release to generate Kubernetes manifest(s) Use make deploy to restart the component using the updated manifest This can be shortened to a one-liner using just the deploy target: $ make deploy","title":"Dev / Deployment Workflow"},{"location":"contributing/development-environment/#useful-commands","text":"Once your customized Drycc component has been deployed, here are some helpful commands that will allow you to inspect your cluster and to troubleshoot, if necessary:","title":"Useful Commands"},{"location":"contributing/development-environment/#see-all-drycc-pods","text":"$ kubectl --namespace=drycc get pods","title":"See All Drycc Pods"},{"location":"contributing/development-environment/#describe-a-pod","text":"This is often useful for troubleshooting pods that are in pending or crashed states: $ kubectl --namespace=drycc describe -f <pod name>","title":"Describe a Pod"},{"location":"contributing/development-environment/#tail-logs","text":"$ kubectl --namespace=drycc logs -f <pod name>","title":"Tail Logs"},{"location":"contributing/development-environment/#django-shell","text":"Specific to drycc/controller $ kubectl --namespace=drycc exec -it <pod name> -- python manage.py shell Have commands other Drycc contributors might find useful? Send us a PR!","title":"Django Shell"},{"location":"contributing/development-environment/#pull-requests","text":"Satisfied with your changes? Share them! Please read Submitting a Pull Request . It contains a checklist of things you should do when proposing a change to any Drycc component.","title":"Pull Requests"},{"location":"contributing/maintainers/","text":"Drycc Maintainers \u00b6 This document serves to describe the leadership structure of the Drycc project, and list the current project maintainers. What is a maintainer? \u00b6 (Unabashedly stolen from the Docker project) There are different types of maintainers, with different responsibilities, but all maintainers have 3 things in common: They share responsibility in the project's success. They have made a long-term, recurring time investment to improve the project. They spend that time doing whatever needs to be done, not necessarily what is the most interesting or fun. Maintainers are often under-appreciated, because their work is harder to appreciate. It's easy to appreciate a really cool and technically advanced feature. It's harder to appreciate the absence of bugs, the slow but steady improvement in stability, or the reliability of a release process. But those things distinguish a good project from a great one. Drycc maintainers \u00b6 Drycc has two groups of maintainers in addition to our beloved Benevolent Dictator for Life. BDFL \u00b6 Drycc follows the timeless, highly efficient and totally unfair system known as Benevolent dictator for life . Gabriel Monroy ( @gabrtv ), as creator of the Drycc project, serves as our project's BDFL. While the day-to-day project management is carried out by the maintainers, Gabriel serves as the final arbiter of any disputes and has the final say on project direction. Core maintainers \u00b6 Core maintainers are exceptionally knowledgeable about all areas of Drycc. Some maintainers work on Drycc full-time, although this is not a requirement. The duties of a core maintainer include: Classify and respond to GitHub issues and review pull requests Help to shape the Drycc roadmap and lead efforts to accomplish roadmap milestones Participate actively in feature development and bug fixing Answer questions and help users in the Drycc #community Slack channel The current list of core maintainers can be seen here . No pull requests can be merged until at least one core maintainer signs off with an LGTM . The other LGTM can come from either a core maintainer or contributing maintainer. Contributing maintainers \u00b6 Contributing maintainers are exceptionally knowledgeable about some but not necessarily all areas of Drycc, and are often selected due to specific domain knowledge that complements the project (but a willingness to continually contribute to the project is most important!). Often, core maintainers will ask a contributing maintainer to weigh in on issues, pull requests, or conversations where the contributing maintainer is knowledgeable. The duties of a contributing maintainer are very similar to those of a core maintainer, but they are limited to areas of the Drycc project where the contributing maintainer is knowledgeable. Contributing maintainers are defined in practice as those who have write access to the Drycc repository. All maintainers can review pull requests and add LGTM labels as appropriate. Becoming a maintainer \u00b6 The Drycc project wouldn't be where it is today without its community. Many of the project's community members embody the spirit of maintainership, and have contributed substantially to the project. The contributing maintainers group was created in part so that exceptional members of the community who have an interest in the continued success of the project have the opportunity to join the core maintainers in guiding the future of Drycc. Generally, potential contributing maintainers are selected by the Drycc core maintainers based in part on the following criteria: Sustained contributions to the project over a period of time (usually months) A willingness to help Drycc users on GitHub and in the Drycc #community Slack channel A friendly attitude :) The Drycc core maintainers must unanimously agree before inviting a community member to join as a contributing maintainer, although in many cases the candidate has already been acting in the capacity of a contributing maintainer for some time, and has been consulted on issues, pull requests, etc.","title":"Maintainers"},{"location":"contributing/maintainers/#drycc-maintainers","text":"This document serves to describe the leadership structure of the Drycc project, and list the current project maintainers.","title":"Drycc Maintainers"},{"location":"contributing/maintainers/#what-is-a-maintainer","text":"(Unabashedly stolen from the Docker project) There are different types of maintainers, with different responsibilities, but all maintainers have 3 things in common: They share responsibility in the project's success. They have made a long-term, recurring time investment to improve the project. They spend that time doing whatever needs to be done, not necessarily what is the most interesting or fun. Maintainers are often under-appreciated, because their work is harder to appreciate. It's easy to appreciate a really cool and technically advanced feature. It's harder to appreciate the absence of bugs, the slow but steady improvement in stability, or the reliability of a release process. But those things distinguish a good project from a great one.","title":"What is a maintainer?"},{"location":"contributing/maintainers/#drycc-maintainers_1","text":"Drycc has two groups of maintainers in addition to our beloved Benevolent Dictator for Life.","title":"Drycc maintainers"},{"location":"contributing/maintainers/#bdfl","text":"Drycc follows the timeless, highly efficient and totally unfair system known as Benevolent dictator for life . Gabriel Monroy ( @gabrtv ), as creator of the Drycc project, serves as our project's BDFL. While the day-to-day project management is carried out by the maintainers, Gabriel serves as the final arbiter of any disputes and has the final say on project direction.","title":"BDFL"},{"location":"contributing/maintainers/#core-maintainers","text":"Core maintainers are exceptionally knowledgeable about all areas of Drycc. Some maintainers work on Drycc full-time, although this is not a requirement. The duties of a core maintainer include: Classify and respond to GitHub issues and review pull requests Help to shape the Drycc roadmap and lead efforts to accomplish roadmap milestones Participate actively in feature development and bug fixing Answer questions and help users in the Drycc #community Slack channel The current list of core maintainers can be seen here . No pull requests can be merged until at least one core maintainer signs off with an LGTM . The other LGTM can come from either a core maintainer or contributing maintainer.","title":"Core maintainers"},{"location":"contributing/maintainers/#contributing-maintainers","text":"Contributing maintainers are exceptionally knowledgeable about some but not necessarily all areas of Drycc, and are often selected due to specific domain knowledge that complements the project (but a willingness to continually contribute to the project is most important!). Often, core maintainers will ask a contributing maintainer to weigh in on issues, pull requests, or conversations where the contributing maintainer is knowledgeable. The duties of a contributing maintainer are very similar to those of a core maintainer, but they are limited to areas of the Drycc project where the contributing maintainer is knowledgeable. Contributing maintainers are defined in practice as those who have write access to the Drycc repository. All maintainers can review pull requests and add LGTM labels as appropriate.","title":"Contributing maintainers"},{"location":"contributing/maintainers/#becoming-a-maintainer","text":"The Drycc project wouldn't be where it is today without its community. Many of the project's community members embody the spirit of maintainership, and have contributed substantially to the project. The contributing maintainers group was created in part so that exceptional members of the community who have an interest in the continued success of the project have the opportunity to join the core maintainers in guiding the future of Drycc. Generally, potential contributing maintainers are selected by the Drycc core maintainers based in part on the following criteria: Sustained contributions to the project over a period of time (usually months) A willingness to help Drycc users on GitHub and in the Drycc #community Slack channel A friendly attitude :) The Drycc core maintainers must unanimously agree before inviting a community member to join as a contributing maintainer, although in many cases the candidate has already been acting in the capacity of a contributing maintainer for some time, and has been consulted on issues, pull requests, etc.","title":"Becoming a maintainer"},{"location":"contributing/overview/","text":"Contributor Overview \u00b6 Interested in contributing to a Drycc project? There are lots of ways to help. File Bugs & Enhancements \u00b6 Find a bug? Want to see a new feature? Have a request for the maintainers? Open a Github issue in the applicable repository and we\u2019ll get the conversation started. Our official support channel is the Drycc #community Slack channel . Don't know what the applicable repository for an issue is? Open up in issue in workflow or chat with a maintainer in the Drycc #community Slack channel and we'll make sure it gets to the right place. Additionally, take a look at the troubleshooting documentation for common issues. Before opening a new issue, it's helpful to search and see if anyone else has already reported the problem. You can search through a list of issues for all Drycc projects here . Write Documentation \u00b6 We are always looking to improve and expand our documentation. Most docs reside in the drycc/workflow repository. Simply fork the project, update docs and send us a pull request. Contribute Code \u00b6 We are always looking for help improving the core platform, other workloads, tooling, and test coverage. Interested in contributing code? Let\u2019s chat in the Drycc #community Slack channel . Make sure to check out issues tagged easy fix or help wanted . When you're ready to begin writing code, review Design Documents and get your Development Environment set up. By contributing to any Drycc project you agree to its Developer Certificate of Origin (DCO) . This document was created by the Linux Kernel community and is a simple statement that you, as a contributor, have the legal right to make the contribution. Triage Issues \u00b6 If you don't have time to code, consider helping with triage. The community will thank you for saving them time by spending some of yours. See Triaging Issues for more info. Share your Experience \u00b6 Interact with the community on our user mailing list or live in our Drycc #community Slack channel , where you can chat with other Drycc Workflow users any time of day.","title":"Overview"},{"location":"contributing/overview/#contributor-overview","text":"Interested in contributing to a Drycc project? There are lots of ways to help.","title":"Contributor Overview"},{"location":"contributing/overview/#file-bugs-enhancements","text":"Find a bug? Want to see a new feature? Have a request for the maintainers? Open a Github issue in the applicable repository and we\u2019ll get the conversation started. Our official support channel is the Drycc #community Slack channel . Don't know what the applicable repository for an issue is? Open up in issue in workflow or chat with a maintainer in the Drycc #community Slack channel and we'll make sure it gets to the right place. Additionally, take a look at the troubleshooting documentation for common issues. Before opening a new issue, it's helpful to search and see if anyone else has already reported the problem. You can search through a list of issues for all Drycc projects here .","title":"File Bugs &amp; Enhancements"},{"location":"contributing/overview/#write-documentation","text":"We are always looking to improve and expand our documentation. Most docs reside in the drycc/workflow repository. Simply fork the project, update docs and send us a pull request.","title":"Write Documentation"},{"location":"contributing/overview/#contribute-code","text":"We are always looking for help improving the core platform, other workloads, tooling, and test coverage. Interested in contributing code? Let\u2019s chat in the Drycc #community Slack channel . Make sure to check out issues tagged easy fix or help wanted . When you're ready to begin writing code, review Design Documents and get your Development Environment set up. By contributing to any Drycc project you agree to its Developer Certificate of Origin (DCO) . This document was created by the Linux Kernel community and is a simple statement that you, as a contributor, have the legal right to make the contribution.","title":"Contribute Code"},{"location":"contributing/overview/#triage-issues","text":"If you don't have time to code, consider helping with triage. The community will thank you for saving them time by spending some of yours. See Triaging Issues for more info.","title":"Triage Issues"},{"location":"contributing/overview/#share-your-experience","text":"Interact with the community on our user mailing list or live in our Drycc #community Slack channel , where you can chat with other Drycc Workflow users any time of day.","title":"Share your Experience"},{"location":"contributing/submitting-a-pull-request/","text":"Submitting a Pull Request \u00b6 Proposed changes to Drycc projects are made as GitHub pull requests. Design Document \u00b6 Before opening a pull request, ensure your change also references a design document if the contribution is substantial. For more information, see Design Documents . Single Issue \u00b6 It's hard to reach agreement on the merit of a PR when it isn't focused. When fixing an issue or implementing a new feature, resist the temptation to refactor nearby code or to fix that potential bug you noticed. Instead, open a separate issue or pull request. Keeping concerns separated allows pull requests to be tested, reviewed, and merged more quickly. Squash and rebase the commit or commits in your pull request into logical units of work with git . Include tests and documentation changes in the same commit, so that a revert would remove all traces of the feature or fix. Most pull requests will reference a GitHub issue. In the PR description - not in the commit itself - include a line such as \"closes #1234\". The issue referenced will automatically be closed when your PR is merged. Include Tests \u00b6 If you significantly alter or add functionality to a component that impacts the broader Drycc Workflow PaaS, you should submit a complementary PR to modify or amend end-to-end integration tests. These integration tests can be found in the drycc/workflow-e2e repository. See testing for more information. Include Docs \u00b6 Changes to any Drycc Workflow component that could affect a user's experience also require a change or addition to the relevant documentation. For most Drycc components, this involves updating the component's own documentation. In some cases where a component is tightly integrated into drycc/workflow , its documentation must also be updated. Cross-repo commits \u00b6 If a pull request is part of a larger piece of work involving one or more additional commits in other Workflow repositories, these commits can be referenced in the last PR to be submitted. The downstream e2e test job will then supply every referenced commit (derived from PR issue number supplied) to the test runner so it can source the necessary Docker images for inclusion in the generated Workflow chart to be tested. For example, consider paired commits in drycc/controller and drycc/workflow-e2e . The commit body for the first PR in drycc/workflow-e2e would look like: feat(foo_test): add e2e test for feature foo [skip e2e] test for controller#42 Adding [skip e2e] forgoes the e2e tests on this commit. This and any other required PRs aside from the final PR should be submitted first, so that their respective build and image push jobs run. Lastly, the final PR in drycc/controller should be created with the required PR number(s) listed, in the form of [Rr]equires <repoName>#<pullRequestNumber> , for use by the downstream e2e run. feat(foo): add feature foo Requires workflow-e2e#42 Code Standards \u00b6 Drycc components are implemented in Go and Python . For both languages, we agree with The Zen of Python , which emphasizes simple over clever. Readability counts. Go code should always be run through gofmt on the default settings. Lines of code may be up to 99 characters long. Documentation strings and tests are required for all exported functions. Use of third-party go packages should be minimal, but when doing so, such dependencies should be managed via the glide tool. Python code should always adhere to PEP8 , the python code style guide, with the exception that lines of code may be up to 99 characters long. Docstrings and tests are required for all public methods, although the flake8 tool used by Drycc does not enforce this. Commit Style \u00b6 We follow a convention for commit messages borrowed from CoreOS, who borrowed theirs from AngularJS. This is an example of a commit: feat(scripts/test-cluster): add a cluster test command this uses tmux to setup a test cluster that you can easily kill and start for debugging. To make it more formal, it looks something like this: {type}({scope}): {subject} <BLANK LINE> {body} <BLANK LINE> {footer} The allowed {types} are as follows: feat -> feature fix -> bug fix docs -> documentation style -> formatting ref -> refactoring code test -> adding missing tests chore -> maintenance The {scope} can be anything specifying the location(s) of the commit change(s). The {subject} needs to be an imperative, present tense verb: \u201cchange\u201d, not \u201cchanged\u201d nor \u201cchanges\u201d. The first letter should not be capitalized, and there is no dot (.) at the end. Just like the {subject} , the message {body} needs to be in the present tense, and includes the motivation for the change, as well as a contrast with the previous behavior. The first letter in a paragraph must be capitalized. All breaking changes need to be mentioned in the {footer} with the description of the change, the justification behind the change and any migration notes required. Any line of the commit message cannot be longer than 72 characters, with the subject line limited to 50 characters. This allows the message to be easier to read on GitHub as well as in various git tools. Merge Approval \u00b6 Any code change - other than a simple typo fix or one-line documentation change - requires at least two Drycc maintainers to accept it. Maintainers tag pull requests with \" LGTM1 \" and \" LGTM2 \" (Looks Good To Me) labels to indicate acceptance. No pull requests can be merged until at least one core maintainer signs off with an LGTM. The other LGTM can come from either a core maintainer or contributing maintainer. If the PR is from a Drycc maintainer, then he or she should be the one to close it. This keeps the commit stream clean and gives the maintainer the benefit of revisiting the PR before deciding whether or not to merge the changes. An exception to this is when an errant commit needs to be reverted urgently. If necessary, a PR that only reverts a previous commit can be merged without waiting for LGTM approval.","title":"Submitting a Pull Request"},{"location":"contributing/submitting-a-pull-request/#submitting-a-pull-request","text":"Proposed changes to Drycc projects are made as GitHub pull requests.","title":"Submitting a Pull Request"},{"location":"contributing/submitting-a-pull-request/#design-document","text":"Before opening a pull request, ensure your change also references a design document if the contribution is substantial. For more information, see Design Documents .","title":"Design Document"},{"location":"contributing/submitting-a-pull-request/#single-issue","text":"It's hard to reach agreement on the merit of a PR when it isn't focused. When fixing an issue or implementing a new feature, resist the temptation to refactor nearby code or to fix that potential bug you noticed. Instead, open a separate issue or pull request. Keeping concerns separated allows pull requests to be tested, reviewed, and merged more quickly. Squash and rebase the commit or commits in your pull request into logical units of work with git . Include tests and documentation changes in the same commit, so that a revert would remove all traces of the feature or fix. Most pull requests will reference a GitHub issue. In the PR description - not in the commit itself - include a line such as \"closes #1234\". The issue referenced will automatically be closed when your PR is merged.","title":"Single Issue"},{"location":"contributing/submitting-a-pull-request/#include-tests","text":"If you significantly alter or add functionality to a component that impacts the broader Drycc Workflow PaaS, you should submit a complementary PR to modify or amend end-to-end integration tests. These integration tests can be found in the drycc/workflow-e2e repository. See testing for more information.","title":"Include Tests"},{"location":"contributing/submitting-a-pull-request/#include-docs","text":"Changes to any Drycc Workflow component that could affect a user's experience also require a change or addition to the relevant documentation. For most Drycc components, this involves updating the component's own documentation. In some cases where a component is tightly integrated into drycc/workflow , its documentation must also be updated.","title":"Include Docs"},{"location":"contributing/submitting-a-pull-request/#cross-repo-commits","text":"If a pull request is part of a larger piece of work involving one or more additional commits in other Workflow repositories, these commits can be referenced in the last PR to be submitted. The downstream e2e test job will then supply every referenced commit (derived from PR issue number supplied) to the test runner so it can source the necessary Docker images for inclusion in the generated Workflow chart to be tested. For example, consider paired commits in drycc/controller and drycc/workflow-e2e . The commit body for the first PR in drycc/workflow-e2e would look like: feat(foo_test): add e2e test for feature foo [skip e2e] test for controller#42 Adding [skip e2e] forgoes the e2e tests on this commit. This and any other required PRs aside from the final PR should be submitted first, so that their respective build and image push jobs run. Lastly, the final PR in drycc/controller should be created with the required PR number(s) listed, in the form of [Rr]equires <repoName>#<pullRequestNumber> , for use by the downstream e2e run. feat(foo): add feature foo Requires workflow-e2e#42","title":"Cross-repo commits"},{"location":"contributing/submitting-a-pull-request/#code-standards","text":"Drycc components are implemented in Go and Python . For both languages, we agree with The Zen of Python , which emphasizes simple over clever. Readability counts. Go code should always be run through gofmt on the default settings. Lines of code may be up to 99 characters long. Documentation strings and tests are required for all exported functions. Use of third-party go packages should be minimal, but when doing so, such dependencies should be managed via the glide tool. Python code should always adhere to PEP8 , the python code style guide, with the exception that lines of code may be up to 99 characters long. Docstrings and tests are required for all public methods, although the flake8 tool used by Drycc does not enforce this.","title":"Code Standards"},{"location":"contributing/submitting-a-pull-request/#commit-style","text":"We follow a convention for commit messages borrowed from CoreOS, who borrowed theirs from AngularJS. This is an example of a commit: feat(scripts/test-cluster): add a cluster test command this uses tmux to setup a test cluster that you can easily kill and start for debugging. To make it more formal, it looks something like this: {type}({scope}): {subject} <BLANK LINE> {body} <BLANK LINE> {footer} The allowed {types} are as follows: feat -> feature fix -> bug fix docs -> documentation style -> formatting ref -> refactoring code test -> adding missing tests chore -> maintenance The {scope} can be anything specifying the location(s) of the commit change(s). The {subject} needs to be an imperative, present tense verb: \u201cchange\u201d, not \u201cchanged\u201d nor \u201cchanges\u201d. The first letter should not be capitalized, and there is no dot (.) at the end. Just like the {subject} , the message {body} needs to be in the present tense, and includes the motivation for the change, as well as a contrast with the previous behavior. The first letter in a paragraph must be capitalized. All breaking changes need to be mentioned in the {footer} with the description of the change, the justification behind the change and any migration notes required. Any line of the commit message cannot be longer than 72 characters, with the subject line limited to 50 characters. This allows the message to be easier to read on GitHub as well as in various git tools.","title":"Commit Style"},{"location":"contributing/submitting-a-pull-request/#merge-approval","text":"Any code change - other than a simple typo fix or one-line documentation change - requires at least two Drycc maintainers to accept it. Maintainers tag pull requests with \" LGTM1 \" and \" LGTM2 \" (Looks Good To Me) labels to indicate acceptance. No pull requests can be merged until at least one core maintainer signs off with an LGTM. The other LGTM can come from either a core maintainer or contributing maintainer. If the PR is from a Drycc maintainer, then he or she should be the one to close it. This keeps the commit stream clean and gives the maintainer the benefit of revisiting the PR before deciding whether or not to merge the changes. An exception to this is when an errant commit needs to be reverted urgently. If necessary, a PR that only reverts a previous commit can be merged without waiting for LGTM approval.","title":"Merge Approval"},{"location":"contributing/testing/","text":"Testing Drycc \u00b6 Each Drycc component is one among an ecosystem of such components - many of which integrate with one another - which makes testing each component thoroughly a matter of paramount importance. Each Drycc component includes its own suite of style checks, unit tests , and black-box type functional tests . Integration tests verify the behavior of the Drycc components together as a system and are provided separately by the drycc/workflow-e2e project. GitHub pull requests for all Drycc components are tested automatically by the Travis CI continuous integration system. Contributors should run the same tests locally before proposing any changes to the Drycc codebase. Set Up the Environment \u00b6 Successfully executing the unit and functional tests for any Drycc component requires that the Development Environment is set up first. Run the Tests \u00b6 The style checks, unit tests, and functional tests for each component can all be executed via make targets: To execute style checks: $ make test-style To execute unit tests: $ make test-unit To execute functional tests: $ make test-functional To execute style checks, unit tests, and functional tests all in one shot: $ make test To execute integration tests, refer to drycc/workflow-e2e documentation.","title":"Testing"},{"location":"contributing/testing/#testing-drycc","text":"Each Drycc component is one among an ecosystem of such components - many of which integrate with one another - which makes testing each component thoroughly a matter of paramount importance. Each Drycc component includes its own suite of style checks, unit tests , and black-box type functional tests . Integration tests verify the behavior of the Drycc components together as a system and are provided separately by the drycc/workflow-e2e project. GitHub pull requests for all Drycc components are tested automatically by the Travis CI continuous integration system. Contributors should run the same tests locally before proposing any changes to the Drycc codebase.","title":"Testing Drycc"},{"location":"contributing/testing/#set-up-the-environment","text":"Successfully executing the unit and functional tests for any Drycc component requires that the Development Environment is set up first.","title":"Set Up the Environment"},{"location":"contributing/testing/#run-the-tests","text":"The style checks, unit tests, and functional tests for each component can all be executed via make targets: To execute style checks: $ make test-style To execute unit tests: $ make test-unit To execute functional tests: $ make test-functional To execute style checks, unit tests, and functional tests all in one shot: $ make test To execute integration tests, refer to drycc/workflow-e2e documentation.","title":"Run the Tests"},{"location":"contributing/triaging-issues/","text":"Triaging Issues \u00b6 Issue triage provides an important way to contribute to an open source project. Triage helps ensure issues resolve quickly by: Describing the issue's intent and purpose is conveyed precisely. This is necessary because it can be difficult for an issue to explain how an end user experiences an problem and what actions they took. Giving a contributor the information they need before they commit to resolving an issue. Lowering the issue count by preventing duplicate issues. Streamlining the development process by preventing duplicate discussions. If you don't have time to code, consider helping with triage. The community will thank you for saving them time by spending some of yours. Ensure the Issue Contains Basic Information \u00b6 Before triaging an issue very far, make sure that the issue's author provided the standard issue information. This will help you make an educated recommendation on how this to categorize the issue. Standard information that should be included in most issues are things such as: the version(s) of Drycc this issue affects a reproducible case if this is a bug page URL if this is a docs issue or the name of a man page Depending on the issue, you might not feel all this information is needed. Use your best judgment. If you cannot triage an issue using what its author provided, explain kindly to the author that they must provide the above information to clarify the problem. If the author provides the recommended information but you are still unable to triage the issue, request additional information. Do this kindly and politely because you are asking for more of the author's time. If the author does not respond requested information within the timespan of a week, close the issue with a kind note stating that the author can request for the issue to be reopened when the necessary information is provided. Classifying the Issue \u00b6 An issue can have multiple of the following labels: Issue Kind \u00b6 Kind Description bug Bugs are bugs. The cause may or may not be known at triage time so debugging should be taken account into the time estimate. docs Writing documentation, man pages, articles, blogs, or other significant word-driven task. enhancement Enhancements can drastically improve usability or performance of a component. question Contains a user or contributor question requiring a response. security Security-related issues such as TLS encryption, network segregation, authn/authz features, etc. Functional Area \u00b6 builder cache contrib and provisioning client controller database docs kubernetes registry router store (Ceph) tests Easy Fix \u00b6 \"Easy Fix\" issues are a way for a new contributor to find issues that are fit for their experience level. These issues are typically for users who are new to Drycc, and possibly Go, and is looking to help while learning the basics. Prioritizing issues \u00b6 When attached to a specific milestone, an issue can be attributed one of the following labels to indicate their degree of priority. Priority Description priority 0 Urgent: Security, critical bugs, blocking issues. Drop everything and fix this today, then consider creating a patch release. priority 1 Serious: Impedes user actions or is a regression. Fix this before the next planned release. And that's it. That should be all the information required for a new or existing contributor to come in an resolve an issue.","title":"Triaging Issues"},{"location":"contributing/triaging-issues/#triaging-issues","text":"Issue triage provides an important way to contribute to an open source project. Triage helps ensure issues resolve quickly by: Describing the issue's intent and purpose is conveyed precisely. This is necessary because it can be difficult for an issue to explain how an end user experiences an problem and what actions they took. Giving a contributor the information they need before they commit to resolving an issue. Lowering the issue count by preventing duplicate issues. Streamlining the development process by preventing duplicate discussions. If you don't have time to code, consider helping with triage. The community will thank you for saving them time by spending some of yours.","title":"Triaging Issues"},{"location":"contributing/triaging-issues/#ensure-the-issue-contains-basic-information","text":"Before triaging an issue very far, make sure that the issue's author provided the standard issue information. This will help you make an educated recommendation on how this to categorize the issue. Standard information that should be included in most issues are things such as: the version(s) of Drycc this issue affects a reproducible case if this is a bug page URL if this is a docs issue or the name of a man page Depending on the issue, you might not feel all this information is needed. Use your best judgment. If you cannot triage an issue using what its author provided, explain kindly to the author that they must provide the above information to clarify the problem. If the author provides the recommended information but you are still unable to triage the issue, request additional information. Do this kindly and politely because you are asking for more of the author's time. If the author does not respond requested information within the timespan of a week, close the issue with a kind note stating that the author can request for the issue to be reopened when the necessary information is provided.","title":"Ensure the Issue Contains Basic Information"},{"location":"contributing/triaging-issues/#classifying-the-issue","text":"An issue can have multiple of the following labels:","title":"Classifying the Issue"},{"location":"contributing/triaging-issues/#issue-kind","text":"Kind Description bug Bugs are bugs. The cause may or may not be known at triage time so debugging should be taken account into the time estimate. docs Writing documentation, man pages, articles, blogs, or other significant word-driven task. enhancement Enhancements can drastically improve usability or performance of a component. question Contains a user or contributor question requiring a response. security Security-related issues such as TLS encryption, network segregation, authn/authz features, etc.","title":"Issue Kind"},{"location":"contributing/triaging-issues/#functional-area","text":"builder cache contrib and provisioning client controller database docs kubernetes registry router store (Ceph) tests","title":"Functional Area"},{"location":"contributing/triaging-issues/#easy-fix","text":"\"Easy Fix\" issues are a way for a new contributor to find issues that are fit for their experience level. These issues are typically for users who are new to Drycc, and possibly Go, and is looking to help while learning the basics.","title":"Easy Fix"},{"location":"contributing/triaging-issues/#prioritizing-issues","text":"When attached to a specific milestone, an issue can be attributed one of the following labels to indicate their degree of priority. Priority Description priority 0 Urgent: Security, critical bugs, blocking issues. Drop everything and fix this today, then consider creating a patch release. priority 1 Serious: Impedes user actions or is a regression. Fix this before the next planned release. And that's it. That should be all the information required for a new or existing contributor to come in an resolve an issue.","title":"Prioritizing issues"},{"location":"diagrams/","text":"Architecture Diagrams \u00b6 This is an OmniGraffle file which holds the source materials for the following images. To update a chart: Make your modification! Select \"File > Export\" Select \"Entire Document Choose: Scale: 100% Set Bitmap Resolution to 72 dpi (for web) Uncheck \"Transparent Background\" Select \"images\" directory Click \"Export\" This should update all of the graphics in one go! Commit and pull-request.","title":"Architecture Diagrams"},{"location":"diagrams/#architecture-diagrams","text":"This is an OmniGraffle file which holds the source materials for the following images. To update a chart: Make your modification! Select \"File > Export\" Select \"Entire Document Choose: Scale: 100% Set Bitmap Resolution to 72 dpi (for web) Uncheck \"Transparent Background\" Select \"images\" directory Click \"Export\" This should update all of the graphics in one go! Commit and pull-request.","title":"Architecture Diagrams"},{"location":"installing-workflow/","text":"Installing Drycc Workflow \u00b6 This document is aimed at those who have already provisioned a [Kubernetes v1.12+][] cluster and want to install Drycc Workflow. If help is required getting started with Kubernetes and Drycc Workflow, follow the quickstart guide for assistance. Prerequisites \u00b6 Verify the Kubernetes system requirements Install Helm and Drycc Workflow CLI tools Check Your Setup \u00b6 Check that the helm command is available and the version is v2.5.0 or newer. $ helm version Client: &version.Version{SemVer:\"v2.5.0\", GitCommit:\"012cb0ac1a1b2f888144ef5a67b8dab6c2d45be6\", GitTreeState:\"clean\"} Server: &version.Version{SemVer:\"v2.5.0\", GitCommit:\"012cb0ac1a1b2f888144ef5a67b8dab6c2d45be6\", GitTreeState:\"clean\"} Choose Your Deployment Strategy \u00b6 Drycc Workflow includes everything it needs to run out of the box. However, these defaults are aimed at simplicity rather than production readiness. Production and staging deployments of Workflow should, at a minimum, use off-cluster storage which is used by Workflow components to store and backup critical data. Should an operator need to completely re-install Workflow, the required components can recover from off-cluster storage. See the documentation for configuring object storage for more details. More rigorous installations would benefit from using outside sources for the following things: * Postgres - For example AWS RDS. * Registry - This includes quay.io , dockerhub , Amazon ECR , and Google GCR . * Redis - Such as AWS Elasticache * InfluxDB and Grafana Ingress \u00b6 Now, workflow requires that ingress and cert-manager must be installed. Any compatible Kubernetes entry controller can be used, but only ingress-nginx and ingress-traefik currently support enforced HTTPS and whitelist. Enable entries in accordance with this guide . Add the Drycc Chart Repository \u00b6 The Drycc Chart Repository contains everything needed to install Drycc Workflow onto a Kubernetes cluster, with a single helm install drycc/workflow --namespace drycc --set global.platform_domain=yourdomain.com command. Add this repository to Helm: $ helm repo add drycc https://charts.drycc.cc/stable Install Drycc Workflow \u00b6 If the version of helm is 3.0 +; you need to create the namespace in advance: kubectl create ns drycc Now that Helm is installed and the repository has been added, install Workflow by running: $ helm install --namespace drycc \\ --set global.platform_domain=drycc.cc \\ drycc/workflow Helm will install a variety of Kubernetes resources in the drycc namespace. Wait for the pods that Helm launched to be ready. Monitor their status by running: $ kubectl --namespace=drycc get pods If it's preferred to have kubectl automatically update as the pod states change, run (type Ctrl-C to stop the watch): $ kubectl --namespace=drycc get pods -w Depending on the order in which the Workflow components initialize, some pods may restart. This is common during the installation: if a component's dependencies are not yet available, that component will exit and Kubernetes will automatically restart it. Here, it can be seen that the controller, builder and registry all took a few loops before they were able to start: $ kubectl --namespace=drycc get pods NAME READY STATUS RESTARTS AGE drycc-builder-574483744-l15zj 1/1 Running 0 4m drycc-controller-3953262871-pncgq 1/1 Running 2 4m drycc-database-83844344-47ld6 1/1 Running 0 4m drycc-logger-176328999-wjckx 1/1 Running 4 4m drycc-logger-fluentd-zxnqb 1/1 Running 0 4m drycc-logger-redis-304849759-1f35p 1/1 Running 0 4m drycc-minio-676004970-nxqgt 1/1 Running 0 4m drycc-monitor-grafana-432627134-lnl2h 1/1 Running 0 4m drycc-monitor-influxdb-2729788615-m9b5n 1/1 Running 0 4m drycc-monitor-telegraf-wmcmn 1/1 Running 1 4m drycc-nsqd-3597503299-6mn2x 1/1 Running 0 4m drycc-registry-756475849-lwc6b 1/1 Running 1 4m drycc-registry-proxy-96c4p 1/1 Running 0 4m Once all of the pods are in the READY state, Drycc Workflow is up and running! After installing Workflow, register a user and deploy an application .","title":"Installing Workflow"},{"location":"installing-workflow/#installing-drycc-workflow","text":"This document is aimed at those who have already provisioned a [Kubernetes v1.12+][] cluster and want to install Drycc Workflow. If help is required getting started with Kubernetes and Drycc Workflow, follow the quickstart guide for assistance.","title":"Installing Drycc Workflow"},{"location":"installing-workflow/#prerequisites","text":"Verify the Kubernetes system requirements Install Helm and Drycc Workflow CLI tools","title":"Prerequisites"},{"location":"installing-workflow/#check-your-setup","text":"Check that the helm command is available and the version is v2.5.0 or newer. $ helm version Client: &version.Version{SemVer:\"v2.5.0\", GitCommit:\"012cb0ac1a1b2f888144ef5a67b8dab6c2d45be6\", GitTreeState:\"clean\"} Server: &version.Version{SemVer:\"v2.5.0\", GitCommit:\"012cb0ac1a1b2f888144ef5a67b8dab6c2d45be6\", GitTreeState:\"clean\"}","title":"Check Your Setup"},{"location":"installing-workflow/#choose-your-deployment-strategy","text":"Drycc Workflow includes everything it needs to run out of the box. However, these defaults are aimed at simplicity rather than production readiness. Production and staging deployments of Workflow should, at a minimum, use off-cluster storage which is used by Workflow components to store and backup critical data. Should an operator need to completely re-install Workflow, the required components can recover from off-cluster storage. See the documentation for configuring object storage for more details. More rigorous installations would benefit from using outside sources for the following things: * Postgres - For example AWS RDS. * Registry - This includes quay.io , dockerhub , Amazon ECR , and Google GCR . * Redis - Such as AWS Elasticache * InfluxDB and Grafana","title":"Choose Your Deployment Strategy"},{"location":"installing-workflow/#ingress","text":"Now, workflow requires that ingress and cert-manager must be installed. Any compatible Kubernetes entry controller can be used, but only ingress-nginx and ingress-traefik currently support enforced HTTPS and whitelist. Enable entries in accordance with this guide .","title":"Ingress"},{"location":"installing-workflow/#add-the-drycc-chart-repository","text":"The Drycc Chart Repository contains everything needed to install Drycc Workflow onto a Kubernetes cluster, with a single helm install drycc/workflow --namespace drycc --set global.platform_domain=yourdomain.com command. Add this repository to Helm: $ helm repo add drycc https://charts.drycc.cc/stable","title":"Add the Drycc Chart Repository"},{"location":"installing-workflow/#install-drycc-workflow","text":"If the version of helm is 3.0 +; you need to create the namespace in advance: kubectl create ns drycc Now that Helm is installed and the repository has been added, install Workflow by running: $ helm install --namespace drycc \\ --set global.platform_domain=drycc.cc \\ drycc/workflow Helm will install a variety of Kubernetes resources in the drycc namespace. Wait for the pods that Helm launched to be ready. Monitor their status by running: $ kubectl --namespace=drycc get pods If it's preferred to have kubectl automatically update as the pod states change, run (type Ctrl-C to stop the watch): $ kubectl --namespace=drycc get pods -w Depending on the order in which the Workflow components initialize, some pods may restart. This is common during the installation: if a component's dependencies are not yet available, that component will exit and Kubernetes will automatically restart it. Here, it can be seen that the controller, builder and registry all took a few loops before they were able to start: $ kubectl --namespace=drycc get pods NAME READY STATUS RESTARTS AGE drycc-builder-574483744-l15zj 1/1 Running 0 4m drycc-controller-3953262871-pncgq 1/1 Running 2 4m drycc-database-83844344-47ld6 1/1 Running 0 4m drycc-logger-176328999-wjckx 1/1 Running 4 4m drycc-logger-fluentd-zxnqb 1/1 Running 0 4m drycc-logger-redis-304849759-1f35p 1/1 Running 0 4m drycc-minio-676004970-nxqgt 1/1 Running 0 4m drycc-monitor-grafana-432627134-lnl2h 1/1 Running 0 4m drycc-monitor-influxdb-2729788615-m9b5n 1/1 Running 0 4m drycc-monitor-telegraf-wmcmn 1/1 Running 1 4m drycc-nsqd-3597503299-6mn2x 1/1 Running 0 4m drycc-registry-756475849-lwc6b 1/1 Running 1 4m drycc-registry-proxy-96c4p 1/1 Running 0 4m Once all of the pods are in the READY state, Drycc Workflow is up and running! After installing Workflow, register a user and deploy an application .","title":"Install Drycc Workflow"},{"location":"installing-workflow/chart-provenance/","text":"Chart Provenance \u00b6 Drycc has released Kubernetes Helm charts for Workflow and for each of its components . Helm provides tools for establishing and verifying chart integrity. (For an overview, see the Provenance doc.) All release charts from the Drycc Workflow team are now signed using this mechanism. The full Drycc, Inc. (Helm chart signing key) <security@drycc.cc> public key can be found here , as well as the pgp.mit.edu keyserver and the official Drycc Keybase account . The key's fingerprint can be cross-checked against all of these sources. Verifying a signed chart \u00b6 The public key mentioned above must exist in a local keyring before a signed chart can be verified. To add it to the default ~/.gnupg/pubring.gpg keyring, any of the following commands will work: $ # via our hosted location $ curl https://drycc.cc/workflow/docs/security/1d6a97d0.txt | gpg --import $ # via the pgp.mit.edu keyserver $ gpg --keyserver pgp.mit.edu --recv-keys 1D6A97D0 $ # via Keybase with account... $ keybase follow drycc $ keybase pgp pull $ # via Keybase by curl $ curl https://keybase.io/drycc/key.asc | gpg --import Charts signed with this key can then be verified when fetched: $ helm repo add drycc https://charts.drycc.cc/stable \"drycc\" has been added to your repositories $ helm fetch --verify drycc/workflow --version v2.17.0 Verification: &{0xc420704c80 sha256:a2a140dca075a2eabe20422f1aa5bc1ce210b18a326472d6b2708e1a93afebea workflow-v2.17.0.tgz} One can then inspect the fetched workflow-v2.17.0.tgz.prov provenance file. If the chart was not signed, the command above would result in: Error: Failed to fetch provenance \"https://charts.drycc.cc/stable/workflow/workflow-v2.17.0.tgz.prov\" Alternatively, the chart can also be verified at install time: $ helm install --verify drycc/workflow --namespace drycc \\ --set global.platform_domain=yourdomain.com NAME: exiled-mink LAST DEPLOYED: Wed Aug 9 08:22:16 2017 NAMESPACE: drycc STATUS: DEPLOYED ... $ helm ls NAME REVISION UPDATED STATUS CHART exiled-mink 1 Wed Aug 9 08:22:16 2017 DEPLOYED workflow-v2.17.0 Having done so, one is assured of the origin and authenticity of any installed Workflow chart released by Drycc.","title":"Chart Provenance"},{"location":"installing-workflow/chart-provenance/#chart-provenance","text":"Drycc has released Kubernetes Helm charts for Workflow and for each of its components . Helm provides tools for establishing and verifying chart integrity. (For an overview, see the Provenance doc.) All release charts from the Drycc Workflow team are now signed using this mechanism. The full Drycc, Inc. (Helm chart signing key) <security@drycc.cc> public key can be found here , as well as the pgp.mit.edu keyserver and the official Drycc Keybase account . The key's fingerprint can be cross-checked against all of these sources.","title":"Chart Provenance"},{"location":"installing-workflow/chart-provenance/#verifying-a-signed-chart","text":"The public key mentioned above must exist in a local keyring before a signed chart can be verified. To add it to the default ~/.gnupg/pubring.gpg keyring, any of the following commands will work: $ # via our hosted location $ curl https://drycc.cc/workflow/docs/security/1d6a97d0.txt | gpg --import $ # via the pgp.mit.edu keyserver $ gpg --keyserver pgp.mit.edu --recv-keys 1D6A97D0 $ # via Keybase with account... $ keybase follow drycc $ keybase pgp pull $ # via Keybase by curl $ curl https://keybase.io/drycc/key.asc | gpg --import Charts signed with this key can then be verified when fetched: $ helm repo add drycc https://charts.drycc.cc/stable \"drycc\" has been added to your repositories $ helm fetch --verify drycc/workflow --version v2.17.0 Verification: &{0xc420704c80 sha256:a2a140dca075a2eabe20422f1aa5bc1ce210b18a326472d6b2708e1a93afebea workflow-v2.17.0.tgz} One can then inspect the fetched workflow-v2.17.0.tgz.prov provenance file. If the chart was not signed, the command above would result in: Error: Failed to fetch provenance \"https://charts.drycc.cc/stable/workflow/workflow-v2.17.0.tgz.prov\" Alternatively, the chart can also be verified at install time: $ helm install --verify drycc/workflow --namespace drycc \\ --set global.platform_domain=yourdomain.com NAME: exiled-mink LAST DEPLOYED: Wed Aug 9 08:22:16 2017 NAMESPACE: drycc STATUS: DEPLOYED ... $ helm ls NAME REVISION UPDATED STATUS CHART exiled-mink 1 Wed Aug 9 08:22:16 2017 DEPLOYED workflow-v2.17.0 Having done so, one is assured of the origin and authenticity of any installed Workflow chart released by Drycc.","title":"Verifying a signed chart"},{"location":"installing-workflow/configuring-object-storage/","text":"Configuring Object Storage \u00b6 A variety of Drycc Workflow components rely on an object storage system to do their work including storing application slugs, Docker images and database logs. Drycc Workflow ships with Minio by default, which provides in-cluster, ephemeral object storage. This means that if the Minio server crashes, all data will be lost . Therefore, Minio should be used for development or testing only . Configuring off-cluster Object Storage \u00b6 Every component that relies on object storage uses two inputs for configuration: Component-specific environment variables (e.g. BUILDER_STORAGE and REGISTRY_STORAGE ) Access credentials stored as a Kubernetes secret named objectstorage-keyfile The helm chart for Drycc Workflow can be easily configured to connect Workflow components to off-cluster object storage. Drycc Workflow currently supports Google Compute Storage, Amazon S3, Azure Blob Storage and OpenStack Swift Storage. Step 1: Create storage buckets \u00b6 Create storage buckets for each of the Workflow subsystems: builder , registry , and database . Depending on your chosen object storage you may need to provide globally unique bucket names. If you are using S3, use hyphens instead of periods in the bucket names. Using periods in the bucket name will cause an ssl certificate validation issue with S3 . If you provide credentials with sufficient access to the underlying storage, Workflow components will create the buckets if they do not exist. Step 2: Generate storage credentials \u00b6 If applicable, generate credentials that have create and write access to the storage buckets created in Step 1. If you are using AWS S3 and your Kubernetes nodes are configured with appropriate IAM API keys via InstanceRoles, you do not need to create API credentials. Do, however, validate that the InstanceRole has appropriate permissions to the configured buckets! Step 3: Add Drycc Repo \u00b6 If you haven't already added the Helm repo, do so with helm repo add drycc https://charts.drycc.cc/stable Step 4: Configure Workflow Chart \u00b6 Operators should configure object storage by editing the Helm values file before running helm install . To do so: Fetch the Helm values by running helm inspect values drycc/workflow > values.yaml Update the global/storage parameter to reference the platform you are using, e.g. s3 , azure , gcs , or swift Find the corresponding section for your storage type and provide appropriate values including region, bucket names, and access credentials. Save your changes. Note All values will be automatically (base64) encoded except the key_json values under gcs / gcr . These must be base64-encoded. This is to support cleanly passing said encoded text via helm --set cli functionality rather than attempting to pass the raw JSON data. For example: $ helm install workflow --namespace drycc \\ --set global.platform_domain=youdomain.com --set global.storage=gcs,gcs.key_json=\"$(cat /path/to/gcs_creds.json | base64 -w 0)\" You are now ready to run helm install drycc/workflow --namespace drycc -f values.yaml using your desired object storage.","title":"Configuring Object Storage"},{"location":"installing-workflow/configuring-object-storage/#configuring-object-storage","text":"A variety of Drycc Workflow components rely on an object storage system to do their work including storing application slugs, Docker images and database logs. Drycc Workflow ships with Minio by default, which provides in-cluster, ephemeral object storage. This means that if the Minio server crashes, all data will be lost . Therefore, Minio should be used for development or testing only .","title":"Configuring Object Storage"},{"location":"installing-workflow/configuring-object-storage/#configuring-off-cluster-object-storage","text":"Every component that relies on object storage uses two inputs for configuration: Component-specific environment variables (e.g. BUILDER_STORAGE and REGISTRY_STORAGE ) Access credentials stored as a Kubernetes secret named objectstorage-keyfile The helm chart for Drycc Workflow can be easily configured to connect Workflow components to off-cluster object storage. Drycc Workflow currently supports Google Compute Storage, Amazon S3, Azure Blob Storage and OpenStack Swift Storage.","title":"Configuring off-cluster Object Storage"},{"location":"installing-workflow/configuring-object-storage/#step-1-create-storage-buckets","text":"Create storage buckets for each of the Workflow subsystems: builder , registry , and database . Depending on your chosen object storage you may need to provide globally unique bucket names. If you are using S3, use hyphens instead of periods in the bucket names. Using periods in the bucket name will cause an ssl certificate validation issue with S3 . If you provide credentials with sufficient access to the underlying storage, Workflow components will create the buckets if they do not exist.","title":"Step 1: Create storage buckets"},{"location":"installing-workflow/configuring-object-storage/#step-2-generate-storage-credentials","text":"If applicable, generate credentials that have create and write access to the storage buckets created in Step 1. If you are using AWS S3 and your Kubernetes nodes are configured with appropriate IAM API keys via InstanceRoles, you do not need to create API credentials. Do, however, validate that the InstanceRole has appropriate permissions to the configured buckets!","title":"Step 2: Generate storage credentials"},{"location":"installing-workflow/configuring-object-storage/#step-3-add-drycc-repo","text":"If you haven't already added the Helm repo, do so with helm repo add drycc https://charts.drycc.cc/stable","title":"Step 3: Add Drycc Repo"},{"location":"installing-workflow/configuring-object-storage/#step-4-configure-workflow-chart","text":"Operators should configure object storage by editing the Helm values file before running helm install . To do so: Fetch the Helm values by running helm inspect values drycc/workflow > values.yaml Update the global/storage parameter to reference the platform you are using, e.g. s3 , azure , gcs , or swift Find the corresponding section for your storage type and provide appropriate values including region, bucket names, and access credentials. Save your changes. Note All values will be automatically (base64) encoded except the key_json values under gcs / gcr . These must be base64-encoded. This is to support cleanly passing said encoded text via helm --set cli functionality rather than attempting to pass the raw JSON data. For example: $ helm install workflow --namespace drycc \\ --set global.platform_domain=youdomain.com --set global.storage=gcs,gcs.key_json=\"$(cat /path/to/gcs_creds.json | base64 -w 0)\" You are now ready to run helm install drycc/workflow --namespace drycc -f values.yaml using your desired object storage.","title":"Step 4: Configure Workflow Chart"},{"location":"installing-workflow/configuring-postgres/","text":"Configuring Postgres \u00b6 Drycc Workflow's controller component relies on a PostgreSQL database to store platform state. By default, Drycc Workflow ships with the database component, which provides an in-cluster PostgreSQL database backed up to in-cluster or off-cluster object storage . Currently, for object storage, which is utilized by several Workflow components, only off-cluster solutions such as S3 or GCS are recommended in production environments. Experience has shown that many operators already opting for off-cluster object storage similarly prefer to host Postgres off-cluster as well, using Amazon RDS or similar. When excercising both options, a Workflow installation becomes entirely stateless, and is thus restored or rebuilt with greater ease should the need ever arise. Provisioning off-cluster Postgres \u00b6 First, provision a PostgreSQL RDBMS using the cloud provider or other infrastructure of your choice. Take care to ensure that security groups or other firewall rules will permit connectivity from your Kubernetes worker nodes, any of which may play host to the Workflow controller component. Take note of the following: The hostname or public IP of your PostgreSQL RDBMS The port on which your PostgreSQL RDBMS runs-- typically 5432 Within the off-cluster RDBMS, manually provision the following: A database user (take note of the username and password) A database owned by that user (take note of its name) If you are able to log into the RDBMS as a superuser or a user with appropriate permissions, this process will typically look like this: $ psql -h <host> -p <port> -d postgres -U <\"postgres\" or your own username> > create user <drycc username; typically \"drycc\"> with password '<password>'; > create database <database name; typically \"drycc\"> with owner <drycc username>; > \\q Configuring Workflow \u00b6 The Helm chart for Drycc Workflow can be easily configured to connect the Workflow controller component to an off-cluster PostgreSQL database. Step 1: If you haven't already fetched the values, do so with helm inspect values drycc/workflow > values.yaml Step 2: Update database connection details by modifying values.yaml : Update the database_location parameter to off-cluster . Update the values in the [database] configuration section to properly reflect all connection details. Update the values in the [controller] configuration section to properly reflect platform_domain details. Save your changes. Note: you do not need to (and must not) base64 encode any values, as the Helm chart will automatically handle encoding as necessary. You are now ready to helm install drycc/workflow --namespace drycc -f values.yaml as usual .","title":"Configuring Postgres"},{"location":"installing-workflow/configuring-postgres/#configuring-postgres","text":"Drycc Workflow's controller component relies on a PostgreSQL database to store platform state. By default, Drycc Workflow ships with the database component, which provides an in-cluster PostgreSQL database backed up to in-cluster or off-cluster object storage . Currently, for object storage, which is utilized by several Workflow components, only off-cluster solutions such as S3 or GCS are recommended in production environments. Experience has shown that many operators already opting for off-cluster object storage similarly prefer to host Postgres off-cluster as well, using Amazon RDS or similar. When excercising both options, a Workflow installation becomes entirely stateless, and is thus restored or rebuilt with greater ease should the need ever arise.","title":"Configuring Postgres"},{"location":"installing-workflow/configuring-postgres/#provisioning-off-cluster-postgres","text":"First, provision a PostgreSQL RDBMS using the cloud provider or other infrastructure of your choice. Take care to ensure that security groups or other firewall rules will permit connectivity from your Kubernetes worker nodes, any of which may play host to the Workflow controller component. Take note of the following: The hostname or public IP of your PostgreSQL RDBMS The port on which your PostgreSQL RDBMS runs-- typically 5432 Within the off-cluster RDBMS, manually provision the following: A database user (take note of the username and password) A database owned by that user (take note of its name) If you are able to log into the RDBMS as a superuser or a user with appropriate permissions, this process will typically look like this: $ psql -h <host> -p <port> -d postgres -U <\"postgres\" or your own username> > create user <drycc username; typically \"drycc\"> with password '<password>'; > create database <database name; typically \"drycc\"> with owner <drycc username>; > \\q","title":"Provisioning off-cluster Postgres"},{"location":"installing-workflow/configuring-postgres/#configuring-workflow","text":"The Helm chart for Drycc Workflow can be easily configured to connect the Workflow controller component to an off-cluster PostgreSQL database. Step 1: If you haven't already fetched the values, do so with helm inspect values drycc/workflow > values.yaml Step 2: Update database connection details by modifying values.yaml : Update the database_location parameter to off-cluster . Update the values in the [database] configuration section to properly reflect all connection details. Update the values in the [controller] configuration section to properly reflect platform_domain details. Save your changes. Note: you do not need to (and must not) base64 encode any values, as the Helm chart will automatically handle encoding as necessary. You are now ready to helm install drycc/workflow --namespace drycc -f values.yaml as usual .","title":"Configuring Workflow"},{"location":"installing-workflow/configuring-registry/","text":"Configuring Registry \u00b6 Drycc Workflow's builder component relies on a registry for storing application docker images. Drycc Workflow ships with a registry component by default, which provides an in-cluster Docker registry backed by the platform-configured object storage . Operators might want to use an off-cluster registry for performance or security reasons. Configuring Off-Cluster Private Registry \u00b6 Every component that relies on a registry uses two inputs for configuration: Registry Location environment variable named DRYCC_REGISTRY_LOCATION Access credentials stored as a Kubernetes secret named registry-secret The Helm chart for Drycc Workflow can be easily configured to connect Workflow components to off-cluster registry. Drycc Workflow supports external registries which provide either short-lived tokens that are valid only for a specified amount of time or long-lived tokens (basic username/password) which are valid forever for authenticating to them. For those registries which provide short lived tokens for authentication, Drycc Workflow will generate and refresh them such that the deployed apps will only have access to the short-lived tokens and not to the actual credentials for the registries. When using a private registry the docker images are no longer pulled by Drycc Workflow Controller but rather are managed by Kubernetes . This will increase security and overall speed, however the port information can no longer be discovered. Instead the port information can be set via drycc config:set PORT=<port> prior to deploying the application. Drycc Workflow currently supports: off-cluster: Any provider which supports long-lived username/password authentication, such as Azure Container Registry , Docker Hub , quay.io , or a self-hosted Docker registry. Configuration \u00b6 If you haven't already fetched the values file, do so with helm inspect values drycc/workflow > values.yaml Update registry location details by modifying the values file: Update the registry_location parameter to reference the registry location you are using: off-cluster , ecr , gcr Update the values in the section which corresponds to your registry location type. You are now ready to helm install drycc/workflow --namespace drycc -f values.yaml using your desired registry. Examples \u00b6 Here we show how the relevant parts of the fetched values.yaml file might look like after configuring for a particular off-cluster registry: Azure Container Registry (ACR) \u00b6 After following the docs and creating a registry, e.g. myregistry , with its corresponding login server of myregistry.azurecr.io , the following values should be supplied: global: ... registry_location: \"off-cluster\" ... registry-token-refresher: ... registry: hostname: \"myregistry.azurecr.io\" organization: \"myorg\" username: \"myusername\" password: \"mypassword\" ... Note: The mandatory organization field (here myorg ) will be created as an ACR repository if it does not already exist. Quay.io \u00b6 global: ... registry_location: \"off-cluster\" ... registry-token-refresher: ... registry: hostname: \"quay.io\" organization: \"myorg\" username: \"myusername\" password: \"mypassword\" ...","title":"Configuring the Registry"},{"location":"installing-workflow/configuring-registry/#configuring-registry","text":"Drycc Workflow's builder component relies on a registry for storing application docker images. Drycc Workflow ships with a registry component by default, which provides an in-cluster Docker registry backed by the platform-configured object storage . Operators might want to use an off-cluster registry for performance or security reasons.","title":"Configuring Registry"},{"location":"installing-workflow/configuring-registry/#configuring-off-cluster-private-registry","text":"Every component that relies on a registry uses two inputs for configuration: Registry Location environment variable named DRYCC_REGISTRY_LOCATION Access credentials stored as a Kubernetes secret named registry-secret The Helm chart for Drycc Workflow can be easily configured to connect Workflow components to off-cluster registry. Drycc Workflow supports external registries which provide either short-lived tokens that are valid only for a specified amount of time or long-lived tokens (basic username/password) which are valid forever for authenticating to them. For those registries which provide short lived tokens for authentication, Drycc Workflow will generate and refresh them such that the deployed apps will only have access to the short-lived tokens and not to the actual credentials for the registries. When using a private registry the docker images are no longer pulled by Drycc Workflow Controller but rather are managed by Kubernetes . This will increase security and overall speed, however the port information can no longer be discovered. Instead the port information can be set via drycc config:set PORT=<port> prior to deploying the application. Drycc Workflow currently supports: off-cluster: Any provider which supports long-lived username/password authentication, such as Azure Container Registry , Docker Hub , quay.io , or a self-hosted Docker registry.","title":"Configuring Off-Cluster Private Registry"},{"location":"installing-workflow/configuring-registry/#configuration","text":"If you haven't already fetched the values file, do so with helm inspect values drycc/workflow > values.yaml Update registry location details by modifying the values file: Update the registry_location parameter to reference the registry location you are using: off-cluster , ecr , gcr Update the values in the section which corresponds to your registry location type. You are now ready to helm install drycc/workflow --namespace drycc -f values.yaml using your desired registry.","title":"Configuration"},{"location":"installing-workflow/configuring-registry/#examples","text":"Here we show how the relevant parts of the fetched values.yaml file might look like after configuring for a particular off-cluster registry:","title":"Examples"},{"location":"installing-workflow/configuring-registry/#azure-container-registry-acr","text":"After following the docs and creating a registry, e.g. myregistry , with its corresponding login server of myregistry.azurecr.io , the following values should be supplied: global: ... registry_location: \"off-cluster\" ... registry-token-refresher: ... registry: hostname: \"myregistry.azurecr.io\" organization: \"myorg\" username: \"myusername\" password: \"mypassword\" ... Note: The mandatory organization field (here myorg ) will be created as an ACR repository if it does not already exist.","title":"Azure Container Registry (ACR)"},{"location":"installing-workflow/configuring-registry/#quayio","text":"global: ... registry_location: \"off-cluster\" ... registry-token-refresher: ... registry: hostname: \"quay.io\" organization: \"myorg\" username: \"myusername\" password: \"mypassword\" ...","title":"Quay.io"},{"location":"installing-workflow/ingress/","text":"Specify Ingress \u00b6 Install Drycc Workflow (Specify ingress) \u00b6 Now that Helm is installed and the repository has been added, install Workflow with a native ingress by running: $ helm install drycc/workflow --namespace drycc \\ --set global.ingress_class=nginx \\ --set global.platform_domain=drycc.cc \\ --set builder.service.type=LoadBalancer Of course, if you deploy it on a bare machine, you probably do not have Load Balancer. You need to use NodePort: $ helm install drycc/workflow --namespace drycc \\ --set global.ingress_class=nginx \\ --set global.platform_domain=drycc.cc \\ --set builder.service.type=NodePort \\ --set builder.service.nodePort=32222 If you want to use Load Balancer on a bare machine, you can look at metallb Where global.platform_domain is a required parameter that is traditionally not required for Workflow that is explained in the next section. In this example we are using drycc.cc for $hostname . Helm will install a variety of Kubernetes resources in the drycc namespace. Wait for the pods that Helm launched to be ready. Monitor their status by running: $ kubectl --namespace=drycc get pods You should also notice that several Kubernetes ingresses has been installed on your cluster. You can view it by running: $ kubectl get ingress --namespace drycc Depending on the order in which the Workflow components initialize, some pods may restart. This is common during the installation: if a component's dependencies are not yet available, that component will exit and Kubernetes will automatically restart it. Here, it can be seen that the controller, builder and registry all took a few loops waiting for minio before they were able to start: $ kubectl --namespace=drycc get pods NAME READY STATUS RESTARTS AGE drycc-builder-hy3xv 1/1 Running 5 5m drycc-controller-g3cu8 1/1 Running 5 5m drycc-database-rad1o 1/1 Running 0 5m drycc-logger-fluentd-1v8uk 1/1 Running 0 5m drycc-logger-fluentd-esm60 1/1 Running 0 5m drycc-logger-sm8b3 1/1 Running 0 5m drycc-minio-4ww3t 1/1 Running 0 5m drycc-registry-asozo 1/1 Running 1 5m Install a Kubernetes Ingress Controller \u00b6 Now that Workflow has been deployed with the global.ingress_class , we will need a Kubernetes ingress controller in place to begin routing traffic. Here is an example of how to use traefik as an ingress controller for Workflow. Of course, you are welcome to use any controller you wish. $ helm install stable/traefik --name ingress --namespace kube-system --set ssl.enabled=true Configure DNS \u00b6 User must to set up a hostname, and assumes the drycc.$host convention. We need to point the *.$host record to the public IP address of your ingress controller. You can get the public IP using the following command. A wildcard entry is necessary here as apps will use the same rule after they are deployed. $ kubectl get svc ingress-traefik --namespace kube-system NAME CLUSTER-IP EXTERNAL-IP PORT(S) AGE ingress-traefik 10.0.25.3 138.91.243.152 80:31625/TCP,443:30871/TCP 33m Additionally, we need to point the drycc-builder.$host record to the public IP address of the Builder . $ kubectl get svc drycc-builder --namespace drycc NAME CLUSTER-IP EXTERNAL-IP PORT(S) AGE drycc-builder 10.0.165.140 40.86.182.187 2222:32488/TCP 33m If ingress-nginx is used, ports can be exposed in the following ways. kind: ConfigMap apiVersion: v1 metadata: name: tcp-services namespace: ingress-nginx data: 2222: \"drycc/drycc-builder:2222\" If we were using drycc.cc as a hostname, we would need to create the following A DNS records. Name Type Value *.drycc.cc A 138.91.243.152 drycc-builder.drycc.cc A 40.86.182.187 Once all of the pods are in the READY state, and drycc.$host resolves to the external IP found above, Workflow is up and running! After installing Workflow, register a user and deploy an application .","title":"Installing Ingress"},{"location":"installing-workflow/ingress/#specify-ingress","text":"","title":"Specify Ingress"},{"location":"installing-workflow/ingress/#install-drycc-workflow-specify-ingress","text":"Now that Helm is installed and the repository has been added, install Workflow with a native ingress by running: $ helm install drycc/workflow --namespace drycc \\ --set global.ingress_class=nginx \\ --set global.platform_domain=drycc.cc \\ --set builder.service.type=LoadBalancer Of course, if you deploy it on a bare machine, you probably do not have Load Balancer. You need to use NodePort: $ helm install drycc/workflow --namespace drycc \\ --set global.ingress_class=nginx \\ --set global.platform_domain=drycc.cc \\ --set builder.service.type=NodePort \\ --set builder.service.nodePort=32222 If you want to use Load Balancer on a bare machine, you can look at metallb Where global.platform_domain is a required parameter that is traditionally not required for Workflow that is explained in the next section. In this example we are using drycc.cc for $hostname . Helm will install a variety of Kubernetes resources in the drycc namespace. Wait for the pods that Helm launched to be ready. Monitor their status by running: $ kubectl --namespace=drycc get pods You should also notice that several Kubernetes ingresses has been installed on your cluster. You can view it by running: $ kubectl get ingress --namespace drycc Depending on the order in which the Workflow components initialize, some pods may restart. This is common during the installation: if a component's dependencies are not yet available, that component will exit and Kubernetes will automatically restart it. Here, it can be seen that the controller, builder and registry all took a few loops waiting for minio before they were able to start: $ kubectl --namespace=drycc get pods NAME READY STATUS RESTARTS AGE drycc-builder-hy3xv 1/1 Running 5 5m drycc-controller-g3cu8 1/1 Running 5 5m drycc-database-rad1o 1/1 Running 0 5m drycc-logger-fluentd-1v8uk 1/1 Running 0 5m drycc-logger-fluentd-esm60 1/1 Running 0 5m drycc-logger-sm8b3 1/1 Running 0 5m drycc-minio-4ww3t 1/1 Running 0 5m drycc-registry-asozo 1/1 Running 1 5m","title":"Install Drycc Workflow (Specify ingress)"},{"location":"installing-workflow/ingress/#install-a-kubernetes-ingress-controller","text":"Now that Workflow has been deployed with the global.ingress_class , we will need a Kubernetes ingress controller in place to begin routing traffic. Here is an example of how to use traefik as an ingress controller for Workflow. Of course, you are welcome to use any controller you wish. $ helm install stable/traefik --name ingress --namespace kube-system --set ssl.enabled=true","title":"Install a Kubernetes Ingress Controller"},{"location":"installing-workflow/ingress/#configure-dns","text":"User must to set up a hostname, and assumes the drycc.$host convention. We need to point the *.$host record to the public IP address of your ingress controller. You can get the public IP using the following command. A wildcard entry is necessary here as apps will use the same rule after they are deployed. $ kubectl get svc ingress-traefik --namespace kube-system NAME CLUSTER-IP EXTERNAL-IP PORT(S) AGE ingress-traefik 10.0.25.3 138.91.243.152 80:31625/TCP,443:30871/TCP 33m Additionally, we need to point the drycc-builder.$host record to the public IP address of the Builder . $ kubectl get svc drycc-builder --namespace drycc NAME CLUSTER-IP EXTERNAL-IP PORT(S) AGE drycc-builder 10.0.165.140 40.86.182.187 2222:32488/TCP 33m If ingress-nginx is used, ports can be exposed in the following ways. kind: ConfigMap apiVersion: v1 metadata: name: tcp-services namespace: ingress-nginx data: 2222: \"drycc/drycc-builder:2222\" If we were using drycc.cc as a hostname, we would need to create the following A DNS records. Name Type Value *.drycc.cc A 138.91.243.152 drycc-builder.drycc.cc A 40.86.182.187 Once all of the pods are in the READY state, and drycc.$host resolves to the external IP found above, Workflow is up and running! After installing Workflow, register a user and deploy an application .","title":"Configure DNS"},{"location":"installing-workflow/system-requirements/","text":"Requirements \u00b6 To run Drycc Workflow on a Kubernetes cluster, there are a few requirements to keep in mind. Kubernetes Versions \u00b6 Drycc Workflow requires Kubernetes v1.16.15 or later. Components Requirements \u00b6 Drycc uses ingress as a routing implementation, so you have to choose an ingress. We recommend using nginx-ingress or traefik-ingress , which we have adapted to whitelist and force TLS functions. Workflow supports the use of ACME to manage automatic certificates, cert-manager is also one of the necessary components. Workflow supports stateful apps. You can create and use them through the 'drycc volumes' command. If you want to use this feature, you must have a StorageClass that supports ReadWriteMany . Workflow also supports the OSB API through the 'drycc resources' command. If you want to use this function, you need to install service-catalog . Storage Requirements \u00b6 A variety of Drycc Workflow components rely on an object storage system to do their work, including storing application slugs, Docker images and database logs. Drycc Workflow ships with Minio by default, which provides in-cluster, ephemeral object storage. This means that if the Minio server crashes, all data will be lost. Therefore, Minio should be used for development or testing only. Workflow supports Amazon Simple Storage Service (S3), Google Cloud Storage (GCS), OpenShift Swift, and Azure Blob Storage. See configuring object storage for setup instructions. Resource Requirements \u00b6 When deploying Drycc Workflow, it's important to provision machines with adequate resources. Drycc is a highly-available distributed system, which means that Drycc components and your deployed applications will move around the cluster onto healthy hosts as hosts leave the cluster for various reasons (failures, reboots, autoscalers, etc.). Because of this, you should have ample spare resources on any machine in your cluster to withstand the additional load of running services for failed machines. Drycc Workflow components use about 2.5GB of memory across the cluster, and require approximately 30GB of hard disk space. Because it may need to handle additional load if another one fails, each machine has minimum requirements of: At least 4GB of RAM (more is better) At least 40GB of hard disk space Note that these estimates are for Drycc Workflow and Kubernetes only. Be sure to leave enough spare capacity for your application footprint as well. Running smaller machines will likely result in increased system load and has been known to result in component failures and instability. Warning Workflow versions prior to 2.2 require '--insecure-registry' to function properly. Depending on your Kubernetes and Docker configuration, setting EXTRA_DOCKER_OPTS=\"--insecure-registry=10.0.0.0/8\" may be sufficient. SELinux + OverlayFS \u00b6 If you are using Docker with OverlayFS, you must disable SELinux by adding --selinux-enabled=false to EXTRA_DOCKER_OPTS . For more background information, see: https://github.com/docker/docker/issues/7952 https://github.com/drycc/workflow/issues/63","title":"System Requirements"},{"location":"installing-workflow/system-requirements/#requirements","text":"To run Drycc Workflow on a Kubernetes cluster, there are a few requirements to keep in mind.","title":"Requirements"},{"location":"installing-workflow/system-requirements/#kubernetes-versions","text":"Drycc Workflow requires Kubernetes v1.16.15 or later.","title":"Kubernetes Versions"},{"location":"installing-workflow/system-requirements/#components-requirements","text":"Drycc uses ingress as a routing implementation, so you have to choose an ingress. We recommend using nginx-ingress or traefik-ingress , which we have adapted to whitelist and force TLS functions. Workflow supports the use of ACME to manage automatic certificates, cert-manager is also one of the necessary components. Workflow supports stateful apps. You can create and use them through the 'drycc volumes' command. If you want to use this feature, you must have a StorageClass that supports ReadWriteMany . Workflow also supports the OSB API through the 'drycc resources' command. If you want to use this function, you need to install service-catalog .","title":"Components Requirements"},{"location":"installing-workflow/system-requirements/#storage-requirements","text":"A variety of Drycc Workflow components rely on an object storage system to do their work, including storing application slugs, Docker images and database logs. Drycc Workflow ships with Minio by default, which provides in-cluster, ephemeral object storage. This means that if the Minio server crashes, all data will be lost. Therefore, Minio should be used for development or testing only. Workflow supports Amazon Simple Storage Service (S3), Google Cloud Storage (GCS), OpenShift Swift, and Azure Blob Storage. See configuring object storage for setup instructions.","title":"Storage Requirements"},{"location":"installing-workflow/system-requirements/#resource-requirements","text":"When deploying Drycc Workflow, it's important to provision machines with adequate resources. Drycc is a highly-available distributed system, which means that Drycc components and your deployed applications will move around the cluster onto healthy hosts as hosts leave the cluster for various reasons (failures, reboots, autoscalers, etc.). Because of this, you should have ample spare resources on any machine in your cluster to withstand the additional load of running services for failed machines. Drycc Workflow components use about 2.5GB of memory across the cluster, and require approximately 30GB of hard disk space. Because it may need to handle additional load if another one fails, each machine has minimum requirements of: At least 4GB of RAM (more is better) At least 40GB of hard disk space Note that these estimates are for Drycc Workflow and Kubernetes only. Be sure to leave enough spare capacity for your application footprint as well. Running smaller machines will likely result in increased system load and has been known to result in component failures and instability. Warning Workflow versions prior to 2.2 require '--insecure-registry' to function properly. Depending on your Kubernetes and Docker configuration, setting EXTRA_DOCKER_OPTS=\"--insecure-registry=10.0.0.0/8\" may be sufficient.","title":"Resource Requirements"},{"location":"installing-workflow/system-requirements/#selinux-overlayfs","text":"If you are using Docker with OverlayFS, you must disable SELinux by adding --selinux-enabled=false to EXTRA_DOCKER_OPTS . For more background information, see: https://github.com/docker/docker/issues/7952 https://github.com/drycc/workflow/issues/63","title":"SELinux + OverlayFS"},{"location":"managing-workflow/configuring-dns/","text":"Configure DNS \u00b6 The Drycc Workflow controller and all applications deployed via Workflow are intended (by default) to be accessible as subdomains of the Workflow cluster's domain. For example, assuming example.com were a cluster's domain: The controller should be accessible at drycc.example.com Applications should be accessible (by default) at <application name>.example.com Given that this is the case, the primary objective in configuring DNS is that traffic for all subdomains of a cluster's domain be directed to the cluster node(s) hosting the platform's router component, which is capable of directing traffic within the cluster to the correct endpoints. With a Load Balancer \u00b6 Generally, it is recommended that a [load balancer][] be used to direct inbound traffic to one or more routers. In such a case, configuring DNS is as simple as defining a wildcard record in DNS that points to the load balancer. For example, assuming a domain of example.com : An A record enumerating each of your load balancer(s) IPs (i.e. DNS round-robining) A CNAME record referencing an existing fully-qualified domain name for the load balancer Per AWS' own documentation , this is the recommended strategy when using AWS Elastic Load Balancers, as ELB IPs may change over time. DNS for any applications using a \"custom domain\" (a fully-qualified domain name that is not a subdomain of the cluster's own domain) can be configured by creating a CNAME record that references the wildcard record described above. Although it is dependent upon your distribution of Kubernetes and your underlying infrastructure, in many cases, the IP(s) or existing fully-qualified domain name of a load balancer can be determined directly using the kubectl tool: $ kubectl --namespace=ingress-nginx describe service | grep \"LoadBalancer Ingress\" LoadBalancer Ingress: a493e4e58ea0511e5bb390686bc85da3-1558404688.us-west-2.elb.amazonaws.com The LoadBalancer Ingress field typically describes an existing domain name or public IP(s). Note that if Kubernetes is able to automatically provision a load balancer for you, it does so asynchronously. If the command shown above is issued very soon after Workflow installation, the load balancer may not exist yet. Without a Load Balancer \u00b6 On some platforms (Minikube, for instance), a load balancer is not an easy or practical thing to provision. In these cases, one can directly identify the public IP of a Kubernetes node that is hosting a router pod and use that information to configure the local /etc/hosts file. Because wildcard entries do not work in a local /etc/hosts file, using this strategy may result in frequent editing of that file to add fully-qualified subdomains of a cluster for each application added to that cluster. Because of this a more viable option may be to utilize the xip.io service. In general, for any IP, a.b.c.d , the fully-qualified domain name any-subdomain.a.b.c.d.xip.io will resolve to the IP a.b.c.d . This can be enormously useful. To begin, find the node(s) hosting router instances using kubectl : $ kubectl --namespace=ingress-nginx describe pod | grep Node Node: ip-10-0-0-199.us-west-2.compute.internal/10.0.0.199 Node: ip-10-0-0-198.us-west-2.compute.internal/10.0.0.198 The command will display information for every router pod. For each, a node name and IP are displayed in the Node field. If the IPs appearing in these fields are public, any of these may be used to configure your local /etc/hosts file or may be used with xip.io . If the IPs shown are not public, further investigation may be needed. You can list the IP addresses of a node using kubectl : $ kubectl describe node ip-10-0-0-199.us-west-2.compute.internal # ... Addresses: 10.0.0.199,10.0.0.199,54.218.85.175 # ... Here, the Addresses field lists all the node's IPs. If any of them are public, again, they may be used to configure your local /etc/hosts file or may be used with xip.io . Tutorial: Configuring DNS with Google Cloud DNS \u00b6 In this section, we'll describe how to configure Google Cloud DNS for routing your domain name to your Drycc cluster. We'll assume the following in this section: Your Ingress service has a load balancer in front of it. The load balancer need not be cloud based, it just needs to provide a stable IP address or a stable domain name You have the mystuff.com domain name registered with a registrar Replace your domain name with mystuff.com in the instructions to follow Your registrar lets you alter the nameservers for your domain name (most registrars do) Here are the steps for configuring cloud DNS to route to your drycc cluster: Get the load balancer IP or domain name If you are on Google Container Engine, you can run kubectl get svc -n ingress-nginx and look for the LoadBalancer Ingress column to get the IP address Create a new Cloud DNS Zone (on the console: Networking => Cloud DNS , then click on Create Zone ) Name your zone, and set the DNS name to mystuff.com. (note the . at the end Click on the Create button Click on the Add Record Set button on the resulting page If your load balancer provides a stable IP address, enter the following fields in the resulting form: DNS Name : * Resource Record Type : A TTL : the DNS TTL of your choosing. If you're testing or you anticipate that you'll tear down and rebuild many drycc clusters over time, we recommend a low TTL IPv4 Address : The IP that you got in the very first step Click the Create button If your load balancer provides the stable domain name lbdomain.com , enter the following fields in the resulting form: DNS Name : * Resource Record Type : CNAME TTL : the DNS TTL of your choosing. If you're testing or you anticipate that you'll tear down and rebuild many drycc clusters over time, we recommend a low TTL Canonical name : lbdomain.com. (note the . a the end) Click on the Create button In your domain registrar, set the nameservers for your mystuff.com domain to the ones under the data column in the NS record on the same page. They'll often be something like the below (note the trailing . characters). ns-cloud-b1.googledomains.com. ns-cloud-b2.googledomains.com. ns-cloud-b3.googledomains.com. ns-cloud-b4.googledomains.com. Note: If you ever have to re-create your drycc cluster, simply go back to step 6.4 or 7.4 (depending on your load balancer) and change the IP address or domain name to the new value. You may have to wait for the TTL you set to expire. Testing \u00b6 To test that traffic reaches its intended destination, a request can be sent to the Drycc controller like so (do not forget the trailing slash!): curl http://drycc.example.com/v2/ Or: curl http://drycc.54.218.85.175.xip.io/v2/ Since such requests require authentication, a response such as the following should be considered an indicator of success: {\"detail\":\"Authentication credentials were not provided.\"}","title":"Configuring DNS"},{"location":"managing-workflow/configuring-dns/#configure-dns","text":"The Drycc Workflow controller and all applications deployed via Workflow are intended (by default) to be accessible as subdomains of the Workflow cluster's domain. For example, assuming example.com were a cluster's domain: The controller should be accessible at drycc.example.com Applications should be accessible (by default) at <application name>.example.com Given that this is the case, the primary objective in configuring DNS is that traffic for all subdomains of a cluster's domain be directed to the cluster node(s) hosting the platform's router component, which is capable of directing traffic within the cluster to the correct endpoints.","title":"Configure DNS"},{"location":"managing-workflow/configuring-dns/#with-a-load-balancer","text":"Generally, it is recommended that a [load balancer][] be used to direct inbound traffic to one or more routers. In such a case, configuring DNS is as simple as defining a wildcard record in DNS that points to the load balancer. For example, assuming a domain of example.com : An A record enumerating each of your load balancer(s) IPs (i.e. DNS round-robining) A CNAME record referencing an existing fully-qualified domain name for the load balancer Per AWS' own documentation , this is the recommended strategy when using AWS Elastic Load Balancers, as ELB IPs may change over time. DNS for any applications using a \"custom domain\" (a fully-qualified domain name that is not a subdomain of the cluster's own domain) can be configured by creating a CNAME record that references the wildcard record described above. Although it is dependent upon your distribution of Kubernetes and your underlying infrastructure, in many cases, the IP(s) or existing fully-qualified domain name of a load balancer can be determined directly using the kubectl tool: $ kubectl --namespace=ingress-nginx describe service | grep \"LoadBalancer Ingress\" LoadBalancer Ingress: a493e4e58ea0511e5bb390686bc85da3-1558404688.us-west-2.elb.amazonaws.com The LoadBalancer Ingress field typically describes an existing domain name or public IP(s). Note that if Kubernetes is able to automatically provision a load balancer for you, it does so asynchronously. If the command shown above is issued very soon after Workflow installation, the load balancer may not exist yet.","title":"With a Load Balancer"},{"location":"managing-workflow/configuring-dns/#without-a-load-balancer","text":"On some platforms (Minikube, for instance), a load balancer is not an easy or practical thing to provision. In these cases, one can directly identify the public IP of a Kubernetes node that is hosting a router pod and use that information to configure the local /etc/hosts file. Because wildcard entries do not work in a local /etc/hosts file, using this strategy may result in frequent editing of that file to add fully-qualified subdomains of a cluster for each application added to that cluster. Because of this a more viable option may be to utilize the xip.io service. In general, for any IP, a.b.c.d , the fully-qualified domain name any-subdomain.a.b.c.d.xip.io will resolve to the IP a.b.c.d . This can be enormously useful. To begin, find the node(s) hosting router instances using kubectl : $ kubectl --namespace=ingress-nginx describe pod | grep Node Node: ip-10-0-0-199.us-west-2.compute.internal/10.0.0.199 Node: ip-10-0-0-198.us-west-2.compute.internal/10.0.0.198 The command will display information for every router pod. For each, a node name and IP are displayed in the Node field. If the IPs appearing in these fields are public, any of these may be used to configure your local /etc/hosts file or may be used with xip.io . If the IPs shown are not public, further investigation may be needed. You can list the IP addresses of a node using kubectl : $ kubectl describe node ip-10-0-0-199.us-west-2.compute.internal # ... Addresses: 10.0.0.199,10.0.0.199,54.218.85.175 # ... Here, the Addresses field lists all the node's IPs. If any of them are public, again, they may be used to configure your local /etc/hosts file or may be used with xip.io .","title":"Without a Load Balancer"},{"location":"managing-workflow/configuring-dns/#tutorial-configuring-dns-with-google-cloud-dns","text":"In this section, we'll describe how to configure Google Cloud DNS for routing your domain name to your Drycc cluster. We'll assume the following in this section: Your Ingress service has a load balancer in front of it. The load balancer need not be cloud based, it just needs to provide a stable IP address or a stable domain name You have the mystuff.com domain name registered with a registrar Replace your domain name with mystuff.com in the instructions to follow Your registrar lets you alter the nameservers for your domain name (most registrars do) Here are the steps for configuring cloud DNS to route to your drycc cluster: Get the load balancer IP or domain name If you are on Google Container Engine, you can run kubectl get svc -n ingress-nginx and look for the LoadBalancer Ingress column to get the IP address Create a new Cloud DNS Zone (on the console: Networking => Cloud DNS , then click on Create Zone ) Name your zone, and set the DNS name to mystuff.com. (note the . at the end Click on the Create button Click on the Add Record Set button on the resulting page If your load balancer provides a stable IP address, enter the following fields in the resulting form: DNS Name : * Resource Record Type : A TTL : the DNS TTL of your choosing. If you're testing or you anticipate that you'll tear down and rebuild many drycc clusters over time, we recommend a low TTL IPv4 Address : The IP that you got in the very first step Click the Create button If your load balancer provides the stable domain name lbdomain.com , enter the following fields in the resulting form: DNS Name : * Resource Record Type : CNAME TTL : the DNS TTL of your choosing. If you're testing or you anticipate that you'll tear down and rebuild many drycc clusters over time, we recommend a low TTL Canonical name : lbdomain.com. (note the . a the end) Click on the Create button In your domain registrar, set the nameservers for your mystuff.com domain to the ones under the data column in the NS record on the same page. They'll often be something like the below (note the trailing . characters). ns-cloud-b1.googledomains.com. ns-cloud-b2.googledomains.com. ns-cloud-b3.googledomains.com. ns-cloud-b4.googledomains.com. Note: If you ever have to re-create your drycc cluster, simply go back to step 6.4 or 7.4 (depending on your load balancer) and change the IP address or domain name to the new value. You may have to wait for the TTL you set to expire.","title":"Tutorial: Configuring DNS with Google Cloud DNS"},{"location":"managing-workflow/configuring-dns/#testing","text":"To test that traffic reaches its intended destination, a request can be sent to the Drycc controller like so (do not forget the trailing slash!): curl http://drycc.example.com/v2/ Or: curl http://drycc.54.218.85.175.xip.io/v2/ Since such requests require authentication, a response such as the following should be considered an indicator of success: {\"detail\":\"Authentication credentials were not provided.\"}","title":"Testing"},{"location":"managing-workflow/deploy-hooks/","text":"Deploy Hooks \u00b6 Deploy hooks allow an external service to receive a notification whenever a new version of your app is pushed to Workflow. It\u2019s useful to help keep the development team informed about deploys, while it can also be used to integrate different systems together. After one or more hooks are setup, hook output and errors appear in your application\u2019s logs: $ drycc logs ... 2011-03-15T15:07:29-07:00 drycc[api]: Deploy hook sent to http://drycc.rocks Deploy hooks are a generic HTTP hook. An administrator can create and configure multiple deploy hooks by tuning the controller settings via the Helm chart. HTTP POST Hook \u00b6 The HTTP deploy hook performs an HTTP POST to a URL. The parameters included in the request are the same as the variables available in the hook message: app , release , release_summary , sha and user . See below for their descriptions: app=secure-woodland&release=v4&release_summary=gabrtv%20deployed%35b3726&sha=35b3726&user=gabrtv Optionally, if a deploy hook secret key is added to the controller through tuning the controller settings , a new Authorization header will be present in the POST request. The value of this header is computed as the HMAC hex digest of the request URL, using the secret as the key. In order to authenticate that this request came from Workflow, use the secret key, the full URL and the HMAC-SHA1 hashing algorithm to compute the signature. In Python, that would look something like this: import hashlib import hmac hmac.new(\"my_secret_key\", \"http://drycc.rocks?app=secure-woodland&release=v4&release_summary=gabrtv%20deployed%35b3726&sha=35b3726&user=gabrtv\", digestmod=hashlib.sha1).hexdigest() If the value of the computed HMAC hex digest and the value in the Authorization header are identical, then the request came from Workflow. Important When computing the signature, ensure that the URL parameters are in alphabetic order. This is critical when computing the cryptographic signature as most web applications don't care about the order of the HTTP parameters, but the cryptographic signature will not be the same.","title":"Deploy Hooks"},{"location":"managing-workflow/deploy-hooks/#deploy-hooks","text":"Deploy hooks allow an external service to receive a notification whenever a new version of your app is pushed to Workflow. It\u2019s useful to help keep the development team informed about deploys, while it can also be used to integrate different systems together. After one or more hooks are setup, hook output and errors appear in your application\u2019s logs: $ drycc logs ... 2011-03-15T15:07:29-07:00 drycc[api]: Deploy hook sent to http://drycc.rocks Deploy hooks are a generic HTTP hook. An administrator can create and configure multiple deploy hooks by tuning the controller settings via the Helm chart.","title":"Deploy Hooks"},{"location":"managing-workflow/deploy-hooks/#http-post-hook","text":"The HTTP deploy hook performs an HTTP POST to a URL. The parameters included in the request are the same as the variables available in the hook message: app , release , release_summary , sha and user . See below for their descriptions: app=secure-woodland&release=v4&release_summary=gabrtv%20deployed%35b3726&sha=35b3726&user=gabrtv Optionally, if a deploy hook secret key is added to the controller through tuning the controller settings , a new Authorization header will be present in the POST request. The value of this header is computed as the HMAC hex digest of the request URL, using the secret as the key. In order to authenticate that this request came from Workflow, use the secret key, the full URL and the HMAC-SHA1 hashing algorithm to compute the signature. In Python, that would look something like this: import hashlib import hmac hmac.new(\"my_secret_key\", \"http://drycc.rocks?app=secure-woodland&release=v4&release_summary=gabrtv%20deployed%35b3726&sha=35b3726&user=gabrtv\", digestmod=hashlib.sha1).hexdigest() If the value of the computed HMAC hex digest and the value in the Authorization header are identical, then the request came from Workflow. Important When computing the signature, ensure that the URL parameters are in alphabetic order. This is critical when computing the cryptographic signature as most web applications don't care about the order of the HTTP parameters, but the cryptographic signature will not be the same.","title":"HTTP POST Hook"},{"location":"managing-workflow/extending-workflow/","text":"Extending Workflow \u00b6 Drycc Workflow is an open source project which wouldn't be here without the amazing skill and enthusiasm of the community that has grown up around it. Several projects have blossomed which extend Workflow in various ways. These links are to community-contributed extensions of Drycc Workflow. Drycc makes no guarantees about the functionality, security, or code contained within. As with any software, use with caution in a production environment. Workflow Community Projects \u00b6 alea is a backing services manager for Drycc Workflow, providing easy access to PostgreSQL, Redis, MongoDB, and memcached. dryccdash is a web-based UI supporting many user and app actions without need of the drycc command-line interface. drycc-cleanup is a Drycc-friendly, configurable approach to purging unneeded Docker containers and images. drycc-global-config-plugin stores config values in Vault for easy use in Workflow apps. drycc-node is a controller API client for a browser in NodeJS. drycc-ui is the beginning of a full client-side dashboard that interfaces with the controller API. drycc-workflow-aws simplifies installing Workflow on Amazon Web Services , backed by S3 and using ECR as the container registry. drycc-workflow-gke simplifies installing Workflow on Google Container Engine , backed by Google Cloud Storage and using gcr.io as the container registry. drycc-workflow-ruby contains Workflow controller API bindings for Ruby programming. heroku-to-drycc migrates existing Heroku applications to the Workflow platform. kube-solo-osx creates a zero-to-Kubernetes development environment for macOS in under two minutes, with specific support for installing Workflow with Helm or Helm Classic. Are we missing something? Please open a documentation pull request to add it.","title":"Extending Workflow"},{"location":"managing-workflow/extending-workflow/#extending-workflow","text":"Drycc Workflow is an open source project which wouldn't be here without the amazing skill and enthusiasm of the community that has grown up around it. Several projects have blossomed which extend Workflow in various ways. These links are to community-contributed extensions of Drycc Workflow. Drycc makes no guarantees about the functionality, security, or code contained within. As with any software, use with caution in a production environment.","title":"Extending Workflow"},{"location":"managing-workflow/extending-workflow/#workflow-community-projects","text":"alea is a backing services manager for Drycc Workflow, providing easy access to PostgreSQL, Redis, MongoDB, and memcached. dryccdash is a web-based UI supporting many user and app actions without need of the drycc command-line interface. drycc-cleanup is a Drycc-friendly, configurable approach to purging unneeded Docker containers and images. drycc-global-config-plugin stores config values in Vault for easy use in Workflow apps. drycc-node is a controller API client for a browser in NodeJS. drycc-ui is the beginning of a full client-side dashboard that interfaces with the controller API. drycc-workflow-aws simplifies installing Workflow on Amazon Web Services , backed by S3 and using ECR as the container registry. drycc-workflow-gke simplifies installing Workflow on Google Container Engine , backed by Google Cloud Storage and using gcr.io as the container registry. drycc-workflow-ruby contains Workflow controller API bindings for Ruby programming. heroku-to-drycc migrates existing Heroku applications to the Workflow platform. kube-solo-osx creates a zero-to-Kubernetes development environment for macOS in under two minutes, with specific support for installing Workflow with Helm or Helm Classic. Are we missing something? Please open a documentation pull request to add it.","title":"Workflow Community Projects"},{"location":"managing-workflow/platform-logging/","text":"Platform Logging \u00b6 The logging platform is made up of 2 components - Fluentd and Logger . Fluentd runs on every worker node of the cluster and is deployed as a Daemon Set . The Fluentd pods capture all of the stderr and stdout streams of every container running on the host (even those not hosted directly by kubernetes). Once the log message arrives in our custom fluentd plugin we determine where the message originated. If the message was from the Workflow Controller or from an application deployed via workflow we send it to the logs topic on the local NSQD instance. If the message is from the Workflow Router we build an Influxdb compatible message and send it to the same NSQD instance but instead place the message on the metrics topic. Logger then acts as a consumer reading messages off of the NSQ logs topic storing those messages in a local Redis instance. When a user wants to retrieve log entries using the drycc logs command we make an HTTP request from Controller to Logger which then fetches the appropriate data from Redis. Configuring Off Cluster Redis \u00b6 Even though we provide a redis instance with the default Workflow install, it is recommended that operators use a third-party source like Elasticache or similar offering. This way your data is durable across upgrades or outages. If you have a third-party Redis installation you would like to use all you need to do is set the following values in your helm chart: db = \"0\" host = \"my.host.redis\" port = \"6379\" password = \"\" These can be changed by running helm inspect values drycc/workflow > values.yaml before using helm install to complete the installation. To customize the redis credentials, edit values.yaml and modify the redis section of the file to tune these settings. Debugging Logger \u00b6 If the drycc logs command encounters an error it will return the following message: Error: There are currently no log messages. Please check the following things: 1) Logger and fluentd pods are running. 2) The application is writing logs to the logger component by checking that an entry in the ring buffer was created: kubectl --namespace=drycc logs <logger pod> 3) Making sure that the container logs were mounted properly into the fluentd pod: kubectl --namespace=drycc exec <fluentd pod> ls /var/log/containers Architecture Diagram \u00b6 \u250c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2510 \u2502 Router \u2502 \u250c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2510 \u250c\u2500\u2500\u2500\u2500\u2500\u2510 \u2514\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2518 \u2502 Logger \u2502\u25c0\u2500\u2500\u2500\u25b6\u2502Redis\u2502 \u2502 \u2514\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2518 \u2514\u2500\u2500\u2500\u2500\u2500\u2518 Log file \u25b2 \u2502 \u2502 \u25bc \u2502 \u250c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2510 \u250c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2510 logs/metrics \u250c\u2500\u2500\u2500\u2500\u2500\u2510 \u2502App Logs\u2502\u2500\u2500Log File\u2500\u2500\u25b6\u2502 fluentd \u2502\u2500\u2500\u2500\u2500\u2500\u2500\u2500topics\u2500\u2500\u2500\u2500\u2500\u25b6\u2502 NSQ \u2502 \u2514\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2518 \u2514\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2518 \u2514\u2500\u2500\u2500\u2500\u2500\u2518 \u2502 \u2502 \u250c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2510 \u2502 \u2502 HOST \u2502 \u25bc \u2502 Telegraf \u2502\u2500\u2500\u2500\u2510 \u250c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2510 \u2514\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2518 \u2502 \u2502Telegraf\u2502 \u2502 \u2514\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2518 \u250c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2510 \u2502 \u2502 \u2502 HOST \u2502 \u2502 \u250c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2510 \u2502 \u2502 Telegraf \u2502\u2500\u2500\u2500\u253c\u2500\u2500\u2500\u25b6\u2502 InfluxDB \u2502\u25c0\u2500\u2500\u2500\u2500Wire \u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2518 \u2514\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2518 \u2502 \u2514\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2518 Protocol \u2502 \u25b2 \u250c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2510 \u2502 \u2502 \u2502 HOST \u2502 \u2502 \u25bc \u2502 Telegraf \u2502\u2500\u2500\u2500\u2518 \u250c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2510 \u2514\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2518 \u2502 Grafana \u2502 \u2514\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2518 Default Configuration \u00b6 By default the Fluentd pod can be configured to talk to numerous syslog endpoints. So for example it is possible to have Fluentd send log messages to both the Logger component and Papertrail . This allows production deployments of Drycc to satisfy stringent logging requirements such as offsite backups of log data. Configuring Fluentd to talk to multiple syslog endpoints means modifying the Fluentd daemonset manifest. This means you will need to fetch the chart with helm fetch drycc/workflow --untar , then modify workflow/charts/fluentd/templates/logger-fluentd-daemon.yaml with the following: env: - name: \"SYSLOG_HOST_1\" value: \"my.syslog.host\" - name: \"SYSLOG_PORT_1\" value: \"5144\" .... - name: \"SYSLOG_HOST_N\" value: \"my.syslog.host.n\" - name: \"SYSLOG_PORT_N\" value: \"51333\" If you only need to talk to 1 Syslog endpoint you can use the following configuration within your chart: env: - name: \"SYSLOG_HOST\" value: \"my.syslog.host\" - name: \"SYSLOG_PORT\" value: \"5144\" Then run helm install ./workflow --namespace drycc to install the modified chart. Customizing: \u00b6 We currently support logging information to Syslog, Elastic Search, and Sumo Logic. However, we will gladly accept pull requests that add support to other locations. For more information please visit the fluentd repository . Custom Fluentd Plugins \u00b6 That are many output plugins available for Fluentd . But, we purposefully do not ship our Fluentd image with these installed. Instead, we provide a mechanism that allows users to install a plugin at startup time of the container and configure it. If you would like to install a plugin you can set an environment variable such as the following: FLUENTD_PLUGIN_N=some-fluentd-plugin where N is a positive integer that is incremented for every plugin you wish to install. After you set this value you must then set the configuration text for the FILTER or STORE plugin you are installing. You can do that by setting CUSTOM_STORE_N=configuration text where N is the corresponding index value of the plugin you just installed. Here is an example of setting the values directly in the manifest of the daemonset. env: - name: \"FLUENTD_PLUGIN_1\" value: \"fluent-plugin-kafka\" - name: \"CUSTOM_STORE_1\" value: | <store> @type kafka \\ default_topic some_topic </store> Or you could configure it using the daemon_environment key in the values.yaml : fluentd: daemon_environment: FLUENTD_PLUGIN_1: \"fluent-plugin-kafka\" CUSTOM_STORE_1: \"|\\n <store>\\n @type kafka\\n default_topic some_topic\\n </store>\" INSTALL_BUILD_TOOLS: \"|\\n true\" For more information please see the Custom Plugins section of the README.","title":"Platform Logging"},{"location":"managing-workflow/platform-logging/#platform-logging","text":"The logging platform is made up of 2 components - Fluentd and Logger . Fluentd runs on every worker node of the cluster and is deployed as a Daemon Set . The Fluentd pods capture all of the stderr and stdout streams of every container running on the host (even those not hosted directly by kubernetes). Once the log message arrives in our custom fluentd plugin we determine where the message originated. If the message was from the Workflow Controller or from an application deployed via workflow we send it to the logs topic on the local NSQD instance. If the message is from the Workflow Router we build an Influxdb compatible message and send it to the same NSQD instance but instead place the message on the metrics topic. Logger then acts as a consumer reading messages off of the NSQ logs topic storing those messages in a local Redis instance. When a user wants to retrieve log entries using the drycc logs command we make an HTTP request from Controller to Logger which then fetches the appropriate data from Redis.","title":"Platform Logging"},{"location":"managing-workflow/platform-logging/#configuring-off-cluster-redis","text":"Even though we provide a redis instance with the default Workflow install, it is recommended that operators use a third-party source like Elasticache or similar offering. This way your data is durable across upgrades or outages. If you have a third-party Redis installation you would like to use all you need to do is set the following values in your helm chart: db = \"0\" host = \"my.host.redis\" port = \"6379\" password = \"\" These can be changed by running helm inspect values drycc/workflow > values.yaml before using helm install to complete the installation. To customize the redis credentials, edit values.yaml and modify the redis section of the file to tune these settings.","title":"Configuring Off Cluster Redis"},{"location":"managing-workflow/platform-logging/#debugging-logger","text":"If the drycc logs command encounters an error it will return the following message: Error: There are currently no log messages. Please check the following things: 1) Logger and fluentd pods are running. 2) The application is writing logs to the logger component by checking that an entry in the ring buffer was created: kubectl --namespace=drycc logs <logger pod> 3) Making sure that the container logs were mounted properly into the fluentd pod: kubectl --namespace=drycc exec <fluentd pod> ls /var/log/containers","title":"Debugging Logger"},{"location":"managing-workflow/platform-logging/#architecture-diagram","text":"\u250c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2510 \u2502 Router \u2502 \u250c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2510 \u250c\u2500\u2500\u2500\u2500\u2500\u2510 \u2514\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2518 \u2502 Logger \u2502\u25c0\u2500\u2500\u2500\u25b6\u2502Redis\u2502 \u2502 \u2514\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2518 \u2514\u2500\u2500\u2500\u2500\u2500\u2518 Log file \u25b2 \u2502 \u2502 \u25bc \u2502 \u250c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2510 \u250c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2510 logs/metrics \u250c\u2500\u2500\u2500\u2500\u2500\u2510 \u2502App Logs\u2502\u2500\u2500Log File\u2500\u2500\u25b6\u2502 fluentd \u2502\u2500\u2500\u2500\u2500\u2500\u2500\u2500topics\u2500\u2500\u2500\u2500\u2500\u25b6\u2502 NSQ \u2502 \u2514\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2518 \u2514\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2518 \u2514\u2500\u2500\u2500\u2500\u2500\u2518 \u2502 \u2502 \u250c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2510 \u2502 \u2502 HOST \u2502 \u25bc \u2502 Telegraf \u2502\u2500\u2500\u2500\u2510 \u250c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2510 \u2514\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2518 \u2502 \u2502Telegraf\u2502 \u2502 \u2514\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2518 \u250c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2510 \u2502 \u2502 \u2502 HOST \u2502 \u2502 \u250c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2510 \u2502 \u2502 Telegraf \u2502\u2500\u2500\u2500\u253c\u2500\u2500\u2500\u25b6\u2502 InfluxDB \u2502\u25c0\u2500\u2500\u2500\u2500Wire \u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2518 \u2514\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2518 \u2502 \u2514\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2518 Protocol \u2502 \u25b2 \u250c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2510 \u2502 \u2502 \u2502 HOST \u2502 \u2502 \u25bc \u2502 Telegraf \u2502\u2500\u2500\u2500\u2518 \u250c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2510 \u2514\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2518 \u2502 Grafana \u2502 \u2514\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2518","title":"Architecture Diagram"},{"location":"managing-workflow/platform-logging/#default-configuration","text":"By default the Fluentd pod can be configured to talk to numerous syslog endpoints. So for example it is possible to have Fluentd send log messages to both the Logger component and Papertrail . This allows production deployments of Drycc to satisfy stringent logging requirements such as offsite backups of log data. Configuring Fluentd to talk to multiple syslog endpoints means modifying the Fluentd daemonset manifest. This means you will need to fetch the chart with helm fetch drycc/workflow --untar , then modify workflow/charts/fluentd/templates/logger-fluentd-daemon.yaml with the following: env: - name: \"SYSLOG_HOST_1\" value: \"my.syslog.host\" - name: \"SYSLOG_PORT_1\" value: \"5144\" .... - name: \"SYSLOG_HOST_N\" value: \"my.syslog.host.n\" - name: \"SYSLOG_PORT_N\" value: \"51333\" If you only need to talk to 1 Syslog endpoint you can use the following configuration within your chart: env: - name: \"SYSLOG_HOST\" value: \"my.syslog.host\" - name: \"SYSLOG_PORT\" value: \"5144\" Then run helm install ./workflow --namespace drycc to install the modified chart.","title":"Default Configuration"},{"location":"managing-workflow/platform-logging/#customizing","text":"We currently support logging information to Syslog, Elastic Search, and Sumo Logic. However, we will gladly accept pull requests that add support to other locations. For more information please visit the fluentd repository .","title":"Customizing:"},{"location":"managing-workflow/platform-logging/#custom-fluentd-plugins","text":"That are many output plugins available for Fluentd . But, we purposefully do not ship our Fluentd image with these installed. Instead, we provide a mechanism that allows users to install a plugin at startup time of the container and configure it. If you would like to install a plugin you can set an environment variable such as the following: FLUENTD_PLUGIN_N=some-fluentd-plugin where N is a positive integer that is incremented for every plugin you wish to install. After you set this value you must then set the configuration text for the FILTER or STORE plugin you are installing. You can do that by setting CUSTOM_STORE_N=configuration text where N is the corresponding index value of the plugin you just installed. Here is an example of setting the values directly in the manifest of the daemonset. env: - name: \"FLUENTD_PLUGIN_1\" value: \"fluent-plugin-kafka\" - name: \"CUSTOM_STORE_1\" value: | <store> @type kafka \\ default_topic some_topic </store> Or you could configure it using the daemon_environment key in the values.yaml : fluentd: daemon_environment: FLUENTD_PLUGIN_1: \"fluent-plugin-kafka\" CUSTOM_STORE_1: \"|\\n <store>\\n @type kafka\\n default_topic some_topic\\n </store>\" INSTALL_BUILD_TOOLS: \"|\\n true\" For more information please see the Custom Plugins section of the README.","title":"Custom Fluentd Plugins"},{"location":"managing-workflow/platform-monitoring/","text":"Platform Monitoring \u00b6 Description \u00b6 We now include a monitoring stack for introspection on a running Kubernetes cluster. The stack includes 3 components: Telegraf - Metrics collection daemon written by team behind InfluxDB. InfluxDB - Time series database Grafana - Graphing tool for time series data Architecture Diagram \u00b6 \u250c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2510 \u2502 Router \u2502 \u250c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2510 \u250c\u2500\u2500\u2500\u2500\u2500\u2510 \u2514\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2518 \u2502 Logger \u2502\u25c0\u2500\u2500\u2500\u25b6\u2502Redis\u2502 \u2502 \u2514\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2518 \u2514\u2500\u2500\u2500\u2500\u2500\u2518 Log file \u25b2 \u2502 \u2502 \u25bc \u2502 \u250c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2510 \u250c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2510 logs/metrics \u250c\u2500\u2500\u2500\u2500\u2500\u2510 \u2502App Logs\u2502\u2500\u2500Log File\u2500\u2500\u25b6\u2502 fluentd \u2502\u2500\u2500\u2500\u2500\u2500\u2500\u2500topics\u2500\u2500\u2500\u2500\u2500\u25b6\u2502 NSQ \u2502 \u2514\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2518 \u2514\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2518 \u2514\u2500\u2500\u2500\u2500\u2500\u2518 \u2502 \u2502 \u250c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2510 \u2502 \u2502 HOST \u2502 \u25bc \u2502 Telegraf \u2502\u2500\u2500\u2500\u2510 \u250c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2510 \u2514\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2518 \u2502 \u2502Telegraf\u2502 \u2502 \u2514\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2518 \u250c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2510 \u2502 \u2502 \u2502 HOST \u2502 \u2502 \u250c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2510 \u2502 \u2502 Telegraf \u2502\u2500\u2500\u2500\u253c\u2500\u2500\u2500\u25b6\u2502 InfluxDB \u2502\u25c0\u2500\u2500\u2500\u2500Wire \u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2518 \u2514\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2518 \u2502 \u2514\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2518 Protocol \u2502 \u25b2 \u250c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2510 \u2502 \u2502 \u2502 HOST \u2502 \u2502 \u25bc \u2502 Telegraf \u2502\u2500\u2500\u2500\u2518 \u250c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2510 \u2514\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2518 \u2502 Grafana \u2502 \u2514\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2518 Grafana \u00b6 Grafana allows users to create custom dashboards that visualize the data captured to the running InfluxDB component. By default Grafana is exposed using a service annotation through the router at the following URL: http://grafana.mydomain.com . The default login is admin/admin . If you are interested in changing these values please see Tuning Component Settings . Grafana will preload several dashboards to help operators get started with monitoring Kubernetes and Drycc Workflow. These dashboards are meant as starting points and don't include every item that might be desirable to monitor in a production installation. Drycc Workflow monitoring by default does not write data to the host filesystem or to long-term storage. If the Grafana instance fails, modified dashboards are lost. Production Configuration \u00b6 A production install of Grafana should have the following configuration values changed if possible: Change the default username and password from admin/admin . The value for the password is passed in plain text so it is best to set this value on the command line instead of checking it into version control. Enable persistence Use a supported external database such as mysql or postgres. You can find more information here On Cluster Persistence \u00b6 Enabling persistence will allow your custom configuration to persist across pod restarts. This means that the default sqllite database (which stores things like sessions and user data) will not disappear if you upgrade the Workflow installation. If you wish to have persistence for Grafana you can set enabled to true in the values.yaml file before running helm install . grafana: # Configure the following ONLY if you want persistence for on-cluster grafana # GCP PDs and EBS volumes are supported only persistence: enabled: true # Set to true to enable persistence size: 5Gi # PVC size Off Cluster Grafana \u00b6 If you wish to provide your own Grafana instance you can set grafana_location in the values.yaml file before running helm install . InfluxDB \u00b6 InfluxDB writes data to the host disk; however, if the InfluxDB pod dies and comes back on another host, the data will not be recovered. The InfluxDB Admin UI is also exposed through the router allowing users to access the query engine by going to influx.mydomain.com . You will need to configure where to find the influx-api endpoint by clicking the \"gear\" icon at the top right and changing the host to influx-api.mydomain.com and port to 80 . On Cluster Persistence \u00b6 If you wish to have persistence for InfluxDB you can set enabled to true in the values.yaml file before running helm install . influxdb: # Configure the following ONLY if you want persistence for on-cluster grafana # GCP PDs and EBS volumes are supported only persistence: enabled: true # Set to true to enable persistence size: 5Gi # PVC size Off Cluster Influxdb \u00b6 To use off-cluster Influx, please provide the following values in the values.yaml file before running helm install . influxdb_location=off-cluster url = \"http://my-influxhost.com:8086\" database = \"metrics\" user = \"InfluxUser\" password = \"MysuperSecurePassword\" Telegraf \u00b6 Telegraf is the metrics collection daemon used within the monitoring stack. It will collect and send the following metrics to InfluxDB: System level metrics such as CPU, Load Average, Memory, Disk, and Network stats Container level metrics such as CPU and Memory Kubernetes metrics such as API request latency, Pod Startup Latency, and number of running pods It is possible to send these metrics to other endpoints besides InfluxDB. For more information please consult the following file Customizing the Monitoring Stack \u00b6 To learn more about customizing each of the above components please visit the Tuning Component Settings section.","title":"Platform Monitoring"},{"location":"managing-workflow/platform-monitoring/#platform-monitoring","text":"","title":"Platform Monitoring"},{"location":"managing-workflow/platform-monitoring/#description","text":"We now include a monitoring stack for introspection on a running Kubernetes cluster. The stack includes 3 components: Telegraf - Metrics collection daemon written by team behind InfluxDB. InfluxDB - Time series database Grafana - Graphing tool for time series data","title":"Description"},{"location":"managing-workflow/platform-monitoring/#architecture-diagram","text":"\u250c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2510 \u2502 Router \u2502 \u250c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2510 \u250c\u2500\u2500\u2500\u2500\u2500\u2510 \u2514\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2518 \u2502 Logger \u2502\u25c0\u2500\u2500\u2500\u25b6\u2502Redis\u2502 \u2502 \u2514\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2518 \u2514\u2500\u2500\u2500\u2500\u2500\u2518 Log file \u25b2 \u2502 \u2502 \u25bc \u2502 \u250c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2510 \u250c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2510 logs/metrics \u250c\u2500\u2500\u2500\u2500\u2500\u2510 \u2502App Logs\u2502\u2500\u2500Log File\u2500\u2500\u25b6\u2502 fluentd \u2502\u2500\u2500\u2500\u2500\u2500\u2500\u2500topics\u2500\u2500\u2500\u2500\u2500\u25b6\u2502 NSQ \u2502 \u2514\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2518 \u2514\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2518 \u2514\u2500\u2500\u2500\u2500\u2500\u2518 \u2502 \u2502 \u250c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2510 \u2502 \u2502 HOST \u2502 \u25bc \u2502 Telegraf \u2502\u2500\u2500\u2500\u2510 \u250c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2510 \u2514\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2518 \u2502 \u2502Telegraf\u2502 \u2502 \u2514\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2518 \u250c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2510 \u2502 \u2502 \u2502 HOST \u2502 \u2502 \u250c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2510 \u2502 \u2502 Telegraf \u2502\u2500\u2500\u2500\u253c\u2500\u2500\u2500\u25b6\u2502 InfluxDB \u2502\u25c0\u2500\u2500\u2500\u2500Wire \u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2518 \u2514\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2518 \u2502 \u2514\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2518 Protocol \u2502 \u25b2 \u250c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2510 \u2502 \u2502 \u2502 HOST \u2502 \u2502 \u25bc \u2502 Telegraf \u2502\u2500\u2500\u2500\u2518 \u250c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2510 \u2514\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2518 \u2502 Grafana \u2502 \u2514\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2518","title":"Architecture Diagram"},{"location":"managing-workflow/platform-monitoring/#grafana","text":"Grafana allows users to create custom dashboards that visualize the data captured to the running InfluxDB component. By default Grafana is exposed using a service annotation through the router at the following URL: http://grafana.mydomain.com . The default login is admin/admin . If you are interested in changing these values please see Tuning Component Settings . Grafana will preload several dashboards to help operators get started with monitoring Kubernetes and Drycc Workflow. These dashboards are meant as starting points and don't include every item that might be desirable to monitor in a production installation. Drycc Workflow monitoring by default does not write data to the host filesystem or to long-term storage. If the Grafana instance fails, modified dashboards are lost.","title":"Grafana"},{"location":"managing-workflow/platform-monitoring/#production-configuration","text":"A production install of Grafana should have the following configuration values changed if possible: Change the default username and password from admin/admin . The value for the password is passed in plain text so it is best to set this value on the command line instead of checking it into version control. Enable persistence Use a supported external database such as mysql or postgres. You can find more information here","title":"Production Configuration"},{"location":"managing-workflow/platform-monitoring/#on-cluster-persistence","text":"Enabling persistence will allow your custom configuration to persist across pod restarts. This means that the default sqllite database (which stores things like sessions and user data) will not disappear if you upgrade the Workflow installation. If you wish to have persistence for Grafana you can set enabled to true in the values.yaml file before running helm install . grafana: # Configure the following ONLY if you want persistence for on-cluster grafana # GCP PDs and EBS volumes are supported only persistence: enabled: true # Set to true to enable persistence size: 5Gi # PVC size","title":"On Cluster Persistence"},{"location":"managing-workflow/platform-monitoring/#off-cluster-grafana","text":"If you wish to provide your own Grafana instance you can set grafana_location in the values.yaml file before running helm install .","title":"Off Cluster Grafana"},{"location":"managing-workflow/platform-monitoring/#influxdb","text":"InfluxDB writes data to the host disk; however, if the InfluxDB pod dies and comes back on another host, the data will not be recovered. The InfluxDB Admin UI is also exposed through the router allowing users to access the query engine by going to influx.mydomain.com . You will need to configure where to find the influx-api endpoint by clicking the \"gear\" icon at the top right and changing the host to influx-api.mydomain.com and port to 80 .","title":"InfluxDB"},{"location":"managing-workflow/platform-monitoring/#on-cluster-persistence_1","text":"If you wish to have persistence for InfluxDB you can set enabled to true in the values.yaml file before running helm install . influxdb: # Configure the following ONLY if you want persistence for on-cluster grafana # GCP PDs and EBS volumes are supported only persistence: enabled: true # Set to true to enable persistence size: 5Gi # PVC size","title":"On Cluster Persistence"},{"location":"managing-workflow/platform-monitoring/#off-cluster-influxdb","text":"To use off-cluster Influx, please provide the following values in the values.yaml file before running helm install . influxdb_location=off-cluster url = \"http://my-influxhost.com:8086\" database = \"metrics\" user = \"InfluxUser\" password = \"MysuperSecurePassword\"","title":"Off Cluster Influxdb"},{"location":"managing-workflow/platform-monitoring/#telegraf","text":"Telegraf is the metrics collection daemon used within the monitoring stack. It will collect and send the following metrics to InfluxDB: System level metrics such as CPU, Load Average, Memory, Disk, and Network stats Container level metrics such as CPU and Memory Kubernetes metrics such as API request latency, Pod Startup Latency, and number of running pods It is possible to send these metrics to other endpoints besides InfluxDB. For more information please consult the following file","title":"Telegraf"},{"location":"managing-workflow/platform-monitoring/#customizing-the-monitoring-stack","text":"To learn more about customizing each of the above components please visit the Tuning Component Settings section.","title":"Customizing the Monitoring Stack"},{"location":"managing-workflow/production-deployments/","text":"Production Deployments \u00b6 When readying a Workflow deployment for production workloads, there are some additional recommendations. Running Workflow without Minio \u00b6 Workflow makes use of Minio to provide storage for the Registry , Database , and Logger components. Minio is provided out of the box as a central storage compartment, but it is not resilient to cluster outages. If Minio is shut down, all data is lost. In production, persistent storage can be achieved by running an external object store. For users on AWS, GCE/GKE or Azure, the convenience of Amazon S3, Google GCS or Microsoft Azure Storage makes the prospect of running a Minio-less Workflow cluster quite reasonable. For users who have restriction on using external object storage using swift object storage can be an option. Running a Workflow cluster without Minio provides several advantages: Removal of state from the worker nodes Reduced resource usage Reduced complexity and operational burden of managing Workflow See Configuring Object Storage for details on removing this operational complexity. Review Security Considerations \u00b6 There are some additional security-related considerations when running Workflow in production. See [Security Considerations][] for details. Registration is Admin-Only \u00b6 By default, registration with the Workflow controller is in \"admin_only\" mode. The first user to run a drycc register command becomes the initial \"admin\" user, and registrations after that are disallowed unless requested by an admin. Please see the following documentation to learn about changing registration mode: Customizing Controller Disable Grafana Signups \u00b6 It is also recommended to disable signups for the Grafana dashboards. Please see the following documentation to learn about disabling Grafana signups: Customizing Monitor Using on-cluster registry with CNI \u00b6 If you are using CNI for managing container network, you cannot use hostPort notation due to this issue . In this case you could enable CNI for drycc-registry-proxy by setting use_cni variable to true inside values.yaml or by adding --set global.use_cni=true to helm 's args. Running Workflow with RBAC \u00b6 If your cluster has RBAC amongst your authorization modes ( $ kubectl api-versions should contains rbac.authorization.k8s.io ) it may be necessary to enable RBAC in Workflow. This can be achieved by setting use_rbac in the global section of values.yaml to true , or by adding --set=global.use_rbac=true to the $ helm install/upgrade command. RBAC support was announced in Kubernetes-1.5 and is enabled by default if: - your Kubernetes cluster is in GKE - your Kubernetes cluster built with kubeadm Note : helm may need to be given specific permissions under RBAC if not already done. Attention : Azure ACS Kubernetes clusters are not RBAC-enabled for today due to lack in authentication strategy. Feel free to watch this PR for more details.","title":"Production Deployments"},{"location":"managing-workflow/production-deployments/#production-deployments","text":"When readying a Workflow deployment for production workloads, there are some additional recommendations.","title":"Production Deployments"},{"location":"managing-workflow/production-deployments/#running-workflow-without-minio","text":"Workflow makes use of Minio to provide storage for the Registry , Database , and Logger components. Minio is provided out of the box as a central storage compartment, but it is not resilient to cluster outages. If Minio is shut down, all data is lost. In production, persistent storage can be achieved by running an external object store. For users on AWS, GCE/GKE or Azure, the convenience of Amazon S3, Google GCS or Microsoft Azure Storage makes the prospect of running a Minio-less Workflow cluster quite reasonable. For users who have restriction on using external object storage using swift object storage can be an option. Running a Workflow cluster without Minio provides several advantages: Removal of state from the worker nodes Reduced resource usage Reduced complexity and operational burden of managing Workflow See Configuring Object Storage for details on removing this operational complexity.","title":"Running Workflow without Minio"},{"location":"managing-workflow/production-deployments/#review-security-considerations","text":"There are some additional security-related considerations when running Workflow in production. See [Security Considerations][] for details.","title":"Review Security Considerations"},{"location":"managing-workflow/production-deployments/#registration-is-admin-only","text":"By default, registration with the Workflow controller is in \"admin_only\" mode. The first user to run a drycc register command becomes the initial \"admin\" user, and registrations after that are disallowed unless requested by an admin. Please see the following documentation to learn about changing registration mode: Customizing Controller","title":"Registration is Admin-Only"},{"location":"managing-workflow/production-deployments/#disable-grafana-signups","text":"It is also recommended to disable signups for the Grafana dashboards. Please see the following documentation to learn about disabling Grafana signups: Customizing Monitor","title":"Disable Grafana Signups"},{"location":"managing-workflow/production-deployments/#using-on-cluster-registry-with-cni","text":"If you are using CNI for managing container network, you cannot use hostPort notation due to this issue . In this case you could enable CNI for drycc-registry-proxy by setting use_cni variable to true inside values.yaml or by adding --set global.use_cni=true to helm 's args.","title":"Using on-cluster registry with CNI"},{"location":"managing-workflow/production-deployments/#running-workflow-with-rbac","text":"If your cluster has RBAC amongst your authorization modes ( $ kubectl api-versions should contains rbac.authorization.k8s.io ) it may be necessary to enable RBAC in Workflow. This can be achieved by setting use_rbac in the global section of values.yaml to true , or by adding --set=global.use_rbac=true to the $ helm install/upgrade command. RBAC support was announced in Kubernetes-1.5 and is enabled by default if: - your Kubernetes cluster is in GKE - your Kubernetes cluster built with kubeadm Note : helm may need to be given specific permissions under RBAC if not already done. Attention : Azure ACS Kubernetes clusters are not RBAC-enabled for today due to lack in authentication strategy. Feel free to watch this PR for more details.","title":"Running Workflow with RBAC"},{"location":"managing-workflow/tuning-component-settings/","text":"Tuning Component Settings \u00b6 Helm Charts are a set of Kubernetes manifests that reflect best practices for deploying an application or service on Kubernetes. After you add the Drycc Chart Repository, you can customize the chart using helm inspect values drycc/workflow > values.yaml before using helm install to complete the installation. There are a few ways to customize the respective component: If the value is exposed in the values.yaml file as derived above, one may modify the section of the component to tune these settings. The modified value(s) will then take effect at chart installation or release upgrade time via either of the two respective commands: $ helm install drycc/workflow -n drycc --namespace drycc -f values.yaml $ helm upgrade drycc -f values.yaml If the value hasn't yet been exposed in the values.yaml file, one may edit the component deployment with the tuned setting. Here we edit the drycc-controller deployment: $ kubectl --namespace drycc edit deployment drycc-controller Add/edit the setting via the appropriate environment variable and value under the env section and save. The updated deployment will recreate the component pod with the new/modified setting. Lastly, one may also fetch and edit the chart as served by version control/the chart repository itself: $ helm fetch drycc/workflow --untar $ $EDITOR workflow/charts/controller/templates/controller-deployment.yaml Then run helm install ./workflow --namespace drycc --name drycc to apply the changes, or helm upgrade drycc ./workflow if the cluster is already running. Setting Resource limits \u00b6 You can set resource limits to Workflow components by modifying the values.yaml file fetched earlier. This file has a section for each Workflow component. To set a limit to any Workflow component just add limits_cpu , limits_memory in the section and set them to the appropriate values. Below is an example of how the builder section of values.yaml might look with CPU and memory limits set: builder: org: \"drycc\" pullPolicy: \"Always\" dockerTag: \"canary\" limits_cpu: \"100m\" limits_memory: \"50Mi\" Customizing the Builder \u00b6 The following environment variables are tunable for the Builder component: Setting Description DEBUG Enable debug log output (default: false) BUILDER_POD_NODE_SELECTOR A node selector setting for builder job. As it may sometimes consume a lot of node resources, one may want a given builder job to run in a specific node only, so it won't affect critical nodes. for example pool:testing,disk:magnetic Customizing the Controller \u00b6 The following environment variables are tunable for the Controller component: Setting Description REGISTRATION_MODE set registration to \"enabled\", \"disabled\", or \"admin_only\" (default: \"admin_only\") GUNICORN_WORKERS number of gunicorn workers spawned to process requests (default: CPU cores * 4 + 1) RESERVED_NAMES a comma-separated list of names which applications cannot reserve for routing (default: \"drycc, drycc-builder\") SLUGRUNNER_IMAGE_NAME the image used to run buildpack application slugs (default: \"quay.io/drycc/slugrunner:canary\") DRYCC_DEPLOY_HOOK_URLS a comma-separated list of URLs to send deploy hooks to. DRYCC_DEPLOY_HOOK_SECRET_KEY a private key used to compute the HMAC signature for deploy hooks. DRYCC_DEPLOY_REJECT_IF_PROCFILE_MISSING rejects a deploy if the previous build had a Procfile but the current deploy is missing it. A 409 is thrown in the API. Prevents accidental process types removal. (default: \"false\", allowed values: \"true\", \"false\") DRYCC_DEPLOY_PROCFILE_MISSING_REMOVE when turned on (default) any missing process type in a Procfile compared to the previous deploy is removed. When set to false will allow an empty Procfile to go through without removing missing process types, note that new images, configs and so on will get updated on all proc types. (default: \"true\", allowed values: \"true\", \"false\") DRYCC_DEFAULT_CONFIG_TAGS set tags for all applications by default, for example: '{\"role\": \"worker\"}'. (default: '') KUBERNETES_NAMESPACE_DEFAULT_QUOTA_SPEC set resource quota to application namespace by setting ResourceQuota spec, for example: {\"spec\":{\"hard\":{\"pods\":\"10\"}}} , restrict app owner to spawn more then 10 pods (default: \"\", no quota will be applied to namespace) LDAP authentication settings \u00b6 Configuration options for LDAP authentication are detailed here . The following environment variables are available for enabling LDAP authentication of user accounts in the Controller component: Setting Description LDAP_ENDPOINT The URI of the LDAP server. If not specified, LDAP authentication is not enabled (default: \"\", example: ldap://hostname ). LDAP_BIND_DN The distinguished name to use when binding to the LDAP server (default: \"\") LDAP_BIND_PASSWORD The password to use with LDAP_BIND_DN (default: \"\") LDAP_USER_BASEDN The distinguished name of the search base for user names (default: \"\") LDAP_USER_FILTER The name of the login field in the users search base (default: \"username\") LDAP_GROUP_BASEDN The distinguished name of the search base for user's groups names (default: \"\") LDAP_GROUP_FILTER The filter for user's groups (default: \"\", example: objectClass=person ) Global and per application settings \u00b6 Setting Description DRYCC_DEPLOY_BATCHES the number of pods to bring up and take down sequentially during a scale (default: number of available nodes) DRYCC_DEPLOY_TIMEOUT deploy timeout in seconds per deploy batch (default: 120) IMAGE_PULL_POLICY the kubernetes image pull policy for application images (default: \"IfNotPresent\") (allowed values: \"Always\", \"IfNotPresent\") KUBERNETES_DEPLOYMENTS_REVISION_HISTORY_LIMIT how many revisions Kubernetes keeps around of a given Deployment (default: all revisions) KUBERNETES_POD_TERMINATION_GRACE_PERIOD_SECONDS how many seconds kubernetes waits for a pod to finish work after a SIGTERM before sending SIGKILL (default: 30) See the Deploying Apps guide for more detailed information on those. Customizing the Database \u00b6 The following environment variables are tunable for the Database component: Setting Description BACKUP_FREQUENCY how often the database should perform a base backup (default: \"12h\") BACKUPS_TO_RETAIN number of base backups the backing store should retain (default: 5) Customizing Fluentd \u00b6 The following values can be changed in the values.yaml file or by using the --set flag with the Helm CLI. Key Default Description syslog.host \"\" Host value of a syslog endpoint syslog.port \"\" Port value of a syslog endpoint sources.start_script false Capture kubernetes start script logs sources.docker false Capture docker daemon logs sources.etcd false Capture etcd logs sources.kubelet false Capture kubelet logs sources.kube_api false Capture Kubernetes API logs sources.controller false Capture Kubernetes Controller logs sources.scheduler false Capture Kubernetes Scheduler logs output.disable_drycc false Disable the Drycc output plugin boot.install_build_tools false Install the build tools package. This is useful when using custom plugins daemon_environment Takes key-value pairs and turns them into environment variables. For more information about the various environment variables that can be set please see the README Customizing the Logger \u00b6 The following environment variables are tunable for the Logger component: Setting Description STORAGE_ADAPTER How to store logs that are sent to the logger. Legal values are \"file\", \"memory\", and \"redis\". (default: \"redis\") NUMBER_OF_LINES How many lines to store in the ring buffer (default: 1000) Customizing the Monitor \u00b6 Grafana \u00b6 We have exposed some of the more useful configuration values directly in the chart. This allows them to be set using either the values.yaml file or by using the --set flag with the Helm CLI. You can see these options below: Setting | Default Value | Description ----------------- | -------------- |------------ | user | \"admin\" | The first user created in the database (this user has admin privileges) password | \"admin\" | Password for the first user. allow_sign_up | \"true\" | Allows users to sign up for an account. For a list of other options you can set by using environment variables please see the configuration file in Github. Telegraf \u00b6 For a list of configuration values that can be set by using environment variables please see the following configuration file . InfluxDB \u00b6 You can find a list of values that can be set using environment variables here . Customizing the Registry \u00b6 The Registry component can be tuned by following the drycc/distribution config doc . Customizing the Router \u00b6 The majority of router settings are tunable through annotations, which allows the router to be re-configured with zero downtime post-installation. You can find the list of annotations to tune here . The following environment variables are tunable for the [Router][] component: Setting Description POD_NAMESPACE The pod namespace the router resides in. This is set by the Kubernetes downward API . Customizing Workflow Manager \u00b6 The following environment variables are tunable for [Workflow Manager][]: Setting Description CHECK_VERSIONS Enables the external version check at https://versions.drycc.info/ (default: \"true\") POLL_INTERVAL_SEC The interval when Workflow Manager performs a version check, in seconds (default: 43200, or 12 hours) VERSIONS_API_URL The versions API URL (default: \" https://versions-staging.drycc.info \") DOCTOR_API_URL The doctor API URL (default: \" https://doctor-staging.drycc.info \") API_VERSION The version number Workflow Manager sends to the versions API (default: \"v2\")","title":"Tuning Component Settings"},{"location":"managing-workflow/tuning-component-settings/#tuning-component-settings","text":"Helm Charts are a set of Kubernetes manifests that reflect best practices for deploying an application or service on Kubernetes. After you add the Drycc Chart Repository, you can customize the chart using helm inspect values drycc/workflow > values.yaml before using helm install to complete the installation. There are a few ways to customize the respective component: If the value is exposed in the values.yaml file as derived above, one may modify the section of the component to tune these settings. The modified value(s) will then take effect at chart installation or release upgrade time via either of the two respective commands: $ helm install drycc/workflow -n drycc --namespace drycc -f values.yaml $ helm upgrade drycc -f values.yaml If the value hasn't yet been exposed in the values.yaml file, one may edit the component deployment with the tuned setting. Here we edit the drycc-controller deployment: $ kubectl --namespace drycc edit deployment drycc-controller Add/edit the setting via the appropriate environment variable and value under the env section and save. The updated deployment will recreate the component pod with the new/modified setting. Lastly, one may also fetch and edit the chart as served by version control/the chart repository itself: $ helm fetch drycc/workflow --untar $ $EDITOR workflow/charts/controller/templates/controller-deployment.yaml Then run helm install ./workflow --namespace drycc --name drycc to apply the changes, or helm upgrade drycc ./workflow if the cluster is already running.","title":"Tuning Component Settings"},{"location":"managing-workflow/tuning-component-settings/#setting-resource-limits","text":"You can set resource limits to Workflow components by modifying the values.yaml file fetched earlier. This file has a section for each Workflow component. To set a limit to any Workflow component just add limits_cpu , limits_memory in the section and set them to the appropriate values. Below is an example of how the builder section of values.yaml might look with CPU and memory limits set: builder: org: \"drycc\" pullPolicy: \"Always\" dockerTag: \"canary\" limits_cpu: \"100m\" limits_memory: \"50Mi\"","title":"Setting Resource limits"},{"location":"managing-workflow/tuning-component-settings/#customizing-the-builder","text":"The following environment variables are tunable for the Builder component: Setting Description DEBUG Enable debug log output (default: false) BUILDER_POD_NODE_SELECTOR A node selector setting for builder job. As it may sometimes consume a lot of node resources, one may want a given builder job to run in a specific node only, so it won't affect critical nodes. for example pool:testing,disk:magnetic","title":"Customizing the Builder"},{"location":"managing-workflow/tuning-component-settings/#customizing-the-controller","text":"The following environment variables are tunable for the Controller component: Setting Description REGISTRATION_MODE set registration to \"enabled\", \"disabled\", or \"admin_only\" (default: \"admin_only\") GUNICORN_WORKERS number of gunicorn workers spawned to process requests (default: CPU cores * 4 + 1) RESERVED_NAMES a comma-separated list of names which applications cannot reserve for routing (default: \"drycc, drycc-builder\") SLUGRUNNER_IMAGE_NAME the image used to run buildpack application slugs (default: \"quay.io/drycc/slugrunner:canary\") DRYCC_DEPLOY_HOOK_URLS a comma-separated list of URLs to send deploy hooks to. DRYCC_DEPLOY_HOOK_SECRET_KEY a private key used to compute the HMAC signature for deploy hooks. DRYCC_DEPLOY_REJECT_IF_PROCFILE_MISSING rejects a deploy if the previous build had a Procfile but the current deploy is missing it. A 409 is thrown in the API. Prevents accidental process types removal. (default: \"false\", allowed values: \"true\", \"false\") DRYCC_DEPLOY_PROCFILE_MISSING_REMOVE when turned on (default) any missing process type in a Procfile compared to the previous deploy is removed. When set to false will allow an empty Procfile to go through without removing missing process types, note that new images, configs and so on will get updated on all proc types. (default: \"true\", allowed values: \"true\", \"false\") DRYCC_DEFAULT_CONFIG_TAGS set tags for all applications by default, for example: '{\"role\": \"worker\"}'. (default: '') KUBERNETES_NAMESPACE_DEFAULT_QUOTA_SPEC set resource quota to application namespace by setting ResourceQuota spec, for example: {\"spec\":{\"hard\":{\"pods\":\"10\"}}} , restrict app owner to spawn more then 10 pods (default: \"\", no quota will be applied to namespace)","title":"Customizing the Controller"},{"location":"managing-workflow/tuning-component-settings/#ldap-authentication-settings","text":"Configuration options for LDAP authentication are detailed here . The following environment variables are available for enabling LDAP authentication of user accounts in the Controller component: Setting Description LDAP_ENDPOINT The URI of the LDAP server. If not specified, LDAP authentication is not enabled (default: \"\", example: ldap://hostname ). LDAP_BIND_DN The distinguished name to use when binding to the LDAP server (default: \"\") LDAP_BIND_PASSWORD The password to use with LDAP_BIND_DN (default: \"\") LDAP_USER_BASEDN The distinguished name of the search base for user names (default: \"\") LDAP_USER_FILTER The name of the login field in the users search base (default: \"username\") LDAP_GROUP_BASEDN The distinguished name of the search base for user's groups names (default: \"\") LDAP_GROUP_FILTER The filter for user's groups (default: \"\", example: objectClass=person )","title":"LDAP authentication settings"},{"location":"managing-workflow/tuning-component-settings/#global-and-per-application-settings","text":"Setting Description DRYCC_DEPLOY_BATCHES the number of pods to bring up and take down sequentially during a scale (default: number of available nodes) DRYCC_DEPLOY_TIMEOUT deploy timeout in seconds per deploy batch (default: 120) IMAGE_PULL_POLICY the kubernetes image pull policy for application images (default: \"IfNotPresent\") (allowed values: \"Always\", \"IfNotPresent\") KUBERNETES_DEPLOYMENTS_REVISION_HISTORY_LIMIT how many revisions Kubernetes keeps around of a given Deployment (default: all revisions) KUBERNETES_POD_TERMINATION_GRACE_PERIOD_SECONDS how many seconds kubernetes waits for a pod to finish work after a SIGTERM before sending SIGKILL (default: 30) See the Deploying Apps guide for more detailed information on those.","title":"Global and per application settings"},{"location":"managing-workflow/tuning-component-settings/#customizing-the-database","text":"The following environment variables are tunable for the Database component: Setting Description BACKUP_FREQUENCY how often the database should perform a base backup (default: \"12h\") BACKUPS_TO_RETAIN number of base backups the backing store should retain (default: 5)","title":"Customizing the Database"},{"location":"managing-workflow/tuning-component-settings/#customizing-fluentd","text":"The following values can be changed in the values.yaml file or by using the --set flag with the Helm CLI. Key Default Description syslog.host \"\" Host value of a syslog endpoint syslog.port \"\" Port value of a syslog endpoint sources.start_script false Capture kubernetes start script logs sources.docker false Capture docker daemon logs sources.etcd false Capture etcd logs sources.kubelet false Capture kubelet logs sources.kube_api false Capture Kubernetes API logs sources.controller false Capture Kubernetes Controller logs sources.scheduler false Capture Kubernetes Scheduler logs output.disable_drycc false Disable the Drycc output plugin boot.install_build_tools false Install the build tools package. This is useful when using custom plugins daemon_environment Takes key-value pairs and turns them into environment variables. For more information about the various environment variables that can be set please see the README","title":"Customizing Fluentd"},{"location":"managing-workflow/tuning-component-settings/#customizing-the-logger","text":"The following environment variables are tunable for the Logger component: Setting Description STORAGE_ADAPTER How to store logs that are sent to the logger. Legal values are \"file\", \"memory\", and \"redis\". (default: \"redis\") NUMBER_OF_LINES How many lines to store in the ring buffer (default: 1000)","title":"Customizing the Logger"},{"location":"managing-workflow/tuning-component-settings/#customizing-the-monitor","text":"","title":"Customizing the Monitor"},{"location":"managing-workflow/tuning-component-settings/#grafana","text":"We have exposed some of the more useful configuration values directly in the chart. This allows them to be set using either the values.yaml file or by using the --set flag with the Helm CLI. You can see these options below: Setting | Default Value | Description ----------------- | -------------- |------------ | user | \"admin\" | The first user created in the database (this user has admin privileges) password | \"admin\" | Password for the first user. allow_sign_up | \"true\" | Allows users to sign up for an account. For a list of other options you can set by using environment variables please see the configuration file in Github.","title":"Grafana"},{"location":"managing-workflow/tuning-component-settings/#telegraf","text":"For a list of configuration values that can be set by using environment variables please see the following configuration file .","title":"Telegraf"},{"location":"managing-workflow/tuning-component-settings/#influxdb","text":"You can find a list of values that can be set using environment variables here .","title":"InfluxDB"},{"location":"managing-workflow/tuning-component-settings/#customizing-the-registry","text":"The Registry component can be tuned by following the drycc/distribution config doc .","title":"Customizing the Registry"},{"location":"managing-workflow/tuning-component-settings/#customizing-the-router","text":"The majority of router settings are tunable through annotations, which allows the router to be re-configured with zero downtime post-installation. You can find the list of annotations to tune here . The following environment variables are tunable for the [Router][] component: Setting Description POD_NAMESPACE The pod namespace the router resides in. This is set by the Kubernetes downward API .","title":"Customizing the Router"},{"location":"managing-workflow/tuning-component-settings/#customizing-workflow-manager","text":"The following environment variables are tunable for [Workflow Manager][]: Setting Description CHECK_VERSIONS Enables the external version check at https://versions.drycc.info/ (default: \"true\") POLL_INTERVAL_SEC The interval when Workflow Manager performs a version check, in seconds (default: 43200, or 12 hours) VERSIONS_API_URL The versions API URL (default: \" https://versions-staging.drycc.info \") DOCTOR_API_URL The doctor API URL (default: \" https://doctor-staging.drycc.info \") API_VERSION The version number Workflow Manager sends to the versions API (default: \"v2\")","title":"Customizing Workflow Manager"},{"location":"managing-workflow/upgrading-workflow/","text":"Upgrading Workflow \u00b6 Drycc Workflow releases may be upgraded in-place with minimal downtime. This upgrade process requires: Helm version 2.1.0 or newer Configured Off-Cluster Storage Off-Cluster Storage Required \u00b6 A Workflow upgrade requires using off-cluster object storage, since the default in-cluster storage is ephemeral. Upgrading Workflow with the in-cluster default of Minio will result in data loss. See Configuring Object Storage to learn how to store your Workflow data off-cluster. Upgrade Process \u00b6 Note If upgrading from a Helm Classic install, you'll need to 'migrate' the cluster to a Kubernetes Helm installation. See Workflow-Migration for steps. Step 1: Apply the Workflow upgrade \u00b6 Helm will remove all components from the previous release. Traffic to applications deployed through Workflow will continue to flow during the upgrade. No service interruptions should occur. If Workflow is not configured to use off-cluster Postgres, the Workflow API will experience a brief period of downtime while the database recovers from backup. First, find the name of the release helm gave to your deployment with helm ls , then run $ helm repo update $ helm upgrade <release-name> drycc/workflow Note: If using off-cluster object storage on gcs and/or off-cluster registry using gcr and intending to upgrade from a pre- v2.10.0 chart to v2.10.0 or greater, the key_json values will now need to be pre-base64-encoded. Therefore, assuming the rest of the custom/off-cluster values are defined in the existing values.yaml used for previous installs, the following may be run: $ B64_KEY_JSON=\"$(cat ~/path/to/key.json | base64 -w 0)\" $ helm upgrade <release_name> drycc/workflow -f values.yaml --set gcs.key_json=\"${B64_KEY_JSON}\",registry-token-refresher.gcr.key_json=\"${B64_KEY_JSON}\" Alternatively, simply replace the appropriate values in values.yaml and do without the --set parameter. Make sure to wrap it in single quotes as double quotes will give a parser error when upgrading. Step 2: Verify Upgrade \u00b6 Verify that all components have started and passed their readiness checks: $ kubectl --namespace=drycc get pods NAME READY STATUS RESTARTS AGE drycc-builder-2448122224-3cibz 1/1 Running 0 5m drycc-controller-1410285775-ipc34 1/1 Running 3 5m drycc-database-e7c5z 1/1 Running 0 5m drycc-logger-cgjup 1/1 Running 3 5m drycc-logger-fluentd-45h7j 1/1 Running 0 5m drycc-logger-fluentd-4z7lw 1/1 Running 0 5m drycc-logger-fluentd-k2wsw 1/1 Running 0 5m drycc-logger-fluentd-skdw4 1/1 Running 0 5m drycc-logger-redis-8nazu 1/1 Running 0 5m drycc-monitor-grafana-tm266 1/1 Running 0 5m drycc-monitor-influxdb-ah8io 1/1 Running 0 5m drycc-monitor-telegraf-51zel 1/1 Running 1 5m drycc-monitor-telegraf-cdasg 1/1 Running 0 5m drycc-monitor-telegraf-hea6x 1/1 Running 0 5m drycc-monitor-telegraf-r7lsg 1/1 Running 0 5m drycc-nsqd-3yrg2 1/1 Running 0 5m drycc-registry-1814324048-yomz5 1/1 Running 0 5m drycc-registry-proxy-4m3o4 1/1 Running 0 5m drycc-registry-proxy-no3r1 1/1 Running 0 5m drycc-registry-proxy-ou8is 1/1 Running 0 5m drycc-registry-proxy-zyajl 1/1 Running 0 5m Step 3: Upgrade the Drycc Client \u00b6 Users of Drycc Workflow should now upgrade their drycc client to avoid getting WARNING: Client and server API versions do not match. Please consider upgrading. warnings. curl -sSL https://raw.githubusercontent.com/drycc/workflow-cli/master/install-v2.sh | bash -s v2.20.0 && sudo mv drycc $(which drycc)","title":"Upgrading Workflow"},{"location":"managing-workflow/upgrading-workflow/#upgrading-workflow","text":"Drycc Workflow releases may be upgraded in-place with minimal downtime. This upgrade process requires: Helm version 2.1.0 or newer Configured Off-Cluster Storage","title":"Upgrading Workflow"},{"location":"managing-workflow/upgrading-workflow/#off-cluster-storage-required","text":"A Workflow upgrade requires using off-cluster object storage, since the default in-cluster storage is ephemeral. Upgrading Workflow with the in-cluster default of Minio will result in data loss. See Configuring Object Storage to learn how to store your Workflow data off-cluster.","title":"Off-Cluster Storage Required"},{"location":"managing-workflow/upgrading-workflow/#upgrade-process","text":"Note If upgrading from a Helm Classic install, you'll need to 'migrate' the cluster to a Kubernetes Helm installation. See Workflow-Migration for steps.","title":"Upgrade Process"},{"location":"managing-workflow/upgrading-workflow/#step-1-apply-the-workflow-upgrade","text":"Helm will remove all components from the previous release. Traffic to applications deployed through Workflow will continue to flow during the upgrade. No service interruptions should occur. If Workflow is not configured to use off-cluster Postgres, the Workflow API will experience a brief period of downtime while the database recovers from backup. First, find the name of the release helm gave to your deployment with helm ls , then run $ helm repo update $ helm upgrade <release-name> drycc/workflow Note: If using off-cluster object storage on gcs and/or off-cluster registry using gcr and intending to upgrade from a pre- v2.10.0 chart to v2.10.0 or greater, the key_json values will now need to be pre-base64-encoded. Therefore, assuming the rest of the custom/off-cluster values are defined in the existing values.yaml used for previous installs, the following may be run: $ B64_KEY_JSON=\"$(cat ~/path/to/key.json | base64 -w 0)\" $ helm upgrade <release_name> drycc/workflow -f values.yaml --set gcs.key_json=\"${B64_KEY_JSON}\",registry-token-refresher.gcr.key_json=\"${B64_KEY_JSON}\" Alternatively, simply replace the appropriate values in values.yaml and do without the --set parameter. Make sure to wrap it in single quotes as double quotes will give a parser error when upgrading.","title":"Step 1: Apply the Workflow upgrade"},{"location":"managing-workflow/upgrading-workflow/#step-2-verify-upgrade","text":"Verify that all components have started and passed their readiness checks: $ kubectl --namespace=drycc get pods NAME READY STATUS RESTARTS AGE drycc-builder-2448122224-3cibz 1/1 Running 0 5m drycc-controller-1410285775-ipc34 1/1 Running 3 5m drycc-database-e7c5z 1/1 Running 0 5m drycc-logger-cgjup 1/1 Running 3 5m drycc-logger-fluentd-45h7j 1/1 Running 0 5m drycc-logger-fluentd-4z7lw 1/1 Running 0 5m drycc-logger-fluentd-k2wsw 1/1 Running 0 5m drycc-logger-fluentd-skdw4 1/1 Running 0 5m drycc-logger-redis-8nazu 1/1 Running 0 5m drycc-monitor-grafana-tm266 1/1 Running 0 5m drycc-monitor-influxdb-ah8io 1/1 Running 0 5m drycc-monitor-telegraf-51zel 1/1 Running 1 5m drycc-monitor-telegraf-cdasg 1/1 Running 0 5m drycc-monitor-telegraf-hea6x 1/1 Running 0 5m drycc-monitor-telegraf-r7lsg 1/1 Running 0 5m drycc-nsqd-3yrg2 1/1 Running 0 5m drycc-registry-1814324048-yomz5 1/1 Running 0 5m drycc-registry-proxy-4m3o4 1/1 Running 0 5m drycc-registry-proxy-no3r1 1/1 Running 0 5m drycc-registry-proxy-ou8is 1/1 Running 0 5m drycc-registry-proxy-zyajl 1/1 Running 0 5m","title":"Step 2: Verify Upgrade"},{"location":"managing-workflow/upgrading-workflow/#step-3-upgrade-the-drycc-client","text":"Users of Drycc Workflow should now upgrade their drycc client to avoid getting WARNING: Client and server API versions do not match. Please consider upgrading. warnings. curl -sSL https://raw.githubusercontent.com/drycc/workflow-cli/master/install-v2.sh | bash -s v2.20.0 && sudo mv drycc $(which drycc)","title":"Step 3: Upgrade the Drycc Client"},{"location":"quickstart/","text":"Quick Start \u00b6 Get started with Drycc Workflow in three easy steps. Install CLI tools for Helm and Drycc Workflow Boot a Kubernetes and install Drycc Workflow Deploy your first application This guide will help you set up a cluster suitable for evaluation, development and testing. When you are ready for staging and production, view our production checklist . Step 1: Install CLI tools \u00b6 For the quickstart we will install both Helm and Drycc Workflow CLI . Step 2: Boot Kubernetes and Install Drycc Workflow \u00b6 There are many ways to boot and run Kubernetes. You may choose to get up and running in cloud environments or locally on your laptop. Cloud-based options: Google Container Engine : provides a managed Kubernetes environment, available with a few clicks. Amazon Web Services : uses Kubernetes upstream kube-up.sh to boot a cluster on AWS EC2. Azure Container Service : uses Azure Container Service to provision Kubernetes and install Workflow. If you would like to test on your local machine follow, our guide for Minikube . If you have already created a Kubernetes cluster, check out the system requirements and then proceed to install Drycc Workflow on your own Kubernetes cluster . Step 3: Deploy your first app \u00b6 Last but not least, register a user and deploy your first application .","title":"Overview"},{"location":"quickstart/#quick-start","text":"Get started with Drycc Workflow in three easy steps. Install CLI tools for Helm and Drycc Workflow Boot a Kubernetes and install Drycc Workflow Deploy your first application This guide will help you set up a cluster suitable for evaluation, development and testing. When you are ready for staging and production, view our production checklist .","title":"Quick Start"},{"location":"quickstart/#step-1-install-cli-tools","text":"For the quickstart we will install both Helm and Drycc Workflow CLI .","title":"Step 1: Install CLI tools"},{"location":"quickstart/#step-2-boot-kubernetes-and-install-drycc-workflow","text":"There are many ways to boot and run Kubernetes. You may choose to get up and running in cloud environments or locally on your laptop. Cloud-based options: Google Container Engine : provides a managed Kubernetes environment, available with a few clicks. Amazon Web Services : uses Kubernetes upstream kube-up.sh to boot a cluster on AWS EC2. Azure Container Service : uses Azure Container Service to provision Kubernetes and install Workflow. If you would like to test on your local machine follow, our guide for Minikube . If you have already created a Kubernetes cluster, check out the system requirements and then proceed to install Drycc Workflow on your own Kubernetes cluster .","title":"Step 2: Boot Kubernetes and Install Drycc Workflow"},{"location":"quickstart/#step-3-deploy-your-first-app","text":"Last but not least, register a user and deploy your first application .","title":"Step 3: Deploy your first app"},{"location":"quickstart/deploy-an-app/","text":"Determine Your Host and Hostname Values \u00b6 Drycc workflow requires a wildcard DNS record to dynamically map app names to the router. User should already have DNS set up pointing to their known host. The $hostname value can be calculated by prepending drycc. to the value set in global.platform_domain . Register an Admin User \u00b6 The first user to register against Drycc Workflow will automatically be given administrative privileges. Use the controller $hostname to register a user in the cluster. $ drycc register http://$hostname username: admin password: password (confirm): email: jhansen@drycc.cc Registered admin Logged in as admin $ drycc whoami You are admin at http://$hostname You have now registered your first user and you are ready to deploy an application. Deploy an Application \u00b6 Drycc Workflow supports three different types of applications, Buildpacks, Dockerfiles and Docker Images. Our first application will be a simple Docker Image-based application, so you don't have to wrestle with checking out code. Run drycc create to create a new application on Drycc Workflow. If you do not specify a name for your application, Workflow automatically generates a friendly (and sometimes funny) name. $ drycc create --no-remote Creating Application... done, created proper-barbecue If you want to add a git remote for this app later, use `drycc git:remote -a proper-barbecue` Our application has been created and named proper-barbecue . As with the drycc hostname, any HTTP traffic to proper-barbecue will be automatically routed to your application pods by the edge router. Let's use the CLI to tell the platform to deploy an application and then use curl to send a request to the app: $ drycc pull drycc/example-go -a proper-barbecue Creating build... done $ curl http://proper-barbecue.$hostname Powered by Drycc Note If you see a 404 error, make sure you specified your application name with -a <appname> ! Workflow's edge router knows all about application names and automatically sends traffic to the right application. The router sends traffic for proper-barbecue.104.197.125.75.nip.io to your app, just like drycc.104.197.125.75.nip.io was sent to the Workflow API service. Change Application Configuration \u00b6 Next, let's change some configuration using the CLI. Our example app is built to read configuration from the environment. By using drycc config:set we can change how the application behaves: $ drycc config:set POWERED_BY=\"Docker Images + Kubernetes\" -a proper-barbecue Creating config... done === proper-barbecue Config POWERED_BY Docker Images + Kubernetes Behind the scenes, Workflow creates a new release for your application and uses Kubernetes to provide a zero-downtime rolling deploy to the new release! Validate that our configuration change has worked: $ curl http://proper-barbecue.104.197.125.75.nip.io Powered by Docker Images + Kubernetes Scale Your Application \u00b6 Last, let's scale our application by adding more application processes. Using the CLI you can easily add and remove additional processes to service requests: $ drycc scale cmd=2 -a proper-barbecue Scaling processes... but first, coffee! done in 36s === proper-barbecue Processes --- cmd (started): 2 proper-barbecue-v18-cmd-rk644 up (v18) proper-barbecue-v18-cmd-0ag04 up (v18) Congratulations! You have deployed, configured, and scaled your first application using Drycc Workflow. Going Further \u00b6 There is a lot more you can do with Drycc Workflow, play around with the CLI: Important In order to have permission to push an app you must add a SSH key to your user on the Drycc Workflow. For more information, please check Users and SSH Keys and Troubleshooting Workflow . Roll back to a previous release with drycc rollback -a proper-barbecue See application logs with drycc logs -a proper-barbecue Try one of our other example applications like: drycc/example-ruby-sinatra drycc/example-nodejs-express drycc/example-java-jetty Read about using application Buildpacks or Dockerfiles Join our #community slack channel and meet the team!","title":"Deploy Your First App"},{"location":"quickstart/deploy-an-app/#determine-your-host-and-hostname-values","text":"Drycc workflow requires a wildcard DNS record to dynamically map app names to the router. User should already have DNS set up pointing to their known host. The $hostname value can be calculated by prepending drycc. to the value set in global.platform_domain .","title":"Determine Your Host and Hostname Values"},{"location":"quickstart/deploy-an-app/#register-an-admin-user","text":"The first user to register against Drycc Workflow will automatically be given administrative privileges. Use the controller $hostname to register a user in the cluster. $ drycc register http://$hostname username: admin password: password (confirm): email: jhansen@drycc.cc Registered admin Logged in as admin $ drycc whoami You are admin at http://$hostname You have now registered your first user and you are ready to deploy an application.","title":"Register an Admin User"},{"location":"quickstart/deploy-an-app/#deploy-an-application","text":"Drycc Workflow supports three different types of applications, Buildpacks, Dockerfiles and Docker Images. Our first application will be a simple Docker Image-based application, so you don't have to wrestle with checking out code. Run drycc create to create a new application on Drycc Workflow. If you do not specify a name for your application, Workflow automatically generates a friendly (and sometimes funny) name. $ drycc create --no-remote Creating Application... done, created proper-barbecue If you want to add a git remote for this app later, use `drycc git:remote -a proper-barbecue` Our application has been created and named proper-barbecue . As with the drycc hostname, any HTTP traffic to proper-barbecue will be automatically routed to your application pods by the edge router. Let's use the CLI to tell the platform to deploy an application and then use curl to send a request to the app: $ drycc pull drycc/example-go -a proper-barbecue Creating build... done $ curl http://proper-barbecue.$hostname Powered by Drycc Note If you see a 404 error, make sure you specified your application name with -a <appname> ! Workflow's edge router knows all about application names and automatically sends traffic to the right application. The router sends traffic for proper-barbecue.104.197.125.75.nip.io to your app, just like drycc.104.197.125.75.nip.io was sent to the Workflow API service.","title":"Deploy an Application"},{"location":"quickstart/deploy-an-app/#change-application-configuration","text":"Next, let's change some configuration using the CLI. Our example app is built to read configuration from the environment. By using drycc config:set we can change how the application behaves: $ drycc config:set POWERED_BY=\"Docker Images + Kubernetes\" -a proper-barbecue Creating config... done === proper-barbecue Config POWERED_BY Docker Images + Kubernetes Behind the scenes, Workflow creates a new release for your application and uses Kubernetes to provide a zero-downtime rolling deploy to the new release! Validate that our configuration change has worked: $ curl http://proper-barbecue.104.197.125.75.nip.io Powered by Docker Images + Kubernetes","title":"Change Application Configuration"},{"location":"quickstart/deploy-an-app/#scale-your-application","text":"Last, let's scale our application by adding more application processes. Using the CLI you can easily add and remove additional processes to service requests: $ drycc scale cmd=2 -a proper-barbecue Scaling processes... but first, coffee! done in 36s === proper-barbecue Processes --- cmd (started): 2 proper-barbecue-v18-cmd-rk644 up (v18) proper-barbecue-v18-cmd-0ag04 up (v18) Congratulations! You have deployed, configured, and scaled your first application using Drycc Workflow.","title":"Scale Your Application"},{"location":"quickstart/deploy-an-app/#going-further","text":"There is a lot more you can do with Drycc Workflow, play around with the CLI: Important In order to have permission to push an app you must add a SSH key to your user on the Drycc Workflow. For more information, please check Users and SSH Keys and Troubleshooting Workflow . Roll back to a previous release with drycc rollback -a proper-barbecue See application logs with drycc logs -a proper-barbecue Try one of our other example applications like: drycc/example-ruby-sinatra drycc/example-nodejs-express drycc/example-java-jetty Read about using application Buildpacks or Dockerfiles Join our #community slack channel and meet the team!","title":"Going Further"},{"location":"quickstart/install-cli-tools/","text":"Drycc Workflow Client CLI \u00b6 The Drycc command-line interface (CLI), lets you interact with Drycc Workflow. Use the CLI to create and configure and manage applications. Install the drycc client for Linux or Mac OS X with: $ curl -sSL https://raw.githubusercontent.com/drycc/workflow-cli/master/install.tmpl | bash -s v1.0.1 Others please visit: https://github.com/drycc/workflow-cli/releases The installer places the drycc binary in your current directory, but you should move it somewhere in your $PATH: $ sudo ln -fs $PWD/drycc /usr/local/bin/drycc or : $ sudo mv $PWD/drycc /usr/local/bin/drycc Check your work by running drycc version : $ drycc version v2.17.0 Note Note that version numbers may vary as new releases become available Helm Installation \u00b6 We will install Drycc Workflow using Helm which is a tool for installing and managing software in a Kubernetes cluster. Install the latest helm cli for Linux or Mac OS X by following the installation instructions . Step 2: Boot a Kubernetes Cluster and Install Drycc Workflow \u00b6 There are many ways to boot and run Kubernetes. You may choose to get up and running in cloud environments or locally on your laptop. Cloud-based options: Google Container Engine : provides a managed Kubernetes environment, available with a few clicks. Amazon Web Services : uses Kubernetes upstream kops to boot a cluster on AWS EC2. Azure Container Service : provides a managed Kubernetes environment. If you would like to test on your local machine follow our guide for Minikube .","title":"Install CLI Tools"},{"location":"quickstart/install-cli-tools/#drycc-workflow-client-cli","text":"The Drycc command-line interface (CLI), lets you interact with Drycc Workflow. Use the CLI to create and configure and manage applications. Install the drycc client for Linux or Mac OS X with: $ curl -sSL https://raw.githubusercontent.com/drycc/workflow-cli/master/install.tmpl | bash -s v1.0.1 Others please visit: https://github.com/drycc/workflow-cli/releases The installer places the drycc binary in your current directory, but you should move it somewhere in your $PATH: $ sudo ln -fs $PWD/drycc /usr/local/bin/drycc or : $ sudo mv $PWD/drycc /usr/local/bin/drycc Check your work by running drycc version : $ drycc version v2.17.0 Note Note that version numbers may vary as new releases become available","title":"Drycc Workflow Client CLI"},{"location":"quickstart/install-cli-tools/#helm-installation","text":"We will install Drycc Workflow using Helm which is a tool for installing and managing software in a Kubernetes cluster. Install the latest helm cli for Linux or Mac OS X by following the installation instructions .","title":"Helm Installation"},{"location":"quickstart/install-cli-tools/#step-2-boot-a-kubernetes-cluster-and-install-drycc-workflow","text":"There are many ways to boot and run Kubernetes. You may choose to get up and running in cloud environments or locally on your laptop. Cloud-based options: Google Container Engine : provides a managed Kubernetes environment, available with a few clicks. Amazon Web Services : uses Kubernetes upstream kops to boot a cluster on AWS EC2. Azure Container Service : provides a managed Kubernetes environment. If you would like to test on your local machine follow our guide for Minikube .","title":"Step 2: Boot a Kubernetes Cluster and Install Drycc Workflow"},{"location":"quickstart/provider/aws/boot/","text":"Booting Kubernetes on Amazon Elastic Compute with kops \u00b6 Amazon Elastic Compute Cloud (Amazon EC2) is a web service that provides compute capacity in the cloud. This quickstart guide uses AWS EC2 to boot a Kubernetes cluster using kubernetes kops . Installing kops \u00b6 Download the latest version of kops macOS \u00b6 $ curl -sSL https://github.com/kubernetes/kops/releases/download/1.5.3/kops-darwin-amd64 -O $ chmod +x kops-darwin-amd64 $ sudo mv kops-darwin-amd64 /usr/local/bin/kops linux \u00b6 $ curl -sSL https://github.com/kubernetes/kops/releases/download/1.5.3/kops-linux-amd64 -O $ chmod +x kops-linux-amd64 $ sudo mv kops-linux-amd64 /usr/local/bin/kops For more information see the official kops installation guide . Validate kops is installed \u00b6 $ kops version Version 1.5.3 Install kubectl if you haven't done so yet \u00b6 $ curl -LO https://storage.googleapis.com/kubernetes-release/release/$(curl -s https://storage.googleapis.com/kubernetes-release/release/stable.txt)/bin/darwin/amd64/kubectl $ chmod +x kubectl $ sudo mv kubectl /usr/local/bin/ Setup your AWS account \u00b6 Install the awscli tool \u00b6 The officially supported way of installing the tool is with pip as in $ pip install awscli You can also grab the tool with homebrew (for macOS users only ), although this is not officially supported by AWS. $ brew update && brew install awscli Configure the awscli tool \u00b6 The first thing you need to do is get valid AWS credentials out of the console. See the official documentation on how to find your SecretAccessKey and AccessKeyID . Once you have those you can configure the awscli tool with $ aws configure # Input your credentials here Setting up IAM permission for kops \u00b6 The recommended practice is to use a dedicated IAM user for kops. At a minimum kops will require the following IAM permissions to function properly. AmazonEC2FullAccess This is used to deploy to instances in EC2 AmazonRoute53FullAccess This is used so kops can automatically create friendly DNS records for your cluster resources AmazonS3FullAccess This is used to store meta configuration about your cluster. We will need read/write here to use S3 as a virtual filesystem in kops. IAMFullAccess This is used because kops will create new IAM users for some of its resources. Those resources will have permissions managed securely by kops. AmazonVPCFullAccess This used to create a VPC which serves as the foundation of all networking components in kops. Without a VPC, kops wouldn't be able to deploy any resources dependent on a network. (Optional) Create a dedicated IAM user from the command line \u00b6 Note : This can only be done AFTER you already have valid aws credentials in place. We will use the official kops provided convenience script to configure a new user with the following syntax: sh new-iam-user.sh $group $user $ curl -O https://raw.githubusercontent.com/kubernetes/kops/master/hack/new-iam-user.sh $ sh new-iam-user.sh kops-group kops-user Note the SecretAccessKey and AccessKeyID so you can enter them in the following commands $ aws configure # Input your credentials here $ aws iam list-users Configure DNS \u00b6 In order to build a Kubernetes cluster with kops , we need to prepare somewhere to build the required DNS records. There are three scenarios below and you should choose the one that most closely matches your AWS situation. Scenario 1a: A Domain purchased/hosted via AWS \u00b6 If you bought your domain with AWS, then you should already have a hosted zone in Route53. If you plan to use this domain then no more work is needed. In this example you own example.com and your records for Kubernetes would look like etcd-us-east-1c.internal.clustername.example.com You can now skip to testing your DNS setup Scenario 1b: A subdomain under a domain purchased/hosted via AWS \u00b6 In this scenario you want to contain all kubernetes records under a subdomain of a domain you host in Route53. This requires creating a second hosted zone in route53, and then setting up route delegation to the new zone. In this example you own example.com and your records for Kubernetes would look like etcd-us-east-1c.internal.clustername.kubernetes.example.com This is copying the NS servers of your SUBDOMAIN up to the PARENT domain in Route53. To do this you should: $ ID=$(uuidgen) && aws route53 create-hosted-zone --name subdomain.example.com --caller-reference $ID | jq .DelegationSet.NameServers Note your PARENT hosted zone ID # Note: This example assumes you have jq installed locally. aws route53 list-hosted-zones | jq '.HostedZones[] | select(.Name==\"example.com.\") | .Id' Create a new JSON file with your values ( subdomain.json ) Note: The NS values here are for the SUBDOMAIN { \"Comment\": \"Create a subdomain NS record in the parent domain\", \"Changes\": [ { \"Action\": \"CREATE\", \"ResourceRecordSet\": { \"Name\": \"subdomain.example.com\", \"Type\": \"NS\", \"TTL\": 300, \"ResourceRecords\": [ { \"Value\": \"ns-1.awsdns-1.co.uk\" }, { \"Value\": \"ns-2.awsdns-2.org\" }, { \"Value\": \"ns-3.awsdns-3.com\" }, { \"Value\": \"ns-4.awsdns-4.net\" } ] } } ] } Apply the SUBDOMAIN NS records to the PARENT hosted zone. $ aws route53 change-resource-record-sets \\ --hosted-zone-id <parent-zone-id> \\ --change-batch file://subdomain.json Now traffic to *.example.com will be routed to the correct subdomain hosted zone in Route53. You can now skip to testing your DNS setup Scenario 2: Setting up Route53 for a domain purchased with another registrar \u00b6 If you bought your domain elsewhere, and would like to dedicate the entire domain to AWS you should follow the guide here You can now skip to testing your DNS setup Scenario 3: Subdomain for clusters in route53, leaving the domain at another registrar \u00b6 If you bought your domain elsewhere, but only want to use a subdomain in AWS Route53 you must modify your registrar's NS (NameServer) records. We'll create a hosted zone in Route53, and then migrate the subdomain's NS records to your other registrar. You might need to install jq for some of these instructions. $ ID=$(uuidgen) && aws route53 create-hosted-zone --name subdomain.kubernetes.com --caller-reference $ID | jq .DelegationSet.NameServers You will now go to your registrar's page and log in. You will need to create a new SUBDOMAIN , and use the 4 NS records listed above for the new SUBDOMAIN . This MUST be done in order to use your cluster. Do NOT change your top level NS record, or you might take your site offline. Information on adding NS records with Godaddy.com Information on adding NS records with Google Cloud Platform You can now skip to testing your DNS setup Using Public/Private DNS (Kops 1.5+) \u00b6 By default the assumption is that NS records are publically available. If you require private DNS records you should modify the commands we run later in this guide to include: $ kops create cluster --dns private $NAME Testing your DNS setup \u00b6 You should now able to dig your domain (or subdomain) and see the AWS Name Servers on the other end. $ dig ns subdomain.example.com Should return something similar to: ;; ANSWER SECTION: subdomain.example.com. 172800 IN NS ns-1.awsdns-1.net. subdomain.example.com. 172800 IN NS ns-2.awsdns-2.org. subdomain.example.com. 172800 IN NS ns-3.awsdns-3.com. subdomain.example.com. 172800 IN NS ns-4.awsdns-4.co.uk. This is a critical component of setting up clusters. If you are experiencing problems with the Kubernetes API not coming up, chances are something is wrong with the cluster's DNS. Please DO NOT MOVE ON until you have validated your NS records! Cluster State storage \u00b6 In order to store the state of your cluster, and the representation of your cluster, we need to create a dedicated S3 bucket for kops to use. This bucket will become the source of truth for our cluster configuration. In this guide we'll call this bucket example-com-state-store , but you should add a custom prefix as bucket names need to be unique. We recommend keeping the creation of this bucket confined to us-east-1, otherwise more work will be required. $ aws s3api create-bucket --bucket prefix-example-com-state-store --region us-east-1 Note: We STRONGLY recommend versioning your S3 bucket in case you ever need to revert or recover a previous state store. $ aws s3api put-bucket-versioning --bucket prefix-example-com-state-store --versioning-configuration Status=Enabled Creating your first cluster \u00b6 Prepare local environment \u00b6 We're ready to start creating our first cluster! Let's first setup a few environment variables to make this process easier. $ export NAME=myfirstcluster.example.com $ export KOPS_STATE_STORE=s3://prefix-example-com-state-store Note: You don\u2019t have to use environmental variables here. You can always define the values using the \u2013name and \u2013state flags later. Create cluster configuration \u00b6 We will need to note which availability zones are available to us. In this example we will be deploying our cluster to the us-west-2 region. $ aws ec2 describe-availability-zones --region us-west-2 Below is a basic create cluster command. The below command will generate a cluster configuration, but not start building it. $ kops create cluster \\ --zones us-west-2a \\ ${NAME} All instances created by kops will be built within ASG (Auto Scaling Groups), which means each instance will be automatically monitored and rebuilt by AWS if it suffers any failure. Customize Cluster Configuration \u00b6 Now we have a cluster configuration, we can look at every aspect that defines our cluster by editing the description. $ kops edit cluster ${NAME} This opens your editor (as defined by $EDITOR) and allows you to edit the configuration. The configuration is loaded from the S3 bucket we created earlier, and automatically updated when we save and exit the editor. We'll leave everything set to the defaults for now, but the rest of the kops documentation covers additional settings and configuration you can enable. Build the Cluster \u00b6 Now we take the final step of actually building the cluster. This'll take a while. Once it finishes you'll have to wait longer while the booted instances finish downloading Kubernetes components and reach a \"ready\" state. $ kops update cluster ${NAME} --yes Use the Cluster \u00b6 Remember when you installed kubectl earlier? The configuration for your cluster was automatically generated and written to ~/.kube/config for you! Optionally you can always pull the configuration with the following command: $ kops export kubecfg --name ${NAME} A simple Kubernetes API call can be used to check if the API is online and listening. Let's use kubectl to check the nodes. $ kubectl get nodes You will see a list of nodes that should match the --zones flag defined earlier. This is a great sign that your Kubernetes cluster is online and working. Also kops ships with a handy validation tool that can be ran to ensure your cluster is working as expected. $ kubectl cluster-info You can look at all the system components with the following command. $ kubectl -n kube-system get po You are now ready to install Drycc Workflow","title":"Boot"},{"location":"quickstart/provider/aws/boot/#booting-kubernetes-on-amazon-elastic-compute-with-kops","text":"Amazon Elastic Compute Cloud (Amazon EC2) is a web service that provides compute capacity in the cloud. This quickstart guide uses AWS EC2 to boot a Kubernetes cluster using kubernetes kops .","title":"Booting Kubernetes on Amazon Elastic Compute with kops"},{"location":"quickstart/provider/aws/boot/#installing-kops","text":"Download the latest version of kops","title":"Installing kops"},{"location":"quickstart/provider/aws/boot/#macos","text":"$ curl -sSL https://github.com/kubernetes/kops/releases/download/1.5.3/kops-darwin-amd64 -O $ chmod +x kops-darwin-amd64 $ sudo mv kops-darwin-amd64 /usr/local/bin/kops","title":"macOS"},{"location":"quickstart/provider/aws/boot/#linux","text":"$ curl -sSL https://github.com/kubernetes/kops/releases/download/1.5.3/kops-linux-amd64 -O $ chmod +x kops-linux-amd64 $ sudo mv kops-linux-amd64 /usr/local/bin/kops For more information see the official kops installation guide .","title":"linux"},{"location":"quickstart/provider/aws/boot/#validate-kops-is-installed","text":"$ kops version Version 1.5.3","title":"Validate kops is installed"},{"location":"quickstart/provider/aws/boot/#install-kubectl-if-you-havent-done-so-yet","text":"$ curl -LO https://storage.googleapis.com/kubernetes-release/release/$(curl -s https://storage.googleapis.com/kubernetes-release/release/stable.txt)/bin/darwin/amd64/kubectl $ chmod +x kubectl $ sudo mv kubectl /usr/local/bin/","title":"Install kubectl if you haven't done so yet"},{"location":"quickstart/provider/aws/boot/#setup-your-aws-account","text":"","title":"Setup your AWS account"},{"location":"quickstart/provider/aws/boot/#install-the-awscli-tool","text":"The officially supported way of installing the tool is with pip as in $ pip install awscli You can also grab the tool with homebrew (for macOS users only ), although this is not officially supported by AWS. $ brew update && brew install awscli","title":"Install the awscli tool"},{"location":"quickstart/provider/aws/boot/#configure-the-awscli-tool","text":"The first thing you need to do is get valid AWS credentials out of the console. See the official documentation on how to find your SecretAccessKey and AccessKeyID . Once you have those you can configure the awscli tool with $ aws configure # Input your credentials here","title":"Configure the awscli tool"},{"location":"quickstart/provider/aws/boot/#setting-up-iam-permission-for-kops","text":"The recommended practice is to use a dedicated IAM user for kops. At a minimum kops will require the following IAM permissions to function properly. AmazonEC2FullAccess This is used to deploy to instances in EC2 AmazonRoute53FullAccess This is used so kops can automatically create friendly DNS records for your cluster resources AmazonS3FullAccess This is used to store meta configuration about your cluster. We will need read/write here to use S3 as a virtual filesystem in kops. IAMFullAccess This is used because kops will create new IAM users for some of its resources. Those resources will have permissions managed securely by kops. AmazonVPCFullAccess This used to create a VPC which serves as the foundation of all networking components in kops. Without a VPC, kops wouldn't be able to deploy any resources dependent on a network.","title":"Setting up IAM permission for kops"},{"location":"quickstart/provider/aws/boot/#optional-create-a-dedicated-iam-user-from-the-command-line","text":"Note : This can only be done AFTER you already have valid aws credentials in place. We will use the official kops provided convenience script to configure a new user with the following syntax: sh new-iam-user.sh $group $user $ curl -O https://raw.githubusercontent.com/kubernetes/kops/master/hack/new-iam-user.sh $ sh new-iam-user.sh kops-group kops-user Note the SecretAccessKey and AccessKeyID so you can enter them in the following commands $ aws configure # Input your credentials here $ aws iam list-users","title":"(Optional) Create a dedicated IAM user from the command line"},{"location":"quickstart/provider/aws/boot/#configure-dns","text":"In order to build a Kubernetes cluster with kops , we need to prepare somewhere to build the required DNS records. There are three scenarios below and you should choose the one that most closely matches your AWS situation.","title":"Configure DNS"},{"location":"quickstart/provider/aws/boot/#scenario-1a-a-domain-purchasedhosted-via-aws","text":"If you bought your domain with AWS, then you should already have a hosted zone in Route53. If you plan to use this domain then no more work is needed. In this example you own example.com and your records for Kubernetes would look like etcd-us-east-1c.internal.clustername.example.com You can now skip to testing your DNS setup","title":"Scenario 1a: A Domain purchased/hosted via AWS"},{"location":"quickstart/provider/aws/boot/#scenario-1b-a-subdomain-under-a-domain-purchasedhosted-via-aws","text":"In this scenario you want to contain all kubernetes records under a subdomain of a domain you host in Route53. This requires creating a second hosted zone in route53, and then setting up route delegation to the new zone. In this example you own example.com and your records for Kubernetes would look like etcd-us-east-1c.internal.clustername.kubernetes.example.com This is copying the NS servers of your SUBDOMAIN up to the PARENT domain in Route53. To do this you should: $ ID=$(uuidgen) && aws route53 create-hosted-zone --name subdomain.example.com --caller-reference $ID | jq .DelegationSet.NameServers Note your PARENT hosted zone ID # Note: This example assumes you have jq installed locally. aws route53 list-hosted-zones | jq '.HostedZones[] | select(.Name==\"example.com.\") | .Id' Create a new JSON file with your values ( subdomain.json ) Note: The NS values here are for the SUBDOMAIN { \"Comment\": \"Create a subdomain NS record in the parent domain\", \"Changes\": [ { \"Action\": \"CREATE\", \"ResourceRecordSet\": { \"Name\": \"subdomain.example.com\", \"Type\": \"NS\", \"TTL\": 300, \"ResourceRecords\": [ { \"Value\": \"ns-1.awsdns-1.co.uk\" }, { \"Value\": \"ns-2.awsdns-2.org\" }, { \"Value\": \"ns-3.awsdns-3.com\" }, { \"Value\": \"ns-4.awsdns-4.net\" } ] } } ] } Apply the SUBDOMAIN NS records to the PARENT hosted zone. $ aws route53 change-resource-record-sets \\ --hosted-zone-id <parent-zone-id> \\ --change-batch file://subdomain.json Now traffic to *.example.com will be routed to the correct subdomain hosted zone in Route53. You can now skip to testing your DNS setup","title":"Scenario 1b: A subdomain under a domain purchased/hosted via AWS"},{"location":"quickstart/provider/aws/boot/#scenario-2-setting-up-route53-for-a-domain-purchased-with-another-registrar","text":"If you bought your domain elsewhere, and would like to dedicate the entire domain to AWS you should follow the guide here You can now skip to testing your DNS setup","title":"Scenario 2: Setting up Route53 for a domain purchased with another registrar"},{"location":"quickstart/provider/aws/boot/#scenario-3-subdomain-for-clusters-in-route53-leaving-the-domain-at-another-registrar","text":"If you bought your domain elsewhere, but only want to use a subdomain in AWS Route53 you must modify your registrar's NS (NameServer) records. We'll create a hosted zone in Route53, and then migrate the subdomain's NS records to your other registrar. You might need to install jq for some of these instructions. $ ID=$(uuidgen) && aws route53 create-hosted-zone --name subdomain.kubernetes.com --caller-reference $ID | jq .DelegationSet.NameServers You will now go to your registrar's page and log in. You will need to create a new SUBDOMAIN , and use the 4 NS records listed above for the new SUBDOMAIN . This MUST be done in order to use your cluster. Do NOT change your top level NS record, or you might take your site offline. Information on adding NS records with Godaddy.com Information on adding NS records with Google Cloud Platform You can now skip to testing your DNS setup","title":"Scenario 3: Subdomain for clusters in route53, leaving the domain at another registrar"},{"location":"quickstart/provider/aws/boot/#using-publicprivate-dns-kops-15","text":"By default the assumption is that NS records are publically available. If you require private DNS records you should modify the commands we run later in this guide to include: $ kops create cluster --dns private $NAME","title":"Using Public/Private DNS (Kops 1.5+)"},{"location":"quickstart/provider/aws/boot/#testing-your-dns-setup","text":"You should now able to dig your domain (or subdomain) and see the AWS Name Servers on the other end. $ dig ns subdomain.example.com Should return something similar to: ;; ANSWER SECTION: subdomain.example.com. 172800 IN NS ns-1.awsdns-1.net. subdomain.example.com. 172800 IN NS ns-2.awsdns-2.org. subdomain.example.com. 172800 IN NS ns-3.awsdns-3.com. subdomain.example.com. 172800 IN NS ns-4.awsdns-4.co.uk. This is a critical component of setting up clusters. If you are experiencing problems with the Kubernetes API not coming up, chances are something is wrong with the cluster's DNS. Please DO NOT MOVE ON until you have validated your NS records!","title":"Testing your DNS setup"},{"location":"quickstart/provider/aws/boot/#cluster-state-storage","text":"In order to store the state of your cluster, and the representation of your cluster, we need to create a dedicated S3 bucket for kops to use. This bucket will become the source of truth for our cluster configuration. In this guide we'll call this bucket example-com-state-store , but you should add a custom prefix as bucket names need to be unique. We recommend keeping the creation of this bucket confined to us-east-1, otherwise more work will be required. $ aws s3api create-bucket --bucket prefix-example-com-state-store --region us-east-1 Note: We STRONGLY recommend versioning your S3 bucket in case you ever need to revert or recover a previous state store. $ aws s3api put-bucket-versioning --bucket prefix-example-com-state-store --versioning-configuration Status=Enabled","title":"Cluster State storage"},{"location":"quickstart/provider/aws/boot/#creating-your-first-cluster","text":"","title":"Creating your first cluster"},{"location":"quickstart/provider/aws/boot/#prepare-local-environment","text":"We're ready to start creating our first cluster! Let's first setup a few environment variables to make this process easier. $ export NAME=myfirstcluster.example.com $ export KOPS_STATE_STORE=s3://prefix-example-com-state-store Note: You don\u2019t have to use environmental variables here. You can always define the values using the \u2013name and \u2013state flags later.","title":"Prepare local environment"},{"location":"quickstart/provider/aws/boot/#create-cluster-configuration","text":"We will need to note which availability zones are available to us. In this example we will be deploying our cluster to the us-west-2 region. $ aws ec2 describe-availability-zones --region us-west-2 Below is a basic create cluster command. The below command will generate a cluster configuration, but not start building it. $ kops create cluster \\ --zones us-west-2a \\ ${NAME} All instances created by kops will be built within ASG (Auto Scaling Groups), which means each instance will be automatically monitored and rebuilt by AWS if it suffers any failure.","title":"Create cluster configuration"},{"location":"quickstart/provider/aws/boot/#customize-cluster-configuration","text":"Now we have a cluster configuration, we can look at every aspect that defines our cluster by editing the description. $ kops edit cluster ${NAME} This opens your editor (as defined by $EDITOR) and allows you to edit the configuration. The configuration is loaded from the S3 bucket we created earlier, and automatically updated when we save and exit the editor. We'll leave everything set to the defaults for now, but the rest of the kops documentation covers additional settings and configuration you can enable.","title":"Customize Cluster Configuration"},{"location":"quickstart/provider/aws/boot/#build-the-cluster","text":"Now we take the final step of actually building the cluster. This'll take a while. Once it finishes you'll have to wait longer while the booted instances finish downloading Kubernetes components and reach a \"ready\" state. $ kops update cluster ${NAME} --yes","title":"Build the Cluster"},{"location":"quickstart/provider/aws/boot/#use-the-cluster","text":"Remember when you installed kubectl earlier? The configuration for your cluster was automatically generated and written to ~/.kube/config for you! Optionally you can always pull the configuration with the following command: $ kops export kubecfg --name ${NAME} A simple Kubernetes API call can be used to check if the API is online and listening. Let's use kubectl to check the nodes. $ kubectl get nodes You will see a list of nodes that should match the --zones flag defined earlier. This is a great sign that your Kubernetes cluster is online and working. Also kops ships with a handy validation tool that can be ran to ensure your cluster is working as expected. $ kubectl cluster-info You can look at all the system components with the following command. $ kubectl -n kube-system get po You are now ready to install Drycc Workflow","title":"Use the Cluster"},{"location":"quickstart/provider/aws/dns/","text":"Find Your Load Balancer Hostname \u00b6 On EC2, Drycc Workflow will automatically provision and attach an Elastic Load Balancer (ELB) to the Router . The Router is responsible for routing HTTP and HTTPS requests from the public internet to applications that are deployed and managed by Drycc Workflow, as well as streaming TCP requests to the Builder . By describing the nginx Ingress service, you can see what hostname allocated by AWS for your Drycc Workflow cluster: $ kubectl --namespace=ingress-nginx describe svc | egrep LoadBalancer Type: LoadBalancer LoadBalancer Ingress: abce0d48217d311e69a470643b4d9062-2074277678.us-west-1.elb.amazonaws.com Prepare the Hostname \u00b6 Using DNS \u00b6 Now that we have the hostname of the load balancer, let's create the wildcard DNS record that directs requests from your machine to the application. First, if you haven't already done so, register your domain name. The Internet Corporation for Assigned Names and Numbers (ICANN) manages domain names on the Internet. You register a domain name using a domain name registrar, an ICANN-accredited organization that manages the registry of domain names. The website for your registrar will provide detailed instructions and pricing information for registering your domain name. For more information, see the following resources: To use Amazon Route 53 to register a domain name, see Registering Domain Names Using Amazon Route 53 . For a list of accredited registrars, see the Accredited Registrar Directory . Next, use your DNS service, such as your domain registrar, to create a wildcard CNAME record to route queries to your load balancer. For more information, see the documentation for your DNS service. Alternatively, you can use Amazon Route 53 as your DNS service. You create a hosted zone, which contains information about how to route traffic on the Internet for your domain, and an alias resource record set, which routes queries for your domain name to your load balancer. To create a hosted zone and an alias record set for your domain using Amazon Route 53: Open the Amazon Route 53 console at https://console.aws.amazon.com/route53/. Create a Public Hosted Zone with your domain name. Select the hosted zone that you just created for your domain. Click Go to Record Sets. Create a Record Set with the name as * , the type as CNAME - Canonical Name , and as an alias of the Load Balancer created from the router. Using nip.io \u00b6 If you do not have registered a domain name and just want to try out Workflow on AWS, we can use the nip.io wildcard DNS service to route arbitrary hostnames to the Drycc Workflow edge router. This lets us point the Workflow CLI at your cluster without having to either use your own domain or update DNS! Note this is not how you should connect to your cluster after the quickstart. This is for demonstration purposes only. Instead, you will want to use your own domain name routed to the ELB through your domain registrar. AWS actively manages the ELB IPv4 addresses, so what may be an IP address associated with your ELB today will be something else later on. First, pick one of the IP addresses allocated to your ELB: $ host abce0d48217d311e69a470643b4d9062-2074277678.us-west-1.elb.amazonaws.com abce0d48217d311e69a470643b4d9062-2074277678.us-west-1.elb.amazonaws.com has address 52.8.166.233 abce0d48217d311e69a470643b4d9062-2074277678.us-west-1.elb.amazonaws.com has address 54.193.5.73 Grab either address for the next step. We'll use 52.8.166.233 for this example. To verify the Workflow API server and nip.io, construct your hostname by taking the ip address for your load balancer and adding nip.io . For our example above, the address would be: 52.8.166.233.nip.io . Nip answers with the ip address no matter the hostname: $ host 52.8.166.233.nip.io 52.8.166.233.nip.io has address 52.8.166.233 $ host something-random.52.8.166.233.nip.io something-random.52.8.166.233.nip.io has address 52.8.166.233 By default, any HTTP traffic for the hostname drycc will be sent to the Workflow API service. To test that everything is connected properly you may validate connectivity using curl : $ curl http://drycc.52.8.166.233.nip.io/v2/ && echo {\"detail\":\"Authentication credentials were not provided.\"} You should see a failed request because we provided no credentials to the API server. Remember the hostname, we will use it in the next step. You are now ready to register an admin user and deploy your first app . next: deploy your first app","title":"DNS"},{"location":"quickstart/provider/aws/dns/#find-your-load-balancer-hostname","text":"On EC2, Drycc Workflow will automatically provision and attach an Elastic Load Balancer (ELB) to the Router . The Router is responsible for routing HTTP and HTTPS requests from the public internet to applications that are deployed and managed by Drycc Workflow, as well as streaming TCP requests to the Builder . By describing the nginx Ingress service, you can see what hostname allocated by AWS for your Drycc Workflow cluster: $ kubectl --namespace=ingress-nginx describe svc | egrep LoadBalancer Type: LoadBalancer LoadBalancer Ingress: abce0d48217d311e69a470643b4d9062-2074277678.us-west-1.elb.amazonaws.com","title":"Find Your Load Balancer Hostname"},{"location":"quickstart/provider/aws/dns/#prepare-the-hostname","text":"","title":"Prepare the Hostname"},{"location":"quickstart/provider/aws/dns/#using-dns","text":"Now that we have the hostname of the load balancer, let's create the wildcard DNS record that directs requests from your machine to the application. First, if you haven't already done so, register your domain name. The Internet Corporation for Assigned Names and Numbers (ICANN) manages domain names on the Internet. You register a domain name using a domain name registrar, an ICANN-accredited organization that manages the registry of domain names. The website for your registrar will provide detailed instructions and pricing information for registering your domain name. For more information, see the following resources: To use Amazon Route 53 to register a domain name, see Registering Domain Names Using Amazon Route 53 . For a list of accredited registrars, see the Accredited Registrar Directory . Next, use your DNS service, such as your domain registrar, to create a wildcard CNAME record to route queries to your load balancer. For more information, see the documentation for your DNS service. Alternatively, you can use Amazon Route 53 as your DNS service. You create a hosted zone, which contains information about how to route traffic on the Internet for your domain, and an alias resource record set, which routes queries for your domain name to your load balancer. To create a hosted zone and an alias record set for your domain using Amazon Route 53: Open the Amazon Route 53 console at https://console.aws.amazon.com/route53/. Create a Public Hosted Zone with your domain name. Select the hosted zone that you just created for your domain. Click Go to Record Sets. Create a Record Set with the name as * , the type as CNAME - Canonical Name , and as an alias of the Load Balancer created from the router.","title":"Using DNS"},{"location":"quickstart/provider/aws/dns/#using-nipio","text":"If you do not have registered a domain name and just want to try out Workflow on AWS, we can use the nip.io wildcard DNS service to route arbitrary hostnames to the Drycc Workflow edge router. This lets us point the Workflow CLI at your cluster without having to either use your own domain or update DNS! Note this is not how you should connect to your cluster after the quickstart. This is for demonstration purposes only. Instead, you will want to use your own domain name routed to the ELB through your domain registrar. AWS actively manages the ELB IPv4 addresses, so what may be an IP address associated with your ELB today will be something else later on. First, pick one of the IP addresses allocated to your ELB: $ host abce0d48217d311e69a470643b4d9062-2074277678.us-west-1.elb.amazonaws.com abce0d48217d311e69a470643b4d9062-2074277678.us-west-1.elb.amazonaws.com has address 52.8.166.233 abce0d48217d311e69a470643b4d9062-2074277678.us-west-1.elb.amazonaws.com has address 54.193.5.73 Grab either address for the next step. We'll use 52.8.166.233 for this example. To verify the Workflow API server and nip.io, construct your hostname by taking the ip address for your load balancer and adding nip.io . For our example above, the address would be: 52.8.166.233.nip.io . Nip answers with the ip address no matter the hostname: $ host 52.8.166.233.nip.io 52.8.166.233.nip.io has address 52.8.166.233 $ host something-random.52.8.166.233.nip.io something-random.52.8.166.233.nip.io has address 52.8.166.233 By default, any HTTP traffic for the hostname drycc will be sent to the Workflow API service. To test that everything is connected properly you may validate connectivity using curl : $ curl http://drycc.52.8.166.233.nip.io/v2/ && echo {\"detail\":\"Authentication credentials were not provided.\"} You should see a failed request because we provided no credentials to the API server. Remember the hostname, we will use it in the next step. You are now ready to register an admin user and deploy your first app . next: deploy your first app","title":"Using nip.io"},{"location":"quickstart/provider/aws/install-aws/","text":"Installing Drycc Workflow on Amazon Web Services \u00b6 Check Your Setup \u00b6 First check that the helm command is available and the version is v2.5.0 or newer. $ helm version Client: &version.Version{SemVer:\"v2.5.0\", GitCommit:\"012cb0ac1a1b2f888144ef5a67b8dab6c2d45be6\", GitTreeState:\"clean\"} Server: &version.Version{SemVer:\"v2.5.0\", GitCommit:\"012cb0ac1a1b2f888144ef5a67b8dab6c2d45be6\", GitTreeState:\"clean\"} Ensure the kubectl client is installed and can connect to your Kubernetes cluster. Add the Drycc Chart Repository \u00b6 The Drycc Chart Repository contains everything needed to install Drycc Workflow onto a Kubernetes cluster, with a single helm install drycc/workflow --namespace drycc command. Add this repository to Helm: $ helm repo add drycc https://charts.drycc.cc/stable Install Drycc Workflow \u00b6 Now that Helm is installed and the repository has been added, install Workflow by running: $ helm install drycc/workflow --namespace drycc Helm will install a variety of Kubernetes resources in the drycc namespace. Wait for the pods that Helm launched to be ready. Monitor their status by running: $ kubectl --namespace=drycc get pods If it's preferred to have kubectl automatically update as the pod states change, run (type Ctrl-C to stop the watch): $ kubectl --namespace=drycc get pods -w Depending on the order in which the Workflow components initialize, some pods may restart. This is common during the installation: if a component's dependencies are not yet available, that component will exit and Kubernetes will automatically restart it. Here, it can be seen that the controller, builder and registry all took a few loops before they were able to start: $ kubectl --namespace=drycc get pods NAME READY STATUS RESTARTS AGE drycc-builder-hy3xv 1/1 Running 5 5m drycc-controller-g3cu8 1/1 Running 5 5m drycc-database-rad1o 1/1 Running 0 5m drycc-logger-fluentd-1v8uk 1/1 Running 0 5m drycc-logger-fluentd-esm60 1/1 Running 0 5m drycc-logger-sm8b3 1/1 Running 0 5m drycc-minio-4ww3t 1/1 Running 0 5m drycc-registry-asozo 1/1 Running 1 5m Once all of the pods are in the READY state, Drycc Workflow is up and running! Configure your AWS Load Balancer \u00b6 After installing Workflow on your cluster, you will need to adjust your load balancer configuration. By default, the connection timeout for Elastic Load Blancers is 60 seconds. Unfortunately, this timeout is too short for long running connections when using git push functionality of Drycc Workflow. Drycc Workflow will automatically provision and attach a Elastic Loadbalancer to the router component. This component is responsible for routing HTTP and HTTPS requests from the public internet to applications that are deployed and managed by Drycc Workflow. By describing the nginx Ingress service, you can see what IP hostname has been allocated by AWS for your Drycc Workflow cluster: $ kubectl --namespace=ingress-nginx describe svc | egrep LoadBalancer Type: LoadBalancer LoadBalancer Ingress: abce0d48217d311e69a470643b4d9062-2074277678.us-west-1.elb.amazonaws.com The AWS name for the ELB is the first part of hostname, before the - . List all of your ELBs by name to confirm: $ aws elb describe-load-balancers --query 'LoadBalancerDescriptions[*].LoadBalancerName' abce0d48217d311e69a470643b4d9062 Set the connection timeout to 1200 seconds, make sure you use your load balancer name: $ aws elb modify-load-balancer-attributes \\ --load-balancer-name abce0d48217d311e69a470643b4d9062 \\ --load-balancer-attributes \"{\\\"ConnectionSettings\\\":{\\\"IdleTimeout\\\":1200}}\" abce0d48217d311e69a470643b4d9062 CONNECTIONSETTINGS 1200","title":"Install Workflow"},{"location":"quickstart/provider/aws/install-aws/#installing-drycc-workflow-on-amazon-web-services","text":"","title":"Installing Drycc Workflow on Amazon Web Services"},{"location":"quickstart/provider/aws/install-aws/#check-your-setup","text":"First check that the helm command is available and the version is v2.5.0 or newer. $ helm version Client: &version.Version{SemVer:\"v2.5.0\", GitCommit:\"012cb0ac1a1b2f888144ef5a67b8dab6c2d45be6\", GitTreeState:\"clean\"} Server: &version.Version{SemVer:\"v2.5.0\", GitCommit:\"012cb0ac1a1b2f888144ef5a67b8dab6c2d45be6\", GitTreeState:\"clean\"} Ensure the kubectl client is installed and can connect to your Kubernetes cluster.","title":"Check Your Setup"},{"location":"quickstart/provider/aws/install-aws/#add-the-drycc-chart-repository","text":"The Drycc Chart Repository contains everything needed to install Drycc Workflow onto a Kubernetes cluster, with a single helm install drycc/workflow --namespace drycc command. Add this repository to Helm: $ helm repo add drycc https://charts.drycc.cc/stable","title":"Add the Drycc Chart Repository"},{"location":"quickstart/provider/aws/install-aws/#install-drycc-workflow","text":"Now that Helm is installed and the repository has been added, install Workflow by running: $ helm install drycc/workflow --namespace drycc Helm will install a variety of Kubernetes resources in the drycc namespace. Wait for the pods that Helm launched to be ready. Monitor their status by running: $ kubectl --namespace=drycc get pods If it's preferred to have kubectl automatically update as the pod states change, run (type Ctrl-C to stop the watch): $ kubectl --namespace=drycc get pods -w Depending on the order in which the Workflow components initialize, some pods may restart. This is common during the installation: if a component's dependencies are not yet available, that component will exit and Kubernetes will automatically restart it. Here, it can be seen that the controller, builder and registry all took a few loops before they were able to start: $ kubectl --namespace=drycc get pods NAME READY STATUS RESTARTS AGE drycc-builder-hy3xv 1/1 Running 5 5m drycc-controller-g3cu8 1/1 Running 5 5m drycc-database-rad1o 1/1 Running 0 5m drycc-logger-fluentd-1v8uk 1/1 Running 0 5m drycc-logger-fluentd-esm60 1/1 Running 0 5m drycc-logger-sm8b3 1/1 Running 0 5m drycc-minio-4ww3t 1/1 Running 0 5m drycc-registry-asozo 1/1 Running 1 5m Once all of the pods are in the READY state, Drycc Workflow is up and running!","title":"Install Drycc Workflow"},{"location":"quickstart/provider/aws/install-aws/#configure-your-aws-load-balancer","text":"After installing Workflow on your cluster, you will need to adjust your load balancer configuration. By default, the connection timeout for Elastic Load Blancers is 60 seconds. Unfortunately, this timeout is too short for long running connections when using git push functionality of Drycc Workflow. Drycc Workflow will automatically provision and attach a Elastic Loadbalancer to the router component. This component is responsible for routing HTTP and HTTPS requests from the public internet to applications that are deployed and managed by Drycc Workflow. By describing the nginx Ingress service, you can see what IP hostname has been allocated by AWS for your Drycc Workflow cluster: $ kubectl --namespace=ingress-nginx describe svc | egrep LoadBalancer Type: LoadBalancer LoadBalancer Ingress: abce0d48217d311e69a470643b4d9062-2074277678.us-west-1.elb.amazonaws.com The AWS name for the ELB is the first part of hostname, before the - . List all of your ELBs by name to confirm: $ aws elb describe-load-balancers --query 'LoadBalancerDescriptions[*].LoadBalancerName' abce0d48217d311e69a470643b4d9062 Set the connection timeout to 1200 seconds, make sure you use your load balancer name: $ aws elb modify-load-balancer-attributes \\ --load-balancer-name abce0d48217d311e69a470643b4d9062 \\ --load-balancer-attributes \"{\\\"ConnectionSettings\\\":{\\\"IdleTimeout\\\":1200}}\" abce0d48217d311e69a470643b4d9062 CONNECTIONSETTINGS 1200","title":"Configure your AWS Load Balancer"},{"location":"quickstart/provider/azure-acs/boot/","text":"Booting Kubernetes on Azure Container Service \u00b6 Azure Container Service (ACS) is an optimized container hosting solution that works with all the open source tools you know. Azure is great for Kubernetes and Drycc Workflow. If you don't yet have a Microsoft Azure account, start a trial with $200 of free credit here . Prerequisites \u00b6 You should be able to run the az command, which is used to provision resources in the Azure cloud. Either install Azure CLI to your computer or open a Cloud Shell by clicking this icon near the upper right of the Azure Portal : You need an SSH key to deploy the Kubernetes cluster. For help, see Microsoft's documentation about creating SSH key pairs for Linux VMs on Azure. Configure the Azure CLI \u00b6 If you use Cloud Shell , the az client command is already configured. If you installed az locally, log in to your Azure account by typing az login at a command prompt and complete the confirmation code process. You can verify which account is active with the az account show command. Note Your Azure account needs ownership or contributor permissions on an Azure subscription. If the subscription has 2FA enabled, your Azure account must have ownership credentials in order to create the service principal. Create an ACS Kubernetes Cluster \u00b6 Azure Container Service can create a Kubernetes cluster using either the az command line or the Azure web portal . Option 1: Command Line \u00b6 Create a group to contain the ACS Kubernetes cluster resources. Export the resource group's name and location to environment variables for use by later commands: $ # list worldwide datacenter locations so we can pick one $ az account list-locations --query [].name --output tsv $ export AZURE_DC_LOCATION=southcentralus # for example $ export AZURE_RG_NAME=myresourcegroup $ az group create --name \"${AZURE_RG_NAME}\" --location \"${AZURE_DC_LOCATION}\" Run the az acs create command to create your Kubernetes cluster, replacing the --dns-prefix and --ssh-key-value arguments below with your values: $ export AZURE_SERVICE_NAME=myacs $ export AZURE_DNS_PREFIX=mydnsprefix $ az acs create --resource-group=\"${AZURE_RG_NAME}\" --location=\"${AZURE_DC_LOCATION}\" \\ --orchestrator-type=kubernetes --master-count=1 --agent-count=1 \\ --agent-vm-size=\"Standard_D2_v2\" \\ --admin-username=\"k8sadmin\" \\ --name=\"${AZURE_SERVICE_NAME}\" --dns-prefix=\"${AZURE_DNS_PREFIX}\" \\ --ssh-key-value @$HOME/.ssh/id_rsa.pub Azure Container Services immediately begins creating the Kubernetes cluster. After a few minutes, the command returns with information about the new deployment: { \"id\": \"/subscriptions/a123b456-1234-1ab2-12ab-12345678abcd/resourceGroups/myresourcegroup/providers/Microsoft.Resources/deployments/azurecli1496357873.8344654\", \"name\": \"azurecli1496357873.8344654\", \"properties\": { \"correlationId\": \"eae284bc-4380-484c-9302-f355e278c651\", \"debugSetting\": null, \"dependencies\": [], \"mode\": \"Incremental\", \"outputs\": null, ... }, \"resourceGroup\": \"myresourcegroup\" } Your Kubernetes cluster on Azure is ready. Skip the next section and connect to the ACS Kubernetes cluster . Option 2: Web Portal \u00b6 Sign in to the Azure Portal and create a new Azure Container Service. Click on the + New link, then the Compute link, then Azure Container Service . Select Resource Manager as the deployment model: Then click the Create button. Basics \u00b6 Provide these Basics for a new Azure Kubernetes cluster: Orchestrator: Kubernetes Subscription: choose the Azure subscription to be charged for cloud resources Resource group: \"Create new\" with a unique name Location: choose one of Azure's worldwide datacenters Then click the OK button to move on to Master configuration . Master configuration \u00b6 First take a slight detour to create a service principal to access resources. Then supply the Master configuration options for your Kubernetes cluster: DNS name prefix: the first section of the cluster's hostname User name: name of a unix user who will be added to all Kubernetes nodes SSH public Key: a public key to authenticate the unix user specified above Service principal client ID: the appId field of the service principal Service principal client secret: the password field of the service principal Master count: number of Kubernetes masters for the cluster When you are satisfied with your choices, click OK to move on to Agent Configuration . Agent configuration \u00b6 Choose Agent configuration options for your Kubernetes cluster: Agent count: number of Kubernetes nodes to create Agent virtual machine size: \"Standard DS2\" or better is recommended Operating system: Linux When you are satisfied with your choices, click OK to move on to Summary . Summary \u00b6 Confirm the Summary of configuration choices for your Kubernetes cluster: Click OK to tell Azure Container Services to start creating your new Kubernetes cluster. You can monitor the progress of the deployment on the Azure dashboard, or just wait for a notification that it has completed. Your Kubernetes cluster on Azure is ready. Now make sure you can connect to the ACS Kubernetes cluster . Connect to the ACS Kubernetes Cluster \u00b6 kubectl is the Kubernetes command line client. If you don't already have it installed, you can install it with: az acs kubernetes install-cli Download the master kubernetes cluster configuration to the ~/.kube/config file by running the following command: az acs kubernetes get-credentials --resource-group=$AZURE_RG_NAME --name=$AZURE_SERVICE_NAME Note: If the cluster was provisioned using any other SSH key than /home/myusername/.ssh/id_rsa then the --ssh-key-file parameter must be used pointing to the SSH key utilized to provision the cluster. Verify connectivity to the new ACS Kubernetes cluster by running kubectl cluster-info $ kubectl cluster-info Kubernetes master is running at https://mydnsprefix.myregion.cloudapp.azure.com Heapster is running at https://mydnsprefix.myregion.cloudapp.azure.com/api/v1/proxy/namespaces/kube-system/services/heapster KubeDNS is running at https://mydnsprefix.myregion.cloudapp.azure.com/api/v1/proxy/namespaces/kube-system/services/kube-dns kubernetes-dashboard is running at https://mydnsprefix.myregion.cloudapp.azure.com/api/v1/proxy/namespaces/kube-system/services/kubernetes-dashboard You are now ready to install Drycc Workflow","title":"Boot"},{"location":"quickstart/provider/azure-acs/boot/#booting-kubernetes-on-azure-container-service","text":"Azure Container Service (ACS) is an optimized container hosting solution that works with all the open source tools you know. Azure is great for Kubernetes and Drycc Workflow. If you don't yet have a Microsoft Azure account, start a trial with $200 of free credit here .","title":"Booting Kubernetes on Azure Container Service"},{"location":"quickstart/provider/azure-acs/boot/#prerequisites","text":"You should be able to run the az command, which is used to provision resources in the Azure cloud. Either install Azure CLI to your computer or open a Cloud Shell by clicking this icon near the upper right of the Azure Portal : You need an SSH key to deploy the Kubernetes cluster. For help, see Microsoft's documentation about creating SSH key pairs for Linux VMs on Azure.","title":"Prerequisites"},{"location":"quickstart/provider/azure-acs/boot/#configure-the-azure-cli","text":"If you use Cloud Shell , the az client command is already configured. If you installed az locally, log in to your Azure account by typing az login at a command prompt and complete the confirmation code process. You can verify which account is active with the az account show command. Note Your Azure account needs ownership or contributor permissions on an Azure subscription. If the subscription has 2FA enabled, your Azure account must have ownership credentials in order to create the service principal.","title":"Configure the Azure CLI"},{"location":"quickstart/provider/azure-acs/boot/#create-an-acs-kubernetes-cluster","text":"Azure Container Service can create a Kubernetes cluster using either the az command line or the Azure web portal .","title":"Create an ACS Kubernetes Cluster"},{"location":"quickstart/provider/azure-acs/boot/#option-1-command-line","text":"Create a group to contain the ACS Kubernetes cluster resources. Export the resource group's name and location to environment variables for use by later commands: $ # list worldwide datacenter locations so we can pick one $ az account list-locations --query [].name --output tsv $ export AZURE_DC_LOCATION=southcentralus # for example $ export AZURE_RG_NAME=myresourcegroup $ az group create --name \"${AZURE_RG_NAME}\" --location \"${AZURE_DC_LOCATION}\" Run the az acs create command to create your Kubernetes cluster, replacing the --dns-prefix and --ssh-key-value arguments below with your values: $ export AZURE_SERVICE_NAME=myacs $ export AZURE_DNS_PREFIX=mydnsprefix $ az acs create --resource-group=\"${AZURE_RG_NAME}\" --location=\"${AZURE_DC_LOCATION}\" \\ --orchestrator-type=kubernetes --master-count=1 --agent-count=1 \\ --agent-vm-size=\"Standard_D2_v2\" \\ --admin-username=\"k8sadmin\" \\ --name=\"${AZURE_SERVICE_NAME}\" --dns-prefix=\"${AZURE_DNS_PREFIX}\" \\ --ssh-key-value @$HOME/.ssh/id_rsa.pub Azure Container Services immediately begins creating the Kubernetes cluster. After a few minutes, the command returns with information about the new deployment: { \"id\": \"/subscriptions/a123b456-1234-1ab2-12ab-12345678abcd/resourceGroups/myresourcegroup/providers/Microsoft.Resources/deployments/azurecli1496357873.8344654\", \"name\": \"azurecli1496357873.8344654\", \"properties\": { \"correlationId\": \"eae284bc-4380-484c-9302-f355e278c651\", \"debugSetting\": null, \"dependencies\": [], \"mode\": \"Incremental\", \"outputs\": null, ... }, \"resourceGroup\": \"myresourcegroup\" } Your Kubernetes cluster on Azure is ready. Skip the next section and connect to the ACS Kubernetes cluster .","title":"Option 1: Command Line"},{"location":"quickstart/provider/azure-acs/boot/#option-2-web-portal","text":"Sign in to the Azure Portal and create a new Azure Container Service. Click on the + New link, then the Compute link, then Azure Container Service . Select Resource Manager as the deployment model: Then click the Create button.","title":"Option 2: Web Portal"},{"location":"quickstart/provider/azure-acs/boot/#basics","text":"Provide these Basics for a new Azure Kubernetes cluster: Orchestrator: Kubernetes Subscription: choose the Azure subscription to be charged for cloud resources Resource group: \"Create new\" with a unique name Location: choose one of Azure's worldwide datacenters Then click the OK button to move on to Master configuration .","title":"Basics"},{"location":"quickstart/provider/azure-acs/boot/#master-configuration","text":"First take a slight detour to create a service principal to access resources. Then supply the Master configuration options for your Kubernetes cluster: DNS name prefix: the first section of the cluster's hostname User name: name of a unix user who will be added to all Kubernetes nodes SSH public Key: a public key to authenticate the unix user specified above Service principal client ID: the appId field of the service principal Service principal client secret: the password field of the service principal Master count: number of Kubernetes masters for the cluster When you are satisfied with your choices, click OK to move on to Agent Configuration .","title":"Master configuration"},{"location":"quickstart/provider/azure-acs/boot/#agent-configuration","text":"Choose Agent configuration options for your Kubernetes cluster: Agent count: number of Kubernetes nodes to create Agent virtual machine size: \"Standard DS2\" or better is recommended Operating system: Linux When you are satisfied with your choices, click OK to move on to Summary .","title":"Agent configuration"},{"location":"quickstart/provider/azure-acs/boot/#summary","text":"Confirm the Summary of configuration choices for your Kubernetes cluster: Click OK to tell Azure Container Services to start creating your new Kubernetes cluster. You can monitor the progress of the deployment on the Azure dashboard, or just wait for a notification that it has completed. Your Kubernetes cluster on Azure is ready. Now make sure you can connect to the ACS Kubernetes cluster .","title":"Summary"},{"location":"quickstart/provider/azure-acs/boot/#connect-to-the-acs-kubernetes-cluster","text":"kubectl is the Kubernetes command line client. If you don't already have it installed, you can install it with: az acs kubernetes install-cli Download the master kubernetes cluster configuration to the ~/.kube/config file by running the following command: az acs kubernetes get-credentials --resource-group=$AZURE_RG_NAME --name=$AZURE_SERVICE_NAME Note: If the cluster was provisioned using any other SSH key than /home/myusername/.ssh/id_rsa then the --ssh-key-file parameter must be used pointing to the SSH key utilized to provision the cluster. Verify connectivity to the new ACS Kubernetes cluster by running kubectl cluster-info $ kubectl cluster-info Kubernetes master is running at https://mydnsprefix.myregion.cloudapp.azure.com Heapster is running at https://mydnsprefix.myregion.cloudapp.azure.com/api/v1/proxy/namespaces/kube-system/services/heapster KubeDNS is running at https://mydnsprefix.myregion.cloudapp.azure.com/api/v1/proxy/namespaces/kube-system/services/kube-dns kubernetes-dashboard is running at https://mydnsprefix.myregion.cloudapp.azure.com/api/v1/proxy/namespaces/kube-system/services/kubernetes-dashboard You are now ready to install Drycc Workflow","title":"Connect to the ACS Kubernetes Cluster"},{"location":"quickstart/provider/azure-acs/dns/","text":"Find the Load Balancer Address \u00b6 On Azure Container Engine, Drycc Workflow will automatically provision and attach a Azure Load Balancer to the router component. This component is responsible for routing HTTP and HTTPS requests from the public internet to applications that are deployed and managed by Drycc Workflow. Discover the ip address assigned to the nginx Ingress , by describing the ingress service: $ kubectl --namespace=nginx-ingress get svc NAME CLUSTER-IP EXTERNAL-IP PORT(S) AGE default-backend 10.0.60.172 13.82.148.57 80/TCP,443/TCP,2222/TCP,9090/TCP 54m If the EXTERNAL-IP column shows <pending> instead of an ip address continue to wait until Azure finishes provisioning and attaching the load balancer. Prepare the Hostname \u00b6 Now that an ip address has been attached to the load balancer use the nip.io DNS service to route arbitrary hostnames to the Drycc Workflow edge router. Usage of nip.io is not recommended for long-term use and is intended here as a short cut to prevent fiddling with DNS. To verify connectivity to the Workflow API server and nip.io, construct the hostname by taking the ip address of load balancer and adding nip.io . For our example above, the address would be: 13.82.148.57.nip.io . Nip answers with the ip address no matter the hostname: $ host 13.82.148.57.nip.io 13.82.148.57.nip.io has address 13.82.148.57 $ host something-random.13.82.148.57.nip.io something-random.13.82.148.57.nip.io has address 13.82.148.57 By default, any HTTP traffic destined for the hostname drycc is automatically sent to the Workflow API service. To test that everything is connected properly use curl : $ curl http://drycc.13.82.148.57.nip.io/v2/ && echo {\"detail\":\"Authentication credentials were not provided.\"} Since no authentication information has been provided, curl will return an error. However this does validate that curl has reached the Workflow API service. Remember the hostname, it will used in the next step. You are now ready to register an admin user and deploy your first app .","title":"DNS"},{"location":"quickstart/provider/azure-acs/dns/#find-the-load-balancer-address","text":"On Azure Container Engine, Drycc Workflow will automatically provision and attach a Azure Load Balancer to the router component. This component is responsible for routing HTTP and HTTPS requests from the public internet to applications that are deployed and managed by Drycc Workflow. Discover the ip address assigned to the nginx Ingress , by describing the ingress service: $ kubectl --namespace=nginx-ingress get svc NAME CLUSTER-IP EXTERNAL-IP PORT(S) AGE default-backend 10.0.60.172 13.82.148.57 80/TCP,443/TCP,2222/TCP,9090/TCP 54m If the EXTERNAL-IP column shows <pending> instead of an ip address continue to wait until Azure finishes provisioning and attaching the load balancer.","title":"Find the Load Balancer Address"},{"location":"quickstart/provider/azure-acs/dns/#prepare-the-hostname","text":"Now that an ip address has been attached to the load balancer use the nip.io DNS service to route arbitrary hostnames to the Drycc Workflow edge router. Usage of nip.io is not recommended for long-term use and is intended here as a short cut to prevent fiddling with DNS. To verify connectivity to the Workflow API server and nip.io, construct the hostname by taking the ip address of load balancer and adding nip.io . For our example above, the address would be: 13.82.148.57.nip.io . Nip answers with the ip address no matter the hostname: $ host 13.82.148.57.nip.io 13.82.148.57.nip.io has address 13.82.148.57 $ host something-random.13.82.148.57.nip.io something-random.13.82.148.57.nip.io has address 13.82.148.57 By default, any HTTP traffic destined for the hostname drycc is automatically sent to the Workflow API service. To test that everything is connected properly use curl : $ curl http://drycc.13.82.148.57.nip.io/v2/ && echo {\"detail\":\"Authentication credentials were not provided.\"} Since no authentication information has been provided, curl will return an error. However this does validate that curl has reached the Workflow API service. Remember the hostname, it will used in the next step. You are now ready to register an admin user and deploy your first app .","title":"Prepare the Hostname"},{"location":"quickstart/provider/azure-acs/install-azure-acs/","text":"Install Drycc Workflow on Azure Container Service \u00b6 Check Your Setup \u00b6 First check that the helm command is available and the version is v2.5.0 or newer. $ helm version Client: &version.Version{SemVer:\"v2.5.0\", GitCommit:\"012cb0ac1a1b2f888144ef5a67b8dab6c2d45be6\", GitTreeState:\"clean\"} Server: &version.Version{SemVer:\"v2.5.0\", GitCommit:\"012cb0ac1a1b2f888144ef5a67b8dab6c2d45be6\", GitTreeState:\"clean\"} Finally, initialize Helm: helm init Ensure the kubectl client is installed and can connect to your Kubernetes cluster. Add the Drycc Chart Repository \u00b6 The Drycc Chart Repository contains everything needed to install Drycc Workflow onto a Kubernetes cluster, with a single helm install drycc/workflow --namespace drycc command. Add this repository to Helm: $ helm repo add drycc https://charts.drycc.cc/stable Create New Azure Storage Account \u00b6 It is recommended to use a dedicated storage account for the operational aspects of Workflow, which includes storing slug and container images, database backups, and disaster recovery. This storage account is passed as parameters during the helm install command in the next step. Replace the AZURE_SA_NAME variable with a unique name for your storage account and execute these commands. $ export AZURE_SA_NAME=YourGlobalUniqueName $ az storage account create -n $AZURE_SA_NAME -l $AZURE_DC_LOCATION -g $AZURE_RG_NAME --sku Standard_LRS $ export AZURE_SA_KEY=`az storage account keys list -n $AZURE_SA_NAME -g $AZURE_RG_NAME --query [0].value --output tsv` Note: Premium Storage skus are not supported yet due to lack of block blob storage support required for the drycc database to function. Install Drycc Workflow \u00b6 Now that Helm is installed and the repository has been added, install Workflow by running: $ helm install drycc/workflow --namespace=drycc --set global.storage=azure,azure.accountname=$AZURE_SA_NAME,azure.accountkey=$AZURE_SA_KEY,azure.registry_container=registry,azure.database_container=database,azure.builder_container=builder Helm will install a variety of Kubernetes resources in the drycc namespace. Wait for the pods that Helm launched to be ready. Monitor their status by running: $ kubectl --namespace=drycc get pods If it's preferred to have kubectl automatically update as the pod states change, run (type Ctrl-C to stop the watch): $ kubectl --namespace=drycc get pods -w Depending on the order in which the Workflow components initialize, some pods may restart. This is common during the installation: if a component's dependencies are not yet available, that component will exit and Kubernetes will automatically restart it. Here, it can be seen that the controller, builder and registry all took a few loops before they were able to start: $ kubectl --namespace=drycc get pods NAME READY STATUS RESTARTS AGE drycc-builder-hy3xv 1/1 Running 5 5m drycc-controller-g3cu8 1/1 Running 5 5m drycc-database-rad1o 1/1 Running 0 5m drycc-logger-fluentd-1v8uk 1/1 Running 0 5m drycc-logger-fluentd-esm60 1/1 Running 0 5m drycc-logger-sm8b3 1/1 Running 0 5m drycc-minio-4ww3t 1/1 Running 0 5m drycc-registry-asozo 1/1 Running 1 5m Once all of the pods are in the READY state, Drycc Workflow is up and running! Next, configure dns so you can register your first user and deploy an application.","title":"Install Workflow"},{"location":"quickstart/provider/azure-acs/install-azure-acs/#install-drycc-workflow-on-azure-container-service","text":"","title":"Install Drycc Workflow on Azure Container Service"},{"location":"quickstart/provider/azure-acs/install-azure-acs/#check-your-setup","text":"First check that the helm command is available and the version is v2.5.0 or newer. $ helm version Client: &version.Version{SemVer:\"v2.5.0\", GitCommit:\"012cb0ac1a1b2f888144ef5a67b8dab6c2d45be6\", GitTreeState:\"clean\"} Server: &version.Version{SemVer:\"v2.5.0\", GitCommit:\"012cb0ac1a1b2f888144ef5a67b8dab6c2d45be6\", GitTreeState:\"clean\"} Finally, initialize Helm: helm init Ensure the kubectl client is installed and can connect to your Kubernetes cluster.","title":"Check Your Setup"},{"location":"quickstart/provider/azure-acs/install-azure-acs/#add-the-drycc-chart-repository","text":"The Drycc Chart Repository contains everything needed to install Drycc Workflow onto a Kubernetes cluster, with a single helm install drycc/workflow --namespace drycc command. Add this repository to Helm: $ helm repo add drycc https://charts.drycc.cc/stable","title":"Add the Drycc Chart Repository"},{"location":"quickstart/provider/azure-acs/install-azure-acs/#create-new-azure-storage-account","text":"It is recommended to use a dedicated storage account for the operational aspects of Workflow, which includes storing slug and container images, database backups, and disaster recovery. This storage account is passed as parameters during the helm install command in the next step. Replace the AZURE_SA_NAME variable with a unique name for your storage account and execute these commands. $ export AZURE_SA_NAME=YourGlobalUniqueName $ az storage account create -n $AZURE_SA_NAME -l $AZURE_DC_LOCATION -g $AZURE_RG_NAME --sku Standard_LRS $ export AZURE_SA_KEY=`az storage account keys list -n $AZURE_SA_NAME -g $AZURE_RG_NAME --query [0].value --output tsv` Note: Premium Storage skus are not supported yet due to lack of block blob storage support required for the drycc database to function.","title":"Create New Azure Storage Account"},{"location":"quickstart/provider/azure-acs/install-azure-acs/#install-drycc-workflow","text":"Now that Helm is installed and the repository has been added, install Workflow by running: $ helm install drycc/workflow --namespace=drycc --set global.storage=azure,azure.accountname=$AZURE_SA_NAME,azure.accountkey=$AZURE_SA_KEY,azure.registry_container=registry,azure.database_container=database,azure.builder_container=builder Helm will install a variety of Kubernetes resources in the drycc namespace. Wait for the pods that Helm launched to be ready. Monitor their status by running: $ kubectl --namespace=drycc get pods If it's preferred to have kubectl automatically update as the pod states change, run (type Ctrl-C to stop the watch): $ kubectl --namespace=drycc get pods -w Depending on the order in which the Workflow components initialize, some pods may restart. This is common during the installation: if a component's dependencies are not yet available, that component will exit and Kubernetes will automatically restart it. Here, it can be seen that the controller, builder and registry all took a few loops before they were able to start: $ kubectl --namespace=drycc get pods NAME READY STATUS RESTARTS AGE drycc-builder-hy3xv 1/1 Running 5 5m drycc-controller-g3cu8 1/1 Running 5 5m drycc-database-rad1o 1/1 Running 0 5m drycc-logger-fluentd-1v8uk 1/1 Running 0 5m drycc-logger-fluentd-esm60 1/1 Running 0 5m drycc-logger-sm8b3 1/1 Running 0 5m drycc-minio-4ww3t 1/1 Running 0 5m drycc-registry-asozo 1/1 Running 1 5m Once all of the pods are in the READY state, Drycc Workflow is up and running! Next, configure dns so you can register your first user and deploy an application.","title":"Install Drycc Workflow"},{"location":"quickstart/provider/gke/boot/","text":"Booting Kubernetes on Google Container Engine \u00b6 Google Container Engine (GKE) is a managed Kubernetes environment which is great for hosting Drycc Workflow. Google Container Engine manages the Kubernetes master and you pay for the compute nodes. Clusters smaller than five nodes are charged only for the compute. Clusters six nodes are larger cost $0.15/hour per cluster. If you do not already have a Google Cloud account, you can start a trial with $300 of free credit here . After completing sign up, you must add your billing information. Create Your Google Cloud Project \u00b6 Sign in to your Google Cloud Platform Console and create a new project: Pick a project name. A project groups resources together and can hold more than one container cluster: Note the project ID. This is a unique name across all Google Cloud projects. Later, we will refer to this as PROJECT_ID . Next, enable billing in the console. Next, enable the Container Engine API and Compute Engine API . You must complete all three steps before continuing. Create Your GKE Cluster \u00b6 From the navigation hamburger in the upper left corner, find and select Container Engine : Select Create Container Cluster : For development and testing, we recommend you use the n1-standard-2 machine type which has 2 VCPUs and 7.5 GB of RAM per server, and a cluster size of at least 2: Click \"Create\" and Google Container Engine will provision your cluster. The process will take a few minutes to complete. Check Kubernetes version \u00b6 ] After the cluster is created, check the node version. See Kubernetes Versions under System Requirements for more details. Install and configure the Google Cloud CLI \u00b6 While your container cluster is booting. You will need to install the Google Cloud CLI tools. We will use the tools to fetch cluster credentials to authenitcate to your new Kubernetes cluster. Google maintains a number of quickstart guides which walk you through the installation. Once you have installed the CLI tooling set your default project and list your container clusters: $ gcloud projects list PROJECT_ID NAME PROJECT_NUMBER ascendant-yeti-130419 My First Cluster 614974141267 Set your default project: $ gcloud config set project ascendant-yeti-130419 Then list your container clusters: $ gcloud container clusters list NAME ZONE MASTER_VERSION MASTER_IP MACHINE_TYPE NODE_VERSION NUM_NODES STATUS cluster-1 us-central1-b 1.4.0 104.154.234.246 n1-standard-2 1.4.0 * 2 RUNNING If you haven't configured your default zone, make sure it matches the ZONE for your cluster: $ gcloud config set compute/zone us-central1-b Now you may fetch credentials to connect to Kubernetes: $ gcloud auth application-default login Your browser has been opened to visit: https://accounts.google.com/o/oauth2/auth?redirect_uri=.... Credentials saved to file: [~/.config/gcloud/application_default_credentials.json] These credentials will be used by any library that requests Application Default Credentials. If you don't have kubectl CLI setup just yet, run this to get it available locally: $ gcloud components install kubectl Your local kubectl utility should now be pointed at your new container cluster. You can verify your credentials and local configuration by running: $ kubectl cluster-info Kubernetes master is running at https://104.154.234.246 GLBCDefaultBackend is running at https://104.154.234.246/api/v1/proxy/namespaces/kube-system/services/default-http-backend Heapster is running at https://104.154.234.246/api/v1/proxy/namespaces/kube-system/services/heapster KubeDNS is running at https://104.154.234.246/api/v1/proxy/namespaces/kube-system/services/kube-dns kubernetes-dashboard is running at https://104.154.234.246/api/v1/proxy/namespaces/kube-system/services/kubernetes-dashboard If kubectl cluster-info returned with the following error: The connection to the server localhost:8080 was refused - did you specify the right host or port? You'll need to run: $ gcloud container clusters get-credentials To download the credentials necessary. The kubectl cluster-info command should then work as intended. You are now ready to install Drycc Workflow","title":"Boot"},{"location":"quickstart/provider/gke/boot/#booting-kubernetes-on-google-container-engine","text":"Google Container Engine (GKE) is a managed Kubernetes environment which is great for hosting Drycc Workflow. Google Container Engine manages the Kubernetes master and you pay for the compute nodes. Clusters smaller than five nodes are charged only for the compute. Clusters six nodes are larger cost $0.15/hour per cluster. If you do not already have a Google Cloud account, you can start a trial with $300 of free credit here . After completing sign up, you must add your billing information.","title":"Booting Kubernetes on Google Container Engine"},{"location":"quickstart/provider/gke/boot/#create-your-google-cloud-project","text":"Sign in to your Google Cloud Platform Console and create a new project: Pick a project name. A project groups resources together and can hold more than one container cluster: Note the project ID. This is a unique name across all Google Cloud projects. Later, we will refer to this as PROJECT_ID . Next, enable billing in the console. Next, enable the Container Engine API and Compute Engine API . You must complete all three steps before continuing.","title":"Create Your Google Cloud Project"},{"location":"quickstart/provider/gke/boot/#create-your-gke-cluster","text":"From the navigation hamburger in the upper left corner, find and select Container Engine : Select Create Container Cluster : For development and testing, we recommend you use the n1-standard-2 machine type which has 2 VCPUs and 7.5 GB of RAM per server, and a cluster size of at least 2: Click \"Create\" and Google Container Engine will provision your cluster. The process will take a few minutes to complete.","title":"Create Your GKE Cluster"},{"location":"quickstart/provider/gke/boot/#check-kubernetes-version","text":"] After the cluster is created, check the node version. See Kubernetes Versions under System Requirements for more details.","title":"Check Kubernetes version"},{"location":"quickstart/provider/gke/boot/#install-and-configure-the-google-cloud-cli","text":"While your container cluster is booting. You will need to install the Google Cloud CLI tools. We will use the tools to fetch cluster credentials to authenitcate to your new Kubernetes cluster. Google maintains a number of quickstart guides which walk you through the installation. Once you have installed the CLI tooling set your default project and list your container clusters: $ gcloud projects list PROJECT_ID NAME PROJECT_NUMBER ascendant-yeti-130419 My First Cluster 614974141267 Set your default project: $ gcloud config set project ascendant-yeti-130419 Then list your container clusters: $ gcloud container clusters list NAME ZONE MASTER_VERSION MASTER_IP MACHINE_TYPE NODE_VERSION NUM_NODES STATUS cluster-1 us-central1-b 1.4.0 104.154.234.246 n1-standard-2 1.4.0 * 2 RUNNING If you haven't configured your default zone, make sure it matches the ZONE for your cluster: $ gcloud config set compute/zone us-central1-b Now you may fetch credentials to connect to Kubernetes: $ gcloud auth application-default login Your browser has been opened to visit: https://accounts.google.com/o/oauth2/auth?redirect_uri=.... Credentials saved to file: [~/.config/gcloud/application_default_credentials.json] These credentials will be used by any library that requests Application Default Credentials. If you don't have kubectl CLI setup just yet, run this to get it available locally: $ gcloud components install kubectl Your local kubectl utility should now be pointed at your new container cluster. You can verify your credentials and local configuration by running: $ kubectl cluster-info Kubernetes master is running at https://104.154.234.246 GLBCDefaultBackend is running at https://104.154.234.246/api/v1/proxy/namespaces/kube-system/services/default-http-backend Heapster is running at https://104.154.234.246/api/v1/proxy/namespaces/kube-system/services/heapster KubeDNS is running at https://104.154.234.246/api/v1/proxy/namespaces/kube-system/services/kube-dns kubernetes-dashboard is running at https://104.154.234.246/api/v1/proxy/namespaces/kube-system/services/kubernetes-dashboard If kubectl cluster-info returned with the following error: The connection to the server localhost:8080 was refused - did you specify the right host or port? You'll need to run: $ gcloud container clusters get-credentials To download the credentials necessary. The kubectl cluster-info command should then work as intended. You are now ready to install Drycc Workflow","title":"Install and configure the Google Cloud CLI"},{"location":"quickstart/provider/gke/dns/","text":"Find Your Load Balancer Address \u00b6 On Google Container Engine, Drycc Workflow will automatically provision and attach a Google Cloud Loadbalancer to the router copmonent. This component is responsible for routing HTTP and HTTPS requests from the public internet to applications that are deployed and managed by Drycc Workflow. By describing the nginx ingress service, you can see what IP address has been allocated by Google Cloud for your Drycc Workflow cluster: $ kubectl --namespace=ingress-nginx describe svc | grep LoadBalancer Type: LoadBalancer LoadBalancer Ingress: 104.197.125.75 Prepare the Hostname \u00b6 Now that you have the ip address of your load balancer we can use the nip.io DNS service to route arbitrary hostnames to the Drycc Workflow edge router. This lets us point the Workflow CLI at your cluster without having to either use your own domain or update DNS! To verify the Workflow API server and nip.io, construct your hostname by taking the ip address for your load balancer and adding nip.io . For our example above, the address would be: 104.197.125.75.nip.io . Nip answers with the ip address no matter the hostname: $ host 104.197.125.75.nip.io 104.197.125.75.nip.io has address 104.197.125.75 $ host something-random.104.197.125.75.nip.io something-random.104.197.125.75.nip.io has address 104.197.125.75 By default, any HTTP traffic for the hostname drycc will be sent to the Workflow API service. To test that everything is connected properly you may validate connectivity using curl : $ curl http://drycc.104.197.125.75.nip.io/v2/ && echo {\"detail\":\"Authentication credentials were not provided.\"} You should see a failed request because we provided no credentials to the API server. Remember the hostname, we will use it in the next step. You are now ready to register an admin user and deploy your first app .","title":"DNS"},{"location":"quickstart/provider/gke/dns/#find-your-load-balancer-address","text":"On Google Container Engine, Drycc Workflow will automatically provision and attach a Google Cloud Loadbalancer to the router copmonent. This component is responsible for routing HTTP and HTTPS requests from the public internet to applications that are deployed and managed by Drycc Workflow. By describing the nginx ingress service, you can see what IP address has been allocated by Google Cloud for your Drycc Workflow cluster: $ kubectl --namespace=ingress-nginx describe svc | grep LoadBalancer Type: LoadBalancer LoadBalancer Ingress: 104.197.125.75","title":"Find Your Load Balancer Address"},{"location":"quickstart/provider/gke/dns/#prepare-the-hostname","text":"Now that you have the ip address of your load balancer we can use the nip.io DNS service to route arbitrary hostnames to the Drycc Workflow edge router. This lets us point the Workflow CLI at your cluster without having to either use your own domain or update DNS! To verify the Workflow API server and nip.io, construct your hostname by taking the ip address for your load balancer and adding nip.io . For our example above, the address would be: 104.197.125.75.nip.io . Nip answers with the ip address no matter the hostname: $ host 104.197.125.75.nip.io 104.197.125.75.nip.io has address 104.197.125.75 $ host something-random.104.197.125.75.nip.io something-random.104.197.125.75.nip.io has address 104.197.125.75 By default, any HTTP traffic for the hostname drycc will be sent to the Workflow API service. To test that everything is connected properly you may validate connectivity using curl : $ curl http://drycc.104.197.125.75.nip.io/v2/ && echo {\"detail\":\"Authentication credentials were not provided.\"} You should see a failed request because we provided no credentials to the API server. Remember the hostname, we will use it in the next step. You are now ready to register an admin user and deploy your first app .","title":"Prepare the Hostname"},{"location":"quickstart/provider/gke/install-gke/","text":"Install Drycc Workflow on Google Compute Engine \u00b6 Check Your Setup \u00b6 First check that the helm command is available and the version is v2.5.0 or newer. $ helm version Client: &version.Version{SemVer:\"v2.5.0\", GitCommit:\"012cb0ac1a1b2f888144ef5a67b8dab6c2d45be6\", GitTreeState:\"clean\"} Server: &version.Version{SemVer:\"v2.5.0\", GitCommit:\"012cb0ac1a1b2f888144ef5a67b8dab6c2d45be6\", GitTreeState:\"clean\"} Ensure the kubectl client is installed and can connect to your Kubernetes cluster. Add the Drycc Chart Repository \u00b6 The Drycc Chart Repository contains everything needed to install Drycc Workflow onto a Kubernetes cluster, with a single helm install drycc/workflow --namespace drycc command. Add this repository to Helm: $ helm repo add drycc https://charts.drycc.cc/stable Install Drycc Workflow \u00b6 Now that Helm is installed and the repository has been added, install Workflow by running: $ helm install drycc/workflow --namespace drycc Helm will install a variety of Kubernetes resources in the drycc namespace. Wait for the pods that Helm launched to be ready. Monitor their status by running: $ kubectl --namespace=drycc get pods If it's preferred to have kubectl automatically update as the pod states change, run (type Ctrl-C to stop the watch): $ kubectl --namespace=drycc get pods -w Depending on the order in which the Workflow components initialize, some pods may restart. This is common during the installation: if a component's dependencies are not yet available, that component will exit and Kubernetes will automatically restart it. Here, it can be seen that the controller, builder and registry all took a few loops before they were able to start: $ kubectl --namespace=drycc get pods NAME READY STATUS RESTARTS AGE drycc-builder-hy3xv 1/1 Running 5 5m drycc-controller-g3cu8 1/1 Running 5 5m drycc-database-rad1o 1/1 Running 0 5m drycc-logger-fluentd-1v8uk 1/1 Running 0 5m drycc-logger-fluentd-esm60 1/1 Running 0 5m drycc-logger-sm8b3 1/1 Running 0 5m drycc-minio-4ww3t 1/1 Running 0 5m drycc-registry-asozo 1/1 Running 1 5m Once all of the pods are in the READY state, Drycc Workflow is up and running!","title":"Install Workflow"},{"location":"quickstart/provider/gke/install-gke/#install-drycc-workflow-on-google-compute-engine","text":"","title":"Install Drycc Workflow on Google Compute Engine"},{"location":"quickstart/provider/gke/install-gke/#check-your-setup","text":"First check that the helm command is available and the version is v2.5.0 or newer. $ helm version Client: &version.Version{SemVer:\"v2.5.0\", GitCommit:\"012cb0ac1a1b2f888144ef5a67b8dab6c2d45be6\", GitTreeState:\"clean\"} Server: &version.Version{SemVer:\"v2.5.0\", GitCommit:\"012cb0ac1a1b2f888144ef5a67b8dab6c2d45be6\", GitTreeState:\"clean\"} Ensure the kubectl client is installed and can connect to your Kubernetes cluster.","title":"Check Your Setup"},{"location":"quickstart/provider/gke/install-gke/#add-the-drycc-chart-repository","text":"The Drycc Chart Repository contains everything needed to install Drycc Workflow onto a Kubernetes cluster, with a single helm install drycc/workflow --namespace drycc command. Add this repository to Helm: $ helm repo add drycc https://charts.drycc.cc/stable","title":"Add the Drycc Chart Repository"},{"location":"quickstart/provider/gke/install-gke/#install-drycc-workflow","text":"Now that Helm is installed and the repository has been added, install Workflow by running: $ helm install drycc/workflow --namespace drycc Helm will install a variety of Kubernetes resources in the drycc namespace. Wait for the pods that Helm launched to be ready. Monitor their status by running: $ kubectl --namespace=drycc get pods If it's preferred to have kubectl automatically update as the pod states change, run (type Ctrl-C to stop the watch): $ kubectl --namespace=drycc get pods -w Depending on the order in which the Workflow components initialize, some pods may restart. This is common during the installation: if a component's dependencies are not yet available, that component will exit and Kubernetes will automatically restart it. Here, it can be seen that the controller, builder and registry all took a few loops before they were able to start: $ kubectl --namespace=drycc get pods NAME READY STATUS RESTARTS AGE drycc-builder-hy3xv 1/1 Running 5 5m drycc-controller-g3cu8 1/1 Running 5 5m drycc-database-rad1o 1/1 Running 0 5m drycc-logger-fluentd-1v8uk 1/1 Running 0 5m drycc-logger-fluentd-esm60 1/1 Running 0 5m drycc-logger-sm8b3 1/1 Running 0 5m drycc-minio-4ww3t 1/1 Running 0 5m drycc-registry-asozo 1/1 Running 1 5m Once all of the pods are in the READY state, Drycc Workflow is up and running!","title":"Install Drycc Workflow"},{"location":"quickstart/provider/minikube/boot/","text":"Booting Kubernetes Using Minikube \u00b6 This guide will walk you through the process of installing a small development Kubernetes cluster on your local machine using minikube . Pre-requisites \u00b6 OS X xhyve driver , VirtualBox or VMware Fusion installation Linux VirtualBox or KVM installation Windows Hyper-V VT-x/AMD-v virtualization must be enabled in BIOS The most recent version of kubectl . You can install kubectl following these steps . Internet connection You will need a decent internet connection running minikube start for the first time for Minikube to pull its Docker images. It might take Minikube some time to start. Download and Unpack Minikube \u00b6 See the installation instructions for the latest release of minikube . Set your VM driver (optional) \u00b6 You can set your preferred driver (virtualbox - default, vmwarefusion, kvm, xhyve) using the following command: minikube config set vm-driver virtualbox Boot Your First Cluster \u00b6 We are now ready to boot our first Kubernetes cluster using Minikube! $ minikube start --disk-size=60g --memory=4096 Starting local Kubernetes cluster... Kubectl is now configured to use the cluster. Now that the cluster is up and ready, minikube automatically configures kubectl on your machine with the appropriate authentication and endpoint information. $ kubectl cluster-info Kubernetes master is running at https://192.168.99.100:8443 KubeDNS is running at https://192.168.99.100:8443/api/v1/proxy/namespaces/kube-system/services/kube-dns kubernetes-dashboard is running at https://192.168.99.100:8443/api/v1/proxy/namespaces/kube-system/services/kubernetes-dashboard To further debug and diagnose cluster problems, use 'kubectl cluster-info dump'. You are now ready to install Drycc Workflow","title":"Boot"},{"location":"quickstart/provider/minikube/boot/#booting-kubernetes-using-minikube","text":"This guide will walk you through the process of installing a small development Kubernetes cluster on your local machine using minikube .","title":"Booting Kubernetes Using Minikube"},{"location":"quickstart/provider/minikube/boot/#pre-requisites","text":"OS X xhyve driver , VirtualBox or VMware Fusion installation Linux VirtualBox or KVM installation Windows Hyper-V VT-x/AMD-v virtualization must be enabled in BIOS The most recent version of kubectl . You can install kubectl following these steps . Internet connection You will need a decent internet connection running minikube start for the first time for Minikube to pull its Docker images. It might take Minikube some time to start.","title":"Pre-requisites"},{"location":"quickstart/provider/minikube/boot/#download-and-unpack-minikube","text":"See the installation instructions for the latest release of minikube .","title":"Download and Unpack Minikube"},{"location":"quickstart/provider/minikube/boot/#set-your-vm-driver-optional","text":"You can set your preferred driver (virtualbox - default, vmwarefusion, kvm, xhyve) using the following command: minikube config set vm-driver virtualbox","title":"Set your VM driver (optional)"},{"location":"quickstart/provider/minikube/boot/#boot-your-first-cluster","text":"We are now ready to boot our first Kubernetes cluster using Minikube! $ minikube start --disk-size=60g --memory=4096 Starting local Kubernetes cluster... Kubectl is now configured to use the cluster. Now that the cluster is up and ready, minikube automatically configures kubectl on your machine with the appropriate authentication and endpoint information. $ kubectl cluster-info Kubernetes master is running at https://192.168.99.100:8443 KubeDNS is running at https://192.168.99.100:8443/api/v1/proxy/namespaces/kube-system/services/kube-dns kubernetes-dashboard is running at https://192.168.99.100:8443/api/v1/proxy/namespaces/kube-system/services/kubernetes-dashboard To further debug and diagnose cluster problems, use 'kubectl cluster-info dump'. You are now ready to install Drycc Workflow","title":"Boot Your First Cluster"},{"location":"quickstart/provider/minikube/dns/","text":"Find Your Load Balancer Address \u00b6 During installation, Drycc Workflow specifies that Kubernetes should provision and attach a load balancer to the router component. The router component is responsible for routing HTTP and HTTPS requests from outside the cluster to applications that are managed by Drycc Worfklow. In cloud environments, Kubernetes provisions and attaches a load balancer for you. Since we are running in a local environment, we need to do a little bit of extra work to send requests to the router. First, determine the ip address allocated to the worker node. $ minikube ip 192.168.99.100 Prepare the Hostname \u00b6 Now that you have the ip address of your virtual machine, we can use the nip.io DNS service or dnsmasq to route arbitrary hostnames to the Drycc Workflow edge router. This lets us point the Workflow CLI at your cluster without having to either use your own domain or update DNS! Using nip.io \u00b6 To verify the Workflow API server and nip.io, construct your hostname by taking the ip address for your load balancer and adding nip.io . For our example above, the address would be 192.168.99.100 . Nip answers with the ip address no matter the hostname: $ host 192.168.99.100.nip.io 192.168.99.100.nip.io has address 192.168.99.100 $ host something-random.192.168.99.100.nip.io something-random.192.168.99.100.nip.io has address 192.168.99.100 Using DNSMasq \u00b6 If nip.io is working for you, you can skip this section, and proceed to verify the hostname. If you prefer not to use nip.io or cannot (because your DNS provider might have blocked it), you can use dnsmasq on Linux and macOS or Acrylic on Windows. You can install and configure dnsmasq on macOS with Homebrew with the following commands: # Installing dnsmasq $ brew install dnsmasq # Configure `.minikube` subdomains to always use minikube IP: $ echo \"address=/.minikube/`minikube ip`\" >> /usr/local/etc/dnsmasq.conf $ sudo brew services start dnsmasq # Make the system resolver use dnsmasq to resolve addresses: $ sudo mkdir /etc/resolver $ echo nameserver 127.0.0.1 | sudo tee /etc/resolver/minikube # You might need to clear the DNS resolver cache: $ sudo killall -HUP mDNSResponder You may need to ensure that the dnsmasq service at 127.0.0.1 is listed as a DNS server for your network connection. You may check this using the following command: $ scutil --dns | grep minikube -B 1 -A 3 resolver #8 domain : minikube nameserver[0] : 127.0.0.1 flags : Request A records, Request AAAA records reach : Reachable, Local Address, Directly Reachable Address To verify the hostname, you will need to use drycc.minikube as hostname instead of drycc.192.168.99.100.nip.io in the next section. We will also use it in the next step. Verify the hostname \u00b6 By default, any HTTP traffic for the hostname drycc will be sent to the Workflow API service. To test that everything is connected properly you may validate connectivity using curl : $ curl http://drycc.192.168.99.100.nip.io/v2/ && echo {\"detail\":\"Authentication credentials were not provided.\"} You should see a failed request because we provided no credentials to the API server. Remember the hostname, we will use it in the next step. next: deploy your first app","title":"DNS"},{"location":"quickstart/provider/minikube/dns/#find-your-load-balancer-address","text":"During installation, Drycc Workflow specifies that Kubernetes should provision and attach a load balancer to the router component. The router component is responsible for routing HTTP and HTTPS requests from outside the cluster to applications that are managed by Drycc Worfklow. In cloud environments, Kubernetes provisions and attaches a load balancer for you. Since we are running in a local environment, we need to do a little bit of extra work to send requests to the router. First, determine the ip address allocated to the worker node. $ minikube ip 192.168.99.100","title":"Find Your Load Balancer Address"},{"location":"quickstart/provider/minikube/dns/#prepare-the-hostname","text":"Now that you have the ip address of your virtual machine, we can use the nip.io DNS service or dnsmasq to route arbitrary hostnames to the Drycc Workflow edge router. This lets us point the Workflow CLI at your cluster without having to either use your own domain or update DNS!","title":"Prepare the Hostname"},{"location":"quickstart/provider/minikube/dns/#using-nipio","text":"To verify the Workflow API server and nip.io, construct your hostname by taking the ip address for your load balancer and adding nip.io . For our example above, the address would be 192.168.99.100 . Nip answers with the ip address no matter the hostname: $ host 192.168.99.100.nip.io 192.168.99.100.nip.io has address 192.168.99.100 $ host something-random.192.168.99.100.nip.io something-random.192.168.99.100.nip.io has address 192.168.99.100","title":"Using nip.io"},{"location":"quickstart/provider/minikube/dns/#using-dnsmasq","text":"If nip.io is working for you, you can skip this section, and proceed to verify the hostname. If you prefer not to use nip.io or cannot (because your DNS provider might have blocked it), you can use dnsmasq on Linux and macOS or Acrylic on Windows. You can install and configure dnsmasq on macOS with Homebrew with the following commands: # Installing dnsmasq $ brew install dnsmasq # Configure `.minikube` subdomains to always use minikube IP: $ echo \"address=/.minikube/`minikube ip`\" >> /usr/local/etc/dnsmasq.conf $ sudo brew services start dnsmasq # Make the system resolver use dnsmasq to resolve addresses: $ sudo mkdir /etc/resolver $ echo nameserver 127.0.0.1 | sudo tee /etc/resolver/minikube # You might need to clear the DNS resolver cache: $ sudo killall -HUP mDNSResponder You may need to ensure that the dnsmasq service at 127.0.0.1 is listed as a DNS server for your network connection. You may check this using the following command: $ scutil --dns | grep minikube -B 1 -A 3 resolver #8 domain : minikube nameserver[0] : 127.0.0.1 flags : Request A records, Request AAAA records reach : Reachable, Local Address, Directly Reachable Address To verify the hostname, you will need to use drycc.minikube as hostname instead of drycc.192.168.99.100.nip.io in the next section. We will also use it in the next step.","title":"Using DNSMasq"},{"location":"quickstart/provider/minikube/dns/#verify-the-hostname","text":"By default, any HTTP traffic for the hostname drycc will be sent to the Workflow API service. To test that everything is connected properly you may validate connectivity using curl : $ curl http://drycc.192.168.99.100.nip.io/v2/ && echo {\"detail\":\"Authentication credentials were not provided.\"} You should see a failed request because we provided no credentials to the API server. Remember the hostname, we will use it in the next step. next: deploy your first app","title":"Verify the hostname"},{"location":"quickstart/provider/minikube/install-minikube/","text":"Install Drycc Workflow on Minikube \u00b6 Check Your Setup \u00b6 First check that the helm command is available and the version is v2.5.0 or newer. $ helm version Client: &version.Version{SemVer:\"v2.5.0\", GitCommit:\"012cb0ac1a1b2f888144ef5a67b8dab6c2d45be6\", GitTreeState:\"clean\"} Server: &version.Version{SemVer:\"v2.5.0\", GitCommit:\"012cb0ac1a1b2f888144ef5a67b8dab6c2d45be6\", GitTreeState:\"clean\"} Ensure the kubectl client is installed and can connect to your Kubernetes cluster. Add the Drycc Chart Repository \u00b6 The Drycc Chart Repository contains everything needed to install Drycc Workflow onto a Kubernetes cluster, with a single helm install drycc/workflow --namespace drycc command. Add this repository to Helm: $ helm repo add drycc https://charts.drycc.cc/stable Install Drycc Workflow \u00b6 Now that Helm is installed and the repository has been added, install Workflow by running: $ helm install drycc/workflow --namespace drycc --set router.service.type=NodePort Helm will install a variety of Kubernetes resources in the drycc namespace. Wait for the pods that Helm launched to be ready. Monitor their status by running: $ kubectl --namespace=drycc get pods If it's preferred to have kubectl automatically update as the pod states change, run (type Ctrl-C to stop the watch): $ kubectl --namespace=drycc get pods -w Depending on the order in which the Workflow components initialize, some pods may restart. This is common during the installation: if a component's dependencies are not yet available, that component will exit and Kubernetes will automatically restart it. Here, it can be seen that the controller, builder and registry all took a few loops before they were able to start: $ kubectl --namespace=drycc get pods NAME READY STATUS RESTARTS AGE drycc-builder-hy3xv 1/1 Running 5 5m drycc-controller-g3cu8 1/1 Running 5 5m drycc-database-rad1o 1/1 Running 0 5m drycc-logger-fluentd-1v8uk 1/1 Running 0 5m drycc-logger-fluentd-esm60 1/1 Running 0 5m drycc-logger-sm8b3 1/1 Running 0 5m drycc-minio-4ww3t 1/1 Running 0 5m drycc-registry-asozo 1/1 Running 1 5m Once all of the pods are in the READY state, Drycc Workflow is up and running! Next, configure dns so you can register your first user and deploy an application.","title":"Install Workflow"},{"location":"quickstart/provider/minikube/install-minikube/#install-drycc-workflow-on-minikube","text":"","title":"Install Drycc Workflow on Minikube"},{"location":"quickstart/provider/minikube/install-minikube/#check-your-setup","text":"First check that the helm command is available and the version is v2.5.0 or newer. $ helm version Client: &version.Version{SemVer:\"v2.5.0\", GitCommit:\"012cb0ac1a1b2f888144ef5a67b8dab6c2d45be6\", GitTreeState:\"clean\"} Server: &version.Version{SemVer:\"v2.5.0\", GitCommit:\"012cb0ac1a1b2f888144ef5a67b8dab6c2d45be6\", GitTreeState:\"clean\"} Ensure the kubectl client is installed and can connect to your Kubernetes cluster.","title":"Check Your Setup"},{"location":"quickstart/provider/minikube/install-minikube/#add-the-drycc-chart-repository","text":"The Drycc Chart Repository contains everything needed to install Drycc Workflow onto a Kubernetes cluster, with a single helm install drycc/workflow --namespace drycc command. Add this repository to Helm: $ helm repo add drycc https://charts.drycc.cc/stable","title":"Add the Drycc Chart Repository"},{"location":"quickstart/provider/minikube/install-minikube/#install-drycc-workflow","text":"Now that Helm is installed and the repository has been added, install Workflow by running: $ helm install drycc/workflow --namespace drycc --set router.service.type=NodePort Helm will install a variety of Kubernetes resources in the drycc namespace. Wait for the pods that Helm launched to be ready. Monitor their status by running: $ kubectl --namespace=drycc get pods If it's preferred to have kubectl automatically update as the pod states change, run (type Ctrl-C to stop the watch): $ kubectl --namespace=drycc get pods -w Depending on the order in which the Workflow components initialize, some pods may restart. This is common during the installation: if a component's dependencies are not yet available, that component will exit and Kubernetes will automatically restart it. Here, it can be seen that the controller, builder and registry all took a few loops before they were able to start: $ kubectl --namespace=drycc get pods NAME READY STATUS RESTARTS AGE drycc-builder-hy3xv 1/1 Running 5 5m drycc-controller-g3cu8 1/1 Running 5 5m drycc-database-rad1o 1/1 Running 0 5m drycc-logger-fluentd-1v8uk 1/1 Running 0 5m drycc-logger-fluentd-esm60 1/1 Running 0 5m drycc-logger-sm8b3 1/1 Running 0 5m drycc-minio-4ww3t 1/1 Running 0 5m drycc-registry-asozo 1/1 Running 1 5m Once all of the pods are in the READY state, Drycc Workflow is up and running! Next, configure dns so you can register your first user and deploy an application.","title":"Install Drycc Workflow"},{"location":"reference-guide/creating-a-self-signed-ssl-certificate/","text":"Creating a Self-Signed SSL Certificate \u00b6 When using the app ssl feature for non-production applications or when installing SSL for the platform , you can avoid the costs associated with the SSL certificate by using a self-signed SSL certificate. Though the certificate implements full encryption, visitors to your site will see a browser warning indicating that the certificate should not be trusted. Prerequisites \u00b6 The openssl library is required to generate your own certificate. Run the following command in your local environment to see if you already have openssl installed. $ which openssl /usr/bin/openssl If the which command does not return a path then you will need to install openssl yourself: If you have... Install with... Mac OS X Homebrew: brew install openssl Windows complete package .exe installed Ubuntu Linux apt-get install openssl Generate Private Key and Certificate Signing Request \u00b6 A private key and certificate signing request are required to create an SSL certificate. These can be generated with a few simple commands. When the openssl req command asks for a \u201cchallenge password\u201d, just press return, leaving the password empty. $ openssl genrsa -des3 -passout pass:x -out server.pass.key 2048 ... $ openssl rsa -passin pass:x -in server.pass.key -out server.key writing RSA key $ rm server.pass.key $ openssl req -new -key server.key -out server.csr ... Country Name (2 letter code) [AU]:US State or Province Name (full name) [Some-State]:California ... A challenge password []: ... Generate SSL Certificate \u00b6 The self-signed SSL certificate is generated from the server.key private key and server.csr files. $ openssl x509 -req -days 365 -in server.csr -signkey server.key -out server.crt The server.crt file is your site certificate suitable for use with Drycc's SSL endpoint along with the server.key private key.","title":"Creating a Self-Signed SSL Certificate"},{"location":"reference-guide/creating-a-self-signed-ssl-certificate/#creating-a-self-signed-ssl-certificate","text":"When using the app ssl feature for non-production applications or when installing SSL for the platform , you can avoid the costs associated with the SSL certificate by using a self-signed SSL certificate. Though the certificate implements full encryption, visitors to your site will see a browser warning indicating that the certificate should not be trusted.","title":"Creating a Self-Signed SSL Certificate"},{"location":"reference-guide/creating-a-self-signed-ssl-certificate/#prerequisites","text":"The openssl library is required to generate your own certificate. Run the following command in your local environment to see if you already have openssl installed. $ which openssl /usr/bin/openssl If the which command does not return a path then you will need to install openssl yourself: If you have... Install with... Mac OS X Homebrew: brew install openssl Windows complete package .exe installed Ubuntu Linux apt-get install openssl","title":"Prerequisites"},{"location":"reference-guide/creating-a-self-signed-ssl-certificate/#generate-private-key-and-certificate-signing-request","text":"A private key and certificate signing request are required to create an SSL certificate. These can be generated with a few simple commands. When the openssl req command asks for a \u201cchallenge password\u201d, just press return, leaving the password empty. $ openssl genrsa -des3 -passout pass:x -out server.pass.key 2048 ... $ openssl rsa -passin pass:x -in server.pass.key -out server.key writing RSA key $ rm server.pass.key $ openssl req -new -key server.key -out server.csr ... Country Name (2 letter code) [AU]:US State or Province Name (full name) [Some-State]:California ... A challenge password []: ...","title":"Generate Private Key and Certificate Signing Request"},{"location":"reference-guide/creating-a-self-signed-ssl-certificate/#generate-ssl-certificate","text":"The self-signed SSL certificate is generated from the server.key private key and server.csr files. $ openssl x509 -req -days 365 -in server.csr -signkey server.key -out server.crt The server.crt file is your site certificate suitable for use with Drycc's SSL endpoint along with the server.key private key.","title":"Generate SSL Certificate"},{"location":"reference-guide/terms/","text":"Terms \u00b6 Application \u00b6 An application services requests and background jobs for a deployed git repository. Each application includes a set of Containers used to run isolated processes, and a Release that defines the current Build and Config deployed by containers. Build \u00b6 Drycc builds are created automatically on the controller when a developer uses git push drycc master . When a new build is created, a new Release is created automatically. Config \u00b6 Config refers to a set of environment variables used by Containers in as Application. When Config is changed, a new Release is created automatically. Container \u00b6 Drycc containers are instances of Docker containers used to run Applications. Containers perform the actual work of an Application by servicing requests or by running background tasks as part of the cluster. Ephemeral Filesystem \u00b6 Each container gets its own ephemeral filesystem, with a fresh copy of the most recently deployed code. During the container\u2019s lifetime, its running processes can use the filesystem as a temporary scratchpad, but no files that are written are visible to processes in any other container. Any files written to the ephemeral filesystem will be discarded the moment the container is either stopped or restarted. Container States \u00b6 There are several states that a container can be in at any time. The states are: initialized - the state of the container before it is created created - the container is built and ready for operation up - the container is running down - the container crashed or is stopped destroyed - the container has been destroyed Controller \u00b6 The controller is the \"brain\" of the Drycc platform. A controller manages Applications and their lifecycle. The controller is in charge of: Authenticating and authorizing clients Processing client API calls Managing containers that perform work for applications Managing proxies that route traffic to containers Managing users, keys and other base configuration The Controller stack includes: Django API Server for handling API calls Key \u00b6 Drycc keys are SSH Keys used during the git push process. Each user can use the client to manage a list of keys on the Controller. Release \u00b6 A Drycc release is a combination of a Build with a Config. Each Application is associated with one release at a time. Drycc releases are numbered and new releases always increment by one (e.g. v1, v2, v3). Containers that host an application use these release versions to pull the correct code and configuration. Scheduler \u00b6 The Scheduler is responsible for creating, starting, stopping, and destroying Containers. For example, a command such as drycc scale cmd=10 tells the Scheduler to run ten Containers from the Docker image for your Application. The Scheduler must decide which machines are eligible to run these container jobs. Scheduler backends vary in the details of their job allocation policies and whether or not they are resource-aware, among other features. The Drycc scheduler client is implemented in the Controller component. Service \u00b6 A Kubernetes Service is an abstraction which defines a logical set of Pods and a policy by which to access them. In Workflow, a Service is used to load-balance an application's Containers internally through a virtual IP address.","title":"Terms"},{"location":"reference-guide/terms/#terms","text":"","title":"Terms"},{"location":"reference-guide/terms/#application","text":"An application services requests and background jobs for a deployed git repository. Each application includes a set of Containers used to run isolated processes, and a Release that defines the current Build and Config deployed by containers.","title":"Application"},{"location":"reference-guide/terms/#build","text":"Drycc builds are created automatically on the controller when a developer uses git push drycc master . When a new build is created, a new Release is created automatically.","title":"Build"},{"location":"reference-guide/terms/#config","text":"Config refers to a set of environment variables used by Containers in as Application. When Config is changed, a new Release is created automatically.","title":"Config"},{"location":"reference-guide/terms/#container","text":"Drycc containers are instances of Docker containers used to run Applications. Containers perform the actual work of an Application by servicing requests or by running background tasks as part of the cluster.","title":"Container"},{"location":"reference-guide/terms/#ephemeral-filesystem","text":"Each container gets its own ephemeral filesystem, with a fresh copy of the most recently deployed code. During the container\u2019s lifetime, its running processes can use the filesystem as a temporary scratchpad, but no files that are written are visible to processes in any other container. Any files written to the ephemeral filesystem will be discarded the moment the container is either stopped or restarted.","title":"Ephemeral Filesystem"},{"location":"reference-guide/terms/#container-states","text":"There are several states that a container can be in at any time. The states are: initialized - the state of the container before it is created created - the container is built and ready for operation up - the container is running down - the container crashed or is stopped destroyed - the container has been destroyed","title":"Container States"},{"location":"reference-guide/terms/#controller","text":"The controller is the \"brain\" of the Drycc platform. A controller manages Applications and their lifecycle. The controller is in charge of: Authenticating and authorizing clients Processing client API calls Managing containers that perform work for applications Managing proxies that route traffic to containers Managing users, keys and other base configuration The Controller stack includes: Django API Server for handling API calls","title":"Controller"},{"location":"reference-guide/terms/#key","text":"Drycc keys are SSH Keys used during the git push process. Each user can use the client to manage a list of keys on the Controller.","title":"Key"},{"location":"reference-guide/terms/#release","text":"A Drycc release is a combination of a Build with a Config. Each Application is associated with one release at a time. Drycc releases are numbered and new releases always increment by one (e.g. v1, v2, v3). Containers that host an application use these release versions to pull the correct code and configuration.","title":"Release"},{"location":"reference-guide/terms/#scheduler","text":"The Scheduler is responsible for creating, starting, stopping, and destroying Containers. For example, a command such as drycc scale cmd=10 tells the Scheduler to run ten Containers from the Docker image for your Application. The Scheduler must decide which machines are eligible to run these container jobs. Scheduler backends vary in the details of their job allocation policies and whether or not they are resource-aware, among other features. The Drycc scheduler client is implemented in the Controller component.","title":"Scheduler"},{"location":"reference-guide/terms/#service","text":"A Kubernetes Service is an abstraction which defines a logical set of Pods and a policy by which to access them. In Workflow, a Service is used to load-balance an application's Containers internally through a virtual IP address.","title":"Service"},{"location":"reference-guide/controller-api/v2.0/","text":"Controller API v2.0 \u00b6 This is the v2.0 REST API for the Controller. What's New \u00b6 New! format of POST /v2/apps/<app id>/run has changed. Authentication \u00b6 Register a New User \u00b6 Example Request: POST /v2/auth/register/ HTTP/1.1 Host: drycc.example.com Content-Type: application/json { \"username\": \"test\", \"password\": \"opensesame\", \"email\": \"test@example.com\" } Optional Parameters: { \"first_name\": \"test\", \"last_name\": \"testerson\" } Example Response: HTTP/1.1 201 CREATED DRYCC_API_VERSION: 2.0 DRYCC_PLATFORM_VERSION: 2.1.0 Content-Type: application/json { \"id\": 1, \"last_login\": \"2014-10-19T22:01:00.601Z\", \"is_superuser\": true, \"username\": \"test\", \"first_name\": \"test\", \"last_name\": \"testerson\", \"email\": \"test@example.com\", \"is_staff\": true, \"is_active\": true, \"date_joined\": \"2014-10-19T22:01:00.601Z\", \"groups\": [], \"user_permissions\": [] } Log in \u00b6 Example Request: POST /v2/auth/login/ HTTP/1.1 Host: drycc.example.com Content-Type: application/json {\"username\": \"test\", \"password\": \"opensesame\"} Example Response: HTTP/1.1 200 OK DRYCC_API_VERSION: 2.0 DRYCC_PLATFORM_VERSION: 2.1.0 Content-Type: application/json {\"token\": \"abc123\"} Cancel Account \u00b6 Example Request: DELETE /v2/auth/cancel/ HTTP/1.1 Host: drycc.example.com Authorization: token abc123 Example Response: HTTP/1.1 204 NO CONTENT DRYCC_API_VERSION: 2.0 DRYCC_PLATFORM_VERSION: 2.1.0 Regenerate Token \u00b6 note This command could require administrative privileges Example Request: POST /v2/auth/tokens/ HTTP/1.1 Host: drycc.example.com Authorization: token abc123 Optional Parameters: { \"username\" : \"test\" \"all\" : \"true\" } Example Response: HTTP/1.1 200 OK DRYCC_API_VERSION: 2.0 DRYCC_PLATFORM_VERSION: 2.1.0 Content-Type: application/json {\"token\": \"abc123\"} Change Password \u00b6 Example Request: POST /v2/auth/passwd/ HTTP/1.1 Host: drycc.example.com Authorization: token abc123 { \"password\": \"foo\", \"new_password\": \"bar\" } Optional parameters: {\"username\": \"testuser\"} note Using the username parameter requires administrative privileges and makes the password parameter optional. Example Response: HTTP/1.1 200 OK DRYCC_API_VERSION: 2.0 DRYCC_PLATFORM_VERSION: 2.1.0 Applications \u00b6 List all Applications \u00b6 Example Request: GET /v2/apps HTTP/1.1 Host: drycc.example.com Authorization: token abc123 Example Response: HTTP/1.1 200 OK DRYCC_API_VERSION: 2.0 DRYCC_PLATFORM_VERSION: 2.1.0 Content-Type: application/json { \"count\": 1, \"next\": null, \"previous\": null, \"results\": [ { \"created\": \"2014-01-01T00:00:00UTC\", \"id\": \"example-go\", \"owner\": \"test\", \"structure\": {}, \"updated\": \"2014-01-01T00:00:00UTC\", \"url\": \"example-go.example.com\", \"uuid\": \"de1bf5b5-4a72-4f94-a10c-d2a3741cdf75\" } ] } Create an Application \u00b6 Example Request: POST /v2/apps/ HTTP/1.1 Host: drycc.example.com Content-Type: application/json Authorization: token abc123 Optional parameters: {\"id\": \"example-go\"} Example Response: HTTP/1.1 201 CREATED DRYCC_API_VERSION: 2.0 DRYCC_PLATFORM_VERSION: 2.1.0 Content-Type: application/json { \"created\": \"2014-01-01T00:00:00UTC\", \"id\": \"example-go\", \"owner\": \"test\", \"structure\": {}, \"updated\": \"2014-01-01T00:00:00UTC\", \"url\": \"example-go.example.com\", \"uuid\": \"de1bf5b5-4a72-4f94-a10c-d2a3741cdf75\" } Destroy an Application \u00b6 Example Request: DELETE /v2/apps/example-go/ HTTP/1.1 Host: drycc.example.com Authorization: token abc123 Example Response: HTTP/1.1 204 NO CONTENT DRYCC_API_VERSION: 2.0 DRYCC_PLATFORM_VERSION: 2.1.0 List Application Details \u00b6 Example Request: GET /v2/apps/example-go/ HTTP/1.1 Host: drycc.example.com Authorization: token abc123 Example Response: HTTP/1.1 200 OK DRYCC_API_VERSION: 2.0 DRYCC_PLATFORM_VERSION: 2.1.0 Content-Type: application/json { \"created\": \"2014-01-01T00:00:00UTC\", \"id\": \"example-go\", \"owner\": \"test\", \"structure\": {}, \"updated\": \"2014-01-01T00:00:00UTC\", \"url\": \"example-go.example.com\", \"uuid\": \"de1bf5b5-4a72-4f94-a10c-d2a3741cdf75\" } Update Application Details \u00b6 Example Request: POST /v2/apps/example-go/ HTTP/1.1 Host: drycc.example.com Authorization: token abc123 Optional parameters: { \"owner\": \"test\" } Example Response: HTTP/1.1 200 OK DRYCC_API_VERSION: 2.0 DRYCC_PLATFORM_VERSION: 1.8.0 Content-Type: application/json Retrieve Application Logs \u00b6 Example Request: GET /v2/apps/example-go/logs/ HTTP/1.1 Host: drycc.example.com Authorization: token abc123 Optional URL Query Parameters: ?log_lines= Example Response: HTTP/1.1 200 OK DRYCC_API_VERSION: 2.0 DRYCC_PLATFORM_VERSION: 2.1.0 Content-Type: text/plain \"16:51:14 drycc[api]: test created initial release\\n\" Run one-off Commands \u00b6 POST /v2/apps/example-go/run/ HTTP/1.1 Host: drycc.example.com Content-Type: application/json Authorization: token abc123 {\"command\": \"echo hi\"} Example Response: HTTP/1.1 200 OK DRYCC_API_VERSION: 2.0 DRYCC_PLATFORM_VERSION: 2.1.0 Content-Type: application/json {\"exit_code\": 0, \"output\": \"hi\\n\"} Certificates \u00b6 List all Certificates \u00b6 Example Request: GET /v2/certs HTTP/1.1 Host: drycc.example.com Authorization: token abc123 Example Response: HTTP/1.1 200 OK DRYCC_API_VERSION: 2.0 DRYCC_PLATFORM_VERSION: 2.1.0 Content-Type: application/json { \"count\": 1, \"next\": null, \"previous\": null, \"results\": [ { \"id\": 22, \"owner\": \"test\", \"san\": [], \"domains\": [], \"created\": \"2016-06-22T22:24:20Z\", \"updated\": \"2016-06-22T22:24:20Z\", \"name\": \"foo\", \"common_name\": \"bar.com\", \"fingerprint\": \"7A:CA:B8:50:FF:8D:EB:03:3D:AC:AD:13:4F:EE:03:D5:5D:EB:5E:37:51:8C:E0:98:F8:1B:36:2B:20:83:0D:C0\", \"expires\": \"2017-01-14T23:57:57Z\", \"starts\": \"2016-01-15T23:57:57Z\", \"issuer\": \"/C=US/ST=CA/L=San Francisco/O=Drycc/OU=Engineering/CN=bar.com/emailAddress=engineering@drycc.cc\", \"subject\": \"/C=US/ST=CA/L=San Francisco/O=Drycc/OU=Engineering/CN=bar.com/emailAddress=engineering@drycc.cc\" } ] } Get Certificate Details \u00b6 Example Request: GET /v2/certs/foo HTTP/1.1 Host: drycc.example.com Authorization: token abc123 Example Response: HTTP/1.1 200 OK DRYCC_API_VERSION: 2.0 DRYCC_PLATFORM_VERSION: 2.1.0 Content-Type: application/json { \"id\": 22, \"owner\": \"test\", \"san\": [], \"domains\": [], \"created\": \"2016-06-22T22:24:20Z\", \"updated\": \"2016-06-22T22:24:20Z\", \"name\": \"foo\", \"common_name\": \"bar.com\", \"fingerprint\": \"7A:CA:B8:50:FF:8D:EB:03:3D:AC:AD:13:4F:EE:03:D5:5D:EB:5E:37:51:8C:E0:98:F8:1B:36:2B:20:83:0D:C0\", \"expires\": \"2017-01-14T23:57:57Z\", \"starts\": \"2016-01-15T23:57:57Z\", \"issuer\": \"/C=US/ST=CA/L=San Francisco/O=Drycc/OU=Engineering/CN=bar.com/emailAddress=engineering@drycc.cc\", \"subject\": \"/C=US/ST=CA/L=San Francisco/O=Drycc/OU=Engineering/CN=bar.com/emailAddress=engineering@drycc.cc\" } Create Certificate \u00b6 Example Request: POST /v2/certs/ HTTP/1.1 Host: drycc.example.com Content-Type: application/json Authorization: token abc123 { \"name\": \"foo\" \"certificate\": \"-----BEGIN CERTIFICATE-----\", \"key\": \"-----BEGIN RSA PRIVATE KEY-----\" } Example Response: HTTP/1.1 201 CREATED DRYCC_API_VERSION: 2.0 DRYCC_PLATFORM_VERSION: 2.1.0 Content-Type: application/json { \"id\": 22, \"owner\": \"test\", \"san\": [], \"domains\": [], \"created\": \"2016-06-22T22:24:20Z\", \"updated\": \"2016-06-22T22:24:20Z\", \"name\": \"foo\", \"common_name\": \"bar.com\", \"fingerprint\": \"7A:CA:B8:50:FF:8D:EB:03:3D:AC:AD:13:4F:EE:03:D5:5D:EB:5E:37:51:8C:E0:98:F8:1B:36:2B:20:83:0D:C0\", \"expires\": \"2017-01-14T23:57:57Z\", \"starts\": \"2016-01-15T23:57:57Z\", \"issuer\": \"/C=US/ST=CA/L=San Francisco/O=Drycc/OU=Engineering/CN=bar.com/emailAddress=engineering@drycc.cc\", \"subject\": \"/C=US/ST=CA/L=San Francisco/O=Drycc/OU=Engineering/CN=bar.com/emailAddress=engineering@drycc.cc\" } Destroy a Certificate \u00b6 Example Request: DELETE /v2/certs/foo HTTP/1.1 Host: drycc.example.com Authorization: token abc123 Example Response: HTTP/1.1 204 NO CONTENT DRYCC_API_VERSION: 2.0 DRYCC_PLATFORM_VERSION: 2.1.0 Attach a Domain to a Certificate \u00b6 Example Request: POST /v2/certs/foo/domain/ HTTP/1.1 Host: drycc.example.com Authorization: token abc123 { \"domain\": \"test.com\" } Example Response: HTTP/1.1 201 CREATED DRYCC_API_VERSION: 2.0 DRYCC_PLATFORM_VERSION: 2.1.0 Remove a Domain from a Certificate \u00b6 Example Request: DELETE /v2/certs/foo/domain/test.com/ HTTP/1.1 Host: drycc.example.com Authorization: token abc123 Example Response: HTTP/1.1 204 NO CONTENT DRYCC_API_VERSION: 2.0 DRYCC_PLATFORM_VERSION: 2.1.0 Pods \u00b6 List all Pods \u00b6 Example Request: GET /v2/apps/example-go/pods/ HTTP/1.1 Host: drycc.example.com Authorization: token abc123 Example Response: HTTP/1.1 200 OK DRYCC_API_VERSION: 2.0 DRYCC_PLATFORM_VERSION: 2.1.0 Content-Type: application/json { \"count\": 1, \"results\": [ { \"name\": \"go-v2-web-e7dej\", \"release\": \"v2\", \"started\": \"2014-01-01T00:00:00Z\", \"state\": \"up\", \"type\": \"web\" } ] } List all Pods by Type \u00b6 Example Request: GET /v2/apps/example-go/pods/web/ HTTP/1.1 Host: drycc.example.com Authorization: token abc123 Example Response: HTTP/1.1 200 OK DRYCC_API_VERSION: 2.0 DRYCC_PLATFORM_VERSION: 2.1.0 Content-Type: application/json { \"count\": 1, \"results\": [ { \"name\": \"go-v2-web-e7dej\", \"release\": \"v2\", \"started\": \"2014-01-01T00:00:00Z\", \"state\": \"up\", \"type\": \"web\" } ] } Restart All Pods \u00b6 Example Request: POST /v2/apps/example-go/pods/restart/ HTTP/1.1 Host: drycc.example.com Authorization: token abc123 Example Response: HTTP/1.1 200 OK DRYCC_API_VERSION: 2.0 DRYCC_PLATFORM_VERSION: 2.1.0 Content-Type: application/json [ { \"name\": \"go-v2-web-atots\", \"release\": \"v2\", \"started\": \"2016-04-11T21:07:54Z\", \"state\": \"up\", \"type\": \"web\" } ] Restart Pods by Type \u00b6 Example Request: POST /v2/apps/example-go/pods/web/restart/ HTTP/1.1 Host: drycc.example.com Authorization: token abc123 Example Response: HTTP/1.1 200 OK DRYCC_API_VERSION: 2.0 DRYCC_PLATFORM_VERSION: 2.1.0 Content-Type: application/json [ { \"name\": \"go-v2-web-atots\", \"release\": \"v2\", \"started\": \"2016-04-11T21:07:54Z\", \"state\": \"up\", \"type\": \"web\" } ] Restart Pods by Type and Name \u00b6 Example Request: POST /v2/apps/example-go/pods/go-v2-web-atots/restart/ HTTP/1.1 Host: drycc.example.com Authorization: token abc123 Example Response: HTTP/1.1 200 OK DRYCC_API_VERSION: 2.0 DRYCC_PLATFORM_VERSION: 2.1.0 Content-Type: application/json [ { \"name\": \"go-v2-web-atots\", \"release\": \"v2\", \"started\": \"2016-04-11T21:07:54Z\", \"state\": \"up\", \"type\": \"web\" } ] Scale Pods \u00b6 Example Request: POST /v2/apps/example-go/scale/ HTTP/1.1 Host: drycc.example.com Content-Type: application/json Authorization: token abc123 {\"web\": 3} Example Response: HTTP/1.1 204 NO CONTENT DRYCC_API_VERSION: 2.0 DRYCC_PLATFORM_VERSION: 2.1.0 Configuration \u00b6 List Application Configuration \u00b6 Example Request: GET /v2/apps/example-go/config/ HTTP/1.1 Host: drycc.example.com Authorization: token abc123 Example Response: HTTP/1.1 200 OK DRYCC_API_VERSION: 2.0 DRYCC_PLATFORM_VERSION: 2.1.0 Content-Type: application/json { \"owner\": \"test\", \"app\": \"example-go\", \"values\": { \"PLATFORM\": \"drycc\" }, \"memory\": {}, \"cpu\": {}, \"tags\": {}, \"healthcheck\": {}, \"created\": \"2014-01-01T00:00:00UTC\", \"updated\": \"2014-01-01T00:00:00UTC\", \"uuid\": \"de1bf5b5-4a72-4f94-a10c-d2a3741cdf75\" } Create new Config \u00b6 Example Request: POST /v2/apps/example-go/config/ HTTP/1.1 Host: drycc.example.com Content-Type: application/json Authorization: token abc123 {\"values\": {\"HELLO\": \"world\", \"PLATFORM\": \"drycc\"}} Example Response: HTTP/1.1 201 CREATED DRYCC_API_VERSION: 2.0 DRYCC_PLATFORM_VERSION: 2.1.0 Content-Type: application/json X-Drycc-Release: 3 { \"owner\": \"test\", \"app\": \"example-go\", \"values\": { \"DRYCC_APP\": \"example-go\", \"DRYCC_RELEASE\": \"v3\", \"HELLO\": \"world\", \"PLATFORM\": \"drycc\" }, \"memory\": {}, \"cpu\": {}, \"tags\": {}, \"healthcheck\": {}, \"created\": \"2014-01-01T00:00:00UTC\", \"updated\": \"2014-01-01T00:00:00UTC\", \"uuid\": \"de1bf5b5-4a72-4f94-a10c-d2a3741cdf75\" } Unset Config Variable \u00b6 Example Request: POST /v2/apps/example-go/config/ HTTP/1.1 Host: drycc.example.com Content-Type: application/json Authorization: token abc123 {\"values\": {\"HELLO\": null}} Example Response: HTTP/1.1 201 CREATED DRYCC_API_VERSION: 2.0 DRYCC_PLATFORM_VERSION: 2.1.0 Content-Type: application/json X-Drycc-Release: 4 { \"owner\": \"test\", \"app\": \"example-go\", \"values\": { \"DRYCC_APP\": \"example-go\", \"DRYCC_RELEASE\": \"v4\", \"PLATFORM\": \"drycc\" }, \"memory\": {}, \"cpu\": {}, \"tags\": {}, \"healthcheck\": {}, \"created\": \"2014-01-01T00:00:00UTC\", \"updated\": \"2014-01-01T00:00:00UTC\", \"uuid\": \"de1bf5b5-4a72-4f94-a10c-d2a3741cdf75\" } Domains \u00b6 List Application Domains \u00b6 Example Request: GET /v2/apps/example-go/domains/ HTTP/1.1 Host: drycc.example.com Authorization: token abc123 Example Response: HTTP/1.1 200 OK DRYCC_API_VERSION: 2.0 DRYCC_PLATFORM_VERSION: 2.1.0 Content-Type: application/json { \"count\": 1, \"next\": null, \"previous\": null, \"results\": [ { \"app\": \"example-go\", \"created\": \"2014-01-01T00:00:00UTC\", \"domain\": \"example.example.com\", \"owner\": \"test\", \"updated\": \"2014-01-01T00:00:00UTC\" } ] } Add Domain \u00b6 Example Request: POST /v2/apps/example-go/domains/ HTTP/1.1 Host: drycc.example.com Authorization: token abc123 {'domain': 'example.example.com'} Example Response: HTTP/1.1 201 CREATED DRYCC_API_VERSION: 2.0 DRYCC_PLATFORM_VERSION: 2.1.0 Content-Type: application/json { \"app\": \"example-go\", \"created\": \"2014-01-01T00:00:00UTC\", \"domain\": \"example.example.com\", \"owner\": \"test\", \"updated\": \"2014-01-01T00:00:00UTC\" } Remove Domain \u00b6 Example Request: DELETE /v2/apps/example-go/domains/example.example.com HTTP/1.1 Host: drycc.example.com Authorization: token abc123 Example Response: HTTP/1.1 204 NO CONTENT DRYCC_API_VERSION: 2.0 DRYCC_PLATFORM_VERSION: 2.1.0 Builds \u00b6 List Application Builds \u00b6 Example Request: GET /v2/apps/example-go/builds/ HTTP/1.1 Host: drycc.example.com Authorization: token abc123 Example Response: HTTP/1.1 200 OK DRYCC_API_VERSION: 2.0 DRYCC_PLATFORM_VERSION: 2.1.0 Content-Type: application/json { \"count\": 1, \"next\": null, \"previous\": null, \"results\": [ { \"app\": \"example-go\", \"created\": \"2014-01-01T00:00:00UTC\", \"dockerfile\": \"FROM drycc/slugrunner RUN mkdir -p /app WORKDIR /app ENTRYPOINT [\\\"/runner/init\\\"] ADD slug.tgz /app ENV GIT_SHA 060da68f654e75fac06dbedd1995d5f8ad9084db\", \"image\": \"example-go\", \"owner\": \"test\", \"procfile\": { \"web\": \"example-go\" }, \"sha\": \"060da68f\", \"updated\": \"2014-01-01T00:00:00UTC\", \"uuid\": \"de1bf5b5-4a72-4f94-a10c-d2a3741cdf75\" } ] } Create Application Build \u00b6 Example Request: POST /v2/apps/example-go/builds/ HTTP/1.1 Host: drycc.example.com Content-Type: application/json Authorization: token abc123 {\"image\": \"drycc/example-go:latest\"} Optional Parameters: { \"procfile\": { \"web\": \"./cmd\" } } Example Response: HTTP/1.1 201 CREATED DRYCC_API_VERSION: 2.0 DRYCC_PLATFORM_VERSION: 2.1.0 Content-Type: application/json X-Drycc-Release: 4 { \"app\": \"example-go\", \"created\": \"2014-01-01T00:00:00UTC\", \"dockerfile\": \"\", \"image\": \"drycc/example-go:latest\", \"owner\": \"test\", \"procfile\": {}, \"sha\": \"\", \"updated\": \"2014-01-01T00:00:00UTC\", \"uuid\": \"de1bf5b5-4a72-4f94-a10c-d2a3741cdf75\" } Releases \u00b6 List Application Releases \u00b6 Example Request: GET /v2/apps/example-go/releases/ HTTP/1.1 Host: drycc.example.com Authorization: token abc123 Example Response: HTTP/1.1 200 OK DRYCC_API_VERSION: 2.0 DRYCC_PLATFORM_VERSION: 2.1.0 Content-Type: application/json { \"count\": 3, \"next\": null, \"previous\": null, \"results\": [ { \"app\": \"example-go\", \"build\": \"202d8e4b-600e-4425-a85c-ffc7ea607f61\", \"config\": \"ed637ceb-5d32-44bd-9406-d326a777a513\", \"created\": \"2014-01-01T00:00:00UTC\", \"owner\": \"test\", \"summary\": \"test changed nothing\", \"updated\": \"2014-01-01T00:00:00UTC\", \"uuid\": \"de1bf5b5-4a72-4f94-a10c-d2a3741cdf75\", \"version\": 3 }, { \"app\": \"example-go\", \"build\": \"202d8e4b-600e-4425-a85c-ffc7ea607f61\", \"config\": \"95bd6dea-1685-4f78-a03d-fd7270b058d1\", \"created\": \"2014-01-01T00:00:00UTC\", \"owner\": \"test\", \"summary\": \"test deployed 060da68\", \"updated\": \"2014-01-01T00:00:00UTC\", \"uuid\": \"de1bf5b5-4a72-4f94-a10c-d2a3741cdf75\", \"version\": 2 }, { \"app\": \"example-go\", \"build\": null, \"config\": \"95bd6dea-1685-4f78-a03d-fd7270b058d1\", \"created\": \"2014-01-01T00:00:00UTC\", \"owner\": \"test\", \"summary\": \"test created initial release\", \"updated\": \"2014-01-01T00:00:00UTC\", \"uuid\": \"de1bf5b5-4a72-4f94-a10c-d2a3741cdf75\", \"version\": 1 } ] } List Release Details \u00b6 Example Request: GET /v2/apps/example-go/releases/v2/ HTTP/1.1 Host: drycc.example.com Authorization: token abc123 Example Response: HTTP/1.1 200 OK DRYCC_API_VERSION: 2.0 DRYCC_PLATFORM_VERSION: 2.1.0 Content-Type: application/json { \"app\": \"example-go\", \"build\": null, \"config\": \"95bd6dea-1685-4f78-a03d-fd7270b058d1\", \"created\": \"2014-01-01T00:00:00UTC\", \"owner\": \"test\", \"summary\": \"test created initial release\", \"updated\": \"2014-01-01T00:00:00UTC\", \"uuid\": \"de1bf5b5-4a72-4f94-a10c-d2a3741cdf75\", \"version\": 1 } Rollback Release \u00b6 Example Request: POST /v2/apps/example-go/releases/rollback/ HTTP/1.1 Host: drycc.example.com Content-Type: application/json Authorization: token abc123 {\"version\": 1} Example Response: HTTP/1.1 201 CREATED DRYCC_API_VERSION: 2.0 DRYCC_PLATFORM_VERSION: 2.1.0 Content-Type: application/json {\"version\": 5} Keys \u00b6 List Keys \u00b6 Example Request: GET /v2/keys/ HTTP/1.1 Host: drycc.example.com Authorization: token abc123 Example Response: HTTP/1.1 201 CREATED DRYCC_API_VERSION: 2.0 DRYCC_PLATFORM_VERSION: 2.1.0 Content-Type: application/json { \"count\": 1, \"next\": null, \"previous\": null, \"results\": [ { \"created\": \"2014-01-01T00:00:00UTC\", \"id\": \"test@example.com\", \"owner\": \"test\", \"public\": \"ssh-rsa <...>\", \"updated\": \"2014-01-01T00:00:00UTC\", \"uuid\": \"de1bf5b5-4a72-4f94-a10c-d2a3741cdf75\" } ] } Add Key to User \u00b6 Example Request: POST /v2/keys/ HTTP/1.1 Host: drycc.example.com Authorization: token abc123 { \"id\": \"example\", \"public\": \"ssh-rsa <...>\" } Example Response: HTTP/1.1 201 CREATED DRYCC_API_VERSION: 2.0 DRYCC_PLATFORM_VERSION: 2.1.0 Content-Type: application/json { \"created\": \"2014-01-01T00:00:00UTC\", \"id\": \"example\", \"owner\": \"example\", \"public\": \"ssh-rsa <...>\", \"updated\": \"2014-01-01T00:00:00UTC\", \"uuid\": \"de1bf5b5-4a72-4f94-a10c-d2a3741cdf75\" } Remove Key from User \u00b6 Example Request: DELETE /v2/keys/example HTTP/1.1 Host: drycc.example.com Authorization: token abc123 Example Response: HTTP/1.1 204 NO CONTENT DRYCC_API_VERSION: 2.0 DRYCC_PLATFORM_VERSION: 2.1.0 Permissions \u00b6 List Application Permissions \u00b6 note This does not include the app owner. Example Request: GET /v2/apps/example-go/perms/ HTTP/1.1 Host: drycc.example.com Authorization: token abc123 Example Response: HTTP/1.1 200 OK DRYCC_API_VERSION: 2.0 DRYCC_PLATFORM_VERSION: 2.1.0 Content-Type: application/json { \"users\": [ \"test\", \"foo\" ] } Create Application Permission \u00b6 Example Request: POST /v2/apps/example-go/perms/ HTTP/1.1 Host: drycc.example.com Authorization: token abc123 {\"username\": \"example\"} Example Response: HTTP/1.1 201 CREATED DRYCC_API_VERSION: 2.0 DRYCC_PLATFORM_VERSION: 2.1.0 Remove Application Permission \u00b6 Example Request: DELETE /v2/apps/example-go/perms/example HTTP/1.1 Host: drycc.example.com Authorization: token abc123 Example Response: HTTP/1.1 204 NO CONTENT DRYCC_API_VERSION: 2.0 DRYCC_PLATFORM_VERSION: 2.1.0 List Administrators \u00b6 Example Request: GET /v2/admin/perms/ HTTP/1.1 Host: drycc.example.com Authorization: token abc123 Example Response: HTTP/1.1 200 OK DRYCC_API_VERSION: 2.0 DRYCC_PLATFORM_VERSION: 2.1.0 Content-Type: application/json { \"count\": 2, \"next\": null \"previous\": null, \"results\": [ { \"username\": \"test\", \"is_superuser\": true }, { \"username\": \"foo\", \"is_superuser\": true } ] } Grant User Administrative Privileges \u00b6 note This command requires administrative privileges Example Request: POST /v2/admin/perms HTTP/1.1 Host: drycc.example.com Authorization: token abc123 {\"username\": \"example\"} Example Response: HTTP/1.1 201 CREATED DRYCC_API_VERSION: 2.0 DRYCC_PLATFORM_VERSION: 2.1.0 Remove User's Administrative Privileges \u00b6 note This command requires administrative privileges Example Request: DELETE /v2/admin/perms/example HTTP/1.1 Host: drycc.example.com Authorization: token abc123 Example Response: HTTP/1.1 204 NO CONTENT DRYCC_API_VERSION: 2.0 DRYCC_PLATFORM_VERSION: 2.1.0 Users \u00b6 List all users \u00b6 note This command requires administrative privileges Example Request: GET /v2/users HTTP/1.1 Host: drycc.example.com Authorization: token abc123 Example Response: HTTP/1.1 200 OK DRYCC_API_VERSION: 2.0 DRYCC_PLATFORM_VERSION: 2.1.0 Content-Type: application/json { \"count\": 1, \"next\": null, \"previous\": null, \"results\": [ { \"id\": 1, \"last_login\": \"2014-10-19T22:01:00.601Z\", \"is_superuser\": true, \"username\": \"test\", \"first_name\": \"test\", \"last_name\": \"testerson\", \"email\": \"test@example.com\", \"is_staff\": true, \"is_active\": true, \"date_joined\": \"2014-10-19T22:01:00.601Z\", \"groups\": [], \"user_permissions\": [] } ] }","title":"Controller API v2.0"},{"location":"reference-guide/controller-api/v2.0/#controller-api-v20","text":"This is the v2.0 REST API for the Controller.","title":"Controller API v2.0"},{"location":"reference-guide/controller-api/v2.0/#whats-new","text":"New! format of POST /v2/apps/<app id>/run has changed.","title":"What's New"},{"location":"reference-guide/controller-api/v2.0/#authentication","text":"","title":"Authentication"},{"location":"reference-guide/controller-api/v2.0/#register-a-new-user","text":"Example Request: POST /v2/auth/register/ HTTP/1.1 Host: drycc.example.com Content-Type: application/json { \"username\": \"test\", \"password\": \"opensesame\", \"email\": \"test@example.com\" } Optional Parameters: { \"first_name\": \"test\", \"last_name\": \"testerson\" } Example Response: HTTP/1.1 201 CREATED DRYCC_API_VERSION: 2.0 DRYCC_PLATFORM_VERSION: 2.1.0 Content-Type: application/json { \"id\": 1, \"last_login\": \"2014-10-19T22:01:00.601Z\", \"is_superuser\": true, \"username\": \"test\", \"first_name\": \"test\", \"last_name\": \"testerson\", \"email\": \"test@example.com\", \"is_staff\": true, \"is_active\": true, \"date_joined\": \"2014-10-19T22:01:00.601Z\", \"groups\": [], \"user_permissions\": [] }","title":"Register a New User"},{"location":"reference-guide/controller-api/v2.0/#log-in","text":"Example Request: POST /v2/auth/login/ HTTP/1.1 Host: drycc.example.com Content-Type: application/json {\"username\": \"test\", \"password\": \"opensesame\"} Example Response: HTTP/1.1 200 OK DRYCC_API_VERSION: 2.0 DRYCC_PLATFORM_VERSION: 2.1.0 Content-Type: application/json {\"token\": \"abc123\"}","title":"Log in"},{"location":"reference-guide/controller-api/v2.0/#cancel-account","text":"Example Request: DELETE /v2/auth/cancel/ HTTP/1.1 Host: drycc.example.com Authorization: token abc123 Example Response: HTTP/1.1 204 NO CONTENT DRYCC_API_VERSION: 2.0 DRYCC_PLATFORM_VERSION: 2.1.0","title":"Cancel Account"},{"location":"reference-guide/controller-api/v2.0/#regenerate-token","text":"note This command could require administrative privileges Example Request: POST /v2/auth/tokens/ HTTP/1.1 Host: drycc.example.com Authorization: token abc123 Optional Parameters: { \"username\" : \"test\" \"all\" : \"true\" } Example Response: HTTP/1.1 200 OK DRYCC_API_VERSION: 2.0 DRYCC_PLATFORM_VERSION: 2.1.0 Content-Type: application/json {\"token\": \"abc123\"}","title":"Regenerate Token"},{"location":"reference-guide/controller-api/v2.0/#change-password","text":"Example Request: POST /v2/auth/passwd/ HTTP/1.1 Host: drycc.example.com Authorization: token abc123 { \"password\": \"foo\", \"new_password\": \"bar\" } Optional parameters: {\"username\": \"testuser\"} note Using the username parameter requires administrative privileges and makes the password parameter optional. Example Response: HTTP/1.1 200 OK DRYCC_API_VERSION: 2.0 DRYCC_PLATFORM_VERSION: 2.1.0","title":"Change Password"},{"location":"reference-guide/controller-api/v2.0/#applications","text":"","title":"Applications"},{"location":"reference-guide/controller-api/v2.0/#list-all-applications","text":"Example Request: GET /v2/apps HTTP/1.1 Host: drycc.example.com Authorization: token abc123 Example Response: HTTP/1.1 200 OK DRYCC_API_VERSION: 2.0 DRYCC_PLATFORM_VERSION: 2.1.0 Content-Type: application/json { \"count\": 1, \"next\": null, \"previous\": null, \"results\": [ { \"created\": \"2014-01-01T00:00:00UTC\", \"id\": \"example-go\", \"owner\": \"test\", \"structure\": {}, \"updated\": \"2014-01-01T00:00:00UTC\", \"url\": \"example-go.example.com\", \"uuid\": \"de1bf5b5-4a72-4f94-a10c-d2a3741cdf75\" } ] }","title":"List all Applications"},{"location":"reference-guide/controller-api/v2.0/#create-an-application","text":"Example Request: POST /v2/apps/ HTTP/1.1 Host: drycc.example.com Content-Type: application/json Authorization: token abc123 Optional parameters: {\"id\": \"example-go\"} Example Response: HTTP/1.1 201 CREATED DRYCC_API_VERSION: 2.0 DRYCC_PLATFORM_VERSION: 2.1.0 Content-Type: application/json { \"created\": \"2014-01-01T00:00:00UTC\", \"id\": \"example-go\", \"owner\": \"test\", \"structure\": {}, \"updated\": \"2014-01-01T00:00:00UTC\", \"url\": \"example-go.example.com\", \"uuid\": \"de1bf5b5-4a72-4f94-a10c-d2a3741cdf75\" }","title":"Create an Application"},{"location":"reference-guide/controller-api/v2.0/#destroy-an-application","text":"Example Request: DELETE /v2/apps/example-go/ HTTP/1.1 Host: drycc.example.com Authorization: token abc123 Example Response: HTTP/1.1 204 NO CONTENT DRYCC_API_VERSION: 2.0 DRYCC_PLATFORM_VERSION: 2.1.0","title":"Destroy an Application"},{"location":"reference-guide/controller-api/v2.0/#list-application-details","text":"Example Request: GET /v2/apps/example-go/ HTTP/1.1 Host: drycc.example.com Authorization: token abc123 Example Response: HTTP/1.1 200 OK DRYCC_API_VERSION: 2.0 DRYCC_PLATFORM_VERSION: 2.1.0 Content-Type: application/json { \"created\": \"2014-01-01T00:00:00UTC\", \"id\": \"example-go\", \"owner\": \"test\", \"structure\": {}, \"updated\": \"2014-01-01T00:00:00UTC\", \"url\": \"example-go.example.com\", \"uuid\": \"de1bf5b5-4a72-4f94-a10c-d2a3741cdf75\" }","title":"List Application Details"},{"location":"reference-guide/controller-api/v2.0/#update-application-details","text":"Example Request: POST /v2/apps/example-go/ HTTP/1.1 Host: drycc.example.com Authorization: token abc123 Optional parameters: { \"owner\": \"test\" } Example Response: HTTP/1.1 200 OK DRYCC_API_VERSION: 2.0 DRYCC_PLATFORM_VERSION: 1.8.0 Content-Type: application/json","title":"Update Application Details"},{"location":"reference-guide/controller-api/v2.0/#retrieve-application-logs","text":"Example Request: GET /v2/apps/example-go/logs/ HTTP/1.1 Host: drycc.example.com Authorization: token abc123 Optional URL Query Parameters: ?log_lines= Example Response: HTTP/1.1 200 OK DRYCC_API_VERSION: 2.0 DRYCC_PLATFORM_VERSION: 2.1.0 Content-Type: text/plain \"16:51:14 drycc[api]: test created initial release\\n\"","title":"Retrieve Application Logs"},{"location":"reference-guide/controller-api/v2.0/#run-one-off-commands","text":"POST /v2/apps/example-go/run/ HTTP/1.1 Host: drycc.example.com Content-Type: application/json Authorization: token abc123 {\"command\": \"echo hi\"} Example Response: HTTP/1.1 200 OK DRYCC_API_VERSION: 2.0 DRYCC_PLATFORM_VERSION: 2.1.0 Content-Type: application/json {\"exit_code\": 0, \"output\": \"hi\\n\"}","title":"Run one-off Commands"},{"location":"reference-guide/controller-api/v2.0/#certificates","text":"","title":"Certificates"},{"location":"reference-guide/controller-api/v2.0/#list-all-certificates","text":"Example Request: GET /v2/certs HTTP/1.1 Host: drycc.example.com Authorization: token abc123 Example Response: HTTP/1.1 200 OK DRYCC_API_VERSION: 2.0 DRYCC_PLATFORM_VERSION: 2.1.0 Content-Type: application/json { \"count\": 1, \"next\": null, \"previous\": null, \"results\": [ { \"id\": 22, \"owner\": \"test\", \"san\": [], \"domains\": [], \"created\": \"2016-06-22T22:24:20Z\", \"updated\": \"2016-06-22T22:24:20Z\", \"name\": \"foo\", \"common_name\": \"bar.com\", \"fingerprint\": \"7A:CA:B8:50:FF:8D:EB:03:3D:AC:AD:13:4F:EE:03:D5:5D:EB:5E:37:51:8C:E0:98:F8:1B:36:2B:20:83:0D:C0\", \"expires\": \"2017-01-14T23:57:57Z\", \"starts\": \"2016-01-15T23:57:57Z\", \"issuer\": \"/C=US/ST=CA/L=San Francisco/O=Drycc/OU=Engineering/CN=bar.com/emailAddress=engineering@drycc.cc\", \"subject\": \"/C=US/ST=CA/L=San Francisco/O=Drycc/OU=Engineering/CN=bar.com/emailAddress=engineering@drycc.cc\" } ] }","title":"List all Certificates"},{"location":"reference-guide/controller-api/v2.0/#get-certificate-details","text":"Example Request: GET /v2/certs/foo HTTP/1.1 Host: drycc.example.com Authorization: token abc123 Example Response: HTTP/1.1 200 OK DRYCC_API_VERSION: 2.0 DRYCC_PLATFORM_VERSION: 2.1.0 Content-Type: application/json { \"id\": 22, \"owner\": \"test\", \"san\": [], \"domains\": [], \"created\": \"2016-06-22T22:24:20Z\", \"updated\": \"2016-06-22T22:24:20Z\", \"name\": \"foo\", \"common_name\": \"bar.com\", \"fingerprint\": \"7A:CA:B8:50:FF:8D:EB:03:3D:AC:AD:13:4F:EE:03:D5:5D:EB:5E:37:51:8C:E0:98:F8:1B:36:2B:20:83:0D:C0\", \"expires\": \"2017-01-14T23:57:57Z\", \"starts\": \"2016-01-15T23:57:57Z\", \"issuer\": \"/C=US/ST=CA/L=San Francisco/O=Drycc/OU=Engineering/CN=bar.com/emailAddress=engineering@drycc.cc\", \"subject\": \"/C=US/ST=CA/L=San Francisco/O=Drycc/OU=Engineering/CN=bar.com/emailAddress=engineering@drycc.cc\" }","title":"Get Certificate Details"},{"location":"reference-guide/controller-api/v2.0/#create-certificate","text":"Example Request: POST /v2/certs/ HTTP/1.1 Host: drycc.example.com Content-Type: application/json Authorization: token abc123 { \"name\": \"foo\" \"certificate\": \"-----BEGIN CERTIFICATE-----\", \"key\": \"-----BEGIN RSA PRIVATE KEY-----\" } Example Response: HTTP/1.1 201 CREATED DRYCC_API_VERSION: 2.0 DRYCC_PLATFORM_VERSION: 2.1.0 Content-Type: application/json { \"id\": 22, \"owner\": \"test\", \"san\": [], \"domains\": [], \"created\": \"2016-06-22T22:24:20Z\", \"updated\": \"2016-06-22T22:24:20Z\", \"name\": \"foo\", \"common_name\": \"bar.com\", \"fingerprint\": \"7A:CA:B8:50:FF:8D:EB:03:3D:AC:AD:13:4F:EE:03:D5:5D:EB:5E:37:51:8C:E0:98:F8:1B:36:2B:20:83:0D:C0\", \"expires\": \"2017-01-14T23:57:57Z\", \"starts\": \"2016-01-15T23:57:57Z\", \"issuer\": \"/C=US/ST=CA/L=San Francisco/O=Drycc/OU=Engineering/CN=bar.com/emailAddress=engineering@drycc.cc\", \"subject\": \"/C=US/ST=CA/L=San Francisco/O=Drycc/OU=Engineering/CN=bar.com/emailAddress=engineering@drycc.cc\" }","title":"Create Certificate"},{"location":"reference-guide/controller-api/v2.0/#destroy-a-certificate","text":"Example Request: DELETE /v2/certs/foo HTTP/1.1 Host: drycc.example.com Authorization: token abc123 Example Response: HTTP/1.1 204 NO CONTENT DRYCC_API_VERSION: 2.0 DRYCC_PLATFORM_VERSION: 2.1.0","title":"Destroy a Certificate"},{"location":"reference-guide/controller-api/v2.0/#attach-a-domain-to-a-certificate","text":"Example Request: POST /v2/certs/foo/domain/ HTTP/1.1 Host: drycc.example.com Authorization: token abc123 { \"domain\": \"test.com\" } Example Response: HTTP/1.1 201 CREATED DRYCC_API_VERSION: 2.0 DRYCC_PLATFORM_VERSION: 2.1.0","title":"Attach a Domain to a Certificate"},{"location":"reference-guide/controller-api/v2.0/#remove-a-domain-from-a-certificate","text":"Example Request: DELETE /v2/certs/foo/domain/test.com/ HTTP/1.1 Host: drycc.example.com Authorization: token abc123 Example Response: HTTP/1.1 204 NO CONTENT DRYCC_API_VERSION: 2.0 DRYCC_PLATFORM_VERSION: 2.1.0","title":"Remove a Domain from a Certificate"},{"location":"reference-guide/controller-api/v2.0/#pods","text":"","title":"Pods"},{"location":"reference-guide/controller-api/v2.0/#list-all-pods","text":"Example Request: GET /v2/apps/example-go/pods/ HTTP/1.1 Host: drycc.example.com Authorization: token abc123 Example Response: HTTP/1.1 200 OK DRYCC_API_VERSION: 2.0 DRYCC_PLATFORM_VERSION: 2.1.0 Content-Type: application/json { \"count\": 1, \"results\": [ { \"name\": \"go-v2-web-e7dej\", \"release\": \"v2\", \"started\": \"2014-01-01T00:00:00Z\", \"state\": \"up\", \"type\": \"web\" } ] }","title":"List all Pods"},{"location":"reference-guide/controller-api/v2.0/#list-all-pods-by-type","text":"Example Request: GET /v2/apps/example-go/pods/web/ HTTP/1.1 Host: drycc.example.com Authorization: token abc123 Example Response: HTTP/1.1 200 OK DRYCC_API_VERSION: 2.0 DRYCC_PLATFORM_VERSION: 2.1.0 Content-Type: application/json { \"count\": 1, \"results\": [ { \"name\": \"go-v2-web-e7dej\", \"release\": \"v2\", \"started\": \"2014-01-01T00:00:00Z\", \"state\": \"up\", \"type\": \"web\" } ] }","title":"List all Pods by Type"},{"location":"reference-guide/controller-api/v2.0/#restart-all-pods","text":"Example Request: POST /v2/apps/example-go/pods/restart/ HTTP/1.1 Host: drycc.example.com Authorization: token abc123 Example Response: HTTP/1.1 200 OK DRYCC_API_VERSION: 2.0 DRYCC_PLATFORM_VERSION: 2.1.0 Content-Type: application/json [ { \"name\": \"go-v2-web-atots\", \"release\": \"v2\", \"started\": \"2016-04-11T21:07:54Z\", \"state\": \"up\", \"type\": \"web\" } ]","title":"Restart All Pods"},{"location":"reference-guide/controller-api/v2.0/#restart-pods-by-type","text":"Example Request: POST /v2/apps/example-go/pods/web/restart/ HTTP/1.1 Host: drycc.example.com Authorization: token abc123 Example Response: HTTP/1.1 200 OK DRYCC_API_VERSION: 2.0 DRYCC_PLATFORM_VERSION: 2.1.0 Content-Type: application/json [ { \"name\": \"go-v2-web-atots\", \"release\": \"v2\", \"started\": \"2016-04-11T21:07:54Z\", \"state\": \"up\", \"type\": \"web\" } ]","title":"Restart Pods by Type"},{"location":"reference-guide/controller-api/v2.0/#restart-pods-by-type-and-name","text":"Example Request: POST /v2/apps/example-go/pods/go-v2-web-atots/restart/ HTTP/1.1 Host: drycc.example.com Authorization: token abc123 Example Response: HTTP/1.1 200 OK DRYCC_API_VERSION: 2.0 DRYCC_PLATFORM_VERSION: 2.1.0 Content-Type: application/json [ { \"name\": \"go-v2-web-atots\", \"release\": \"v2\", \"started\": \"2016-04-11T21:07:54Z\", \"state\": \"up\", \"type\": \"web\" } ]","title":"Restart Pods by Type and Name"},{"location":"reference-guide/controller-api/v2.0/#scale-pods","text":"Example Request: POST /v2/apps/example-go/scale/ HTTP/1.1 Host: drycc.example.com Content-Type: application/json Authorization: token abc123 {\"web\": 3} Example Response: HTTP/1.1 204 NO CONTENT DRYCC_API_VERSION: 2.0 DRYCC_PLATFORM_VERSION: 2.1.0","title":"Scale Pods"},{"location":"reference-guide/controller-api/v2.0/#configuration","text":"","title":"Configuration"},{"location":"reference-guide/controller-api/v2.0/#list-application-configuration","text":"Example Request: GET /v2/apps/example-go/config/ HTTP/1.1 Host: drycc.example.com Authorization: token abc123 Example Response: HTTP/1.1 200 OK DRYCC_API_VERSION: 2.0 DRYCC_PLATFORM_VERSION: 2.1.0 Content-Type: application/json { \"owner\": \"test\", \"app\": \"example-go\", \"values\": { \"PLATFORM\": \"drycc\" }, \"memory\": {}, \"cpu\": {}, \"tags\": {}, \"healthcheck\": {}, \"created\": \"2014-01-01T00:00:00UTC\", \"updated\": \"2014-01-01T00:00:00UTC\", \"uuid\": \"de1bf5b5-4a72-4f94-a10c-d2a3741cdf75\" }","title":"List Application Configuration"},{"location":"reference-guide/controller-api/v2.0/#create-new-config","text":"Example Request: POST /v2/apps/example-go/config/ HTTP/1.1 Host: drycc.example.com Content-Type: application/json Authorization: token abc123 {\"values\": {\"HELLO\": \"world\", \"PLATFORM\": \"drycc\"}} Example Response: HTTP/1.1 201 CREATED DRYCC_API_VERSION: 2.0 DRYCC_PLATFORM_VERSION: 2.1.0 Content-Type: application/json X-Drycc-Release: 3 { \"owner\": \"test\", \"app\": \"example-go\", \"values\": { \"DRYCC_APP\": \"example-go\", \"DRYCC_RELEASE\": \"v3\", \"HELLO\": \"world\", \"PLATFORM\": \"drycc\" }, \"memory\": {}, \"cpu\": {}, \"tags\": {}, \"healthcheck\": {}, \"created\": \"2014-01-01T00:00:00UTC\", \"updated\": \"2014-01-01T00:00:00UTC\", \"uuid\": \"de1bf5b5-4a72-4f94-a10c-d2a3741cdf75\" }","title":"Create new Config"},{"location":"reference-guide/controller-api/v2.0/#unset-config-variable","text":"Example Request: POST /v2/apps/example-go/config/ HTTP/1.1 Host: drycc.example.com Content-Type: application/json Authorization: token abc123 {\"values\": {\"HELLO\": null}} Example Response: HTTP/1.1 201 CREATED DRYCC_API_VERSION: 2.0 DRYCC_PLATFORM_VERSION: 2.1.0 Content-Type: application/json X-Drycc-Release: 4 { \"owner\": \"test\", \"app\": \"example-go\", \"values\": { \"DRYCC_APP\": \"example-go\", \"DRYCC_RELEASE\": \"v4\", \"PLATFORM\": \"drycc\" }, \"memory\": {}, \"cpu\": {}, \"tags\": {}, \"healthcheck\": {}, \"created\": \"2014-01-01T00:00:00UTC\", \"updated\": \"2014-01-01T00:00:00UTC\", \"uuid\": \"de1bf5b5-4a72-4f94-a10c-d2a3741cdf75\" }","title":"Unset Config Variable"},{"location":"reference-guide/controller-api/v2.0/#domains","text":"","title":"Domains"},{"location":"reference-guide/controller-api/v2.0/#list-application-domains","text":"Example Request: GET /v2/apps/example-go/domains/ HTTP/1.1 Host: drycc.example.com Authorization: token abc123 Example Response: HTTP/1.1 200 OK DRYCC_API_VERSION: 2.0 DRYCC_PLATFORM_VERSION: 2.1.0 Content-Type: application/json { \"count\": 1, \"next\": null, \"previous\": null, \"results\": [ { \"app\": \"example-go\", \"created\": \"2014-01-01T00:00:00UTC\", \"domain\": \"example.example.com\", \"owner\": \"test\", \"updated\": \"2014-01-01T00:00:00UTC\" } ] }","title":"List Application Domains"},{"location":"reference-guide/controller-api/v2.0/#add-domain","text":"Example Request: POST /v2/apps/example-go/domains/ HTTP/1.1 Host: drycc.example.com Authorization: token abc123 {'domain': 'example.example.com'} Example Response: HTTP/1.1 201 CREATED DRYCC_API_VERSION: 2.0 DRYCC_PLATFORM_VERSION: 2.1.0 Content-Type: application/json { \"app\": \"example-go\", \"created\": \"2014-01-01T00:00:00UTC\", \"domain\": \"example.example.com\", \"owner\": \"test\", \"updated\": \"2014-01-01T00:00:00UTC\" }","title":"Add Domain"},{"location":"reference-guide/controller-api/v2.0/#remove-domain","text":"Example Request: DELETE /v2/apps/example-go/domains/example.example.com HTTP/1.1 Host: drycc.example.com Authorization: token abc123 Example Response: HTTP/1.1 204 NO CONTENT DRYCC_API_VERSION: 2.0 DRYCC_PLATFORM_VERSION: 2.1.0","title":"Remove Domain"},{"location":"reference-guide/controller-api/v2.0/#builds","text":"","title":"Builds"},{"location":"reference-guide/controller-api/v2.0/#list-application-builds","text":"Example Request: GET /v2/apps/example-go/builds/ HTTP/1.1 Host: drycc.example.com Authorization: token abc123 Example Response: HTTP/1.1 200 OK DRYCC_API_VERSION: 2.0 DRYCC_PLATFORM_VERSION: 2.1.0 Content-Type: application/json { \"count\": 1, \"next\": null, \"previous\": null, \"results\": [ { \"app\": \"example-go\", \"created\": \"2014-01-01T00:00:00UTC\", \"dockerfile\": \"FROM drycc/slugrunner RUN mkdir -p /app WORKDIR /app ENTRYPOINT [\\\"/runner/init\\\"] ADD slug.tgz /app ENV GIT_SHA 060da68f654e75fac06dbedd1995d5f8ad9084db\", \"image\": \"example-go\", \"owner\": \"test\", \"procfile\": { \"web\": \"example-go\" }, \"sha\": \"060da68f\", \"updated\": \"2014-01-01T00:00:00UTC\", \"uuid\": \"de1bf5b5-4a72-4f94-a10c-d2a3741cdf75\" } ] }","title":"List Application Builds"},{"location":"reference-guide/controller-api/v2.0/#create-application-build","text":"Example Request: POST /v2/apps/example-go/builds/ HTTP/1.1 Host: drycc.example.com Content-Type: application/json Authorization: token abc123 {\"image\": \"drycc/example-go:latest\"} Optional Parameters: { \"procfile\": { \"web\": \"./cmd\" } } Example Response: HTTP/1.1 201 CREATED DRYCC_API_VERSION: 2.0 DRYCC_PLATFORM_VERSION: 2.1.0 Content-Type: application/json X-Drycc-Release: 4 { \"app\": \"example-go\", \"created\": \"2014-01-01T00:00:00UTC\", \"dockerfile\": \"\", \"image\": \"drycc/example-go:latest\", \"owner\": \"test\", \"procfile\": {}, \"sha\": \"\", \"updated\": \"2014-01-01T00:00:00UTC\", \"uuid\": \"de1bf5b5-4a72-4f94-a10c-d2a3741cdf75\" }","title":"Create Application Build"},{"location":"reference-guide/controller-api/v2.0/#releases","text":"","title":"Releases"},{"location":"reference-guide/controller-api/v2.0/#list-application-releases","text":"Example Request: GET /v2/apps/example-go/releases/ HTTP/1.1 Host: drycc.example.com Authorization: token abc123 Example Response: HTTP/1.1 200 OK DRYCC_API_VERSION: 2.0 DRYCC_PLATFORM_VERSION: 2.1.0 Content-Type: application/json { \"count\": 3, \"next\": null, \"previous\": null, \"results\": [ { \"app\": \"example-go\", \"build\": \"202d8e4b-600e-4425-a85c-ffc7ea607f61\", \"config\": \"ed637ceb-5d32-44bd-9406-d326a777a513\", \"created\": \"2014-01-01T00:00:00UTC\", \"owner\": \"test\", \"summary\": \"test changed nothing\", \"updated\": \"2014-01-01T00:00:00UTC\", \"uuid\": \"de1bf5b5-4a72-4f94-a10c-d2a3741cdf75\", \"version\": 3 }, { \"app\": \"example-go\", \"build\": \"202d8e4b-600e-4425-a85c-ffc7ea607f61\", \"config\": \"95bd6dea-1685-4f78-a03d-fd7270b058d1\", \"created\": \"2014-01-01T00:00:00UTC\", \"owner\": \"test\", \"summary\": \"test deployed 060da68\", \"updated\": \"2014-01-01T00:00:00UTC\", \"uuid\": \"de1bf5b5-4a72-4f94-a10c-d2a3741cdf75\", \"version\": 2 }, { \"app\": \"example-go\", \"build\": null, \"config\": \"95bd6dea-1685-4f78-a03d-fd7270b058d1\", \"created\": \"2014-01-01T00:00:00UTC\", \"owner\": \"test\", \"summary\": \"test created initial release\", \"updated\": \"2014-01-01T00:00:00UTC\", \"uuid\": \"de1bf5b5-4a72-4f94-a10c-d2a3741cdf75\", \"version\": 1 } ] }","title":"List Application Releases"},{"location":"reference-guide/controller-api/v2.0/#list-release-details","text":"Example Request: GET /v2/apps/example-go/releases/v2/ HTTP/1.1 Host: drycc.example.com Authorization: token abc123 Example Response: HTTP/1.1 200 OK DRYCC_API_VERSION: 2.0 DRYCC_PLATFORM_VERSION: 2.1.0 Content-Type: application/json { \"app\": \"example-go\", \"build\": null, \"config\": \"95bd6dea-1685-4f78-a03d-fd7270b058d1\", \"created\": \"2014-01-01T00:00:00UTC\", \"owner\": \"test\", \"summary\": \"test created initial release\", \"updated\": \"2014-01-01T00:00:00UTC\", \"uuid\": \"de1bf5b5-4a72-4f94-a10c-d2a3741cdf75\", \"version\": 1 }","title":"List Release Details"},{"location":"reference-guide/controller-api/v2.0/#rollback-release","text":"Example Request: POST /v2/apps/example-go/releases/rollback/ HTTP/1.1 Host: drycc.example.com Content-Type: application/json Authorization: token abc123 {\"version\": 1} Example Response: HTTP/1.1 201 CREATED DRYCC_API_VERSION: 2.0 DRYCC_PLATFORM_VERSION: 2.1.0 Content-Type: application/json {\"version\": 5}","title":"Rollback Release"},{"location":"reference-guide/controller-api/v2.0/#keys","text":"","title":"Keys"},{"location":"reference-guide/controller-api/v2.0/#list-keys","text":"Example Request: GET /v2/keys/ HTTP/1.1 Host: drycc.example.com Authorization: token abc123 Example Response: HTTP/1.1 201 CREATED DRYCC_API_VERSION: 2.0 DRYCC_PLATFORM_VERSION: 2.1.0 Content-Type: application/json { \"count\": 1, \"next\": null, \"previous\": null, \"results\": [ { \"created\": \"2014-01-01T00:00:00UTC\", \"id\": \"test@example.com\", \"owner\": \"test\", \"public\": \"ssh-rsa <...>\", \"updated\": \"2014-01-01T00:00:00UTC\", \"uuid\": \"de1bf5b5-4a72-4f94-a10c-d2a3741cdf75\" } ] }","title":"List Keys"},{"location":"reference-guide/controller-api/v2.0/#add-key-to-user","text":"Example Request: POST /v2/keys/ HTTP/1.1 Host: drycc.example.com Authorization: token abc123 { \"id\": \"example\", \"public\": \"ssh-rsa <...>\" } Example Response: HTTP/1.1 201 CREATED DRYCC_API_VERSION: 2.0 DRYCC_PLATFORM_VERSION: 2.1.0 Content-Type: application/json { \"created\": \"2014-01-01T00:00:00UTC\", \"id\": \"example\", \"owner\": \"example\", \"public\": \"ssh-rsa <...>\", \"updated\": \"2014-01-01T00:00:00UTC\", \"uuid\": \"de1bf5b5-4a72-4f94-a10c-d2a3741cdf75\" }","title":"Add Key to User"},{"location":"reference-guide/controller-api/v2.0/#remove-key-from-user","text":"Example Request: DELETE /v2/keys/example HTTP/1.1 Host: drycc.example.com Authorization: token abc123 Example Response: HTTP/1.1 204 NO CONTENT DRYCC_API_VERSION: 2.0 DRYCC_PLATFORM_VERSION: 2.1.0","title":"Remove Key from User"},{"location":"reference-guide/controller-api/v2.0/#permissions","text":"","title":"Permissions"},{"location":"reference-guide/controller-api/v2.0/#list-application-permissions","text":"note This does not include the app owner. Example Request: GET /v2/apps/example-go/perms/ HTTP/1.1 Host: drycc.example.com Authorization: token abc123 Example Response: HTTP/1.1 200 OK DRYCC_API_VERSION: 2.0 DRYCC_PLATFORM_VERSION: 2.1.0 Content-Type: application/json { \"users\": [ \"test\", \"foo\" ] }","title":"List Application Permissions"},{"location":"reference-guide/controller-api/v2.0/#create-application-permission","text":"Example Request: POST /v2/apps/example-go/perms/ HTTP/1.1 Host: drycc.example.com Authorization: token abc123 {\"username\": \"example\"} Example Response: HTTP/1.1 201 CREATED DRYCC_API_VERSION: 2.0 DRYCC_PLATFORM_VERSION: 2.1.0","title":"Create Application Permission"},{"location":"reference-guide/controller-api/v2.0/#remove-application-permission","text":"Example Request: DELETE /v2/apps/example-go/perms/example HTTP/1.1 Host: drycc.example.com Authorization: token abc123 Example Response: HTTP/1.1 204 NO CONTENT DRYCC_API_VERSION: 2.0 DRYCC_PLATFORM_VERSION: 2.1.0","title":"Remove Application Permission"},{"location":"reference-guide/controller-api/v2.0/#list-administrators","text":"Example Request: GET /v2/admin/perms/ HTTP/1.1 Host: drycc.example.com Authorization: token abc123 Example Response: HTTP/1.1 200 OK DRYCC_API_VERSION: 2.0 DRYCC_PLATFORM_VERSION: 2.1.0 Content-Type: application/json { \"count\": 2, \"next\": null \"previous\": null, \"results\": [ { \"username\": \"test\", \"is_superuser\": true }, { \"username\": \"foo\", \"is_superuser\": true } ] }","title":"List Administrators"},{"location":"reference-guide/controller-api/v2.0/#grant-user-administrative-privileges","text":"note This command requires administrative privileges Example Request: POST /v2/admin/perms HTTP/1.1 Host: drycc.example.com Authorization: token abc123 {\"username\": \"example\"} Example Response: HTTP/1.1 201 CREATED DRYCC_API_VERSION: 2.0 DRYCC_PLATFORM_VERSION: 2.1.0","title":"Grant User Administrative Privileges"},{"location":"reference-guide/controller-api/v2.0/#remove-users-administrative-privileges","text":"note This command requires administrative privileges Example Request: DELETE /v2/admin/perms/example HTTP/1.1 Host: drycc.example.com Authorization: token abc123 Example Response: HTTP/1.1 204 NO CONTENT DRYCC_API_VERSION: 2.0 DRYCC_PLATFORM_VERSION: 2.1.0","title":"Remove User's Administrative Privileges"},{"location":"reference-guide/controller-api/v2.0/#users","text":"","title":"Users"},{"location":"reference-guide/controller-api/v2.0/#list-all-users","text":"note This command requires administrative privileges Example Request: GET /v2/users HTTP/1.1 Host: drycc.example.com Authorization: token abc123 Example Response: HTTP/1.1 200 OK DRYCC_API_VERSION: 2.0 DRYCC_PLATFORM_VERSION: 2.1.0 Content-Type: application/json { \"count\": 1, \"next\": null, \"previous\": null, \"results\": [ { \"id\": 1, \"last_login\": \"2014-10-19T22:01:00.601Z\", \"is_superuser\": true, \"username\": \"test\", \"first_name\": \"test\", \"last_name\": \"testerson\", \"email\": \"test@example.com\", \"is_staff\": true, \"is_active\": true, \"date_joined\": \"2014-10-19T22:01:00.601Z\", \"groups\": [], \"user_permissions\": [] } ] }","title":"List all users"},{"location":"reference-guide/controller-api/v2.1/","text":"Controller API v2.1 \u00b6 This is the v2.1 REST API for the Controller. What's New \u00b6 New! healthcheck field in configuration, deprecates the HEALTHCHECK_* environment variables. New! Unsetting a configuration variable that does not exist will return a 422. New! Creating an identical sequential release returns a 409 rather than create a no-op release. Authentication \u00b6 Register a New User \u00b6 Example Request: POST /v2/auth/register/ HTTP/1.1 Host: drycc.example.com Content-Type: application/json { \"username\": \"test\", \"password\": \"opensesame\", \"email\": \"test@example.com\" } Optional Parameters: { \"first_name\": \"test\", \"last_name\": \"testerson\" } Example Response: HTTP/1.1 201 CREATED DRYCC_API_VERSION: 2.1 DRYCC_PLATFORM_VERSION: 2.1.0 Content-Type: application/json { \"id\": 1, \"last_login\": \"2014-10-19T22:01:00.601Z\", \"is_superuser\": true, \"username\": \"test\", \"first_name\": \"test\", \"last_name\": \"testerson\", \"email\": \"test@example.com\", \"is_staff\": true, \"is_active\": true, \"date_joined\": \"2014-10-19T22:01:00.601Z\", \"groups\": [], \"user_permissions\": [] } Log in \u00b6 Example Request: POST /v2/auth/login/ HTTP/1.1 Host: drycc.example.com Content-Type: application/json {\"username\": \"test\", \"password\": \"opensesame\"} Example Response: HTTP/1.1 200 OK DRYCC_API_VERSION: 2.1 DRYCC_PLATFORM_VERSION: 2.1.0 Content-Type: application/json {\"token\": \"abc123\"} Cancel Account \u00b6 Example Request: DELETE /v2/auth/cancel/ HTTP/1.1 Host: drycc.example.com Authorization: token abc123 Example Response: HTTP/1.1 204 NO CONTENT DRYCC_API_VERSION: 2.1 DRYCC_PLATFORM_VERSION: 2.1.0 Regenerate Token \u00b6 note This command could require administrative privileges Example Request: POST /v2/auth/tokens/ HTTP/1.1 Host: drycc.example.com Authorization: token abc123 Optional Parameters: { \"username\" : \"test\" \"all\" : \"true\" } Example Response: HTTP/1.1 200 OK DRYCC_API_VERSION: 2.1 DRYCC_PLATFORM_VERSION: 2.1.0 Content-Type: application/json {\"token\": \"abc123\"} Change Password \u00b6 Example Request: POST /v2/auth/passwd/ HTTP/1.1 Host: drycc.example.com Authorization: token abc123 { \"password\": \"foo\", \"new_password\": \"bar\" } Optional parameters: {\"username\": \"testuser\"} note Using the username parameter requires administrative privileges and makes the password parameter optional. Example Response: HTTP/1.1 200 OK DRYCC_API_VERSION: 2.1 DRYCC_PLATFORM_VERSION: 2.1.0 Applications \u00b6 List all Applications \u00b6 Example Request: GET /v2/apps HTTP/1.1 Host: drycc.example.com Authorization: token abc123 Example Response: HTTP/1.1 200 OK DRYCC_API_VERSION: 2.1 DRYCC_PLATFORM_VERSION: 2.1.0 Content-Type: application/json { \"count\": 1, \"next\": null, \"previous\": null, \"results\": [ { \"created\": \"2014-01-01T00:00:00UTC\", \"id\": \"example-go\", \"owner\": \"test\", \"structure\": {}, \"updated\": \"2014-01-01T00:00:00UTC\", \"url\": \"example-go.example.com\", \"uuid\": \"de1bf5b5-4a72-4f94-a10c-d2a3741cdf75\" } ] } Create an Application \u00b6 Example Request: POST /v2/apps/ HTTP/1.1 Host: drycc.example.com Content-Type: application/json Authorization: token abc123 Optional parameters: {\"id\": \"example-go\"} Example Response: HTTP/1.1 201 CREATED DRYCC_API_VERSION: 2.1 DRYCC_PLATFORM_VERSION: 2.1.0 Content-Type: application/json { \"created\": \"2014-01-01T00:00:00UTC\", \"id\": \"example-go\", \"owner\": \"test\", \"structure\": {}, \"updated\": \"2014-01-01T00:00:00UTC\", \"url\": \"example-go.example.com\", \"uuid\": \"de1bf5b5-4a72-4f94-a10c-d2a3741cdf75\" } Destroy an Application \u00b6 Example Request: DELETE /v2/apps/example-go/ HTTP/1.1 Host: drycc.example.com Authorization: token abc123 Example Response: HTTP/1.1 204 NO CONTENT DRYCC_API_VERSION: 2.1 DRYCC_PLATFORM_VERSION: 2.1.0 List Application Details \u00b6 Example Request: GET /v2/apps/example-go/ HTTP/1.1 Host: drycc.example.com Authorization: token abc123 Example Response: HTTP/1.1 200 OK DRYCC_API_VERSION: 2.1 DRYCC_PLATFORM_VERSION: 2.1.0 Content-Type: application/json { \"created\": \"2014-01-01T00:00:00UTC\", \"id\": \"example-go\", \"owner\": \"test\", \"structure\": {}, \"updated\": \"2014-01-01T00:00:00UTC\", \"url\": \"example-go.example.com\", \"uuid\": \"de1bf5b5-4a72-4f94-a10c-d2a3741cdf75\" } Update Application Details \u00b6 Example Request: POST /v2/apps/example-go/ HTTP/1.1 Host: drycc.example.com Authorization: token abc123 Optional parameters: { \"owner\": \"test\" } Example Response: HTTP/1.1 200 OK DRYCC_API_VERSION: 2.1 DRYCC_PLATFORM_VERSION: 1.8.0 Content-Type: application/json Retrieve Application Logs \u00b6 Example Request: GET /v2/apps/example-go/logs/ HTTP/1.1 Host: drycc.example.com Authorization: token abc123 Optional URL Query Parameters: ?log_lines= Example Response: HTTP/1.1 200 OK DRYCC_API_VERSION: 2.1 DRYCC_PLATFORM_VERSION: 2.1.0 Content-Type: text/plain \"16:51:14 drycc[api]: test created initial release\\n\" Run one-off Commands \u00b6 POST /v2/apps/example-go/run/ HTTP/1.1 Host: drycc.example.com Content-Type: application/json Authorization: token abc123 {\"command\": \"echo hi\"} Example Response: HTTP/1.1 200 OK DRYCC_API_VERSION: 2.1 DRYCC_PLATFORM_VERSION: 2.1.0 Content-Type: application/json {\"exit_code\": 0, \"output\": \"hi\\n\"} Certificates \u00b6 List all Certificates \u00b6 Example Request: GET /v2/certs HTTP/1.1 Host: drycc.example.com Authorization: token abc123 Example Response: HTTP/1.1 200 OK DRYCC_API_VERSION: 2.1 DRYCC_PLATFORM_VERSION: 2.1.0 Content-Type: application/json { \"count\": 1, \"next\": null, \"previous\": null, \"results\": [ { \"id\": 22, \"owner\": \"test\", \"san\": [], \"domains\": [], \"created\": \"2016-06-22T22:24:20Z\", \"updated\": \"2016-06-22T22:24:20Z\", \"name\": \"foo\", \"common_name\": \"bar.com\", \"fingerprint\": \"7A:CA:B8:50:FF:8D:EB:03:3D:AC:AD:13:4F:EE:03:D5:5D:EB:5E:37:51:8C:E0:98:F8:1B:36:2B:20:83:0D:C0\", \"expires\": \"2017-01-14T23:57:57Z\", \"starts\": \"2016-01-15T23:57:57Z\", \"issuer\": \"/C=US/ST=CA/L=San Francisco/O=Drycc/OU=Engineering/CN=bar.com/emailAddress=engineering@drycc.cc\", \"subject\": \"/C=US/ST=CA/L=San Francisco/O=Drycc/OU=Engineering/CN=bar.com/emailAddress=engineering@drycc.cc\" } ] } Get Certificate Details \u00b6 Example Request: GET /v2/certs/foo HTTP/1.1 Host: drycc.example.com Authorization: token abc123 Example Response: HTTP/1.1 200 OK DRYCC_API_VERSION: 2.1 DRYCC_PLATFORM_VERSION: 2.1.0 Content-Type: application/json { \"id\": 22, \"owner\": \"test\", \"san\": [], \"domains\": [], \"created\": \"2016-06-22T22:24:20Z\", \"updated\": \"2016-06-22T22:24:20Z\", \"name\": \"foo\", \"common_name\": \"bar.com\", \"fingerprint\": \"7A:CA:B8:50:FF:8D:EB:03:3D:AC:AD:13:4F:EE:03:D5:5D:EB:5E:37:51:8C:E0:98:F8:1B:36:2B:20:83:0D:C0\", \"expires\": \"2017-01-14T23:57:57Z\", \"starts\": \"2016-01-15T23:57:57Z\", \"issuer\": \"/C=US/ST=CA/L=San Francisco/O=Drycc/OU=Engineering/CN=bar.com/emailAddress=engineering@drycc.cc\", \"subject\": \"/C=US/ST=CA/L=San Francisco/O=Drycc/OU=Engineering/CN=bar.com/emailAddress=engineering@drycc.cc\" } Create Certificate \u00b6 Example Request: POST /v2/certs/ HTTP/1.1 Host: drycc.example.com Content-Type: application/json Authorization: token abc123 { \"name\": \"foo\" \"certificate\": \"-----BEGIN CERTIFICATE-----\", \"key\": \"-----BEGIN RSA PRIVATE KEY-----\" } Example Response: HTTP/1.1 201 CREATED DRYCC_API_VERSION: 2.1 DRYCC_PLATFORM_VERSION: 2.1.0 Content-Type: application/json { \"id\": 22, \"owner\": \"test\", \"san\": [], \"domains\": [], \"created\": \"2016-06-22T22:24:20Z\", \"updated\": \"2016-06-22T22:24:20Z\", \"name\": \"foo\", \"common_name\": \"bar.com\", \"fingerprint\": \"7A:CA:B8:50:FF:8D:EB:03:3D:AC:AD:13:4F:EE:03:D5:5D:EB:5E:37:51:8C:E0:98:F8:1B:36:2B:20:83:0D:C0\", \"expires\": \"2017-01-14T23:57:57Z\", \"starts\": \"2016-01-15T23:57:57Z\", \"issuer\": \"/C=US/ST=CA/L=San Francisco/O=Drycc/OU=Engineering/CN=bar.com/emailAddress=engineering@drycc.cc\", \"subject\": \"/C=US/ST=CA/L=San Francisco/O=Drycc/OU=Engineering/CN=bar.com/emailAddress=engineering@drycc.cc\" } Destroy a Certificate \u00b6 Example Request: DELETE /v2/certs/foo HTTP/1.1 Host: drycc.example.com Authorization: token abc123 Example Response: HTTP/1.1 204 NO CONTENT DRYCC_API_VERSION: 2.1 DRYCC_PLATFORM_VERSION: 2.1.0 Attach a Domain to a Certificate \u00b6 Example Request: POST /v2/certs/foo/domain/ HTTP/1.1 Host: drycc.example.com Authorization: token abc123 { \"domain\": \"test.com\" } Example Response: HTTP/1.1 201 CREATED DRYCC_API_VERSION: 2.1 DRYCC_PLATFORM_VERSION: 2.1.0 Remove a Domain from a Certificate \u00b6 Example Request: DELETE /v2/certs/foo/domain/test.com/ HTTP/1.1 Host: drycc.example.com Authorization: token abc123 Example Response: HTTP/1.1 204 NO CONTENT DRYCC_API_VERSION: 2.1 DRYCC_PLATFORM_VERSION: 2.1.0 Pods \u00b6 List all Pods \u00b6 Example Request: GET /v2/apps/example-go/pods/ HTTP/1.1 Host: drycc.example.com Authorization: token abc123 Example Response: HTTP/1.1 200 OK DRYCC_API_VERSION: 2.1 DRYCC_PLATFORM_VERSION: 2.1.0 Content-Type: application/json { \"count\": 1, \"results\": [ { \"name\": \"go-v2-web-e7dej\", \"release\": \"v2\", \"started\": \"2014-01-01T00:00:00Z\", \"state\": \"up\", \"type\": \"web\" } ] } List all Pods by Type \u00b6 Example Request: GET /v2/apps/example-go/pods/web/ HTTP/1.1 Host: drycc.example.com Authorization: token abc123 Example Response: HTTP/1.1 200 OK DRYCC_API_VERSION: 2.1 DRYCC_PLATFORM_VERSION: 2.1.0 Content-Type: application/json { \"count\": 1, \"results\": [ { \"name\": \"go-v2-web-e7dej\", \"release\": \"v2\", \"started\": \"2014-01-01T00:00:00Z\", \"state\": \"up\", \"type\": \"web\" } ] } Restart All Pods \u00b6 Example Request: POST /v2/apps/example-go/pods/restart/ HTTP/1.1 Host: drycc.example.com Authorization: token abc123 Example Response: HTTP/1.1 200 OK DRYCC_API_VERSION: 2.1 DRYCC_PLATFORM_VERSION: 2.1.0 Content-Type: application/json [ { \"name\": \"go-v2-web-atots\", \"release\": \"v2\", \"started\": \"2016-04-11T21:07:54Z\", \"state\": \"up\", \"type\": \"web\" } ] Restart Pods by Type \u00b6 Example Request: POST /v2/apps/example-go/pods/web/restart/ HTTP/1.1 Host: drycc.example.com Authorization: token abc123 Example Response: HTTP/1.1 200 OK DRYCC_API_VERSION: 2.1 DRYCC_PLATFORM_VERSION: 2.1.0 Content-Type: application/json [ { \"name\": \"go-v2-web-atots\", \"release\": \"v2\", \"started\": \"2016-04-11T21:07:54Z\", \"state\": \"up\", \"type\": \"web\" } ] Restart Pods by Type and Name \u00b6 Example Request: POST /v2/apps/example-go/pods/go-v2-web-atots/restart/ HTTP/1.1 Host: drycc.example.com Authorization: token abc123 Example Response: HTTP/1.1 200 OK DRYCC_API_VERSION: 2.1 DRYCC_PLATFORM_VERSION: 2.1.0 Content-Type: application/json [ { \"name\": \"go-v2-web-atots\", \"release\": \"v2\", \"started\": \"2016-04-11T21:07:54Z\", \"state\": \"up\", \"type\": \"web\" } ] Scale Pods \u00b6 Example Request: POST /v2/apps/example-go/scale/ HTTP/1.1 Host: drycc.example.com Content-Type: application/json Authorization: token abc123 {\"web\": 3} Example Response: HTTP/1.1 204 NO CONTENT DRYCC_API_VERSION: 2.1 DRYCC_PLATFORM_VERSION: 2.1.0 Configuration \u00b6 List Application Configuration \u00b6 Example Request: GET /v2/apps/example-go/config/ HTTP/1.1 Host: drycc.example.com Authorization: token abc123 Example Response: HTTP/1.1 200 OK DRYCC_API_VERSION: 2.1 DRYCC_PLATFORM_VERSION: 2.1.0 Content-Type: application/json { \"owner\": \"test\", \"app\": \"example-go\", \"values\": { \"PLATFORM\": \"drycc\" }, \"memory\": {}, \"cpu\": {}, \"tags\": {}, \"healthcheck\": {}, \"created\": \"2014-01-01T00:00:00UTC\", \"updated\": \"2014-01-01T00:00:00UTC\", \"uuid\": \"de1bf5b5-4a72-4f94-a10c-d2a3741cdf75\" } Create new Config \u00b6 Example Request: POST /v2/apps/example-go/config/ HTTP/1.1 Host: drycc.example.com Content-Type: application/json Authorization: token abc123 {\"values\": {\"HELLO\": \"world\", \"PLATFORM\": \"drycc\"}} Example Response: HTTP/1.1 201 CREATED DRYCC_API_VERSION: 2.1 DRYCC_PLATFORM_VERSION: 2.1.0 Content-Type: application/json { \"owner\": \"test\", \"app\": \"example-go\", \"values\": { \"DRYCC_APP\": \"example-go\", \"DRYCC_RELEASE\": \"v3\", \"HELLO\": \"world\", \"PLATFORM\": \"drycc\" }, \"memory\": {}, \"cpu\": {}, \"tags\": {}, \"healthcheck\": {}, \"created\": \"2014-01-01T00:00:00UTC\", \"updated\": \"2014-01-01T00:00:00UTC\", \"uuid\": \"de1bf5b5-4a72-4f94-a10c-d2a3741cdf75\" } Unset Config Variable \u00b6 Example Request: POST /v2/apps/example-go/config/ HTTP/1.1 Host: drycc.example.com Content-Type: application/json Authorization: token abc123 {\"values\": {\"HELLO\": null}} Example Response: HTTP/1.1 201 CREATED DRYCC_API_VERSION: 2.1 DRYCC_PLATFORM_VERSION: 2.1.0 Content-Type: application/json { \"owner\": \"test\", \"app\": \"example-go\", \"values\": { \"DRYCC_APP\": \"example-go\", \"DRYCC_RELEASE\": \"v4\", \"PLATFORM\": \"drycc\" }, \"memory\": {}, \"cpu\": {}, \"tags\": {}, \"healthcheck\": {}, \"created\": \"2014-01-01T00:00:00UTC\", \"updated\": \"2014-01-01T00:00:00UTC\", \"uuid\": \"de1bf5b5-4a72-4f94-a10c-d2a3741cdf75\" } Domains \u00b6 List Application Domains \u00b6 Example Request: GET /v2/apps/example-go/domains/ HTTP/1.1 Host: drycc.example.com Authorization: token abc123 Example Response: HTTP/1.1 200 OK DRYCC_API_VERSION: 2.1 DRYCC_PLATFORM_VERSION: 2.1.0 Content-Type: application/json { \"count\": 1, \"next\": null, \"previous\": null, \"results\": [ { \"app\": \"example-go\", \"created\": \"2014-01-01T00:00:00UTC\", \"domain\": \"example.example.com\", \"owner\": \"test\", \"updated\": \"2014-01-01T00:00:00UTC\" } ] } Add Domain \u00b6 Example Request: POST /v2/apps/example-go/domains/ HTTP/1.1 Host: drycc.example.com Authorization: token abc123 {'domain': 'example.example.com'} Example Response: HTTP/1.1 201 CREATED DRYCC_API_VERSION: 2.1 DRYCC_PLATFORM_VERSION: 2.1.0 Content-Type: application/json { \"app\": \"example-go\", \"created\": \"2014-01-01T00:00:00UTC\", \"domain\": \"example.example.com\", \"owner\": \"test\", \"updated\": \"2014-01-01T00:00:00UTC\" } Remove Domain \u00b6 Example Request: DELETE /v2/apps/example-go/domains/example.example.com HTTP/1.1 Host: drycc.example.com Authorization: token abc123 Example Response: HTTP/1.1 204 NO CONTENT DRYCC_API_VERSION: 2.1 DRYCC_PLATFORM_VERSION: 2.1.0 Builds \u00b6 List Application Builds \u00b6 Example Request: GET /v2/apps/example-go/builds/ HTTP/1.1 Host: drycc.example.com Authorization: token abc123 Example Response: HTTP/1.1 200 OK DRYCC_API_VERSION: 2.1 DRYCC_PLATFORM_VERSION: 2.1.0 Content-Type: application/json { \"count\": 1, \"next\": null, \"previous\": null, \"results\": [ { \"app\": \"example-go\", \"created\": \"2014-01-01T00:00:00UTC\", \"dockerfile\": \"FROM drycc/slugrunner RUN mkdir -p /app WORKDIR /app ENTRYPOINT [\\\"/runner/init\\\"] ADD slug.tgz /app ENV GIT_SHA 060da68f654e75fac06dbedd1995d5f8ad9084db\", \"image\": \"example-go\", \"owner\": \"test\", \"procfile\": { \"web\": \"example-go\" }, \"sha\": \"060da68f\", \"updated\": \"2014-01-01T00:00:00UTC\", \"uuid\": \"de1bf5b5-4a72-4f94-a10c-d2a3741cdf75\" } ] } Create Application Build \u00b6 Example Request: POST /v2/apps/example-go/builds/ HTTP/1.1 Host: drycc.example.com Content-Type: application/json Authorization: token abc123 {\"image\": \"drycc/example-go:latest\"} Optional Parameters: { \"procfile\": { \"web\": \"./cmd\" } } Example Response: HTTP/1.1 201 CREATED DRYCC_API_VERSION: 2.1 DRYCC_PLATFORM_VERSION: 2.1.0 Content-Type: application/json { \"app\": \"example-go\", \"created\": \"2014-01-01T00:00:00UTC\", \"dockerfile\": \"\", \"image\": \"drycc/example-go:latest\", \"owner\": \"test\", \"procfile\": {}, \"sha\": \"\", \"updated\": \"2014-01-01T00:00:00UTC\", \"uuid\": \"de1bf5b5-4a72-4f94-a10c-d2a3741cdf75\" } Releases \u00b6 List Application Releases \u00b6 Example Request: GET /v2/apps/example-go/releases/ HTTP/1.1 Host: drycc.example.com Authorization: token abc123 Example Response: HTTP/1.1 200 OK DRYCC_API_VERSION: 2.1 DRYCC_PLATFORM_VERSION: 2.1.0 Content-Type: application/json { \"count\": 3, \"next\": null, \"previous\": null, \"results\": [ { \"app\": \"example-go\", \"build\": \"202d8e4b-600e-4425-a85c-ffc7ea607f61\", \"config\": \"ed637ceb-5d32-44bd-9406-d326a777a513\", \"created\": \"2014-01-01T00:00:00UTC\", \"owner\": \"test\", \"summary\": \"test changed nothing\", \"updated\": \"2014-01-01T00:00:00UTC\", \"uuid\": \"de1bf5b5-4a72-4f94-a10c-d2a3741cdf75\", \"version\": 3 }, { \"app\": \"example-go\", \"build\": \"202d8e4b-600e-4425-a85c-ffc7ea607f61\", \"config\": \"95bd6dea-1685-4f78-a03d-fd7270b058d1\", \"created\": \"2014-01-01T00:00:00UTC\", \"owner\": \"test\", \"summary\": \"test deployed 060da68\", \"updated\": \"2014-01-01T00:00:00UTC\", \"uuid\": \"de1bf5b5-4a72-4f94-a10c-d2a3741cdf75\", \"version\": 2 }, { \"app\": \"example-go\", \"build\": null, \"config\": \"95bd6dea-1685-4f78-a03d-fd7270b058d1\", \"created\": \"2014-01-01T00:00:00UTC\", \"owner\": \"test\", \"summary\": \"test created initial release\", \"updated\": \"2014-01-01T00:00:00UTC\", \"uuid\": \"de1bf5b5-4a72-4f94-a10c-d2a3741cdf75\", \"version\": 1 } ] } List Release Details \u00b6 Example Request: GET /v2/apps/example-go/releases/v2/ HTTP/1.1 Host: drycc.example.com Authorization: token abc123 Example Response: HTTP/1.1 200 OK DRYCC_API_VERSION: 2.1 DRYCC_PLATFORM_VERSION: 2.1.0 Content-Type: application/json { \"app\": \"example-go\", \"build\": null, \"config\": \"95bd6dea-1685-4f78-a03d-fd7270b058d1\", \"created\": \"2014-01-01T00:00:00UTC\", \"owner\": \"test\", \"summary\": \"test created initial release\", \"updated\": \"2014-01-01T00:00:00UTC\", \"uuid\": \"de1bf5b5-4a72-4f94-a10c-d2a3741cdf75\", \"version\": 1 } Rollback Release \u00b6 Example Request: POST /v2/apps/example-go/releases/rollback/ HTTP/1.1 Host: drycc.example.com Content-Type: application/json Authorization: token abc123 {\"version\": 1} Example Response: HTTP/1.1 201 CREATED DRYCC_API_VERSION: 2.1 DRYCC_PLATFORM_VERSION: 2.1.0 Content-Type: application/json {\"version\": 5} Keys \u00b6 List Keys \u00b6 Example Request: GET /v2/keys/ HTTP/1.1 Host: drycc.example.com Authorization: token abc123 Example Response: HTTP/1.1 201 CREATED DRYCC_API_VERSION: 2.1 DRYCC_PLATFORM_VERSION: 2.1.0 Content-Type: application/json { \"count\": 1, \"next\": null, \"previous\": null, \"results\": [ { \"created\": \"2014-01-01T00:00:00UTC\", \"id\": \"test@example.com\", \"owner\": \"test\", \"public\": \"ssh-rsa <...>\", \"updated\": \"2014-01-01T00:00:00UTC\", \"uuid\": \"de1bf5b5-4a72-4f94-a10c-d2a3741cdf75\" } ] } Add Key to User \u00b6 Example Request: POST /v2/keys/ HTTP/1.1 Host: drycc.example.com Authorization: token abc123 { \"id\": \"example\", \"public\": \"ssh-rsa <...>\" } Example Response: HTTP/1.1 201 CREATED DRYCC_API_VERSION: 2.1 DRYCC_PLATFORM_VERSION: 2.1.0 Content-Type: application/json { \"created\": \"2014-01-01T00:00:00UTC\", \"id\": \"example\", \"owner\": \"example\", \"public\": \"ssh-rsa <...>\", \"updated\": \"2014-01-01T00:00:00UTC\", \"uuid\": \"de1bf5b5-4a72-4f94-a10c-d2a3741cdf75\" } Remove Key from User \u00b6 Example Request: DELETE /v2/keys/example HTTP/1.1 Host: drycc.example.com Authorization: token abc123 Example Response: HTTP/1.1 204 NO CONTENT DRYCC_API_VERSION: 2.1 DRYCC_PLATFORM_VERSION: 2.1.0 Permissions \u00b6 List Application Permissions \u00b6 note This does not include the app owner. Example Request: GET /v2/apps/example-go/perms/ HTTP/1.1 Host: drycc.example.com Authorization: token abc123 Example Response: HTTP/1.1 200 OK DRYCC_API_VERSION: 2.1 DRYCC_PLATFORM_VERSION: 2.1.0 Content-Type: application/json { \"users\": [ \"test\", \"foo\" ] } Create Application Permission \u00b6 Example Request: POST /v2/apps/example-go/perms/ HTTP/1.1 Host: drycc.example.com Authorization: token abc123 {\"username\": \"example\"} Example Response: HTTP/1.1 201 CREATED DRYCC_API_VERSION: 2.1 DRYCC_PLATFORM_VERSION: 2.1.0 Remove Application Permission \u00b6 Example Request: DELETE /v2/apps/example-go/perms/example HTTP/1.1 Host: drycc.example.com Authorization: token abc123 Example Response: HTTP/1.1 204 NO CONTENT DRYCC_API_VERSION: 2.1 DRYCC_PLATFORM_VERSION: 2.1.0 List Administrators \u00b6 Example Request: GET /v2/admin/perms/ HTTP/1.1 Host: drycc.example.com Authorization: token abc123 Example Response: HTTP/1.1 200 OK DRYCC_API_VERSION: 2.1 DRYCC_PLATFORM_VERSION: 2.1.0 Content-Type: application/json { \"count\": 2, \"next\": null \"previous\": null, \"results\": [ { \"username\": \"test\", \"is_superuser\": true }, { \"username\": \"foo\", \"is_superuser\": true } ] } Grant User Administrative Privileges \u00b6 note This command requires administrative privileges Example Request: POST /v2/admin/perms HTTP/1.1 Host: drycc.example.com Authorization: token abc123 {\"username\": \"example\"} Example Response: HTTP/1.1 201 CREATED DRYCC_API_VERSION: 2.1 DRYCC_PLATFORM_VERSION: 2.1.0 Remove User's Administrative Privileges \u00b6 note This command requires administrative privileges Example Request: DELETE /v2/admin/perms/example HTTP/1.1 Host: drycc.example.com Authorization: token abc123 Example Response: HTTP/1.1 204 NO CONTENT DRYCC_API_VERSION: 2.1 DRYCC_PLATFORM_VERSION: 2.1.0 Users \u00b6 List all users \u00b6 note This command requires administrative privileges Example Request: GET /v2/users HTTP/1.1 Host: drycc.example.com Authorization: token abc123 Example Response: HTTP/1.1 200 OK DRYCC_API_VERSION: 2.1 DRYCC_PLATFORM_VERSION: 2.1.0 Content-Type: application/json { \"count\": 1, \"next\": null, \"previous\": null, \"results\": [ { \"id\": 1, \"last_login\": \"2014-10-19T22:01:00.601Z\", \"is_superuser\": true, \"username\": \"test\", \"first_name\": \"test\", \"last_name\": \"testerson\", \"email\": \"test@example.com\", \"is_staff\": true, \"is_active\": true, \"date_joined\": \"2014-10-19T22:01:00.601Z\", \"groups\": [], \"user_permissions\": [] } ] }","title":"Controller API v2.1"},{"location":"reference-guide/controller-api/v2.1/#controller-api-v21","text":"This is the v2.1 REST API for the Controller.","title":"Controller API v2.1"},{"location":"reference-guide/controller-api/v2.1/#whats-new","text":"New! healthcheck field in configuration, deprecates the HEALTHCHECK_* environment variables. New! Unsetting a configuration variable that does not exist will return a 422. New! Creating an identical sequential release returns a 409 rather than create a no-op release.","title":"What's New"},{"location":"reference-guide/controller-api/v2.1/#authentication","text":"","title":"Authentication"},{"location":"reference-guide/controller-api/v2.1/#register-a-new-user","text":"Example Request: POST /v2/auth/register/ HTTP/1.1 Host: drycc.example.com Content-Type: application/json { \"username\": \"test\", \"password\": \"opensesame\", \"email\": \"test@example.com\" } Optional Parameters: { \"first_name\": \"test\", \"last_name\": \"testerson\" } Example Response: HTTP/1.1 201 CREATED DRYCC_API_VERSION: 2.1 DRYCC_PLATFORM_VERSION: 2.1.0 Content-Type: application/json { \"id\": 1, \"last_login\": \"2014-10-19T22:01:00.601Z\", \"is_superuser\": true, \"username\": \"test\", \"first_name\": \"test\", \"last_name\": \"testerson\", \"email\": \"test@example.com\", \"is_staff\": true, \"is_active\": true, \"date_joined\": \"2014-10-19T22:01:00.601Z\", \"groups\": [], \"user_permissions\": [] }","title":"Register a New User"},{"location":"reference-guide/controller-api/v2.1/#log-in","text":"Example Request: POST /v2/auth/login/ HTTP/1.1 Host: drycc.example.com Content-Type: application/json {\"username\": \"test\", \"password\": \"opensesame\"} Example Response: HTTP/1.1 200 OK DRYCC_API_VERSION: 2.1 DRYCC_PLATFORM_VERSION: 2.1.0 Content-Type: application/json {\"token\": \"abc123\"}","title":"Log in"},{"location":"reference-guide/controller-api/v2.1/#cancel-account","text":"Example Request: DELETE /v2/auth/cancel/ HTTP/1.1 Host: drycc.example.com Authorization: token abc123 Example Response: HTTP/1.1 204 NO CONTENT DRYCC_API_VERSION: 2.1 DRYCC_PLATFORM_VERSION: 2.1.0","title":"Cancel Account"},{"location":"reference-guide/controller-api/v2.1/#regenerate-token","text":"note This command could require administrative privileges Example Request: POST /v2/auth/tokens/ HTTP/1.1 Host: drycc.example.com Authorization: token abc123 Optional Parameters: { \"username\" : \"test\" \"all\" : \"true\" } Example Response: HTTP/1.1 200 OK DRYCC_API_VERSION: 2.1 DRYCC_PLATFORM_VERSION: 2.1.0 Content-Type: application/json {\"token\": \"abc123\"}","title":"Regenerate Token"},{"location":"reference-guide/controller-api/v2.1/#change-password","text":"Example Request: POST /v2/auth/passwd/ HTTP/1.1 Host: drycc.example.com Authorization: token abc123 { \"password\": \"foo\", \"new_password\": \"bar\" } Optional parameters: {\"username\": \"testuser\"} note Using the username parameter requires administrative privileges and makes the password parameter optional. Example Response: HTTP/1.1 200 OK DRYCC_API_VERSION: 2.1 DRYCC_PLATFORM_VERSION: 2.1.0","title":"Change Password"},{"location":"reference-guide/controller-api/v2.1/#applications","text":"","title":"Applications"},{"location":"reference-guide/controller-api/v2.1/#list-all-applications","text":"Example Request: GET /v2/apps HTTP/1.1 Host: drycc.example.com Authorization: token abc123 Example Response: HTTP/1.1 200 OK DRYCC_API_VERSION: 2.1 DRYCC_PLATFORM_VERSION: 2.1.0 Content-Type: application/json { \"count\": 1, \"next\": null, \"previous\": null, \"results\": [ { \"created\": \"2014-01-01T00:00:00UTC\", \"id\": \"example-go\", \"owner\": \"test\", \"structure\": {}, \"updated\": \"2014-01-01T00:00:00UTC\", \"url\": \"example-go.example.com\", \"uuid\": \"de1bf5b5-4a72-4f94-a10c-d2a3741cdf75\" } ] }","title":"List all Applications"},{"location":"reference-guide/controller-api/v2.1/#create-an-application","text":"Example Request: POST /v2/apps/ HTTP/1.1 Host: drycc.example.com Content-Type: application/json Authorization: token abc123 Optional parameters: {\"id\": \"example-go\"} Example Response: HTTP/1.1 201 CREATED DRYCC_API_VERSION: 2.1 DRYCC_PLATFORM_VERSION: 2.1.0 Content-Type: application/json { \"created\": \"2014-01-01T00:00:00UTC\", \"id\": \"example-go\", \"owner\": \"test\", \"structure\": {}, \"updated\": \"2014-01-01T00:00:00UTC\", \"url\": \"example-go.example.com\", \"uuid\": \"de1bf5b5-4a72-4f94-a10c-d2a3741cdf75\" }","title":"Create an Application"},{"location":"reference-guide/controller-api/v2.1/#destroy-an-application","text":"Example Request: DELETE /v2/apps/example-go/ HTTP/1.1 Host: drycc.example.com Authorization: token abc123 Example Response: HTTP/1.1 204 NO CONTENT DRYCC_API_VERSION: 2.1 DRYCC_PLATFORM_VERSION: 2.1.0","title":"Destroy an Application"},{"location":"reference-guide/controller-api/v2.1/#list-application-details","text":"Example Request: GET /v2/apps/example-go/ HTTP/1.1 Host: drycc.example.com Authorization: token abc123 Example Response: HTTP/1.1 200 OK DRYCC_API_VERSION: 2.1 DRYCC_PLATFORM_VERSION: 2.1.0 Content-Type: application/json { \"created\": \"2014-01-01T00:00:00UTC\", \"id\": \"example-go\", \"owner\": \"test\", \"structure\": {}, \"updated\": \"2014-01-01T00:00:00UTC\", \"url\": \"example-go.example.com\", \"uuid\": \"de1bf5b5-4a72-4f94-a10c-d2a3741cdf75\" }","title":"List Application Details"},{"location":"reference-guide/controller-api/v2.1/#update-application-details","text":"Example Request: POST /v2/apps/example-go/ HTTP/1.1 Host: drycc.example.com Authorization: token abc123 Optional parameters: { \"owner\": \"test\" } Example Response: HTTP/1.1 200 OK DRYCC_API_VERSION: 2.1 DRYCC_PLATFORM_VERSION: 1.8.0 Content-Type: application/json","title":"Update Application Details"},{"location":"reference-guide/controller-api/v2.1/#retrieve-application-logs","text":"Example Request: GET /v2/apps/example-go/logs/ HTTP/1.1 Host: drycc.example.com Authorization: token abc123 Optional URL Query Parameters: ?log_lines= Example Response: HTTP/1.1 200 OK DRYCC_API_VERSION: 2.1 DRYCC_PLATFORM_VERSION: 2.1.0 Content-Type: text/plain \"16:51:14 drycc[api]: test created initial release\\n\"","title":"Retrieve Application Logs"},{"location":"reference-guide/controller-api/v2.1/#run-one-off-commands","text":"POST /v2/apps/example-go/run/ HTTP/1.1 Host: drycc.example.com Content-Type: application/json Authorization: token abc123 {\"command\": \"echo hi\"} Example Response: HTTP/1.1 200 OK DRYCC_API_VERSION: 2.1 DRYCC_PLATFORM_VERSION: 2.1.0 Content-Type: application/json {\"exit_code\": 0, \"output\": \"hi\\n\"}","title":"Run one-off Commands"},{"location":"reference-guide/controller-api/v2.1/#certificates","text":"","title":"Certificates"},{"location":"reference-guide/controller-api/v2.1/#list-all-certificates","text":"Example Request: GET /v2/certs HTTP/1.1 Host: drycc.example.com Authorization: token abc123 Example Response: HTTP/1.1 200 OK DRYCC_API_VERSION: 2.1 DRYCC_PLATFORM_VERSION: 2.1.0 Content-Type: application/json { \"count\": 1, \"next\": null, \"previous\": null, \"results\": [ { \"id\": 22, \"owner\": \"test\", \"san\": [], \"domains\": [], \"created\": \"2016-06-22T22:24:20Z\", \"updated\": \"2016-06-22T22:24:20Z\", \"name\": \"foo\", \"common_name\": \"bar.com\", \"fingerprint\": \"7A:CA:B8:50:FF:8D:EB:03:3D:AC:AD:13:4F:EE:03:D5:5D:EB:5E:37:51:8C:E0:98:F8:1B:36:2B:20:83:0D:C0\", \"expires\": \"2017-01-14T23:57:57Z\", \"starts\": \"2016-01-15T23:57:57Z\", \"issuer\": \"/C=US/ST=CA/L=San Francisco/O=Drycc/OU=Engineering/CN=bar.com/emailAddress=engineering@drycc.cc\", \"subject\": \"/C=US/ST=CA/L=San Francisco/O=Drycc/OU=Engineering/CN=bar.com/emailAddress=engineering@drycc.cc\" } ] }","title":"List all Certificates"},{"location":"reference-guide/controller-api/v2.1/#get-certificate-details","text":"Example Request: GET /v2/certs/foo HTTP/1.1 Host: drycc.example.com Authorization: token abc123 Example Response: HTTP/1.1 200 OK DRYCC_API_VERSION: 2.1 DRYCC_PLATFORM_VERSION: 2.1.0 Content-Type: application/json { \"id\": 22, \"owner\": \"test\", \"san\": [], \"domains\": [], \"created\": \"2016-06-22T22:24:20Z\", \"updated\": \"2016-06-22T22:24:20Z\", \"name\": \"foo\", \"common_name\": \"bar.com\", \"fingerprint\": \"7A:CA:B8:50:FF:8D:EB:03:3D:AC:AD:13:4F:EE:03:D5:5D:EB:5E:37:51:8C:E0:98:F8:1B:36:2B:20:83:0D:C0\", \"expires\": \"2017-01-14T23:57:57Z\", \"starts\": \"2016-01-15T23:57:57Z\", \"issuer\": \"/C=US/ST=CA/L=San Francisco/O=Drycc/OU=Engineering/CN=bar.com/emailAddress=engineering@drycc.cc\", \"subject\": \"/C=US/ST=CA/L=San Francisco/O=Drycc/OU=Engineering/CN=bar.com/emailAddress=engineering@drycc.cc\" }","title":"Get Certificate Details"},{"location":"reference-guide/controller-api/v2.1/#create-certificate","text":"Example Request: POST /v2/certs/ HTTP/1.1 Host: drycc.example.com Content-Type: application/json Authorization: token abc123 { \"name\": \"foo\" \"certificate\": \"-----BEGIN CERTIFICATE-----\", \"key\": \"-----BEGIN RSA PRIVATE KEY-----\" } Example Response: HTTP/1.1 201 CREATED DRYCC_API_VERSION: 2.1 DRYCC_PLATFORM_VERSION: 2.1.0 Content-Type: application/json { \"id\": 22, \"owner\": \"test\", \"san\": [], \"domains\": [], \"created\": \"2016-06-22T22:24:20Z\", \"updated\": \"2016-06-22T22:24:20Z\", \"name\": \"foo\", \"common_name\": \"bar.com\", \"fingerprint\": \"7A:CA:B8:50:FF:8D:EB:03:3D:AC:AD:13:4F:EE:03:D5:5D:EB:5E:37:51:8C:E0:98:F8:1B:36:2B:20:83:0D:C0\", \"expires\": \"2017-01-14T23:57:57Z\", \"starts\": \"2016-01-15T23:57:57Z\", \"issuer\": \"/C=US/ST=CA/L=San Francisco/O=Drycc/OU=Engineering/CN=bar.com/emailAddress=engineering@drycc.cc\", \"subject\": \"/C=US/ST=CA/L=San Francisco/O=Drycc/OU=Engineering/CN=bar.com/emailAddress=engineering@drycc.cc\" }","title":"Create Certificate"},{"location":"reference-guide/controller-api/v2.1/#destroy-a-certificate","text":"Example Request: DELETE /v2/certs/foo HTTP/1.1 Host: drycc.example.com Authorization: token abc123 Example Response: HTTP/1.1 204 NO CONTENT DRYCC_API_VERSION: 2.1 DRYCC_PLATFORM_VERSION: 2.1.0","title":"Destroy a Certificate"},{"location":"reference-guide/controller-api/v2.1/#attach-a-domain-to-a-certificate","text":"Example Request: POST /v2/certs/foo/domain/ HTTP/1.1 Host: drycc.example.com Authorization: token abc123 { \"domain\": \"test.com\" } Example Response: HTTP/1.1 201 CREATED DRYCC_API_VERSION: 2.1 DRYCC_PLATFORM_VERSION: 2.1.0","title":"Attach a Domain to a Certificate"},{"location":"reference-guide/controller-api/v2.1/#remove-a-domain-from-a-certificate","text":"Example Request: DELETE /v2/certs/foo/domain/test.com/ HTTP/1.1 Host: drycc.example.com Authorization: token abc123 Example Response: HTTP/1.1 204 NO CONTENT DRYCC_API_VERSION: 2.1 DRYCC_PLATFORM_VERSION: 2.1.0","title":"Remove a Domain from a Certificate"},{"location":"reference-guide/controller-api/v2.1/#pods","text":"","title":"Pods"},{"location":"reference-guide/controller-api/v2.1/#list-all-pods","text":"Example Request: GET /v2/apps/example-go/pods/ HTTP/1.1 Host: drycc.example.com Authorization: token abc123 Example Response: HTTP/1.1 200 OK DRYCC_API_VERSION: 2.1 DRYCC_PLATFORM_VERSION: 2.1.0 Content-Type: application/json { \"count\": 1, \"results\": [ { \"name\": \"go-v2-web-e7dej\", \"release\": \"v2\", \"started\": \"2014-01-01T00:00:00Z\", \"state\": \"up\", \"type\": \"web\" } ] }","title":"List all Pods"},{"location":"reference-guide/controller-api/v2.1/#list-all-pods-by-type","text":"Example Request: GET /v2/apps/example-go/pods/web/ HTTP/1.1 Host: drycc.example.com Authorization: token abc123 Example Response: HTTP/1.1 200 OK DRYCC_API_VERSION: 2.1 DRYCC_PLATFORM_VERSION: 2.1.0 Content-Type: application/json { \"count\": 1, \"results\": [ { \"name\": \"go-v2-web-e7dej\", \"release\": \"v2\", \"started\": \"2014-01-01T00:00:00Z\", \"state\": \"up\", \"type\": \"web\" } ] }","title":"List all Pods by Type"},{"location":"reference-guide/controller-api/v2.1/#restart-all-pods","text":"Example Request: POST /v2/apps/example-go/pods/restart/ HTTP/1.1 Host: drycc.example.com Authorization: token abc123 Example Response: HTTP/1.1 200 OK DRYCC_API_VERSION: 2.1 DRYCC_PLATFORM_VERSION: 2.1.0 Content-Type: application/json [ { \"name\": \"go-v2-web-atots\", \"release\": \"v2\", \"started\": \"2016-04-11T21:07:54Z\", \"state\": \"up\", \"type\": \"web\" } ]","title":"Restart All Pods"},{"location":"reference-guide/controller-api/v2.1/#restart-pods-by-type","text":"Example Request: POST /v2/apps/example-go/pods/web/restart/ HTTP/1.1 Host: drycc.example.com Authorization: token abc123 Example Response: HTTP/1.1 200 OK DRYCC_API_VERSION: 2.1 DRYCC_PLATFORM_VERSION: 2.1.0 Content-Type: application/json [ { \"name\": \"go-v2-web-atots\", \"release\": \"v2\", \"started\": \"2016-04-11T21:07:54Z\", \"state\": \"up\", \"type\": \"web\" } ]","title":"Restart Pods by Type"},{"location":"reference-guide/controller-api/v2.1/#restart-pods-by-type-and-name","text":"Example Request: POST /v2/apps/example-go/pods/go-v2-web-atots/restart/ HTTP/1.1 Host: drycc.example.com Authorization: token abc123 Example Response: HTTP/1.1 200 OK DRYCC_API_VERSION: 2.1 DRYCC_PLATFORM_VERSION: 2.1.0 Content-Type: application/json [ { \"name\": \"go-v2-web-atots\", \"release\": \"v2\", \"started\": \"2016-04-11T21:07:54Z\", \"state\": \"up\", \"type\": \"web\" } ]","title":"Restart Pods by Type and Name"},{"location":"reference-guide/controller-api/v2.1/#scale-pods","text":"Example Request: POST /v2/apps/example-go/scale/ HTTP/1.1 Host: drycc.example.com Content-Type: application/json Authorization: token abc123 {\"web\": 3} Example Response: HTTP/1.1 204 NO CONTENT DRYCC_API_VERSION: 2.1 DRYCC_PLATFORM_VERSION: 2.1.0","title":"Scale Pods"},{"location":"reference-guide/controller-api/v2.1/#configuration","text":"","title":"Configuration"},{"location":"reference-guide/controller-api/v2.1/#list-application-configuration","text":"Example Request: GET /v2/apps/example-go/config/ HTTP/1.1 Host: drycc.example.com Authorization: token abc123 Example Response: HTTP/1.1 200 OK DRYCC_API_VERSION: 2.1 DRYCC_PLATFORM_VERSION: 2.1.0 Content-Type: application/json { \"owner\": \"test\", \"app\": \"example-go\", \"values\": { \"PLATFORM\": \"drycc\" }, \"memory\": {}, \"cpu\": {}, \"tags\": {}, \"healthcheck\": {}, \"created\": \"2014-01-01T00:00:00UTC\", \"updated\": \"2014-01-01T00:00:00UTC\", \"uuid\": \"de1bf5b5-4a72-4f94-a10c-d2a3741cdf75\" }","title":"List Application Configuration"},{"location":"reference-guide/controller-api/v2.1/#create-new-config","text":"Example Request: POST /v2/apps/example-go/config/ HTTP/1.1 Host: drycc.example.com Content-Type: application/json Authorization: token abc123 {\"values\": {\"HELLO\": \"world\", \"PLATFORM\": \"drycc\"}} Example Response: HTTP/1.1 201 CREATED DRYCC_API_VERSION: 2.1 DRYCC_PLATFORM_VERSION: 2.1.0 Content-Type: application/json { \"owner\": \"test\", \"app\": \"example-go\", \"values\": { \"DRYCC_APP\": \"example-go\", \"DRYCC_RELEASE\": \"v3\", \"HELLO\": \"world\", \"PLATFORM\": \"drycc\" }, \"memory\": {}, \"cpu\": {}, \"tags\": {}, \"healthcheck\": {}, \"created\": \"2014-01-01T00:00:00UTC\", \"updated\": \"2014-01-01T00:00:00UTC\", \"uuid\": \"de1bf5b5-4a72-4f94-a10c-d2a3741cdf75\" }","title":"Create new Config"},{"location":"reference-guide/controller-api/v2.1/#unset-config-variable","text":"Example Request: POST /v2/apps/example-go/config/ HTTP/1.1 Host: drycc.example.com Content-Type: application/json Authorization: token abc123 {\"values\": {\"HELLO\": null}} Example Response: HTTP/1.1 201 CREATED DRYCC_API_VERSION: 2.1 DRYCC_PLATFORM_VERSION: 2.1.0 Content-Type: application/json { \"owner\": \"test\", \"app\": \"example-go\", \"values\": { \"DRYCC_APP\": \"example-go\", \"DRYCC_RELEASE\": \"v4\", \"PLATFORM\": \"drycc\" }, \"memory\": {}, \"cpu\": {}, \"tags\": {}, \"healthcheck\": {}, \"created\": \"2014-01-01T00:00:00UTC\", \"updated\": \"2014-01-01T00:00:00UTC\", \"uuid\": \"de1bf5b5-4a72-4f94-a10c-d2a3741cdf75\" }","title":"Unset Config Variable"},{"location":"reference-guide/controller-api/v2.1/#domains","text":"","title":"Domains"},{"location":"reference-guide/controller-api/v2.1/#list-application-domains","text":"Example Request: GET /v2/apps/example-go/domains/ HTTP/1.1 Host: drycc.example.com Authorization: token abc123 Example Response: HTTP/1.1 200 OK DRYCC_API_VERSION: 2.1 DRYCC_PLATFORM_VERSION: 2.1.0 Content-Type: application/json { \"count\": 1, \"next\": null, \"previous\": null, \"results\": [ { \"app\": \"example-go\", \"created\": \"2014-01-01T00:00:00UTC\", \"domain\": \"example.example.com\", \"owner\": \"test\", \"updated\": \"2014-01-01T00:00:00UTC\" } ] }","title":"List Application Domains"},{"location":"reference-guide/controller-api/v2.1/#add-domain","text":"Example Request: POST /v2/apps/example-go/domains/ HTTP/1.1 Host: drycc.example.com Authorization: token abc123 {'domain': 'example.example.com'} Example Response: HTTP/1.1 201 CREATED DRYCC_API_VERSION: 2.1 DRYCC_PLATFORM_VERSION: 2.1.0 Content-Type: application/json { \"app\": \"example-go\", \"created\": \"2014-01-01T00:00:00UTC\", \"domain\": \"example.example.com\", \"owner\": \"test\", \"updated\": \"2014-01-01T00:00:00UTC\" }","title":"Add Domain"},{"location":"reference-guide/controller-api/v2.1/#remove-domain","text":"Example Request: DELETE /v2/apps/example-go/domains/example.example.com HTTP/1.1 Host: drycc.example.com Authorization: token abc123 Example Response: HTTP/1.1 204 NO CONTENT DRYCC_API_VERSION: 2.1 DRYCC_PLATFORM_VERSION: 2.1.0","title":"Remove Domain"},{"location":"reference-guide/controller-api/v2.1/#builds","text":"","title":"Builds"},{"location":"reference-guide/controller-api/v2.1/#list-application-builds","text":"Example Request: GET /v2/apps/example-go/builds/ HTTP/1.1 Host: drycc.example.com Authorization: token abc123 Example Response: HTTP/1.1 200 OK DRYCC_API_VERSION: 2.1 DRYCC_PLATFORM_VERSION: 2.1.0 Content-Type: application/json { \"count\": 1, \"next\": null, \"previous\": null, \"results\": [ { \"app\": \"example-go\", \"created\": \"2014-01-01T00:00:00UTC\", \"dockerfile\": \"FROM drycc/slugrunner RUN mkdir -p /app WORKDIR /app ENTRYPOINT [\\\"/runner/init\\\"] ADD slug.tgz /app ENV GIT_SHA 060da68f654e75fac06dbedd1995d5f8ad9084db\", \"image\": \"example-go\", \"owner\": \"test\", \"procfile\": { \"web\": \"example-go\" }, \"sha\": \"060da68f\", \"updated\": \"2014-01-01T00:00:00UTC\", \"uuid\": \"de1bf5b5-4a72-4f94-a10c-d2a3741cdf75\" } ] }","title":"List Application Builds"},{"location":"reference-guide/controller-api/v2.1/#create-application-build","text":"Example Request: POST /v2/apps/example-go/builds/ HTTP/1.1 Host: drycc.example.com Content-Type: application/json Authorization: token abc123 {\"image\": \"drycc/example-go:latest\"} Optional Parameters: { \"procfile\": { \"web\": \"./cmd\" } } Example Response: HTTP/1.1 201 CREATED DRYCC_API_VERSION: 2.1 DRYCC_PLATFORM_VERSION: 2.1.0 Content-Type: application/json { \"app\": \"example-go\", \"created\": \"2014-01-01T00:00:00UTC\", \"dockerfile\": \"\", \"image\": \"drycc/example-go:latest\", \"owner\": \"test\", \"procfile\": {}, \"sha\": \"\", \"updated\": \"2014-01-01T00:00:00UTC\", \"uuid\": \"de1bf5b5-4a72-4f94-a10c-d2a3741cdf75\" }","title":"Create Application Build"},{"location":"reference-guide/controller-api/v2.1/#releases","text":"","title":"Releases"},{"location":"reference-guide/controller-api/v2.1/#list-application-releases","text":"Example Request: GET /v2/apps/example-go/releases/ HTTP/1.1 Host: drycc.example.com Authorization: token abc123 Example Response: HTTP/1.1 200 OK DRYCC_API_VERSION: 2.1 DRYCC_PLATFORM_VERSION: 2.1.0 Content-Type: application/json { \"count\": 3, \"next\": null, \"previous\": null, \"results\": [ { \"app\": \"example-go\", \"build\": \"202d8e4b-600e-4425-a85c-ffc7ea607f61\", \"config\": \"ed637ceb-5d32-44bd-9406-d326a777a513\", \"created\": \"2014-01-01T00:00:00UTC\", \"owner\": \"test\", \"summary\": \"test changed nothing\", \"updated\": \"2014-01-01T00:00:00UTC\", \"uuid\": \"de1bf5b5-4a72-4f94-a10c-d2a3741cdf75\", \"version\": 3 }, { \"app\": \"example-go\", \"build\": \"202d8e4b-600e-4425-a85c-ffc7ea607f61\", \"config\": \"95bd6dea-1685-4f78-a03d-fd7270b058d1\", \"created\": \"2014-01-01T00:00:00UTC\", \"owner\": \"test\", \"summary\": \"test deployed 060da68\", \"updated\": \"2014-01-01T00:00:00UTC\", \"uuid\": \"de1bf5b5-4a72-4f94-a10c-d2a3741cdf75\", \"version\": 2 }, { \"app\": \"example-go\", \"build\": null, \"config\": \"95bd6dea-1685-4f78-a03d-fd7270b058d1\", \"created\": \"2014-01-01T00:00:00UTC\", \"owner\": \"test\", \"summary\": \"test created initial release\", \"updated\": \"2014-01-01T00:00:00UTC\", \"uuid\": \"de1bf5b5-4a72-4f94-a10c-d2a3741cdf75\", \"version\": 1 } ] }","title":"List Application Releases"},{"location":"reference-guide/controller-api/v2.1/#list-release-details","text":"Example Request: GET /v2/apps/example-go/releases/v2/ HTTP/1.1 Host: drycc.example.com Authorization: token abc123 Example Response: HTTP/1.1 200 OK DRYCC_API_VERSION: 2.1 DRYCC_PLATFORM_VERSION: 2.1.0 Content-Type: application/json { \"app\": \"example-go\", \"build\": null, \"config\": \"95bd6dea-1685-4f78-a03d-fd7270b058d1\", \"created\": \"2014-01-01T00:00:00UTC\", \"owner\": \"test\", \"summary\": \"test created initial release\", \"updated\": \"2014-01-01T00:00:00UTC\", \"uuid\": \"de1bf5b5-4a72-4f94-a10c-d2a3741cdf75\", \"version\": 1 }","title":"List Release Details"},{"location":"reference-guide/controller-api/v2.1/#rollback-release","text":"Example Request: POST /v2/apps/example-go/releases/rollback/ HTTP/1.1 Host: drycc.example.com Content-Type: application/json Authorization: token abc123 {\"version\": 1} Example Response: HTTP/1.1 201 CREATED DRYCC_API_VERSION: 2.1 DRYCC_PLATFORM_VERSION: 2.1.0 Content-Type: application/json {\"version\": 5}","title":"Rollback Release"},{"location":"reference-guide/controller-api/v2.1/#keys","text":"","title":"Keys"},{"location":"reference-guide/controller-api/v2.1/#list-keys","text":"Example Request: GET /v2/keys/ HTTP/1.1 Host: drycc.example.com Authorization: token abc123 Example Response: HTTP/1.1 201 CREATED DRYCC_API_VERSION: 2.1 DRYCC_PLATFORM_VERSION: 2.1.0 Content-Type: application/json { \"count\": 1, \"next\": null, \"previous\": null, \"results\": [ { \"created\": \"2014-01-01T00:00:00UTC\", \"id\": \"test@example.com\", \"owner\": \"test\", \"public\": \"ssh-rsa <...>\", \"updated\": \"2014-01-01T00:00:00UTC\", \"uuid\": \"de1bf5b5-4a72-4f94-a10c-d2a3741cdf75\" } ] }","title":"List Keys"},{"location":"reference-guide/controller-api/v2.1/#add-key-to-user","text":"Example Request: POST /v2/keys/ HTTP/1.1 Host: drycc.example.com Authorization: token abc123 { \"id\": \"example\", \"public\": \"ssh-rsa <...>\" } Example Response: HTTP/1.1 201 CREATED DRYCC_API_VERSION: 2.1 DRYCC_PLATFORM_VERSION: 2.1.0 Content-Type: application/json { \"created\": \"2014-01-01T00:00:00UTC\", \"id\": \"example\", \"owner\": \"example\", \"public\": \"ssh-rsa <...>\", \"updated\": \"2014-01-01T00:00:00UTC\", \"uuid\": \"de1bf5b5-4a72-4f94-a10c-d2a3741cdf75\" }","title":"Add Key to User"},{"location":"reference-guide/controller-api/v2.1/#remove-key-from-user","text":"Example Request: DELETE /v2/keys/example HTTP/1.1 Host: drycc.example.com Authorization: token abc123 Example Response: HTTP/1.1 204 NO CONTENT DRYCC_API_VERSION: 2.1 DRYCC_PLATFORM_VERSION: 2.1.0","title":"Remove Key from User"},{"location":"reference-guide/controller-api/v2.1/#permissions","text":"","title":"Permissions"},{"location":"reference-guide/controller-api/v2.1/#list-application-permissions","text":"note This does not include the app owner. Example Request: GET /v2/apps/example-go/perms/ HTTP/1.1 Host: drycc.example.com Authorization: token abc123 Example Response: HTTP/1.1 200 OK DRYCC_API_VERSION: 2.1 DRYCC_PLATFORM_VERSION: 2.1.0 Content-Type: application/json { \"users\": [ \"test\", \"foo\" ] }","title":"List Application Permissions"},{"location":"reference-guide/controller-api/v2.1/#create-application-permission","text":"Example Request: POST /v2/apps/example-go/perms/ HTTP/1.1 Host: drycc.example.com Authorization: token abc123 {\"username\": \"example\"} Example Response: HTTP/1.1 201 CREATED DRYCC_API_VERSION: 2.1 DRYCC_PLATFORM_VERSION: 2.1.0","title":"Create Application Permission"},{"location":"reference-guide/controller-api/v2.1/#remove-application-permission","text":"Example Request: DELETE /v2/apps/example-go/perms/example HTTP/1.1 Host: drycc.example.com Authorization: token abc123 Example Response: HTTP/1.1 204 NO CONTENT DRYCC_API_VERSION: 2.1 DRYCC_PLATFORM_VERSION: 2.1.0","title":"Remove Application Permission"},{"location":"reference-guide/controller-api/v2.1/#list-administrators","text":"Example Request: GET /v2/admin/perms/ HTTP/1.1 Host: drycc.example.com Authorization: token abc123 Example Response: HTTP/1.1 200 OK DRYCC_API_VERSION: 2.1 DRYCC_PLATFORM_VERSION: 2.1.0 Content-Type: application/json { \"count\": 2, \"next\": null \"previous\": null, \"results\": [ { \"username\": \"test\", \"is_superuser\": true }, { \"username\": \"foo\", \"is_superuser\": true } ] }","title":"List Administrators"},{"location":"reference-guide/controller-api/v2.1/#grant-user-administrative-privileges","text":"note This command requires administrative privileges Example Request: POST /v2/admin/perms HTTP/1.1 Host: drycc.example.com Authorization: token abc123 {\"username\": \"example\"} Example Response: HTTP/1.1 201 CREATED DRYCC_API_VERSION: 2.1 DRYCC_PLATFORM_VERSION: 2.1.0","title":"Grant User Administrative Privileges"},{"location":"reference-guide/controller-api/v2.1/#remove-users-administrative-privileges","text":"note This command requires administrative privileges Example Request: DELETE /v2/admin/perms/example HTTP/1.1 Host: drycc.example.com Authorization: token abc123 Example Response: HTTP/1.1 204 NO CONTENT DRYCC_API_VERSION: 2.1 DRYCC_PLATFORM_VERSION: 2.1.0","title":"Remove User's Administrative Privileges"},{"location":"reference-guide/controller-api/v2.1/#users","text":"","title":"Users"},{"location":"reference-guide/controller-api/v2.1/#list-all-users","text":"note This command requires administrative privileges Example Request: GET /v2/users HTTP/1.1 Host: drycc.example.com Authorization: token abc123 Example Response: HTTP/1.1 200 OK DRYCC_API_VERSION: 2.1 DRYCC_PLATFORM_VERSION: 2.1.0 Content-Type: application/json { \"count\": 1, \"next\": null, \"previous\": null, \"results\": [ { \"id\": 1, \"last_login\": \"2014-10-19T22:01:00.601Z\", \"is_superuser\": true, \"username\": \"test\", \"first_name\": \"test\", \"last_name\": \"testerson\", \"email\": \"test@example.com\", \"is_staff\": true, \"is_active\": true, \"date_joined\": \"2014-10-19T22:01:00.601Z\", \"groups\": [], \"user_permissions\": [] } ] }","title":"List all users"},{"location":"reference-guide/controller-api/v2.2/","text":"Controller API v2.2 \u00b6 This is the v2.2 REST API for the Controller. What's New \u00b6 New! /v2/auth/whoami endpoint Authentication \u00b6 Register a New User \u00b6 Example Request: POST /v2/auth/register/ HTTP/1.1 Host: drycc.example.com Content-Type: application/json { \"username\": \"test\", \"password\": \"opensesame\", \"email\": \"test@example.com\" } Optional Parameters: { \"first_name\": \"test\", \"last_name\": \"testerson\" } Example Response: HTTP/1.1 201 CREATED DRYCC_API_VERSION: 2.2 DRYCC_PLATFORM_VERSION: 2.2.0 Content-Type: application/json { \"id\": 1, \"last_login\": \"2014-10-19T22:01:00.601Z\", \"is_superuser\": true, \"username\": \"test\", \"first_name\": \"test\", \"last_name\": \"testerson\", \"email\": \"test@example.com\", \"is_staff\": true, \"is_active\": true, \"date_joined\": \"2014-10-19T22:01:00.601Z\", \"groups\": [], \"user_permissions\": [] } Log in \u00b6 Example Request: POST /v2/auth/login/ HTTP/1.1 Host: drycc.example.com Content-Type: application/json {\"username\": \"test\", \"password\": \"opensesame\"} Example Response: HTTP/1.1 200 OK DRYCC_API_VERSION: 2.2 DRYCC_PLATFORM_VERSION: 2.2.0 Content-Type: application/json {\"token\": \"abc123\"} Cancel Account \u00b6 Example Request: DELETE /v2/auth/cancel/ HTTP/1.1 Host: drycc.example.com Authorization: token abc123 Example Response: HTTP/1.1 204 NO CONTENT DRYCC_API_VERSION: 2.2 DRYCC_PLATFORM_VERSION: 2.2.0 Who Am I \u00b6 Example Request: GET /v2/auth/whoami/ HTTP/1.1 Host: drycc.example.com Authorization: token abc123 Example Response: HTTP/1.1 200 OK DRYCC_API_VERSION: 2.2 DRYCC_PLATFORM_VERSION: 2.2.0 Content-Type: application/json { \"id\": 1, \"last_login\": \"2014-10-19T22:01:00.601Z\", \"is_superuser\": true, \"username\": \"test\", \"first_name\": \"test\", \"last_name\": \"testerson\", \"email\": \"test@example.com\", \"is_staff\": true, \"is_active\": true, \"date_joined\": \"2014-10-19T22:01:00.601Z\", \"groups\": [], \"user_permissions\": [] } Regenerate Token \u00b6 note This command could require administrative privileges Example Request: POST /v2/auth/tokens/ HTTP/1.1 Host: drycc.example.com Authorization: token abc123 Optional Parameters: { \"username\" : \"test\" \"all\" : \"true\" } Example Response: HTTP/1.1 200 OK DRYCC_API_VERSION: 2.2 DRYCC_PLATFORM_VERSION: 2.2.0 Content-Type: application/json {\"token\": \"abc123\"} Change Password \u00b6 Example Request: POST /v2/auth/passwd/ HTTP/1.1 Host: drycc.example.com Authorization: token abc123 { \"password\": \"foo\", \"new_password\": \"bar\" } Optional parameters: {\"username\": \"testuser\"} note Using the username parameter requires administrative privileges and makes the password parameter optional. Example Response: HTTP/1.1 200 OK DRYCC_API_VERSION: 2.2 DRYCC_PLATFORM_VERSION: 2.2.0 Applications \u00b6 List all Applications \u00b6 Example Request: GET /v2/apps HTTP/1.1 Host: drycc.example.com Authorization: token abc123 Example Response: HTTP/1.1 200 OK DRYCC_API_VERSION: 2.2 DRYCC_PLATFORM_VERSION: 2.2.0 Content-Type: application/json { \"count\": 1, \"next\": null, \"previous\": null, \"results\": [ { \"created\": \"2014-01-01T00:00:00UTC\", \"id\": \"example-go\", \"owner\": \"test\", \"structure\": {}, \"updated\": \"2014-01-01T00:00:00UTC\", \"url\": \"example-go.example.com\", \"uuid\": \"de1bf5b5-4a72-4f94-a10c-d2a3741cdf75\" } ] } Create an Application \u00b6 Example Request: POST /v2/apps/ HTTP/1.1 Host: drycc.example.com Content-Type: application/json Authorization: token abc123 Optional parameters: {\"id\": \"example-go\"} Example Response: HTTP/1.1 201 CREATED DRYCC_API_VERSION: 2.2 DRYCC_PLATFORM_VERSION: 2.2.0 Content-Type: application/json { \"created\": \"2014-01-01T00:00:00UTC\", \"id\": \"example-go\", \"owner\": \"test\", \"structure\": {}, \"updated\": \"2014-01-01T00:00:00UTC\", \"url\": \"example-go.example.com\", \"uuid\": \"de1bf5b5-4a72-4f94-a10c-d2a3741cdf75\" } Destroy an Application \u00b6 Example Request: DELETE /v2/apps/example-go/ HTTP/1.1 Host: drycc.example.com Authorization: token abc123 Example Response: HTTP/1.1 204 NO CONTENT DRYCC_API_VERSION: 2.2 DRYCC_PLATFORM_VERSION: 2.2.0 List Application Details \u00b6 Example Request: GET /v2/apps/example-go/ HTTP/1.1 Host: drycc.example.com Authorization: token abc123 Example Response: HTTP/1.1 200 OK DRYCC_API_VERSION: 2.2 DRYCC_PLATFORM_VERSION: 2.2.0 Content-Type: application/json { \"created\": \"2014-01-01T00:00:00UTC\", \"id\": \"example-go\", \"owner\": \"test\", \"structure\": {}, \"updated\": \"2014-01-01T00:00:00UTC\", \"url\": \"example-go.example.com\", \"uuid\": \"de1bf5b5-4a72-4f94-a10c-d2a3741cdf75\" } Update Application Details \u00b6 Example Request: POST /v2/apps/example-go/ HTTP/1.1 Host: drycc.example.com Authorization: token abc123 Optional parameters: { \"owner\": \"test\" } Example Response: HTTP/1.1 200 OK DRYCC_API_VERSION: 2.2 DRYCC_PLATFORM_VERSION: 1.8.0 Content-Type: application/json Retrieve Application Logs \u00b6 Example Request: GET /v2/apps/example-go/logs/ HTTP/1.1 Host: drycc.example.com Authorization: token abc123 Optional URL Query Parameters: ?log_lines= Example Response: HTTP/1.1 200 OK DRYCC_API_VERSION: 2.2 DRYCC_PLATFORM_VERSION: 2.2.0 Content-Type: text/plain \"16:51:14 drycc[api]: test created initial release\\n\" Run one-off Commands \u00b6 POST /v2/apps/example-go/run/ HTTP/1.1 Host: drycc.example.com Content-Type: application/json Authorization: token abc123 {\"command\": \"echo hi\"} Example Response: HTTP/1.1 200 OK DRYCC_API_VERSION: 2.2 DRYCC_PLATFORM_VERSION: 2.2.0 Content-Type: application/json {\"exit_code\": 0, \"output\": \"hi\\n\"} Certificates \u00b6 List all Certificates \u00b6 Example Request: GET /v2/certs HTTP/1.1 Host: drycc.example.com Authorization: token abc123 Example Response: HTTP/1.1 200 OK DRYCC_API_VERSION: 2.2 DRYCC_PLATFORM_VERSION: 2.2.0 Content-Type: application/json { \"count\": 1, \"next\": null, \"previous\": null, \"results\": [ { \"id\": 22, \"owner\": \"test\", \"san\": [], \"domains\": [], \"created\": \"2016-06-22T22:24:20Z\", \"updated\": \"2016-06-22T22:24:20Z\", \"name\": \"foo\", \"common_name\": \"bar.com\", \"fingerprint\": \"7A:CA:B8:50:FF:8D:EB:03:3D:AC:AD:13:4F:EE:03:D5:5D:EB:5E:37:51:8C:E0:98:F8:1B:36:2B:20:83:0D:C0\", \"expires\": \"2017-01-14T23:57:57Z\", \"starts\": \"2016-01-15T23:57:57Z\", \"issuer\": \"/C=US/ST=CA/L=San Francisco/O=Drycc/OU=Engineering/CN=bar.com/emailAddress=engineering@drycc.cc\", \"subject\": \"/C=US/ST=CA/L=San Francisco/O=Drycc/OU=Engineering/CN=bar.com/emailAddress=engineering@drycc.cc\" } ] } Get Certificate Details \u00b6 Example Request: GET /v2/certs/foo HTTP/1.1 Host: drycc.example.com Authorization: token abc123 Example Response: HTTP/1.1 200 OK DRYCC_API_VERSION: 2.2 DRYCC_PLATFORM_VERSION: 2.2.0 Content-Type: application/json { \"id\": 22, \"owner\": \"test\", \"san\": [], \"domains\": [], \"created\": \"2016-06-22T22:24:20Z\", \"updated\": \"2016-06-22T22:24:20Z\", \"name\": \"foo\", \"common_name\": \"bar.com\", \"fingerprint\": \"7A:CA:B8:50:FF:8D:EB:03:3D:AC:AD:13:4F:EE:03:D5:5D:EB:5E:37:51:8C:E0:98:F8:1B:36:2B:20:83:0D:C0\", \"expires\": \"2017-01-14T23:57:57Z\", \"starts\": \"2016-01-15T23:57:57Z\", \"issuer\": \"/C=US/ST=CA/L=San Francisco/O=Drycc/OU=Engineering/CN=bar.com/emailAddress=engineering@drycc.cc\", \"subject\": \"/C=US/ST=CA/L=San Francisco/O=Drycc/OU=Engineering/CN=bar.com/emailAddress=engineering@drycc.cc\" } Create Certificate \u00b6 Example Request: POST /v2/certs/ HTTP/1.1 Host: drycc.example.com Content-Type: application/json Authorization: token abc123 { \"name\": \"foo\" \"certificate\": \"-----BEGIN CERTIFICATE-----\", \"key\": \"-----BEGIN RSA PRIVATE KEY-----\" } Example Response: HTTP/1.1 201 CREATED DRYCC_API_VERSION: 2.2 DRYCC_PLATFORM_VERSION: 2.2.0 Content-Type: application/json { \"id\": 22, \"owner\": \"test\", \"san\": [], \"domains\": [], \"created\": \"2016-06-22T22:24:20Z\", \"updated\": \"2016-06-22T22:24:20Z\", \"name\": \"foo\", \"common_name\": \"bar.com\", \"fingerprint\": \"7A:CA:B8:50:FF:8D:EB:03:3D:AC:AD:13:4F:EE:03:D5:5D:EB:5E:37:51:8C:E0:98:F8:1B:36:2B:20:83:0D:C0\", \"expires\": \"2017-01-14T23:57:57Z\", \"starts\": \"2016-01-15T23:57:57Z\", \"issuer\": \"/C=US/ST=CA/L=San Francisco/O=Drycc/OU=Engineering/CN=bar.com/emailAddress=engineering@drycc.cc\", \"subject\": \"/C=US/ST=CA/L=San Francisco/O=Drycc/OU=Engineering/CN=bar.com/emailAddress=engineering@drycc.cc\" } Destroy a Certificate \u00b6 Example Request: DELETE /v2/certs/foo HTTP/1.1 Host: drycc.example.com Authorization: token abc123 Example Response: HTTP/1.1 204 NO CONTENT DRYCC_API_VERSION: 2.2 DRYCC_PLATFORM_VERSION: 2.2.0 Attach a Domain to a Certificate \u00b6 Example Request: POST /v2/certs/foo/domain/ HTTP/1.1 Host: drycc.example.com Authorization: token abc123 { \"domain\": \"test.com\" } Example Response: HTTP/1.1 201 CREATED DRYCC_API_VERSION: 2.2 DRYCC_PLATFORM_VERSION: 2.2.0 Remove a Domain from a Certificate \u00b6 Example Request: DELETE /v2/certs/foo/domain/test.com/ HTTP/1.1 Host: drycc.example.com Authorization: token abc123 Example Response: HTTP/1.1 204 NO CONTENT DRYCC_API_VERSION: 2.2 DRYCC_PLATFORM_VERSION: 2.2.0 Pods \u00b6 List all Pods \u00b6 Example Request: GET /v2/apps/example-go/pods/ HTTP/1.1 Host: drycc.example.com Authorization: token abc123 Example Response: HTTP/1.1 200 OK DRYCC_API_VERSION: 2.2 DRYCC_PLATFORM_VERSION: 2.2.0 Content-Type: application/json { \"count\": 1, \"results\": [ { \"name\": \"go-v2-web-e7dej\", \"release\": \"v2\", \"started\": \"2014-01-01T00:00:00Z\", \"state\": \"up\", \"type\": \"web\" } ] } List all Pods by Type \u00b6 Example Request: GET /v2/apps/example-go/pods/web/ HTTP/1.1 Host: drycc.example.com Authorization: token abc123 Example Response: HTTP/1.1 200 OK DRYCC_API_VERSION: 2.2 DRYCC_PLATFORM_VERSION: 2.2.0 Content-Type: application/json { \"count\": 1, \"results\": [ { \"name\": \"go-v2-web-e7dej\", \"release\": \"v2\", \"started\": \"2014-01-01T00:00:00Z\", \"state\": \"up\", \"type\": \"web\" } ] } Restart All Pods \u00b6 Example Request: POST /v2/apps/example-go/pods/restart/ HTTP/1.1 Host: drycc.example.com Authorization: token abc123 Example Response: HTTP/1.1 200 OK DRYCC_API_VERSION: 2.2 DRYCC_PLATFORM_VERSION: 2.2.0 Content-Type: application/json [ { \"name\": \"go-v2-web-atots\", \"release\": \"v2\", \"started\": \"2016-04-11T21:07:54Z\", \"state\": \"up\", \"type\": \"web\" } ] Restart Pods by Type \u00b6 Example Request: POST /v2/apps/example-go/pods/web/restart/ HTTP/1.1 Host: drycc.example.com Authorization: token abc123 Example Response: HTTP/1.1 200 OK DRYCC_API_VERSION: 2.2 DRYCC_PLATFORM_VERSION: 2.2.0 Content-Type: application/json [ { \"name\": \"go-v2-web-atots\", \"release\": \"v2\", \"started\": \"2016-04-11T21:07:54Z\", \"state\": \"up\", \"type\": \"web\" } ] Restart Pods by Type and Name \u00b6 Example Request: POST /v2/apps/example-go/pods/go-v2-web-atots/restart/ HTTP/1.1 Host: drycc.example.com Authorization: token abc123 Example Response: HTTP/1.1 200 OK DRYCC_API_VERSION: 2.2 DRYCC_PLATFORM_VERSION: 2.2.0 Content-Type: application/json [ { \"name\": \"go-v2-web-atots\", \"release\": \"v2\", \"started\": \"2016-04-11T21:07:54Z\", \"state\": \"up\", \"type\": \"web\" } ] Scale Pods \u00b6 Example Request: POST /v2/apps/example-go/scale/ HTTP/1.1 Host: drycc.example.com Content-Type: application/json Authorization: token abc123 {\"web\": 3} Example Response: HTTP/1.1 204 NO CONTENT DRYCC_API_VERSION: 2.2 DRYCC_PLATFORM_VERSION: 2.2.0 Configuration \u00b6 List Application Configuration \u00b6 Example Request: GET /v2/apps/example-go/config/ HTTP/1.1 Host: drycc.example.com Authorization: token abc123 Example Response: HTTP/1.1 200 OK DRYCC_API_VERSION: 2.2 DRYCC_PLATFORM_VERSION: 2.2.0 Content-Type: application/json { \"owner\": \"test\", \"app\": \"example-go\", \"values\": { \"PLATFORM\": \"drycc\" }, \"memory\": {}, \"cpu\": {}, \"tags\": {}, \"healthcheck\": {}, \"created\": \"2014-01-01T00:00:00UTC\", \"updated\": \"2014-01-01T00:00:00UTC\", \"uuid\": \"de1bf5b5-4a72-4f94-a10c-d2a3741cdf75\" } Create new Config \u00b6 Example Request: POST /v2/apps/example-go/config/ HTTP/1.1 Host: drycc.example.com Content-Type: application/json Authorization: token abc123 {\"values\": {\"HELLO\": \"world\", \"PLATFORM\": \"drycc\"}} Example Response: HTTP/1.1 201 CREATED DRYCC_API_VERSION: 2.2 DRYCC_PLATFORM_VERSION: 2.2.0 Content-Type: application/json { \"owner\": \"test\", \"app\": \"example-go\", \"values\": { \"DRYCC_APP\": \"example-go\", \"DRYCC_RELEASE\": \"v3\", \"HELLO\": \"world\", \"PLATFORM\": \"drycc\" }, \"memory\": {}, \"cpu\": {}, \"tags\": {}, \"healthcheck\": {}, \"created\": \"2014-01-01T00:00:00UTC\", \"updated\": \"2014-01-01T00:00:00UTC\", \"uuid\": \"de1bf5b5-4a72-4f94-a10c-d2a3741cdf75\" } Unset Config Variable \u00b6 Example Request: POST /v2/apps/example-go/config/ HTTP/1.1 Host: drycc.example.com Content-Type: application/json Authorization: token abc123 {\"values\": {\"HELLO\": null}} Example Response: HTTP/1.1 201 CREATED DRYCC_API_VERSION: 2.2 DRYCC_PLATFORM_VERSION: 2.2.0 Content-Type: application/json { \"owner\": \"test\", \"app\": \"example-go\", \"values\": { \"DRYCC_APP\": \"example-go\", \"DRYCC_RELEASE\": \"v4\", \"PLATFORM\": \"drycc\" }, \"memory\": {}, \"cpu\": {}, \"tags\": {}, \"healthcheck\": {}, \"created\": \"2014-01-01T00:00:00UTC\", \"updated\": \"2014-01-01T00:00:00UTC\", \"uuid\": \"de1bf5b5-4a72-4f94-a10c-d2a3741cdf75\" } Domains \u00b6 List Application Domains \u00b6 Example Request: GET /v2/apps/example-go/domains/ HTTP/1.1 Host: drycc.example.com Authorization: token abc123 Example Response: HTTP/1.1 200 OK DRYCC_API_VERSION: 2.2 DRYCC_PLATFORM_VERSION: 2.2.0 Content-Type: application/json { \"count\": 1, \"next\": null, \"previous\": null, \"results\": [ { \"app\": \"example-go\", \"created\": \"2014-01-01T00:00:00UTC\", \"domain\": \"example.example.com\", \"owner\": \"test\", \"updated\": \"2014-01-01T00:00:00UTC\" } ] } Add Domain \u00b6 Example Request: POST /v2/apps/example-go/domains/ HTTP/1.1 Host: drycc.example.com Authorization: token abc123 {'domain': 'example.example.com'} Example Response: HTTP/1.1 201 CREATED DRYCC_API_VERSION: 2.2 DRYCC_PLATFORM_VERSION: 2.2.0 Content-Type: application/json { \"app\": \"example-go\", \"created\": \"2014-01-01T00:00:00UTC\", \"domain\": \"example.example.com\", \"owner\": \"test\", \"updated\": \"2014-01-01T00:00:00UTC\" } Remove Domain \u00b6 Example Request: DELETE /v2/apps/example-go/domains/example.example.com HTTP/1.1 Host: drycc.example.com Authorization: token abc123 Example Response: HTTP/1.1 204 NO CONTENT DRYCC_API_VERSION: 2.2 DRYCC_PLATFORM_VERSION: 2.2.0 Builds \u00b6 List Application Builds \u00b6 Example Request: GET /v2/apps/example-go/builds/ HTTP/1.1 Host: drycc.example.com Authorization: token abc123 Example Response: HTTP/1.1 200 OK DRYCC_API_VERSION: 2.2 DRYCC_PLATFORM_VERSION: 2.2.0 Content-Type: application/json { \"count\": 1, \"next\": null, \"previous\": null, \"results\": [ { \"app\": \"example-go\", \"created\": \"2014-01-01T00:00:00UTC\", \"dockerfile\": \"FROM drycc/slugrunner RUN mkdir -p /app WORKDIR /app ENTRYPOINT [\\\"/runner/init\\\"] ADD slug.tgz /app ENV GIT_SHA 060da68f654e75fac06dbedd1995d5f8ad9084db\", \"image\": \"example-go\", \"owner\": \"test\", \"procfile\": { \"web\": \"example-go\" }, \"sha\": \"060da68f\", \"updated\": \"2014-01-01T00:00:00UTC\", \"uuid\": \"de1bf5b5-4a72-4f94-a10c-d2a3741cdf75\" } ] } Create Application Build \u00b6 Example Request: POST /v2/apps/example-go/builds/ HTTP/1.1 Host: drycc.example.com Content-Type: application/json Authorization: token abc123 {\"image\": \"drycc/example-go:latest\"} Optional Parameters: { \"procfile\": { \"web\": \"./cmd\" } } Example Response: HTTP/1.1 201 CREATED DRYCC_API_VERSION: 2.2 DRYCC_PLATFORM_VERSION: 2.2.0 Content-Type: application/json { \"app\": \"example-go\", \"created\": \"2014-01-01T00:00:00UTC\", \"dockerfile\": \"\", \"image\": \"drycc/example-go:latest\", \"owner\": \"test\", \"procfile\": {}, \"sha\": \"\", \"updated\": \"2014-01-01T00:00:00UTC\", \"uuid\": \"de1bf5b5-4a72-4f94-a10c-d2a3741cdf75\" } Releases \u00b6 List Application Releases \u00b6 Example Request: GET /v2/apps/example-go/releases/ HTTP/1.1 Host: drycc.example.com Authorization: token abc123 Example Response: HTTP/1.1 200 OK DRYCC_API_VERSION: 2.2 DRYCC_PLATFORM_VERSION: 2.2.0 Content-Type: application/json { \"count\": 3, \"next\": null, \"previous\": null, \"results\": [ { \"app\": \"example-go\", \"build\": \"202d8e4b-600e-4425-a85c-ffc7ea607f61\", \"config\": \"ed637ceb-5d32-44bd-9406-d326a777a513\", \"created\": \"2014-01-01T00:00:00UTC\", \"owner\": \"test\", \"summary\": \"test changed nothing\", \"updated\": \"2014-01-01T00:00:00UTC\", \"uuid\": \"de1bf5b5-4a72-4f94-a10c-d2a3741cdf75\", \"version\": 3 }, { \"app\": \"example-go\", \"build\": \"202d8e4b-600e-4425-a85c-ffc7ea607f61\", \"config\": \"95bd6dea-1685-4f78-a03d-fd7270b058d1\", \"created\": \"2014-01-01T00:00:00UTC\", \"owner\": \"test\", \"summary\": \"test deployed 060da68\", \"updated\": \"2014-01-01T00:00:00UTC\", \"uuid\": \"de1bf5b5-4a72-4f94-a10c-d2a3741cdf75\", \"version\": 2 }, { \"app\": \"example-go\", \"build\": null, \"config\": \"95bd6dea-1685-4f78-a03d-fd7270b058d1\", \"created\": \"2014-01-01T00:00:00UTC\", \"owner\": \"test\", \"summary\": \"test created initial release\", \"updated\": \"2014-01-01T00:00:00UTC\", \"uuid\": \"de1bf5b5-4a72-4f94-a10c-d2a3741cdf75\", \"version\": 1 } ] } List Release Details \u00b6 Example Request: GET /v2/apps/example-go/releases/v2/ HTTP/1.1 Host: drycc.example.com Authorization: token abc123 Example Response: HTTP/1.1 200 OK DRYCC_API_VERSION: 2.2 DRYCC_PLATFORM_VERSION: 2.2.0 Content-Type: application/json { \"app\": \"example-go\", \"build\": null, \"config\": \"95bd6dea-1685-4f78-a03d-fd7270b058d1\", \"created\": \"2014-01-01T00:00:00UTC\", \"owner\": \"test\", \"summary\": \"test created initial release\", \"updated\": \"2014-01-01T00:00:00UTC\", \"uuid\": \"de1bf5b5-4a72-4f94-a10c-d2a3741cdf75\", \"version\": 1 } Rollback Release \u00b6 Example Request: POST /v2/apps/example-go/releases/rollback/ HTTP/1.1 Host: drycc.example.com Content-Type: application/json Authorization: token abc123 {\"version\": 1} Example Response: HTTP/1.1 201 CREATED DRYCC_API_VERSION: 2.2 DRYCC_PLATFORM_VERSION: 2.2.0 Content-Type: application/json {\"version\": 5} Keys \u00b6 List Keys \u00b6 Example Request: GET /v2/keys/ HTTP/1.1 Host: drycc.example.com Authorization: token abc123 Example Response: HTTP/1.1 201 CREATED DRYCC_API_VERSION: 2.2 DRYCC_PLATFORM_VERSION: 2.2.0 Content-Type: application/json { \"count\": 1, \"next\": null, \"previous\": null, \"results\": [ { \"created\": \"2014-01-01T00:00:00UTC\", \"id\": \"test@example.com\", \"owner\": \"test\", \"public\": \"ssh-rsa <...>\", \"updated\": \"2014-01-01T00:00:00UTC\", \"uuid\": \"de1bf5b5-4a72-4f94-a10c-d2a3741cdf75\" } ] } Add Key to User \u00b6 Example Request: POST /v2/keys/ HTTP/1.1 Host: drycc.example.com Authorization: token abc123 { \"id\": \"example\", \"public\": \"ssh-rsa <...>\" } Example Response: HTTP/1.1 201 CREATED DRYCC_API_VERSION: 2.2 DRYCC_PLATFORM_VERSION: 2.2.0 Content-Type: application/json { \"created\": \"2014-01-01T00:00:00UTC\", \"id\": \"example\", \"owner\": \"example\", \"public\": \"ssh-rsa <...>\", \"updated\": \"2014-01-01T00:00:00UTC\", \"uuid\": \"de1bf5b5-4a72-4f94-a10c-d2a3741cdf75\" } Remove Key from User \u00b6 Example Request: DELETE /v2/keys/example HTTP/1.1 Host: drycc.example.com Authorization: token abc123 Example Response: HTTP/1.1 204 NO CONTENT DRYCC_API_VERSION: 2.2 DRYCC_PLATFORM_VERSION: 2.2.0 Permissions \u00b6 List Application Permissions \u00b6 note This does not include the app owner. Example Request: GET /v2/apps/example-go/perms/ HTTP/1.1 Host: drycc.example.com Authorization: token abc123 Example Response: HTTP/1.1 200 OK DRYCC_API_VERSION: 2.2 DRYCC_PLATFORM_VERSION: 2.2.0 Content-Type: application/json { \"users\": [ \"test\", \"foo\" ] } Create Application Permission \u00b6 Example Request: POST /v2/apps/example-go/perms/ HTTP/1.1 Host: drycc.example.com Authorization: token abc123 {\"username\": \"example\"} Example Response: HTTP/1.1 201 CREATED DRYCC_API_VERSION: 2.2 DRYCC_PLATFORM_VERSION: 2.2.0 Remove Application Permission \u00b6 Example Request: DELETE /v2/apps/example-go/perms/example HTTP/1.1 Host: drycc.example.com Authorization: token abc123 Example Response: HTTP/1.1 204 NO CONTENT DRYCC_API_VERSION: 2.2 DRYCC_PLATFORM_VERSION: 2.2.0 List Administrators \u00b6 Example Request: GET /v2/admin/perms/ HTTP/1.1 Host: drycc.example.com Authorization: token abc123 Example Response: HTTP/1.1 200 OK DRYCC_API_VERSION: 2.2 DRYCC_PLATFORM_VERSION: 2.2.0 Content-Type: application/json { \"count\": 2, \"next\": null \"previous\": null, \"results\": [ { \"username\": \"test\", \"is_superuser\": true }, { \"username\": \"foo\", \"is_superuser\": true } ] } Grant User Administrative Privileges \u00b6 note This command requires administrative privileges Example Request: POST /v2/admin/perms HTTP/1.1 Host: drycc.example.com Authorization: token abc123 {\"username\": \"example\"} Example Response: HTTP/1.1 201 CREATED DRYCC_API_VERSION: 2.2 DRYCC_PLATFORM_VERSION: 2.2.0 Remove User's Administrative Privileges \u00b6 note This command requires administrative privileges Example Request: DELETE /v2/admin/perms/example HTTP/1.1 Host: drycc.example.com Authorization: token abc123 Example Response: HTTP/1.1 204 NO CONTENT DRYCC_API_VERSION: 2.2 DRYCC_PLATFORM_VERSION: 2.2.0 Users \u00b6 List all users \u00b6 note This command requires administrative privileges Example Request: GET /v2/users HTTP/1.1 Host: drycc.example.com Authorization: token abc123 Example Response: HTTP/1.1 200 OK DRYCC_API_VERSION: 2.2 DRYCC_PLATFORM_VERSION: 2.2.0 Content-Type: application/json { \"count\": 1, \"next\": null, \"previous\": null, \"results\": [ { \"id\": 1, \"last_login\": \"2014-10-19T22:01:00.601Z\", \"is_superuser\": true, \"username\": \"test\", \"first_name\": \"test\", \"last_name\": \"testerson\", \"email\": \"test@example.com\", \"is_staff\": true, \"is_active\": true, \"date_joined\": \"2014-10-19T22:01:00.601Z\", \"groups\": [], \"user_permissions\": [] } ] }","title":"Controller API v2.2"},{"location":"reference-guide/controller-api/v2.2/#controller-api-v22","text":"This is the v2.2 REST API for the Controller.","title":"Controller API v2.2"},{"location":"reference-guide/controller-api/v2.2/#whats-new","text":"New! /v2/auth/whoami endpoint","title":"What's New"},{"location":"reference-guide/controller-api/v2.2/#authentication","text":"","title":"Authentication"},{"location":"reference-guide/controller-api/v2.2/#register-a-new-user","text":"Example Request: POST /v2/auth/register/ HTTP/1.1 Host: drycc.example.com Content-Type: application/json { \"username\": \"test\", \"password\": \"opensesame\", \"email\": \"test@example.com\" } Optional Parameters: { \"first_name\": \"test\", \"last_name\": \"testerson\" } Example Response: HTTP/1.1 201 CREATED DRYCC_API_VERSION: 2.2 DRYCC_PLATFORM_VERSION: 2.2.0 Content-Type: application/json { \"id\": 1, \"last_login\": \"2014-10-19T22:01:00.601Z\", \"is_superuser\": true, \"username\": \"test\", \"first_name\": \"test\", \"last_name\": \"testerson\", \"email\": \"test@example.com\", \"is_staff\": true, \"is_active\": true, \"date_joined\": \"2014-10-19T22:01:00.601Z\", \"groups\": [], \"user_permissions\": [] }","title":"Register a New User"},{"location":"reference-guide/controller-api/v2.2/#log-in","text":"Example Request: POST /v2/auth/login/ HTTP/1.1 Host: drycc.example.com Content-Type: application/json {\"username\": \"test\", \"password\": \"opensesame\"} Example Response: HTTP/1.1 200 OK DRYCC_API_VERSION: 2.2 DRYCC_PLATFORM_VERSION: 2.2.0 Content-Type: application/json {\"token\": \"abc123\"}","title":"Log in"},{"location":"reference-guide/controller-api/v2.2/#cancel-account","text":"Example Request: DELETE /v2/auth/cancel/ HTTP/1.1 Host: drycc.example.com Authorization: token abc123 Example Response: HTTP/1.1 204 NO CONTENT DRYCC_API_VERSION: 2.2 DRYCC_PLATFORM_VERSION: 2.2.0","title":"Cancel Account"},{"location":"reference-guide/controller-api/v2.2/#who-am-i","text":"Example Request: GET /v2/auth/whoami/ HTTP/1.1 Host: drycc.example.com Authorization: token abc123 Example Response: HTTP/1.1 200 OK DRYCC_API_VERSION: 2.2 DRYCC_PLATFORM_VERSION: 2.2.0 Content-Type: application/json { \"id\": 1, \"last_login\": \"2014-10-19T22:01:00.601Z\", \"is_superuser\": true, \"username\": \"test\", \"first_name\": \"test\", \"last_name\": \"testerson\", \"email\": \"test@example.com\", \"is_staff\": true, \"is_active\": true, \"date_joined\": \"2014-10-19T22:01:00.601Z\", \"groups\": [], \"user_permissions\": [] }","title":"Who Am I"},{"location":"reference-guide/controller-api/v2.2/#regenerate-token","text":"note This command could require administrative privileges Example Request: POST /v2/auth/tokens/ HTTP/1.1 Host: drycc.example.com Authorization: token abc123 Optional Parameters: { \"username\" : \"test\" \"all\" : \"true\" } Example Response: HTTP/1.1 200 OK DRYCC_API_VERSION: 2.2 DRYCC_PLATFORM_VERSION: 2.2.0 Content-Type: application/json {\"token\": \"abc123\"}","title":"Regenerate Token"},{"location":"reference-guide/controller-api/v2.2/#change-password","text":"Example Request: POST /v2/auth/passwd/ HTTP/1.1 Host: drycc.example.com Authorization: token abc123 { \"password\": \"foo\", \"new_password\": \"bar\" } Optional parameters: {\"username\": \"testuser\"} note Using the username parameter requires administrative privileges and makes the password parameter optional. Example Response: HTTP/1.1 200 OK DRYCC_API_VERSION: 2.2 DRYCC_PLATFORM_VERSION: 2.2.0","title":"Change Password"},{"location":"reference-guide/controller-api/v2.2/#applications","text":"","title":"Applications"},{"location":"reference-guide/controller-api/v2.2/#list-all-applications","text":"Example Request: GET /v2/apps HTTP/1.1 Host: drycc.example.com Authorization: token abc123 Example Response: HTTP/1.1 200 OK DRYCC_API_VERSION: 2.2 DRYCC_PLATFORM_VERSION: 2.2.0 Content-Type: application/json { \"count\": 1, \"next\": null, \"previous\": null, \"results\": [ { \"created\": \"2014-01-01T00:00:00UTC\", \"id\": \"example-go\", \"owner\": \"test\", \"structure\": {}, \"updated\": \"2014-01-01T00:00:00UTC\", \"url\": \"example-go.example.com\", \"uuid\": \"de1bf5b5-4a72-4f94-a10c-d2a3741cdf75\" } ] }","title":"List all Applications"},{"location":"reference-guide/controller-api/v2.2/#create-an-application","text":"Example Request: POST /v2/apps/ HTTP/1.1 Host: drycc.example.com Content-Type: application/json Authorization: token abc123 Optional parameters: {\"id\": \"example-go\"} Example Response: HTTP/1.1 201 CREATED DRYCC_API_VERSION: 2.2 DRYCC_PLATFORM_VERSION: 2.2.0 Content-Type: application/json { \"created\": \"2014-01-01T00:00:00UTC\", \"id\": \"example-go\", \"owner\": \"test\", \"structure\": {}, \"updated\": \"2014-01-01T00:00:00UTC\", \"url\": \"example-go.example.com\", \"uuid\": \"de1bf5b5-4a72-4f94-a10c-d2a3741cdf75\" }","title":"Create an Application"},{"location":"reference-guide/controller-api/v2.2/#destroy-an-application","text":"Example Request: DELETE /v2/apps/example-go/ HTTP/1.1 Host: drycc.example.com Authorization: token abc123 Example Response: HTTP/1.1 204 NO CONTENT DRYCC_API_VERSION: 2.2 DRYCC_PLATFORM_VERSION: 2.2.0","title":"Destroy an Application"},{"location":"reference-guide/controller-api/v2.2/#list-application-details","text":"Example Request: GET /v2/apps/example-go/ HTTP/1.1 Host: drycc.example.com Authorization: token abc123 Example Response: HTTP/1.1 200 OK DRYCC_API_VERSION: 2.2 DRYCC_PLATFORM_VERSION: 2.2.0 Content-Type: application/json { \"created\": \"2014-01-01T00:00:00UTC\", \"id\": \"example-go\", \"owner\": \"test\", \"structure\": {}, \"updated\": \"2014-01-01T00:00:00UTC\", \"url\": \"example-go.example.com\", \"uuid\": \"de1bf5b5-4a72-4f94-a10c-d2a3741cdf75\" }","title":"List Application Details"},{"location":"reference-guide/controller-api/v2.2/#update-application-details","text":"Example Request: POST /v2/apps/example-go/ HTTP/1.1 Host: drycc.example.com Authorization: token abc123 Optional parameters: { \"owner\": \"test\" } Example Response: HTTP/1.1 200 OK DRYCC_API_VERSION: 2.2 DRYCC_PLATFORM_VERSION: 1.8.0 Content-Type: application/json","title":"Update Application Details"},{"location":"reference-guide/controller-api/v2.2/#retrieve-application-logs","text":"Example Request: GET /v2/apps/example-go/logs/ HTTP/1.1 Host: drycc.example.com Authorization: token abc123 Optional URL Query Parameters: ?log_lines= Example Response: HTTP/1.1 200 OK DRYCC_API_VERSION: 2.2 DRYCC_PLATFORM_VERSION: 2.2.0 Content-Type: text/plain \"16:51:14 drycc[api]: test created initial release\\n\"","title":"Retrieve Application Logs"},{"location":"reference-guide/controller-api/v2.2/#run-one-off-commands","text":"POST /v2/apps/example-go/run/ HTTP/1.1 Host: drycc.example.com Content-Type: application/json Authorization: token abc123 {\"command\": \"echo hi\"} Example Response: HTTP/1.1 200 OK DRYCC_API_VERSION: 2.2 DRYCC_PLATFORM_VERSION: 2.2.0 Content-Type: application/json {\"exit_code\": 0, \"output\": \"hi\\n\"}","title":"Run one-off Commands"},{"location":"reference-guide/controller-api/v2.2/#certificates","text":"","title":"Certificates"},{"location":"reference-guide/controller-api/v2.2/#list-all-certificates","text":"Example Request: GET /v2/certs HTTP/1.1 Host: drycc.example.com Authorization: token abc123 Example Response: HTTP/1.1 200 OK DRYCC_API_VERSION: 2.2 DRYCC_PLATFORM_VERSION: 2.2.0 Content-Type: application/json { \"count\": 1, \"next\": null, \"previous\": null, \"results\": [ { \"id\": 22, \"owner\": \"test\", \"san\": [], \"domains\": [], \"created\": \"2016-06-22T22:24:20Z\", \"updated\": \"2016-06-22T22:24:20Z\", \"name\": \"foo\", \"common_name\": \"bar.com\", \"fingerprint\": \"7A:CA:B8:50:FF:8D:EB:03:3D:AC:AD:13:4F:EE:03:D5:5D:EB:5E:37:51:8C:E0:98:F8:1B:36:2B:20:83:0D:C0\", \"expires\": \"2017-01-14T23:57:57Z\", \"starts\": \"2016-01-15T23:57:57Z\", \"issuer\": \"/C=US/ST=CA/L=San Francisco/O=Drycc/OU=Engineering/CN=bar.com/emailAddress=engineering@drycc.cc\", \"subject\": \"/C=US/ST=CA/L=San Francisco/O=Drycc/OU=Engineering/CN=bar.com/emailAddress=engineering@drycc.cc\" } ] }","title":"List all Certificates"},{"location":"reference-guide/controller-api/v2.2/#get-certificate-details","text":"Example Request: GET /v2/certs/foo HTTP/1.1 Host: drycc.example.com Authorization: token abc123 Example Response: HTTP/1.1 200 OK DRYCC_API_VERSION: 2.2 DRYCC_PLATFORM_VERSION: 2.2.0 Content-Type: application/json { \"id\": 22, \"owner\": \"test\", \"san\": [], \"domains\": [], \"created\": \"2016-06-22T22:24:20Z\", \"updated\": \"2016-06-22T22:24:20Z\", \"name\": \"foo\", \"common_name\": \"bar.com\", \"fingerprint\": \"7A:CA:B8:50:FF:8D:EB:03:3D:AC:AD:13:4F:EE:03:D5:5D:EB:5E:37:51:8C:E0:98:F8:1B:36:2B:20:83:0D:C0\", \"expires\": \"2017-01-14T23:57:57Z\", \"starts\": \"2016-01-15T23:57:57Z\", \"issuer\": \"/C=US/ST=CA/L=San Francisco/O=Drycc/OU=Engineering/CN=bar.com/emailAddress=engineering@drycc.cc\", \"subject\": \"/C=US/ST=CA/L=San Francisco/O=Drycc/OU=Engineering/CN=bar.com/emailAddress=engineering@drycc.cc\" }","title":"Get Certificate Details"},{"location":"reference-guide/controller-api/v2.2/#create-certificate","text":"Example Request: POST /v2/certs/ HTTP/1.1 Host: drycc.example.com Content-Type: application/json Authorization: token abc123 { \"name\": \"foo\" \"certificate\": \"-----BEGIN CERTIFICATE-----\", \"key\": \"-----BEGIN RSA PRIVATE KEY-----\" } Example Response: HTTP/1.1 201 CREATED DRYCC_API_VERSION: 2.2 DRYCC_PLATFORM_VERSION: 2.2.0 Content-Type: application/json { \"id\": 22, \"owner\": \"test\", \"san\": [], \"domains\": [], \"created\": \"2016-06-22T22:24:20Z\", \"updated\": \"2016-06-22T22:24:20Z\", \"name\": \"foo\", \"common_name\": \"bar.com\", \"fingerprint\": \"7A:CA:B8:50:FF:8D:EB:03:3D:AC:AD:13:4F:EE:03:D5:5D:EB:5E:37:51:8C:E0:98:F8:1B:36:2B:20:83:0D:C0\", \"expires\": \"2017-01-14T23:57:57Z\", \"starts\": \"2016-01-15T23:57:57Z\", \"issuer\": \"/C=US/ST=CA/L=San Francisco/O=Drycc/OU=Engineering/CN=bar.com/emailAddress=engineering@drycc.cc\", \"subject\": \"/C=US/ST=CA/L=San Francisco/O=Drycc/OU=Engineering/CN=bar.com/emailAddress=engineering@drycc.cc\" }","title":"Create Certificate"},{"location":"reference-guide/controller-api/v2.2/#destroy-a-certificate","text":"Example Request: DELETE /v2/certs/foo HTTP/1.1 Host: drycc.example.com Authorization: token abc123 Example Response: HTTP/1.1 204 NO CONTENT DRYCC_API_VERSION: 2.2 DRYCC_PLATFORM_VERSION: 2.2.0","title":"Destroy a Certificate"},{"location":"reference-guide/controller-api/v2.2/#attach-a-domain-to-a-certificate","text":"Example Request: POST /v2/certs/foo/domain/ HTTP/1.1 Host: drycc.example.com Authorization: token abc123 { \"domain\": \"test.com\" } Example Response: HTTP/1.1 201 CREATED DRYCC_API_VERSION: 2.2 DRYCC_PLATFORM_VERSION: 2.2.0","title":"Attach a Domain to a Certificate"},{"location":"reference-guide/controller-api/v2.2/#remove-a-domain-from-a-certificate","text":"Example Request: DELETE /v2/certs/foo/domain/test.com/ HTTP/1.1 Host: drycc.example.com Authorization: token abc123 Example Response: HTTP/1.1 204 NO CONTENT DRYCC_API_VERSION: 2.2 DRYCC_PLATFORM_VERSION: 2.2.0","title":"Remove a Domain from a Certificate"},{"location":"reference-guide/controller-api/v2.2/#pods","text":"","title":"Pods"},{"location":"reference-guide/controller-api/v2.2/#list-all-pods","text":"Example Request: GET /v2/apps/example-go/pods/ HTTP/1.1 Host: drycc.example.com Authorization: token abc123 Example Response: HTTP/1.1 200 OK DRYCC_API_VERSION: 2.2 DRYCC_PLATFORM_VERSION: 2.2.0 Content-Type: application/json { \"count\": 1, \"results\": [ { \"name\": \"go-v2-web-e7dej\", \"release\": \"v2\", \"started\": \"2014-01-01T00:00:00Z\", \"state\": \"up\", \"type\": \"web\" } ] }","title":"List all Pods"},{"location":"reference-guide/controller-api/v2.2/#list-all-pods-by-type","text":"Example Request: GET /v2/apps/example-go/pods/web/ HTTP/1.1 Host: drycc.example.com Authorization: token abc123 Example Response: HTTP/1.1 200 OK DRYCC_API_VERSION: 2.2 DRYCC_PLATFORM_VERSION: 2.2.0 Content-Type: application/json { \"count\": 1, \"results\": [ { \"name\": \"go-v2-web-e7dej\", \"release\": \"v2\", \"started\": \"2014-01-01T00:00:00Z\", \"state\": \"up\", \"type\": \"web\" } ] }","title":"List all Pods by Type"},{"location":"reference-guide/controller-api/v2.2/#restart-all-pods","text":"Example Request: POST /v2/apps/example-go/pods/restart/ HTTP/1.1 Host: drycc.example.com Authorization: token abc123 Example Response: HTTP/1.1 200 OK DRYCC_API_VERSION: 2.2 DRYCC_PLATFORM_VERSION: 2.2.0 Content-Type: application/json [ { \"name\": \"go-v2-web-atots\", \"release\": \"v2\", \"started\": \"2016-04-11T21:07:54Z\", \"state\": \"up\", \"type\": \"web\" } ]","title":"Restart All Pods"},{"location":"reference-guide/controller-api/v2.2/#restart-pods-by-type","text":"Example Request: POST /v2/apps/example-go/pods/web/restart/ HTTP/1.1 Host: drycc.example.com Authorization: token abc123 Example Response: HTTP/1.1 200 OK DRYCC_API_VERSION: 2.2 DRYCC_PLATFORM_VERSION: 2.2.0 Content-Type: application/json [ { \"name\": \"go-v2-web-atots\", \"release\": \"v2\", \"started\": \"2016-04-11T21:07:54Z\", \"state\": \"up\", \"type\": \"web\" } ]","title":"Restart Pods by Type"},{"location":"reference-guide/controller-api/v2.2/#restart-pods-by-type-and-name","text":"Example Request: POST /v2/apps/example-go/pods/go-v2-web-atots/restart/ HTTP/1.1 Host: drycc.example.com Authorization: token abc123 Example Response: HTTP/1.1 200 OK DRYCC_API_VERSION: 2.2 DRYCC_PLATFORM_VERSION: 2.2.0 Content-Type: application/json [ { \"name\": \"go-v2-web-atots\", \"release\": \"v2\", \"started\": \"2016-04-11T21:07:54Z\", \"state\": \"up\", \"type\": \"web\" } ]","title":"Restart Pods by Type and Name"},{"location":"reference-guide/controller-api/v2.2/#scale-pods","text":"Example Request: POST /v2/apps/example-go/scale/ HTTP/1.1 Host: drycc.example.com Content-Type: application/json Authorization: token abc123 {\"web\": 3} Example Response: HTTP/1.1 204 NO CONTENT DRYCC_API_VERSION: 2.2 DRYCC_PLATFORM_VERSION: 2.2.0","title":"Scale Pods"},{"location":"reference-guide/controller-api/v2.2/#configuration","text":"","title":"Configuration"},{"location":"reference-guide/controller-api/v2.2/#list-application-configuration","text":"Example Request: GET /v2/apps/example-go/config/ HTTP/1.1 Host: drycc.example.com Authorization: token abc123 Example Response: HTTP/1.1 200 OK DRYCC_API_VERSION: 2.2 DRYCC_PLATFORM_VERSION: 2.2.0 Content-Type: application/json { \"owner\": \"test\", \"app\": \"example-go\", \"values\": { \"PLATFORM\": \"drycc\" }, \"memory\": {}, \"cpu\": {}, \"tags\": {}, \"healthcheck\": {}, \"created\": \"2014-01-01T00:00:00UTC\", \"updated\": \"2014-01-01T00:00:00UTC\", \"uuid\": \"de1bf5b5-4a72-4f94-a10c-d2a3741cdf75\" }","title":"List Application Configuration"},{"location":"reference-guide/controller-api/v2.2/#create-new-config","text":"Example Request: POST /v2/apps/example-go/config/ HTTP/1.1 Host: drycc.example.com Content-Type: application/json Authorization: token abc123 {\"values\": {\"HELLO\": \"world\", \"PLATFORM\": \"drycc\"}} Example Response: HTTP/1.1 201 CREATED DRYCC_API_VERSION: 2.2 DRYCC_PLATFORM_VERSION: 2.2.0 Content-Type: application/json { \"owner\": \"test\", \"app\": \"example-go\", \"values\": { \"DRYCC_APP\": \"example-go\", \"DRYCC_RELEASE\": \"v3\", \"HELLO\": \"world\", \"PLATFORM\": \"drycc\" }, \"memory\": {}, \"cpu\": {}, \"tags\": {}, \"healthcheck\": {}, \"created\": \"2014-01-01T00:00:00UTC\", \"updated\": \"2014-01-01T00:00:00UTC\", \"uuid\": \"de1bf5b5-4a72-4f94-a10c-d2a3741cdf75\" }","title":"Create new Config"},{"location":"reference-guide/controller-api/v2.2/#unset-config-variable","text":"Example Request: POST /v2/apps/example-go/config/ HTTP/1.1 Host: drycc.example.com Content-Type: application/json Authorization: token abc123 {\"values\": {\"HELLO\": null}} Example Response: HTTP/1.1 201 CREATED DRYCC_API_VERSION: 2.2 DRYCC_PLATFORM_VERSION: 2.2.0 Content-Type: application/json { \"owner\": \"test\", \"app\": \"example-go\", \"values\": { \"DRYCC_APP\": \"example-go\", \"DRYCC_RELEASE\": \"v4\", \"PLATFORM\": \"drycc\" }, \"memory\": {}, \"cpu\": {}, \"tags\": {}, \"healthcheck\": {}, \"created\": \"2014-01-01T00:00:00UTC\", \"updated\": \"2014-01-01T00:00:00UTC\", \"uuid\": \"de1bf5b5-4a72-4f94-a10c-d2a3741cdf75\" }","title":"Unset Config Variable"},{"location":"reference-guide/controller-api/v2.2/#domains","text":"","title":"Domains"},{"location":"reference-guide/controller-api/v2.2/#list-application-domains","text":"Example Request: GET /v2/apps/example-go/domains/ HTTP/1.1 Host: drycc.example.com Authorization: token abc123 Example Response: HTTP/1.1 200 OK DRYCC_API_VERSION: 2.2 DRYCC_PLATFORM_VERSION: 2.2.0 Content-Type: application/json { \"count\": 1, \"next\": null, \"previous\": null, \"results\": [ { \"app\": \"example-go\", \"created\": \"2014-01-01T00:00:00UTC\", \"domain\": \"example.example.com\", \"owner\": \"test\", \"updated\": \"2014-01-01T00:00:00UTC\" } ] }","title":"List Application Domains"},{"location":"reference-guide/controller-api/v2.2/#add-domain","text":"Example Request: POST /v2/apps/example-go/domains/ HTTP/1.1 Host: drycc.example.com Authorization: token abc123 {'domain': 'example.example.com'} Example Response: HTTP/1.1 201 CREATED DRYCC_API_VERSION: 2.2 DRYCC_PLATFORM_VERSION: 2.2.0 Content-Type: application/json { \"app\": \"example-go\", \"created\": \"2014-01-01T00:00:00UTC\", \"domain\": \"example.example.com\", \"owner\": \"test\", \"updated\": \"2014-01-01T00:00:00UTC\" }","title":"Add Domain"},{"location":"reference-guide/controller-api/v2.2/#remove-domain","text":"Example Request: DELETE /v2/apps/example-go/domains/example.example.com HTTP/1.1 Host: drycc.example.com Authorization: token abc123 Example Response: HTTP/1.1 204 NO CONTENT DRYCC_API_VERSION: 2.2 DRYCC_PLATFORM_VERSION: 2.2.0","title":"Remove Domain"},{"location":"reference-guide/controller-api/v2.2/#builds","text":"","title":"Builds"},{"location":"reference-guide/controller-api/v2.2/#list-application-builds","text":"Example Request: GET /v2/apps/example-go/builds/ HTTP/1.1 Host: drycc.example.com Authorization: token abc123 Example Response: HTTP/1.1 200 OK DRYCC_API_VERSION: 2.2 DRYCC_PLATFORM_VERSION: 2.2.0 Content-Type: application/json { \"count\": 1, \"next\": null, \"previous\": null, \"results\": [ { \"app\": \"example-go\", \"created\": \"2014-01-01T00:00:00UTC\", \"dockerfile\": \"FROM drycc/slugrunner RUN mkdir -p /app WORKDIR /app ENTRYPOINT [\\\"/runner/init\\\"] ADD slug.tgz /app ENV GIT_SHA 060da68f654e75fac06dbedd1995d5f8ad9084db\", \"image\": \"example-go\", \"owner\": \"test\", \"procfile\": { \"web\": \"example-go\" }, \"sha\": \"060da68f\", \"updated\": \"2014-01-01T00:00:00UTC\", \"uuid\": \"de1bf5b5-4a72-4f94-a10c-d2a3741cdf75\" } ] }","title":"List Application Builds"},{"location":"reference-guide/controller-api/v2.2/#create-application-build","text":"Example Request: POST /v2/apps/example-go/builds/ HTTP/1.1 Host: drycc.example.com Content-Type: application/json Authorization: token abc123 {\"image\": \"drycc/example-go:latest\"} Optional Parameters: { \"procfile\": { \"web\": \"./cmd\" } } Example Response: HTTP/1.1 201 CREATED DRYCC_API_VERSION: 2.2 DRYCC_PLATFORM_VERSION: 2.2.0 Content-Type: application/json { \"app\": \"example-go\", \"created\": \"2014-01-01T00:00:00UTC\", \"dockerfile\": \"\", \"image\": \"drycc/example-go:latest\", \"owner\": \"test\", \"procfile\": {}, \"sha\": \"\", \"updated\": \"2014-01-01T00:00:00UTC\", \"uuid\": \"de1bf5b5-4a72-4f94-a10c-d2a3741cdf75\" }","title":"Create Application Build"},{"location":"reference-guide/controller-api/v2.2/#releases","text":"","title":"Releases"},{"location":"reference-guide/controller-api/v2.2/#list-application-releases","text":"Example Request: GET /v2/apps/example-go/releases/ HTTP/1.1 Host: drycc.example.com Authorization: token abc123 Example Response: HTTP/1.1 200 OK DRYCC_API_VERSION: 2.2 DRYCC_PLATFORM_VERSION: 2.2.0 Content-Type: application/json { \"count\": 3, \"next\": null, \"previous\": null, \"results\": [ { \"app\": \"example-go\", \"build\": \"202d8e4b-600e-4425-a85c-ffc7ea607f61\", \"config\": \"ed637ceb-5d32-44bd-9406-d326a777a513\", \"created\": \"2014-01-01T00:00:00UTC\", \"owner\": \"test\", \"summary\": \"test changed nothing\", \"updated\": \"2014-01-01T00:00:00UTC\", \"uuid\": \"de1bf5b5-4a72-4f94-a10c-d2a3741cdf75\", \"version\": 3 }, { \"app\": \"example-go\", \"build\": \"202d8e4b-600e-4425-a85c-ffc7ea607f61\", \"config\": \"95bd6dea-1685-4f78-a03d-fd7270b058d1\", \"created\": \"2014-01-01T00:00:00UTC\", \"owner\": \"test\", \"summary\": \"test deployed 060da68\", \"updated\": \"2014-01-01T00:00:00UTC\", \"uuid\": \"de1bf5b5-4a72-4f94-a10c-d2a3741cdf75\", \"version\": 2 }, { \"app\": \"example-go\", \"build\": null, \"config\": \"95bd6dea-1685-4f78-a03d-fd7270b058d1\", \"created\": \"2014-01-01T00:00:00UTC\", \"owner\": \"test\", \"summary\": \"test created initial release\", \"updated\": \"2014-01-01T00:00:00UTC\", \"uuid\": \"de1bf5b5-4a72-4f94-a10c-d2a3741cdf75\", \"version\": 1 } ] }","title":"List Application Releases"},{"location":"reference-guide/controller-api/v2.2/#list-release-details","text":"Example Request: GET /v2/apps/example-go/releases/v2/ HTTP/1.1 Host: drycc.example.com Authorization: token abc123 Example Response: HTTP/1.1 200 OK DRYCC_API_VERSION: 2.2 DRYCC_PLATFORM_VERSION: 2.2.0 Content-Type: application/json { \"app\": \"example-go\", \"build\": null, \"config\": \"95bd6dea-1685-4f78-a03d-fd7270b058d1\", \"created\": \"2014-01-01T00:00:00UTC\", \"owner\": \"test\", \"summary\": \"test created initial release\", \"updated\": \"2014-01-01T00:00:00UTC\", \"uuid\": \"de1bf5b5-4a72-4f94-a10c-d2a3741cdf75\", \"version\": 1 }","title":"List Release Details"},{"location":"reference-guide/controller-api/v2.2/#rollback-release","text":"Example Request: POST /v2/apps/example-go/releases/rollback/ HTTP/1.1 Host: drycc.example.com Content-Type: application/json Authorization: token abc123 {\"version\": 1} Example Response: HTTP/1.1 201 CREATED DRYCC_API_VERSION: 2.2 DRYCC_PLATFORM_VERSION: 2.2.0 Content-Type: application/json {\"version\": 5}","title":"Rollback Release"},{"location":"reference-guide/controller-api/v2.2/#keys","text":"","title":"Keys"},{"location":"reference-guide/controller-api/v2.2/#list-keys","text":"Example Request: GET /v2/keys/ HTTP/1.1 Host: drycc.example.com Authorization: token abc123 Example Response: HTTP/1.1 201 CREATED DRYCC_API_VERSION: 2.2 DRYCC_PLATFORM_VERSION: 2.2.0 Content-Type: application/json { \"count\": 1, \"next\": null, \"previous\": null, \"results\": [ { \"created\": \"2014-01-01T00:00:00UTC\", \"id\": \"test@example.com\", \"owner\": \"test\", \"public\": \"ssh-rsa <...>\", \"updated\": \"2014-01-01T00:00:00UTC\", \"uuid\": \"de1bf5b5-4a72-4f94-a10c-d2a3741cdf75\" } ] }","title":"List Keys"},{"location":"reference-guide/controller-api/v2.2/#add-key-to-user","text":"Example Request: POST /v2/keys/ HTTP/1.1 Host: drycc.example.com Authorization: token abc123 { \"id\": \"example\", \"public\": \"ssh-rsa <...>\" } Example Response: HTTP/1.1 201 CREATED DRYCC_API_VERSION: 2.2 DRYCC_PLATFORM_VERSION: 2.2.0 Content-Type: application/json { \"created\": \"2014-01-01T00:00:00UTC\", \"id\": \"example\", \"owner\": \"example\", \"public\": \"ssh-rsa <...>\", \"updated\": \"2014-01-01T00:00:00UTC\", \"uuid\": \"de1bf5b5-4a72-4f94-a10c-d2a3741cdf75\" }","title":"Add Key to User"},{"location":"reference-guide/controller-api/v2.2/#remove-key-from-user","text":"Example Request: DELETE /v2/keys/example HTTP/1.1 Host: drycc.example.com Authorization: token abc123 Example Response: HTTP/1.1 204 NO CONTENT DRYCC_API_VERSION: 2.2 DRYCC_PLATFORM_VERSION: 2.2.0","title":"Remove Key from User"},{"location":"reference-guide/controller-api/v2.2/#permissions","text":"","title":"Permissions"},{"location":"reference-guide/controller-api/v2.2/#list-application-permissions","text":"note This does not include the app owner. Example Request: GET /v2/apps/example-go/perms/ HTTP/1.1 Host: drycc.example.com Authorization: token abc123 Example Response: HTTP/1.1 200 OK DRYCC_API_VERSION: 2.2 DRYCC_PLATFORM_VERSION: 2.2.0 Content-Type: application/json { \"users\": [ \"test\", \"foo\" ] }","title":"List Application Permissions"},{"location":"reference-guide/controller-api/v2.2/#create-application-permission","text":"Example Request: POST /v2/apps/example-go/perms/ HTTP/1.1 Host: drycc.example.com Authorization: token abc123 {\"username\": \"example\"} Example Response: HTTP/1.1 201 CREATED DRYCC_API_VERSION: 2.2 DRYCC_PLATFORM_VERSION: 2.2.0","title":"Create Application Permission"},{"location":"reference-guide/controller-api/v2.2/#remove-application-permission","text":"Example Request: DELETE /v2/apps/example-go/perms/example HTTP/1.1 Host: drycc.example.com Authorization: token abc123 Example Response: HTTP/1.1 204 NO CONTENT DRYCC_API_VERSION: 2.2 DRYCC_PLATFORM_VERSION: 2.2.0","title":"Remove Application Permission"},{"location":"reference-guide/controller-api/v2.2/#list-administrators","text":"Example Request: GET /v2/admin/perms/ HTTP/1.1 Host: drycc.example.com Authorization: token abc123 Example Response: HTTP/1.1 200 OK DRYCC_API_VERSION: 2.2 DRYCC_PLATFORM_VERSION: 2.2.0 Content-Type: application/json { \"count\": 2, \"next\": null \"previous\": null, \"results\": [ { \"username\": \"test\", \"is_superuser\": true }, { \"username\": \"foo\", \"is_superuser\": true } ] }","title":"List Administrators"},{"location":"reference-guide/controller-api/v2.2/#grant-user-administrative-privileges","text":"note This command requires administrative privileges Example Request: POST /v2/admin/perms HTTP/1.1 Host: drycc.example.com Authorization: token abc123 {\"username\": \"example\"} Example Response: HTTP/1.1 201 CREATED DRYCC_API_VERSION: 2.2 DRYCC_PLATFORM_VERSION: 2.2.0","title":"Grant User Administrative Privileges"},{"location":"reference-guide/controller-api/v2.2/#remove-users-administrative-privileges","text":"note This command requires administrative privileges Example Request: DELETE /v2/admin/perms/example HTTP/1.1 Host: drycc.example.com Authorization: token abc123 Example Response: HTTP/1.1 204 NO CONTENT DRYCC_API_VERSION: 2.2 DRYCC_PLATFORM_VERSION: 2.2.0","title":"Remove User's Administrative Privileges"},{"location":"reference-guide/controller-api/v2.2/#users","text":"","title":"Users"},{"location":"reference-guide/controller-api/v2.2/#list-all-users","text":"note This command requires administrative privileges Example Request: GET /v2/users HTTP/1.1 Host: drycc.example.com Authorization: token abc123 Example Response: HTTP/1.1 200 OK DRYCC_API_VERSION: 2.2 DRYCC_PLATFORM_VERSION: 2.2.0 Content-Type: application/json { \"count\": 1, \"next\": null, \"previous\": null, \"results\": [ { \"id\": 1, \"last_login\": \"2014-10-19T22:01:00.601Z\", \"is_superuser\": true, \"username\": \"test\", \"first_name\": \"test\", \"last_name\": \"testerson\", \"email\": \"test@example.com\", \"is_staff\": true, \"is_active\": true, \"date_joined\": \"2014-10-19T22:01:00.601Z\", \"groups\": [], \"user_permissions\": [] } ] }","title":"List all users"},{"location":"reference-guide/controller-api/v2.3/","text":"Controller API v2.3 \u00b6 This is the v2.3 REST API for the Controller. What's New \u00b6 New! /v2/apps/{name}/logs endpoint was fixed and no longer returns b'log data' and instead returns a normal string log data Authentication \u00b6 Register a New User \u00b6 Example Request: POST /v2/auth/register/ HTTP/1.1 Host: drycc.example.com Content-Type: application/json { \"username\": \"test\", \"password\": \"opensesame\", \"email\": \"test@example.com\" } Optional Parameters: { \"first_name\": \"test\", \"last_name\": \"testerson\" } Example Response: HTTP/1.1 201 CREATED DRYCC_API_VERSION: 2.3 DRYCC_PLATFORM_VERSION: 2.3.0 Content-Type: application/json { \"id\": 1, \"last_login\": \"2014-10-19T22:01:00.601Z\", \"is_superuser\": true, \"username\": \"test\", \"first_name\": \"test\", \"last_name\": \"testerson\", \"email\": \"test@example.com\", \"is_staff\": true, \"is_active\": true, \"date_joined\": \"2014-10-19T22:01:00.601Z\", \"groups\": [], \"user_permissions\": [] } Log in \u00b6 Example Request: POST /v2/auth/login/ HTTP/1.1 Host: drycc.example.com Content-Type: application/json {\"username\": \"test\", \"password\": \"opensesame\"} Example Response: HTTP/1.1 200 OK DRYCC_API_VERSION: 2.3 DRYCC_PLATFORM_VERSION: 2.3.0 Content-Type: application/json {\"token\": \"abc123\"} Cancel Account \u00b6 Example Request: DELETE /v2/auth/cancel/ HTTP/1.1 Host: drycc.example.com Authorization: token abc123 Example Response: HTTP/1.1 204 NO CONTENT DRYCC_API_VERSION: 2.3 DRYCC_PLATFORM_VERSION: 2.3.0 Who Am I \u00b6 Example Request: GET /v2/auth/whoami/ HTTP/1.1 Host: drycc.example.com Authorization: token abc123 Example Response: HTTP/1.1 200 OK DRYCC_API_VERSION: 2.3 DRYCC_PLATFORM_VERSION: 2.3.0 Content-Type: application/json { \"id\": 1, \"last_login\": \"2014-10-19T22:01:00.601Z\", \"is_superuser\": true, \"username\": \"test\", \"first_name\": \"test\", \"last_name\": \"testerson\", \"email\": \"test@example.com\", \"is_staff\": true, \"is_active\": true, \"date_joined\": \"2014-10-19T22:01:00.601Z\", \"groups\": [], \"user_permissions\": [] } Regenerate Token \u00b6 note This command could require administrative privileges Example Request: POST /v2/auth/tokens/ HTTP/1.1 Host: drycc.example.com Authorization: token abc123 Optional Parameters: { \"username\" : \"test\" \"all\" : \"true\" } Example Response: HTTP/1.1 200 OK DRYCC_API_VERSION: 2.3 DRYCC_PLATFORM_VERSION: 2.3.0 Content-Type: application/json {\"token\": \"abc123\"} Change Password \u00b6 Example Request: POST /v2/auth/passwd/ HTTP/1.1 Host: drycc.example.com Authorization: token abc123 { \"password\": \"foo\", \"new_password\": \"bar\" } Optional parameters: {\"username\": \"testuser\"} note Using the username parameter requires administrative privileges and makes the password parameter optional. Example Response: HTTP/1.1 200 OK DRYCC_API_VERSION: 2.3 DRYCC_PLATFORM_VERSION: 2.3.0 Applications \u00b6 List all Applications \u00b6 Example Request: GET /v2/apps HTTP/1.1 Host: drycc.example.com Authorization: token abc123 Example Response: HTTP/1.1 200 OK DRYCC_API_VERSION: 2.3 DRYCC_PLATFORM_VERSION: 2.3.0 Content-Type: application/json { \"count\": 1, \"next\": null, \"previous\": null, \"results\": [ { \"created\": \"2014-01-01T00:00:00UTC\", \"id\": \"example-go\", \"owner\": \"test\", \"structure\": {}, \"updated\": \"2014-01-01T00:00:00UTC\", \"url\": \"example-go.example.com\", \"uuid\": \"de1bf5b5-4a72-4f94-a10c-d2a3741cdf75\" } ] } Create an Application \u00b6 Example Request: POST /v2/apps/ HTTP/1.1 Host: drycc.example.com Content-Type: application/json Authorization: token abc123 Optional parameters: {\"id\": \"example-go\"} Example Response: HTTP/1.1 201 CREATED DRYCC_API_VERSION: 2.3 DRYCC_PLATFORM_VERSION: 2.3.0 Content-Type: application/json { \"created\": \"2014-01-01T00:00:00UTC\", \"id\": \"example-go\", \"owner\": \"test\", \"structure\": {}, \"updated\": \"2014-01-01T00:00:00UTC\", \"url\": \"example-go.example.com\", \"uuid\": \"de1bf5b5-4a72-4f94-a10c-d2a3741cdf75\" } Destroy an Application \u00b6 Example Request: DELETE /v2/apps/example-go/ HTTP/1.1 Host: drycc.example.com Authorization: token abc123 Example Response: HTTP/1.1 204 NO CONTENT DRYCC_API_VERSION: 2.3 DRYCC_PLATFORM_VERSION: 2.3.0 List Application Details \u00b6 Example Request: GET /v2/apps/example-go/ HTTP/1.1 Host: drycc.example.com Authorization: token abc123 Example Response: HTTP/1.1 200 OK DRYCC_API_VERSION: 2.3 DRYCC_PLATFORM_VERSION: 2.3.0 Content-Type: application/json { \"created\": \"2014-01-01T00:00:00UTC\", \"id\": \"example-go\", \"owner\": \"test\", \"structure\": {}, \"updated\": \"2014-01-01T00:00:00UTC\", \"url\": \"example-go.example.com\", \"uuid\": \"de1bf5b5-4a72-4f94-a10c-d2a3741cdf75\" } Update Application Details \u00b6 Example Request: POST /v2/apps/example-go/ HTTP/1.1 Host: drycc.example.com Authorization: token abc123 Optional parameters: { \"owner\": \"test\" } Example Response: HTTP/1.1 200 OK DRYCC_API_VERSION: 2.3 DRYCC_PLATFORM_VERSION: 1.8.0 Content-Type: application/json Retrieve Application Logs \u00b6 Example Request: GET /v2/apps/example-go/logs/ HTTP/1.1 Host: drycc.example.com Authorization: token abc123 Optional URL Query Parameters: ?log_lines= Example Response: HTTP/1.1 200 OK DRYCC_API_VERSION: 2.3 DRYCC_PLATFORM_VERSION: 2.3.0 Content-Type: text/plain \"16:51:14 drycc[api]: test created initial release\\n\" Run one-off Commands \u00b6 POST /v2/apps/example-go/run/ HTTP/1.1 Host: drycc.example.com Content-Type: application/json Authorization: token abc123 {\"command\": \"echo hi\"} Example Response: HTTP/1.1 200 OK DRYCC_API_VERSION: 2.3 DRYCC_PLATFORM_VERSION: 2.3.0 Content-Type: application/json {\"exit_code\": 0, \"output\": \"hi\\n\"} Certificates \u00b6 List all Certificates \u00b6 Example Request: GET /v2/certs HTTP/1.1 Host: drycc.example.com Authorization: token abc123 Example Response: HTTP/1.1 200 OK DRYCC_API_VERSION: 2.3 DRYCC_PLATFORM_VERSION: 2.3.0 Content-Type: application/json { \"count\": 1, \"next\": null, \"previous\": null, \"results\": [ { \"id\": 22, \"owner\": \"test\", \"san\": [], \"domains\": [], \"created\": \"2016-06-22.32.34:20Z\", \"updated\": \"2016-06-22.32.34:20Z\", \"name\": \"foo\", \"common_name\": \"bar.com\", \"fingerprint\": \"7A:CA:B8:50:FF:8D:EB:03:3D:AC:AD:13:4F:EE:03:D5:5D:EB:5E:37:51:8C:E0:98:F8:1B:36:2B:20:83:0D:C0\", \"expires\": \"2017-01-14T23:57:57Z\", \"starts\": \"2016-01-15T23:57:57Z\", \"issuer\": \"/C=US/ST=CA/L=San Francisco/O=Drycc/OU=Engineering/CN=bar.com/emailAddress=engineering@drycc.cc\", \"subject\": \"/C=US/ST=CA/L=San Francisco/O=Drycc/OU=Engineering/CN=bar.com/emailAddress=engineering@drycc.cc\" } ] } Get Certificate Details \u00b6 Example Request: GET /v2/certs/foo HTTP/1.1 Host: drycc.example.com Authorization: token abc123 Example Response: HTTP/1.1 200 OK DRYCC_API_VERSION: 2.3 DRYCC_PLATFORM_VERSION: 2.3.0 Content-Type: application/json { \"id\": 22, \"owner\": \"test\", \"san\": [], \"domains\": [], \"created\": \"2016-06-22.32.34:20Z\", \"updated\": \"2016-06-22.32.34:20Z\", \"name\": \"foo\", \"common_name\": \"bar.com\", \"fingerprint\": \"7A:CA:B8:50:FF:8D:EB:03:3D:AC:AD:13:4F:EE:03:D5:5D:EB:5E:37:51:8C:E0:98:F8:1B:36:2B:20:83:0D:C0\", \"expires\": \"2017-01-14T23:57:57Z\", \"starts\": \"2016-01-15T23:57:57Z\", \"issuer\": \"/C=US/ST=CA/L=San Francisco/O=Drycc/OU=Engineering/CN=bar.com/emailAddress=engineering@drycc.cc\", \"subject\": \"/C=US/ST=CA/L=San Francisco/O=Drycc/OU=Engineering/CN=bar.com/emailAddress=engineering@drycc.cc\" } Create Certificate \u00b6 Example Request: POST /v2/certs/ HTTP/1.1 Host: drycc.example.com Content-Type: application/json Authorization: token abc123 { \"name\": \"foo\" \"certificate\": \"-----BEGIN CERTIFICATE-----\", \"key\": \"-----BEGIN RSA PRIVATE KEY-----\" } Example Response: HTTP/1.1 201 CREATED DRYCC_API_VERSION: 2.3 DRYCC_PLATFORM_VERSION: 2.3.0 Content-Type: application/json { \"id\": 22, \"owner\": \"test\", \"san\": [], \"domains\": [], \"created\": \"2016-06-22.32.34:20Z\", \"updated\": \"2016-06-22.32.34:20Z\", \"name\": \"foo\", \"common_name\": \"bar.com\", \"fingerprint\": \"7A:CA:B8:50:FF:8D:EB:03:3D:AC:AD:13:4F:EE:03:D5:5D:EB:5E:37:51:8C:E0:98:F8:1B:36:2B:20:83:0D:C0\", \"expires\": \"2017-01-14T23:57:57Z\", \"starts\": \"2016-01-15T23:57:57Z\", \"issuer\": \"/C=US/ST=CA/L=San Francisco/O=Drycc/OU=Engineering/CN=bar.com/emailAddress=engineering@drycc.cc\", \"subject\": \"/C=US/ST=CA/L=San Francisco/O=Drycc/OU=Engineering/CN=bar.com/emailAddress=engineering@drycc.cc\" } Destroy a Certificate \u00b6 Example Request: DELETE /v2/certs/foo HTTP/1.1 Host: drycc.example.com Authorization: token abc123 Example Response: HTTP/1.1 204 NO CONTENT DRYCC_API_VERSION: 2.3 DRYCC_PLATFORM_VERSION: 2.3.0 Attach a Domain to a Certificate \u00b6 Example Request: POST /v2/certs/foo/domain/ HTTP/1.1 Host: drycc.example.com Authorization: token abc123 { \"domain\": \"test.com\" } Example Response: HTTP/1.1 201 CREATED DRYCC_API_VERSION: 2.3 DRYCC_PLATFORM_VERSION: 2.3.0 Remove a Domain from a Certificate \u00b6 Example Request: DELETE /v2/certs/foo/domain/test.com/ HTTP/1.1 Host: drycc.example.com Authorization: token abc123 Example Response: HTTP/1.1 204 NO CONTENT DRYCC_API_VERSION: 2.3 DRYCC_PLATFORM_VERSION: 2.3.0 Enable or disable TLS \u00b6 Example Request: POST /v2/apps/example-go/tls/ HTTP/1.1 Host: drycc.example.com Content-Type: application/json Authorization: token abc123 { \"https_enforced\": true } Example Response: HTTP/1.1 201 CREATED DRYCC_API_VERSION: 2.3 DRYCC_PLATFORM_VERSION: 2.3.0 Content-Type: application/json { \"created\": \"2014-01-01T00:00:00UTC\", \"app\": \"example-go\", \"owner\": \"test\", \"https_enforced\": true, \"updated\": \"2014-01-01T00:00:00UTC\", \"uuid\": \"de1bf5b5-4a72-4f94-a10c-d2a3741cdf75\" } Get TLS status \u00b6 Example Request: GET /v2/apps/example-go/tls/ HTTP/1.1 Host: drycc.example.com Authorization: token abc123 Example Response: HTTP/1.1 200 OK DRYCC_API_VERSION: 2.3 DRYCC_PLATFORM_VERSION: 2.3.0 Content-Type: application/json { \"created\": \"2014-01-01T00:00:00UTC\", \"app\": \"example-go\", \"owner\": \"test\", \"https_enforced\": false, \"updated\": \"2014-01-01T00:00:00UTC\", \"uuid\": \"de1bf5b5-4a72-4f94-a10c-d2a3741cdf75\" } Pods \u00b6 List all Pods \u00b6 Example Request: GET /v2/apps/example-go/pods/ HTTP/1.1 Host: drycc.example.com Authorization: token abc123 Example Response: HTTP/1.1 200 OK DRYCC_API_VERSION: 2.3 DRYCC_PLATFORM_VERSION: 2.3.0 Content-Type: application/json { \"count\": 1, \"results\": [ { \"name\": \"go-v2-web-e7dej\", \"release\": \"v2\", \"started\": \"2014-01-01T00:00:00Z\", \"state\": \"up\", \"type\": \"web\" } ] } List all Pods by Type \u00b6 Example Request: GET /v2/apps/example-go/pods/web/ HTTP/1.1 Host: drycc.example.com Authorization: token abc123 Example Response: HTTP/1.1 200 OK DRYCC_API_VERSION: 2.3 DRYCC_PLATFORM_VERSION: 2.3.0 Content-Type: application/json { \"count\": 1, \"results\": [ { \"name\": \"go-v2-web-e7dej\", \"release\": \"v2\", \"started\": \"2014-01-01T00:00:00Z\", \"state\": \"up\", \"type\": \"web\" } ] } Restart All Pods \u00b6 Example Request: POST /v2/apps/example-go/pods/restart/ HTTP/1.1 Host: drycc.example.com Authorization: token abc123 Example Response: HTTP/1.1 200 OK DRYCC_API_VERSION: 2.3 DRYCC_PLATFORM_VERSION: 2.3.0 Content-Type: application/json [ { \"name\": \"go-v2-web-atots\", \"release\": \"v2\", \"started\": \"2016-04-11T21:07:54Z\", \"state\": \"up\", \"type\": \"web\" } ] Restart Pods by Type \u00b6 Example Request: POST /v2/apps/example-go/pods/web/restart/ HTTP/1.1 Host: drycc.example.com Authorization: token abc123 Example Response: HTTP/1.1 200 OK DRYCC_API_VERSION: 2.3 DRYCC_PLATFORM_VERSION: 2.3.0 Content-Type: application/json [ { \"name\": \"go-v2-web-atots\", \"release\": \"v2\", \"started\": \"2016-04-11T21:07:54Z\", \"state\": \"up\", \"type\": \"web\" } ] Restart Pods by Type and Name \u00b6 Example Request: POST /v2/apps/example-go/pods/go-v2-web-atots/restart/ HTTP/1.1 Host: drycc.example.com Authorization: token abc123 Example Response: HTTP/1.1 200 OK DRYCC_API_VERSION: 2.3 DRYCC_PLATFORM_VERSION: 2.3.0 Content-Type: application/json [ { \"name\": \"go-v2-web-atots\", \"release\": \"v2\", \"started\": \"2016-04-11T21:07:54Z\", \"state\": \"up\", \"type\": \"web\" } ] Scale Pods \u00b6 Example Request: POST /v2/apps/example-go/scale/ HTTP/1.1 Host: drycc.example.com Content-Type: application/json Authorization: token abc123 {\"web\": 3} Example Response: HTTP/1.1 204 NO CONTENT DRYCC_API_VERSION: 2.3 DRYCC_PLATFORM_VERSION: 2.3.0 Configuration \u00b6 List Application Configuration \u00b6 Example Request: GET /v2/apps/example-go/config/ HTTP/1.1 Host: drycc.example.com Authorization: token abc123 Example Response: HTTP/1.1 200 OK DRYCC_API_VERSION: 2.3 DRYCC_PLATFORM_VERSION: 2.3.0 Content-Type: application/json { \"owner\": \"test\", \"app\": \"example-go\", \"values\": { \"PLATFORM\": \"drycc\" }, \"memory\": {}, \"cpu\": {}, \"tags\": {}, \"healthcheck\": {}, \"created\": \"2014-01-01T00:00:00UTC\", \"updated\": \"2014-01-01T00:00:00UTC\", \"uuid\": \"de1bf5b5-4a72-4f94-a10c-d2a3741cdf75\" } Create new Config \u00b6 Example Request: POST /v2/apps/example-go/config/ HTTP/1.1 Host: drycc.example.com Content-Type: application/json Authorization: token abc123 {\"values\": {\"HELLO\": \"world\", \"PLATFORM\": \"drycc\"}} Example Response: HTTP/1.1 201 CREATED DRYCC_API_VERSION: 2.3 DRYCC_PLATFORM_VERSION: 2.3.0 Content-Type: application/json { \"owner\": \"test\", \"app\": \"example-go\", \"values\": { \"DRYCC_APP\": \"example-go\", \"DRYCC_RELEASE\": \"v3\", \"HELLO\": \"world\", \"PLATFORM\": \"drycc\" }, \"memory\": {}, \"cpu\": {}, \"tags\": {}, \"healthcheck\": {}, \"created\": \"2014-01-01T00:00:00UTC\", \"updated\": \"2014-01-01T00:00:00UTC\", \"uuid\": \"de1bf5b5-4a72-4f94-a10c-d2a3741cdf75\" } Unset Config Variable \u00b6 Example Request: POST /v2/apps/example-go/config/ HTTP/1.1 Host: drycc.example.com Content-Type: application/json Authorization: token abc123 {\"values\": {\"HELLO\": null}} Example Response: HTTP/1.1 201 CREATED DRYCC_API_VERSION: 2.3 DRYCC_PLATFORM_VERSION: 2.3.0 Content-Type: application/json { \"owner\": \"test\", \"app\": \"example-go\", \"values\": { \"DRYCC_APP\": \"example-go\", \"DRYCC_RELEASE\": \"v4\", \"PLATFORM\": \"drycc\" }, \"memory\": {}, \"cpu\": {}, \"tags\": {}, \"healthcheck\": {}, \"created\": \"2014-01-01T00:00:00UTC\", \"updated\": \"2014-01-01T00:00:00UTC\", \"uuid\": \"de1bf5b5-4a72-4f94-a10c-d2a3741cdf75\" } Domains \u00b6 List Application Domains \u00b6 Example Request: GET /v2/apps/example-go/domains/ HTTP/1.1 Host: drycc.example.com Authorization: token abc123 Example Response: HTTP/1.1 200 OK DRYCC_API_VERSION: 2.3 DRYCC_PLATFORM_VERSION: 2.3.0 Content-Type: application/json { \"count\": 1, \"next\": null, \"previous\": null, \"results\": [ { \"app\": \"example-go\", \"created\": \"2014-01-01T00:00:00UTC\", \"domain\": \"example.example.com\", \"owner\": \"test\", \"updated\": \"2014-01-01T00:00:00UTC\" } ] } Add Domain \u00b6 Example Request: POST /v2/apps/example-go/domains/ HTTP/1.1 Host: drycc.example.com Authorization: token abc123 {'domain': 'example.example.com'} Example Response: HTTP/1.1 201 CREATED DRYCC_API_VERSION: 2.3 DRYCC_PLATFORM_VERSION: 2.3.0 Content-Type: application/json { \"app\": \"example-go\", \"created\": \"2014-01-01T00:00:00UTC\", \"domain\": \"example.example.com\", \"owner\": \"test\", \"updated\": \"2014-01-01T00:00:00UTC\" } Remove Domain \u00b6 Example Request: DELETE /v2/apps/example-go/domains/example.example.com HTTP/1.1 Host: drycc.example.com Authorization: token abc123 Example Response: HTTP/1.1 204 NO CONTENT DRYCC_API_VERSION: 2.3 DRYCC_PLATFORM_VERSION: 2.3.0 Builds \u00b6 List Application Builds \u00b6 Example Request: GET /v2/apps/example-go/builds/ HTTP/1.1 Host: drycc.example.com Authorization: token abc123 Example Response: HTTP/1.1 200 OK DRYCC_API_VERSION: 2.3 DRYCC_PLATFORM_VERSION: 2.3.0 Content-Type: application/json { \"count\": 1, \"next\": null, \"previous\": null, \"results\": [ { \"app\": \"example-go\", \"created\": \"2014-01-01T00:00:00UTC\", \"dockerfile\": \"FROM drycc/slugrunner RUN mkdir -p /app WORKDIR /app ENTRYPOINT [\\\"/runner/init\\\"] ADD slug.tgz /app ENV GIT_SHA 060da68f654e75fac06dbedd1995d5f8ad9084db\", \"image\": \"example-go\", \"owner\": \"test\", \"procfile\": { \"web\": \"example-go\" }, \"sha\": \"060da68f\", \"updated\": \"2014-01-01T00:00:00UTC\", \"uuid\": \"de1bf5b5-4a72-4f94-a10c-d2a3741cdf75\" } ] } Create Application Build \u00b6 Example Request: POST /v2/apps/example-go/builds/ HTTP/1.1 Host: drycc.example.com Content-Type: application/json Authorization: token abc123 {\"image\": \"drycc/example-go:latest\"} Optional Parameters: { \"procfile\": { \"web\": \"./cmd\" } } Example Response: HTTP/1.1 201 CREATED DRYCC_API_VERSION: 2.3 DRYCC_PLATFORM_VERSION: 2.3.0 Content-Type: application/json { \"app\": \"example-go\", \"created\": \"2014-01-01T00:00:00UTC\", \"dockerfile\": \"\", \"image\": \"drycc/example-go:latest\", \"owner\": \"test\", \"procfile\": {}, \"sha\": \"\", \"updated\": \"2014-01-01T00:00:00UTC\", \"uuid\": \"de1bf5b5-4a72-4f94-a10c-d2a3741cdf75\" } Releases \u00b6 List Application Releases \u00b6 Example Request: GET /v2/apps/example-go/releases/ HTTP/1.1 Host: drycc.example.com Authorization: token abc123 Example Response: HTTP/1.1 200 OK DRYCC_API_VERSION: 2.3 DRYCC_PLATFORM_VERSION: 2.3.0 Content-Type: application/json { \"count\": 3, \"next\": null, \"previous\": null, \"results\": [ { \"app\": \"example-go\", \"build\": \"2.3d8e4b-600e-4425-a85c-ffc7ea607f61\", \"config\": \"ed637ceb-5d32-44bd-9406-d326a777a513\", \"created\": \"2014-01-01T00:00:00UTC\", \"owner\": \"test\", \"summary\": \"test changed nothing\", \"updated\": \"2014-01-01T00:00:00UTC\", \"uuid\": \"de1bf5b5-4a72-4f94-a10c-d2a3741cdf75\", \"version\": 3 }, { \"app\": \"example-go\", \"build\": \"2.3d8e4b-600e-4425-a85c-ffc7ea607f61\", \"config\": \"95bd6dea-1685-4f78-a03d-fd7270b058d1\", \"created\": \"2014-01-01T00:00:00UTC\", \"owner\": \"test\", \"summary\": \"test deployed 060da68\", \"updated\": \"2014-01-01T00:00:00UTC\", \"uuid\": \"de1bf5b5-4a72-4f94-a10c-d2a3741cdf75\", \"version\": 2 }, { \"app\": \"example-go\", \"build\": null, \"config\": \"95bd6dea-1685-4f78-a03d-fd7270b058d1\", \"created\": \"2014-01-01T00:00:00UTC\", \"owner\": \"test\", \"summary\": \"test created initial release\", \"updated\": \"2014-01-01T00:00:00UTC\", \"uuid\": \"de1bf5b5-4a72-4f94-a10c-d2a3741cdf75\", \"version\": 1 } ] } List Release Details \u00b6 Example Request: GET /v2/apps/example-go/releases/v2/ HTTP/1.1 Host: drycc.example.com Authorization: token abc123 Example Response: HTTP/1.1 200 OK DRYCC_API_VERSION: 2.3 DRYCC_PLATFORM_VERSION: 2.3.0 Content-Type: application/json { \"app\": \"example-go\", \"build\": null, \"config\": \"95bd6dea-1685-4f78-a03d-fd7270b058d1\", \"created\": \"2014-01-01T00:00:00UTC\", \"owner\": \"test\", \"summary\": \"test created initial release\", \"updated\": \"2014-01-01T00:00:00UTC\", \"uuid\": \"de1bf5b5-4a72-4f94-a10c-d2a3741cdf75\", \"version\": 1 } Rollback Release \u00b6 Example Request: POST /v2/apps/example-go/releases/rollback/ HTTP/1.1 Host: drycc.example.com Content-Type: application/json Authorization: token abc123 {\"version\": 1} Example Response: HTTP/1.1 201 CREATED DRYCC_API_VERSION: 2.3 DRYCC_PLATFORM_VERSION: 2.3.0 Content-Type: application/json {\"version\": 5} Keys \u00b6 List Keys \u00b6 Example Request: GET /v2/keys/ HTTP/1.1 Host: drycc.example.com Authorization: token abc123 Example Response: HTTP/1.1 201 CREATED DRYCC_API_VERSION: 2.3 DRYCC_PLATFORM_VERSION: 2.3.0 Content-Type: application/json { \"count\": 1, \"next\": null, \"previous\": null, \"results\": [ { \"created\": \"2014-01-01T00:00:00UTC\", \"id\": \"test@example.com\", \"owner\": \"test\", \"public\": \"ssh-rsa <...>\", \"updated\": \"2014-01-01T00:00:00UTC\", \"uuid\": \"de1bf5b5-4a72-4f94-a10c-d2a3741cdf75\" } ] } Add Key to User \u00b6 Example Request: POST /v2/keys/ HTTP/1.1 Host: drycc.example.com Authorization: token abc123 { \"id\": \"example\", \"public\": \"ssh-rsa <...>\" } Example Response: HTTP/1.1 201 CREATED DRYCC_API_VERSION: 2.3 DRYCC_PLATFORM_VERSION: 2.3.0 Content-Type: application/json { \"created\": \"2014-01-01T00:00:00UTC\", \"id\": \"example\", \"owner\": \"example\", \"public\": \"ssh-rsa <...>\", \"updated\": \"2014-01-01T00:00:00UTC\", \"uuid\": \"de1bf5b5-4a72-4f94-a10c-d2a3741cdf75\" } Remove Key from User \u00b6 Example Request: DELETE /v2/keys/example HTTP/1.1 Host: drycc.example.com Authorization: token abc123 Example Response: HTTP/1.1 204 NO CONTENT DRYCC_API_VERSION: 2.3 DRYCC_PLATFORM_VERSION: 2.3.0 Permissions \u00b6 List Application Permissions \u00b6 note This does not include the app owner. Example Request: GET /v2/apps/example-go/perms/ HTTP/1.1 Host: drycc.example.com Authorization: token abc123 Example Response: HTTP/1.1 200 OK DRYCC_API_VERSION: 2.3 DRYCC_PLATFORM_VERSION: 2.3.0 Content-Type: application/json { \"users\": [ \"test\", \"foo\" ] } Create Application Permission \u00b6 Example Request: POST /v2/apps/example-go/perms/ HTTP/1.1 Host: drycc.example.com Authorization: token abc123 {\"username\": \"example\"} Example Response: HTTP/1.1 201 CREATED DRYCC_API_VERSION: 2.3 DRYCC_PLATFORM_VERSION: 2.3.0 Remove Application Permission \u00b6 Example Request: DELETE /v2/apps/example-go/perms/example HTTP/1.1 Host: drycc.example.com Authorization: token abc123 Example Response: HTTP/1.1 204 NO CONTENT DRYCC_API_VERSION: 2.3 DRYCC_PLATFORM_VERSION: 2.3.0 List Administrators \u00b6 Example Request: GET /v2/admin/perms/ HTTP/1.1 Host: drycc.example.com Authorization: token abc123 Example Response: HTTP/1.1 200 OK DRYCC_API_VERSION: 2.3 DRYCC_PLATFORM_VERSION: 2.3.0 Content-Type: application/json { \"count\": 2, \"next\": null \"previous\": null, \"results\": [ { \"username\": \"test\", \"is_superuser\": true }, { \"username\": \"foo\", \"is_superuser\": true } ] } Grant User Administrative Privileges \u00b6 note This command requires administrative privileges Example Request: POST /v2/admin/perms HTTP/1.1 Host: drycc.example.com Authorization: token abc123 {\"username\": \"example\"} Example Response: HTTP/1.1 201 CREATED DRYCC_API_VERSION: 2.3 DRYCC_PLATFORM_VERSION: 2.3.0 Remove User's Administrative Privileges \u00b6 note This command requires administrative privileges Example Request: DELETE /v2/admin/perms/example HTTP/1.1 Host: drycc.example.com Authorization: token abc123 Example Response: HTTP/1.1 204 NO CONTENT DRYCC_API_VERSION: 2.3 DRYCC_PLATFORM_VERSION: 2.3.0 Users \u00b6 List all users \u00b6 note This command requires administrative privileges Example Request: GET /v2/users HTTP/1.1 Host: drycc.example.com Authorization: token abc123 Example Response: HTTP/1.1 200 OK DRYCC_API_VERSION: 2.3 DRYCC_PLATFORM_VERSION: 2.3.0 Content-Type: application/json { \"count\": 1, \"next\": null, \"previous\": null, \"results\": [ { \"id\": 1, \"last_login\": \"2014-10-19T22:01:00.601Z\", \"is_superuser\": true, \"username\": \"test\", \"first_name\": \"test\", \"last_name\": \"testerson\", \"email\": \"test@example.com\", \"is_staff\": true, \"is_active\": true, \"date_joined\": \"2014-10-19T22:01:00.601Z\", \"groups\": [], \"user_permissions\": [] } ] }","title":"Controller API v2.3"},{"location":"reference-guide/controller-api/v2.3/#controller-api-v23","text":"This is the v2.3 REST API for the Controller.","title":"Controller API v2.3"},{"location":"reference-guide/controller-api/v2.3/#whats-new","text":"New! /v2/apps/{name}/logs endpoint was fixed and no longer returns b'log data' and instead returns a normal string log data","title":"What's New"},{"location":"reference-guide/controller-api/v2.3/#authentication","text":"","title":"Authentication"},{"location":"reference-guide/controller-api/v2.3/#register-a-new-user","text":"Example Request: POST /v2/auth/register/ HTTP/1.1 Host: drycc.example.com Content-Type: application/json { \"username\": \"test\", \"password\": \"opensesame\", \"email\": \"test@example.com\" } Optional Parameters: { \"first_name\": \"test\", \"last_name\": \"testerson\" } Example Response: HTTP/1.1 201 CREATED DRYCC_API_VERSION: 2.3 DRYCC_PLATFORM_VERSION: 2.3.0 Content-Type: application/json { \"id\": 1, \"last_login\": \"2014-10-19T22:01:00.601Z\", \"is_superuser\": true, \"username\": \"test\", \"first_name\": \"test\", \"last_name\": \"testerson\", \"email\": \"test@example.com\", \"is_staff\": true, \"is_active\": true, \"date_joined\": \"2014-10-19T22:01:00.601Z\", \"groups\": [], \"user_permissions\": [] }","title":"Register a New User"},{"location":"reference-guide/controller-api/v2.3/#log-in","text":"Example Request: POST /v2/auth/login/ HTTP/1.1 Host: drycc.example.com Content-Type: application/json {\"username\": \"test\", \"password\": \"opensesame\"} Example Response: HTTP/1.1 200 OK DRYCC_API_VERSION: 2.3 DRYCC_PLATFORM_VERSION: 2.3.0 Content-Type: application/json {\"token\": \"abc123\"}","title":"Log in"},{"location":"reference-guide/controller-api/v2.3/#cancel-account","text":"Example Request: DELETE /v2/auth/cancel/ HTTP/1.1 Host: drycc.example.com Authorization: token abc123 Example Response: HTTP/1.1 204 NO CONTENT DRYCC_API_VERSION: 2.3 DRYCC_PLATFORM_VERSION: 2.3.0","title":"Cancel Account"},{"location":"reference-guide/controller-api/v2.3/#who-am-i","text":"Example Request: GET /v2/auth/whoami/ HTTP/1.1 Host: drycc.example.com Authorization: token abc123 Example Response: HTTP/1.1 200 OK DRYCC_API_VERSION: 2.3 DRYCC_PLATFORM_VERSION: 2.3.0 Content-Type: application/json { \"id\": 1, \"last_login\": \"2014-10-19T22:01:00.601Z\", \"is_superuser\": true, \"username\": \"test\", \"first_name\": \"test\", \"last_name\": \"testerson\", \"email\": \"test@example.com\", \"is_staff\": true, \"is_active\": true, \"date_joined\": \"2014-10-19T22:01:00.601Z\", \"groups\": [], \"user_permissions\": [] }","title":"Who Am I"},{"location":"reference-guide/controller-api/v2.3/#regenerate-token","text":"note This command could require administrative privileges Example Request: POST /v2/auth/tokens/ HTTP/1.1 Host: drycc.example.com Authorization: token abc123 Optional Parameters: { \"username\" : \"test\" \"all\" : \"true\" } Example Response: HTTP/1.1 200 OK DRYCC_API_VERSION: 2.3 DRYCC_PLATFORM_VERSION: 2.3.0 Content-Type: application/json {\"token\": \"abc123\"}","title":"Regenerate Token"},{"location":"reference-guide/controller-api/v2.3/#change-password","text":"Example Request: POST /v2/auth/passwd/ HTTP/1.1 Host: drycc.example.com Authorization: token abc123 { \"password\": \"foo\", \"new_password\": \"bar\" } Optional parameters: {\"username\": \"testuser\"} note Using the username parameter requires administrative privileges and makes the password parameter optional. Example Response: HTTP/1.1 200 OK DRYCC_API_VERSION: 2.3 DRYCC_PLATFORM_VERSION: 2.3.0","title":"Change Password"},{"location":"reference-guide/controller-api/v2.3/#applications","text":"","title":"Applications"},{"location":"reference-guide/controller-api/v2.3/#list-all-applications","text":"Example Request: GET /v2/apps HTTP/1.1 Host: drycc.example.com Authorization: token abc123 Example Response: HTTP/1.1 200 OK DRYCC_API_VERSION: 2.3 DRYCC_PLATFORM_VERSION: 2.3.0 Content-Type: application/json { \"count\": 1, \"next\": null, \"previous\": null, \"results\": [ { \"created\": \"2014-01-01T00:00:00UTC\", \"id\": \"example-go\", \"owner\": \"test\", \"structure\": {}, \"updated\": \"2014-01-01T00:00:00UTC\", \"url\": \"example-go.example.com\", \"uuid\": \"de1bf5b5-4a72-4f94-a10c-d2a3741cdf75\" } ] }","title":"List all Applications"},{"location":"reference-guide/controller-api/v2.3/#create-an-application","text":"Example Request: POST /v2/apps/ HTTP/1.1 Host: drycc.example.com Content-Type: application/json Authorization: token abc123 Optional parameters: {\"id\": \"example-go\"} Example Response: HTTP/1.1 201 CREATED DRYCC_API_VERSION: 2.3 DRYCC_PLATFORM_VERSION: 2.3.0 Content-Type: application/json { \"created\": \"2014-01-01T00:00:00UTC\", \"id\": \"example-go\", \"owner\": \"test\", \"structure\": {}, \"updated\": \"2014-01-01T00:00:00UTC\", \"url\": \"example-go.example.com\", \"uuid\": \"de1bf5b5-4a72-4f94-a10c-d2a3741cdf75\" }","title":"Create an Application"},{"location":"reference-guide/controller-api/v2.3/#destroy-an-application","text":"Example Request: DELETE /v2/apps/example-go/ HTTP/1.1 Host: drycc.example.com Authorization: token abc123 Example Response: HTTP/1.1 204 NO CONTENT DRYCC_API_VERSION: 2.3 DRYCC_PLATFORM_VERSION: 2.3.0","title":"Destroy an Application"},{"location":"reference-guide/controller-api/v2.3/#list-application-details","text":"Example Request: GET /v2/apps/example-go/ HTTP/1.1 Host: drycc.example.com Authorization: token abc123 Example Response: HTTP/1.1 200 OK DRYCC_API_VERSION: 2.3 DRYCC_PLATFORM_VERSION: 2.3.0 Content-Type: application/json { \"created\": \"2014-01-01T00:00:00UTC\", \"id\": \"example-go\", \"owner\": \"test\", \"structure\": {}, \"updated\": \"2014-01-01T00:00:00UTC\", \"url\": \"example-go.example.com\", \"uuid\": \"de1bf5b5-4a72-4f94-a10c-d2a3741cdf75\" }","title":"List Application Details"},{"location":"reference-guide/controller-api/v2.3/#update-application-details","text":"Example Request: POST /v2/apps/example-go/ HTTP/1.1 Host: drycc.example.com Authorization: token abc123 Optional parameters: { \"owner\": \"test\" } Example Response: HTTP/1.1 200 OK DRYCC_API_VERSION: 2.3 DRYCC_PLATFORM_VERSION: 1.8.0 Content-Type: application/json","title":"Update Application Details"},{"location":"reference-guide/controller-api/v2.3/#retrieve-application-logs","text":"Example Request: GET /v2/apps/example-go/logs/ HTTP/1.1 Host: drycc.example.com Authorization: token abc123 Optional URL Query Parameters: ?log_lines= Example Response: HTTP/1.1 200 OK DRYCC_API_VERSION: 2.3 DRYCC_PLATFORM_VERSION: 2.3.0 Content-Type: text/plain \"16:51:14 drycc[api]: test created initial release\\n\"","title":"Retrieve Application Logs"},{"location":"reference-guide/controller-api/v2.3/#run-one-off-commands","text":"POST /v2/apps/example-go/run/ HTTP/1.1 Host: drycc.example.com Content-Type: application/json Authorization: token abc123 {\"command\": \"echo hi\"} Example Response: HTTP/1.1 200 OK DRYCC_API_VERSION: 2.3 DRYCC_PLATFORM_VERSION: 2.3.0 Content-Type: application/json {\"exit_code\": 0, \"output\": \"hi\\n\"}","title":"Run one-off Commands"},{"location":"reference-guide/controller-api/v2.3/#certificates","text":"","title":"Certificates"},{"location":"reference-guide/controller-api/v2.3/#list-all-certificates","text":"Example Request: GET /v2/certs HTTP/1.1 Host: drycc.example.com Authorization: token abc123 Example Response: HTTP/1.1 200 OK DRYCC_API_VERSION: 2.3 DRYCC_PLATFORM_VERSION: 2.3.0 Content-Type: application/json { \"count\": 1, \"next\": null, \"previous\": null, \"results\": [ { \"id\": 22, \"owner\": \"test\", \"san\": [], \"domains\": [], \"created\": \"2016-06-22.32.34:20Z\", \"updated\": \"2016-06-22.32.34:20Z\", \"name\": \"foo\", \"common_name\": \"bar.com\", \"fingerprint\": \"7A:CA:B8:50:FF:8D:EB:03:3D:AC:AD:13:4F:EE:03:D5:5D:EB:5E:37:51:8C:E0:98:F8:1B:36:2B:20:83:0D:C0\", \"expires\": \"2017-01-14T23:57:57Z\", \"starts\": \"2016-01-15T23:57:57Z\", \"issuer\": \"/C=US/ST=CA/L=San Francisco/O=Drycc/OU=Engineering/CN=bar.com/emailAddress=engineering@drycc.cc\", \"subject\": \"/C=US/ST=CA/L=San Francisco/O=Drycc/OU=Engineering/CN=bar.com/emailAddress=engineering@drycc.cc\" } ] }","title":"List all Certificates"},{"location":"reference-guide/controller-api/v2.3/#get-certificate-details","text":"Example Request: GET /v2/certs/foo HTTP/1.1 Host: drycc.example.com Authorization: token abc123 Example Response: HTTP/1.1 200 OK DRYCC_API_VERSION: 2.3 DRYCC_PLATFORM_VERSION: 2.3.0 Content-Type: application/json { \"id\": 22, \"owner\": \"test\", \"san\": [], \"domains\": [], \"created\": \"2016-06-22.32.34:20Z\", \"updated\": \"2016-06-22.32.34:20Z\", \"name\": \"foo\", \"common_name\": \"bar.com\", \"fingerprint\": \"7A:CA:B8:50:FF:8D:EB:03:3D:AC:AD:13:4F:EE:03:D5:5D:EB:5E:37:51:8C:E0:98:F8:1B:36:2B:20:83:0D:C0\", \"expires\": \"2017-01-14T23:57:57Z\", \"starts\": \"2016-01-15T23:57:57Z\", \"issuer\": \"/C=US/ST=CA/L=San Francisco/O=Drycc/OU=Engineering/CN=bar.com/emailAddress=engineering@drycc.cc\", \"subject\": \"/C=US/ST=CA/L=San Francisco/O=Drycc/OU=Engineering/CN=bar.com/emailAddress=engineering@drycc.cc\" }","title":"Get Certificate Details"},{"location":"reference-guide/controller-api/v2.3/#create-certificate","text":"Example Request: POST /v2/certs/ HTTP/1.1 Host: drycc.example.com Content-Type: application/json Authorization: token abc123 { \"name\": \"foo\" \"certificate\": \"-----BEGIN CERTIFICATE-----\", \"key\": \"-----BEGIN RSA PRIVATE KEY-----\" } Example Response: HTTP/1.1 201 CREATED DRYCC_API_VERSION: 2.3 DRYCC_PLATFORM_VERSION: 2.3.0 Content-Type: application/json { \"id\": 22, \"owner\": \"test\", \"san\": [], \"domains\": [], \"created\": \"2016-06-22.32.34:20Z\", \"updated\": \"2016-06-22.32.34:20Z\", \"name\": \"foo\", \"common_name\": \"bar.com\", \"fingerprint\": \"7A:CA:B8:50:FF:8D:EB:03:3D:AC:AD:13:4F:EE:03:D5:5D:EB:5E:37:51:8C:E0:98:F8:1B:36:2B:20:83:0D:C0\", \"expires\": \"2017-01-14T23:57:57Z\", \"starts\": \"2016-01-15T23:57:57Z\", \"issuer\": \"/C=US/ST=CA/L=San Francisco/O=Drycc/OU=Engineering/CN=bar.com/emailAddress=engineering@drycc.cc\", \"subject\": \"/C=US/ST=CA/L=San Francisco/O=Drycc/OU=Engineering/CN=bar.com/emailAddress=engineering@drycc.cc\" }","title":"Create Certificate"},{"location":"reference-guide/controller-api/v2.3/#destroy-a-certificate","text":"Example Request: DELETE /v2/certs/foo HTTP/1.1 Host: drycc.example.com Authorization: token abc123 Example Response: HTTP/1.1 204 NO CONTENT DRYCC_API_VERSION: 2.3 DRYCC_PLATFORM_VERSION: 2.3.0","title":"Destroy a Certificate"},{"location":"reference-guide/controller-api/v2.3/#attach-a-domain-to-a-certificate","text":"Example Request: POST /v2/certs/foo/domain/ HTTP/1.1 Host: drycc.example.com Authorization: token abc123 { \"domain\": \"test.com\" } Example Response: HTTP/1.1 201 CREATED DRYCC_API_VERSION: 2.3 DRYCC_PLATFORM_VERSION: 2.3.0","title":"Attach a Domain to a Certificate"},{"location":"reference-guide/controller-api/v2.3/#remove-a-domain-from-a-certificate","text":"Example Request: DELETE /v2/certs/foo/domain/test.com/ HTTP/1.1 Host: drycc.example.com Authorization: token abc123 Example Response: HTTP/1.1 204 NO CONTENT DRYCC_API_VERSION: 2.3 DRYCC_PLATFORM_VERSION: 2.3.0","title":"Remove a Domain from a Certificate"},{"location":"reference-guide/controller-api/v2.3/#enable-or-disable-tls","text":"Example Request: POST /v2/apps/example-go/tls/ HTTP/1.1 Host: drycc.example.com Content-Type: application/json Authorization: token abc123 { \"https_enforced\": true } Example Response: HTTP/1.1 201 CREATED DRYCC_API_VERSION: 2.3 DRYCC_PLATFORM_VERSION: 2.3.0 Content-Type: application/json { \"created\": \"2014-01-01T00:00:00UTC\", \"app\": \"example-go\", \"owner\": \"test\", \"https_enforced\": true, \"updated\": \"2014-01-01T00:00:00UTC\", \"uuid\": \"de1bf5b5-4a72-4f94-a10c-d2a3741cdf75\" }","title":"Enable or disable TLS"},{"location":"reference-guide/controller-api/v2.3/#get-tls-status","text":"Example Request: GET /v2/apps/example-go/tls/ HTTP/1.1 Host: drycc.example.com Authorization: token abc123 Example Response: HTTP/1.1 200 OK DRYCC_API_VERSION: 2.3 DRYCC_PLATFORM_VERSION: 2.3.0 Content-Type: application/json { \"created\": \"2014-01-01T00:00:00UTC\", \"app\": \"example-go\", \"owner\": \"test\", \"https_enforced\": false, \"updated\": \"2014-01-01T00:00:00UTC\", \"uuid\": \"de1bf5b5-4a72-4f94-a10c-d2a3741cdf75\" }","title":"Get TLS status"},{"location":"reference-guide/controller-api/v2.3/#pods","text":"","title":"Pods"},{"location":"reference-guide/controller-api/v2.3/#list-all-pods","text":"Example Request: GET /v2/apps/example-go/pods/ HTTP/1.1 Host: drycc.example.com Authorization: token abc123 Example Response: HTTP/1.1 200 OK DRYCC_API_VERSION: 2.3 DRYCC_PLATFORM_VERSION: 2.3.0 Content-Type: application/json { \"count\": 1, \"results\": [ { \"name\": \"go-v2-web-e7dej\", \"release\": \"v2\", \"started\": \"2014-01-01T00:00:00Z\", \"state\": \"up\", \"type\": \"web\" } ] }","title":"List all Pods"},{"location":"reference-guide/controller-api/v2.3/#list-all-pods-by-type","text":"Example Request: GET /v2/apps/example-go/pods/web/ HTTP/1.1 Host: drycc.example.com Authorization: token abc123 Example Response: HTTP/1.1 200 OK DRYCC_API_VERSION: 2.3 DRYCC_PLATFORM_VERSION: 2.3.0 Content-Type: application/json { \"count\": 1, \"results\": [ { \"name\": \"go-v2-web-e7dej\", \"release\": \"v2\", \"started\": \"2014-01-01T00:00:00Z\", \"state\": \"up\", \"type\": \"web\" } ] }","title":"List all Pods by Type"},{"location":"reference-guide/controller-api/v2.3/#restart-all-pods","text":"Example Request: POST /v2/apps/example-go/pods/restart/ HTTP/1.1 Host: drycc.example.com Authorization: token abc123 Example Response: HTTP/1.1 200 OK DRYCC_API_VERSION: 2.3 DRYCC_PLATFORM_VERSION: 2.3.0 Content-Type: application/json [ { \"name\": \"go-v2-web-atots\", \"release\": \"v2\", \"started\": \"2016-04-11T21:07:54Z\", \"state\": \"up\", \"type\": \"web\" } ]","title":"Restart All Pods"},{"location":"reference-guide/controller-api/v2.3/#restart-pods-by-type","text":"Example Request: POST /v2/apps/example-go/pods/web/restart/ HTTP/1.1 Host: drycc.example.com Authorization: token abc123 Example Response: HTTP/1.1 200 OK DRYCC_API_VERSION: 2.3 DRYCC_PLATFORM_VERSION: 2.3.0 Content-Type: application/json [ { \"name\": \"go-v2-web-atots\", \"release\": \"v2\", \"started\": \"2016-04-11T21:07:54Z\", \"state\": \"up\", \"type\": \"web\" } ]","title":"Restart Pods by Type"},{"location":"reference-guide/controller-api/v2.3/#restart-pods-by-type-and-name","text":"Example Request: POST /v2/apps/example-go/pods/go-v2-web-atots/restart/ HTTP/1.1 Host: drycc.example.com Authorization: token abc123 Example Response: HTTP/1.1 200 OK DRYCC_API_VERSION: 2.3 DRYCC_PLATFORM_VERSION: 2.3.0 Content-Type: application/json [ { \"name\": \"go-v2-web-atots\", \"release\": \"v2\", \"started\": \"2016-04-11T21:07:54Z\", \"state\": \"up\", \"type\": \"web\" } ]","title":"Restart Pods by Type and Name"},{"location":"reference-guide/controller-api/v2.3/#scale-pods","text":"Example Request: POST /v2/apps/example-go/scale/ HTTP/1.1 Host: drycc.example.com Content-Type: application/json Authorization: token abc123 {\"web\": 3} Example Response: HTTP/1.1 204 NO CONTENT DRYCC_API_VERSION: 2.3 DRYCC_PLATFORM_VERSION: 2.3.0","title":"Scale Pods"},{"location":"reference-guide/controller-api/v2.3/#configuration","text":"","title":"Configuration"},{"location":"reference-guide/controller-api/v2.3/#list-application-configuration","text":"Example Request: GET /v2/apps/example-go/config/ HTTP/1.1 Host: drycc.example.com Authorization: token abc123 Example Response: HTTP/1.1 200 OK DRYCC_API_VERSION: 2.3 DRYCC_PLATFORM_VERSION: 2.3.0 Content-Type: application/json { \"owner\": \"test\", \"app\": \"example-go\", \"values\": { \"PLATFORM\": \"drycc\" }, \"memory\": {}, \"cpu\": {}, \"tags\": {}, \"healthcheck\": {}, \"created\": \"2014-01-01T00:00:00UTC\", \"updated\": \"2014-01-01T00:00:00UTC\", \"uuid\": \"de1bf5b5-4a72-4f94-a10c-d2a3741cdf75\" }","title":"List Application Configuration"},{"location":"reference-guide/controller-api/v2.3/#create-new-config","text":"Example Request: POST /v2/apps/example-go/config/ HTTP/1.1 Host: drycc.example.com Content-Type: application/json Authorization: token abc123 {\"values\": {\"HELLO\": \"world\", \"PLATFORM\": \"drycc\"}} Example Response: HTTP/1.1 201 CREATED DRYCC_API_VERSION: 2.3 DRYCC_PLATFORM_VERSION: 2.3.0 Content-Type: application/json { \"owner\": \"test\", \"app\": \"example-go\", \"values\": { \"DRYCC_APP\": \"example-go\", \"DRYCC_RELEASE\": \"v3\", \"HELLO\": \"world\", \"PLATFORM\": \"drycc\" }, \"memory\": {}, \"cpu\": {}, \"tags\": {}, \"healthcheck\": {}, \"created\": \"2014-01-01T00:00:00UTC\", \"updated\": \"2014-01-01T00:00:00UTC\", \"uuid\": \"de1bf5b5-4a72-4f94-a10c-d2a3741cdf75\" }","title":"Create new Config"},{"location":"reference-guide/controller-api/v2.3/#unset-config-variable","text":"Example Request: POST /v2/apps/example-go/config/ HTTP/1.1 Host: drycc.example.com Content-Type: application/json Authorization: token abc123 {\"values\": {\"HELLO\": null}} Example Response: HTTP/1.1 201 CREATED DRYCC_API_VERSION: 2.3 DRYCC_PLATFORM_VERSION: 2.3.0 Content-Type: application/json { \"owner\": \"test\", \"app\": \"example-go\", \"values\": { \"DRYCC_APP\": \"example-go\", \"DRYCC_RELEASE\": \"v4\", \"PLATFORM\": \"drycc\" }, \"memory\": {}, \"cpu\": {}, \"tags\": {}, \"healthcheck\": {}, \"created\": \"2014-01-01T00:00:00UTC\", \"updated\": \"2014-01-01T00:00:00UTC\", \"uuid\": \"de1bf5b5-4a72-4f94-a10c-d2a3741cdf75\" }","title":"Unset Config Variable"},{"location":"reference-guide/controller-api/v2.3/#domains","text":"","title":"Domains"},{"location":"reference-guide/controller-api/v2.3/#list-application-domains","text":"Example Request: GET /v2/apps/example-go/domains/ HTTP/1.1 Host: drycc.example.com Authorization: token abc123 Example Response: HTTP/1.1 200 OK DRYCC_API_VERSION: 2.3 DRYCC_PLATFORM_VERSION: 2.3.0 Content-Type: application/json { \"count\": 1, \"next\": null, \"previous\": null, \"results\": [ { \"app\": \"example-go\", \"created\": \"2014-01-01T00:00:00UTC\", \"domain\": \"example.example.com\", \"owner\": \"test\", \"updated\": \"2014-01-01T00:00:00UTC\" } ] }","title":"List Application Domains"},{"location":"reference-guide/controller-api/v2.3/#add-domain","text":"Example Request: POST /v2/apps/example-go/domains/ HTTP/1.1 Host: drycc.example.com Authorization: token abc123 {'domain': 'example.example.com'} Example Response: HTTP/1.1 201 CREATED DRYCC_API_VERSION: 2.3 DRYCC_PLATFORM_VERSION: 2.3.0 Content-Type: application/json { \"app\": \"example-go\", \"created\": \"2014-01-01T00:00:00UTC\", \"domain\": \"example.example.com\", \"owner\": \"test\", \"updated\": \"2014-01-01T00:00:00UTC\" }","title":"Add Domain"},{"location":"reference-guide/controller-api/v2.3/#remove-domain","text":"Example Request: DELETE /v2/apps/example-go/domains/example.example.com HTTP/1.1 Host: drycc.example.com Authorization: token abc123 Example Response: HTTP/1.1 204 NO CONTENT DRYCC_API_VERSION: 2.3 DRYCC_PLATFORM_VERSION: 2.3.0","title":"Remove Domain"},{"location":"reference-guide/controller-api/v2.3/#builds","text":"","title":"Builds"},{"location":"reference-guide/controller-api/v2.3/#list-application-builds","text":"Example Request: GET /v2/apps/example-go/builds/ HTTP/1.1 Host: drycc.example.com Authorization: token abc123 Example Response: HTTP/1.1 200 OK DRYCC_API_VERSION: 2.3 DRYCC_PLATFORM_VERSION: 2.3.0 Content-Type: application/json { \"count\": 1, \"next\": null, \"previous\": null, \"results\": [ { \"app\": \"example-go\", \"created\": \"2014-01-01T00:00:00UTC\", \"dockerfile\": \"FROM drycc/slugrunner RUN mkdir -p /app WORKDIR /app ENTRYPOINT [\\\"/runner/init\\\"] ADD slug.tgz /app ENV GIT_SHA 060da68f654e75fac06dbedd1995d5f8ad9084db\", \"image\": \"example-go\", \"owner\": \"test\", \"procfile\": { \"web\": \"example-go\" }, \"sha\": \"060da68f\", \"updated\": \"2014-01-01T00:00:00UTC\", \"uuid\": \"de1bf5b5-4a72-4f94-a10c-d2a3741cdf75\" } ] }","title":"List Application Builds"},{"location":"reference-guide/controller-api/v2.3/#create-application-build","text":"Example Request: POST /v2/apps/example-go/builds/ HTTP/1.1 Host: drycc.example.com Content-Type: application/json Authorization: token abc123 {\"image\": \"drycc/example-go:latest\"} Optional Parameters: { \"procfile\": { \"web\": \"./cmd\" } } Example Response: HTTP/1.1 201 CREATED DRYCC_API_VERSION: 2.3 DRYCC_PLATFORM_VERSION: 2.3.0 Content-Type: application/json { \"app\": \"example-go\", \"created\": \"2014-01-01T00:00:00UTC\", \"dockerfile\": \"\", \"image\": \"drycc/example-go:latest\", \"owner\": \"test\", \"procfile\": {}, \"sha\": \"\", \"updated\": \"2014-01-01T00:00:00UTC\", \"uuid\": \"de1bf5b5-4a72-4f94-a10c-d2a3741cdf75\" }","title":"Create Application Build"},{"location":"reference-guide/controller-api/v2.3/#releases","text":"","title":"Releases"},{"location":"reference-guide/controller-api/v2.3/#list-application-releases","text":"Example Request: GET /v2/apps/example-go/releases/ HTTP/1.1 Host: drycc.example.com Authorization: token abc123 Example Response: HTTP/1.1 200 OK DRYCC_API_VERSION: 2.3 DRYCC_PLATFORM_VERSION: 2.3.0 Content-Type: application/json { \"count\": 3, \"next\": null, \"previous\": null, \"results\": [ { \"app\": \"example-go\", \"build\": \"2.3d8e4b-600e-4425-a85c-ffc7ea607f61\", \"config\": \"ed637ceb-5d32-44bd-9406-d326a777a513\", \"created\": \"2014-01-01T00:00:00UTC\", \"owner\": \"test\", \"summary\": \"test changed nothing\", \"updated\": \"2014-01-01T00:00:00UTC\", \"uuid\": \"de1bf5b5-4a72-4f94-a10c-d2a3741cdf75\", \"version\": 3 }, { \"app\": \"example-go\", \"build\": \"2.3d8e4b-600e-4425-a85c-ffc7ea607f61\", \"config\": \"95bd6dea-1685-4f78-a03d-fd7270b058d1\", \"created\": \"2014-01-01T00:00:00UTC\", \"owner\": \"test\", \"summary\": \"test deployed 060da68\", \"updated\": \"2014-01-01T00:00:00UTC\", \"uuid\": \"de1bf5b5-4a72-4f94-a10c-d2a3741cdf75\", \"version\": 2 }, { \"app\": \"example-go\", \"build\": null, \"config\": \"95bd6dea-1685-4f78-a03d-fd7270b058d1\", \"created\": \"2014-01-01T00:00:00UTC\", \"owner\": \"test\", \"summary\": \"test created initial release\", \"updated\": \"2014-01-01T00:00:00UTC\", \"uuid\": \"de1bf5b5-4a72-4f94-a10c-d2a3741cdf75\", \"version\": 1 } ] }","title":"List Application Releases"},{"location":"reference-guide/controller-api/v2.3/#list-release-details","text":"Example Request: GET /v2/apps/example-go/releases/v2/ HTTP/1.1 Host: drycc.example.com Authorization: token abc123 Example Response: HTTP/1.1 200 OK DRYCC_API_VERSION: 2.3 DRYCC_PLATFORM_VERSION: 2.3.0 Content-Type: application/json { \"app\": \"example-go\", \"build\": null, \"config\": \"95bd6dea-1685-4f78-a03d-fd7270b058d1\", \"created\": \"2014-01-01T00:00:00UTC\", \"owner\": \"test\", \"summary\": \"test created initial release\", \"updated\": \"2014-01-01T00:00:00UTC\", \"uuid\": \"de1bf5b5-4a72-4f94-a10c-d2a3741cdf75\", \"version\": 1 }","title":"List Release Details"},{"location":"reference-guide/controller-api/v2.3/#rollback-release","text":"Example Request: POST /v2/apps/example-go/releases/rollback/ HTTP/1.1 Host: drycc.example.com Content-Type: application/json Authorization: token abc123 {\"version\": 1} Example Response: HTTP/1.1 201 CREATED DRYCC_API_VERSION: 2.3 DRYCC_PLATFORM_VERSION: 2.3.0 Content-Type: application/json {\"version\": 5}","title":"Rollback Release"},{"location":"reference-guide/controller-api/v2.3/#keys","text":"","title":"Keys"},{"location":"reference-guide/controller-api/v2.3/#list-keys","text":"Example Request: GET /v2/keys/ HTTP/1.1 Host: drycc.example.com Authorization: token abc123 Example Response: HTTP/1.1 201 CREATED DRYCC_API_VERSION: 2.3 DRYCC_PLATFORM_VERSION: 2.3.0 Content-Type: application/json { \"count\": 1, \"next\": null, \"previous\": null, \"results\": [ { \"created\": \"2014-01-01T00:00:00UTC\", \"id\": \"test@example.com\", \"owner\": \"test\", \"public\": \"ssh-rsa <...>\", \"updated\": \"2014-01-01T00:00:00UTC\", \"uuid\": \"de1bf5b5-4a72-4f94-a10c-d2a3741cdf75\" } ] }","title":"List Keys"},{"location":"reference-guide/controller-api/v2.3/#add-key-to-user","text":"Example Request: POST /v2/keys/ HTTP/1.1 Host: drycc.example.com Authorization: token abc123 { \"id\": \"example\", \"public\": \"ssh-rsa <...>\" } Example Response: HTTP/1.1 201 CREATED DRYCC_API_VERSION: 2.3 DRYCC_PLATFORM_VERSION: 2.3.0 Content-Type: application/json { \"created\": \"2014-01-01T00:00:00UTC\", \"id\": \"example\", \"owner\": \"example\", \"public\": \"ssh-rsa <...>\", \"updated\": \"2014-01-01T00:00:00UTC\", \"uuid\": \"de1bf5b5-4a72-4f94-a10c-d2a3741cdf75\" }","title":"Add Key to User"},{"location":"reference-guide/controller-api/v2.3/#remove-key-from-user","text":"Example Request: DELETE /v2/keys/example HTTP/1.1 Host: drycc.example.com Authorization: token abc123 Example Response: HTTP/1.1 204 NO CONTENT DRYCC_API_VERSION: 2.3 DRYCC_PLATFORM_VERSION: 2.3.0","title":"Remove Key from User"},{"location":"reference-guide/controller-api/v2.3/#permissions","text":"","title":"Permissions"},{"location":"reference-guide/controller-api/v2.3/#list-application-permissions","text":"note This does not include the app owner. Example Request: GET /v2/apps/example-go/perms/ HTTP/1.1 Host: drycc.example.com Authorization: token abc123 Example Response: HTTP/1.1 200 OK DRYCC_API_VERSION: 2.3 DRYCC_PLATFORM_VERSION: 2.3.0 Content-Type: application/json { \"users\": [ \"test\", \"foo\" ] }","title":"List Application Permissions"},{"location":"reference-guide/controller-api/v2.3/#create-application-permission","text":"Example Request: POST /v2/apps/example-go/perms/ HTTP/1.1 Host: drycc.example.com Authorization: token abc123 {\"username\": \"example\"} Example Response: HTTP/1.1 201 CREATED DRYCC_API_VERSION: 2.3 DRYCC_PLATFORM_VERSION: 2.3.0","title":"Create Application Permission"},{"location":"reference-guide/controller-api/v2.3/#remove-application-permission","text":"Example Request: DELETE /v2/apps/example-go/perms/example HTTP/1.1 Host: drycc.example.com Authorization: token abc123 Example Response: HTTP/1.1 204 NO CONTENT DRYCC_API_VERSION: 2.3 DRYCC_PLATFORM_VERSION: 2.3.0","title":"Remove Application Permission"},{"location":"reference-guide/controller-api/v2.3/#list-administrators","text":"Example Request: GET /v2/admin/perms/ HTTP/1.1 Host: drycc.example.com Authorization: token abc123 Example Response: HTTP/1.1 200 OK DRYCC_API_VERSION: 2.3 DRYCC_PLATFORM_VERSION: 2.3.0 Content-Type: application/json { \"count\": 2, \"next\": null \"previous\": null, \"results\": [ { \"username\": \"test\", \"is_superuser\": true }, { \"username\": \"foo\", \"is_superuser\": true } ] }","title":"List Administrators"},{"location":"reference-guide/controller-api/v2.3/#grant-user-administrative-privileges","text":"note This command requires administrative privileges Example Request: POST /v2/admin/perms HTTP/1.1 Host: drycc.example.com Authorization: token abc123 {\"username\": \"example\"} Example Response: HTTP/1.1 201 CREATED DRYCC_API_VERSION: 2.3 DRYCC_PLATFORM_VERSION: 2.3.0","title":"Grant User Administrative Privileges"},{"location":"reference-guide/controller-api/v2.3/#remove-users-administrative-privileges","text":"note This command requires administrative privileges Example Request: DELETE /v2/admin/perms/example HTTP/1.1 Host: drycc.example.com Authorization: token abc123 Example Response: HTTP/1.1 204 NO CONTENT DRYCC_API_VERSION: 2.3 DRYCC_PLATFORM_VERSION: 2.3.0","title":"Remove User's Administrative Privileges"},{"location":"reference-guide/controller-api/v2.3/#users","text":"","title":"Users"},{"location":"reference-guide/controller-api/v2.3/#list-all-users","text":"note This command requires administrative privileges Example Request: GET /v2/users HTTP/1.1 Host: drycc.example.com Authorization: token abc123 Example Response: HTTP/1.1 200 OK DRYCC_API_VERSION: 2.3 DRYCC_PLATFORM_VERSION: 2.3.0 Content-Type: application/json { \"count\": 1, \"next\": null, \"previous\": null, \"results\": [ { \"id\": 1, \"last_login\": \"2014-10-19T22:01:00.601Z\", \"is_superuser\": true, \"username\": \"test\", \"first_name\": \"test\", \"last_name\": \"testerson\", \"email\": \"test@example.com\", \"is_staff\": true, \"is_active\": true, \"date_joined\": \"2014-10-19T22:01:00.601Z\", \"groups\": [], \"user_permissions\": [] } ] }","title":"List all users"},{"location":"roadmap/planning-process/","text":"Planning Process \u00b6 Drycc features a lightweight process that emphasizes openness and ensures every community member can be an integral part of planning for the future. The Role of Maintainers \u00b6 Maintainers lead the Drycc projects. Their duties include proposing the Roadmap, reviewing and integrating contributions and maintaining the vision of the project. Open Roadmap \u00b6 The Drycc Roadmap is a community document. While Maintainers propose the Roadmap, it gets discussed and refined in Release Planning Meetings. Contributing to the Roadmap \u00b6 Proposals and issues can be opened by anyone. Every member of the community is welcome to participate in the discussion by providing feedback and/or offering counter-proposals. Release Milestones \u00b6 The Roadmap gets delivered progressively via the Release Schedule . Releases are defined during Release Planning Meetings and managed using GitHub Milestones which track specific deliverables and work-in-progress. Release Planning Meetings \u00b6 Major decisions affecting the Roadmap are discussed during Release Planning Meetings on the first Thursday of each month, aligned with the Release Schedule . Release Planning Meetings are open to the public with access coordinated via the Drycc #community Slack channel . Notes from past meetings are below, along with links to a recording of the entire meeting on YouTube. Credits \u00b6 Thanks to Amy Lindburg and our friends at Docker for their inspiration.","title":"Planning Process"},{"location":"roadmap/planning-process/#planning-process","text":"Drycc features a lightweight process that emphasizes openness and ensures every community member can be an integral part of planning for the future.","title":"Planning Process"},{"location":"roadmap/planning-process/#the-role-of-maintainers","text":"Maintainers lead the Drycc projects. Their duties include proposing the Roadmap, reviewing and integrating contributions and maintaining the vision of the project.","title":"The Role of Maintainers"},{"location":"roadmap/planning-process/#open-roadmap","text":"The Drycc Roadmap is a community document. While Maintainers propose the Roadmap, it gets discussed and refined in Release Planning Meetings.","title":"Open Roadmap"},{"location":"roadmap/planning-process/#contributing-to-the-roadmap","text":"Proposals and issues can be opened by anyone. Every member of the community is welcome to participate in the discussion by providing feedback and/or offering counter-proposals.","title":"Contributing to the Roadmap"},{"location":"roadmap/planning-process/#release-milestones","text":"The Roadmap gets delivered progressively via the Release Schedule . Releases are defined during Release Planning Meetings and managed using GitHub Milestones which track specific deliverables and work-in-progress.","title":"Release Milestones"},{"location":"roadmap/planning-process/#release-planning-meetings","text":"Major decisions affecting the Roadmap are discussed during Release Planning Meetings on the first Thursday of each month, aligned with the Release Schedule . Release Planning Meetings are open to the public with access coordinated via the Drycc #community Slack channel . Notes from past meetings are below, along with links to a recording of the entire meeting on YouTube.","title":"Release Planning Meetings"},{"location":"roadmap/planning-process/#credits","text":"Thanks to Amy Lindburg and our friends at Docker for their inspiration.","title":"Credits"},{"location":"roadmap/releases/","text":"Releases \u00b6 Drycc uses a continuous delivery approach for creating releases. Every merged commit that passes testing results in a deliverable that can be given a semantic version tag and shipped. The master git branch of a project should always work. Only changes considered ready to be released publicly are merged. Components Release as Needed \u00b6 Drycc components release new versions as often as needed. Fixing a high priority bug requires the project maintainer to create a new patch release. Merging a backward-compatible feature implies a minor release. By releasing often, each component release becomes a safe and routine event. This makes it faster and easier for users to obtain specific fixes. Continuous delivery also reduces the work necessary to release a product such as Drycc Workflow, which integrates several components. \"Components\" applies not just to Drycc Workflow projects, but also to development and release tools, to Docker base images, and to other Drycc projects that do semantic version releases. See \" How to Release a Component \" for more detail. Workflow Releases Each Month \u00b6 Drycc Workflow has a regular, public release cadence. From v2.8.0 onward, new Workflow feature releases arrive on the first Thursday of each month. Patch releases are created at any time, as needed. GitHub milestones are used to communicate the content and timing of major and minor releases, and longer-term planning is visible at the Roadmap . Workflow release timing is not linked to specific features. If a feature is merged before the release date, it is included in the next release. See \" How to Release Workflow \" for more detail. Semantic Versioning \u00b6 Drycc releases comply with semantic versioning , with the \"public API\" broadly defined as: REST, gRPC, or other API that is network-accessible Library or framework API intended for public use \"Pluggable\" socket-level protocols users can redirect CLI commands and output formats In general, changes to anything a user might reasonably link to, customize, or integrate with should be backward-compatible, or else require a major release. Drycc users can be confident that upgrading to a patch or to a minor release will not break anything. How to Release a Component \u00b6 Most Drycc projects are \"components\" which produce a Docker image or binary executable as a deliverable. This section leads a maintainer through creating a component release. Step 1: Update Code and Run the Release Tool \u00b6 Major or minor releases should happen on the master branch. Patch releases should check out the previous release tag and cherry-pick specific commits from master. Note: if a patch release, the release artifact will have to be manually promoted by triggering the component-promote job with the following values: COMPONENT_NAME=<component name> COMPONENT_SHA=<patch commit sha> Make sure you have the dryccrel release tool in your search $PATH . Run dryccrel release once with a fake semver tag to proofread the changelog content. (If HEAD of master is not what is intended for the release, add the --sha flag as described in dryccrel release --help .) $ dryccrel release controller v0.0.0 Doing a dry run of the component release... skipping commit 943a49267eeb28546819a266654806cfcbae0e38 Creating changelog for controller with tag v2.8.1 through commit 943a49267eeb28546819a266654806cfcbae0e38 ### v2.8.1 -> v0.0.0 #### Fixes - [`615b834`](https://github.com/drycc/controller/commit/615b834f39cb68a854cc1f1e2f0f82d862ea2731) boot: Ensure DRYCC_DEBUG==true for debug output Based on the changelog content, determine whether the component deserves a minor or patch release. Run the command again with that semver tag and --dry-run=false . You will still be asked for confirmation before the release is created: $ dryccrel release controller v2.8.2 --dry-run=false skipping commit 943a49267eeb28546819a266654806cfcbae0e38 Creating changelog for controller with tag v2.8.1 through commit 943a49267eeb28546819a266654806cfcbae0e38 ### v2.8.1 -> v2.8.2 #### Fixes - [`615b834`](https://github.com/drycc/controller/commit/615b834f39cb68a854cc1f1e2f0f82d862ea2731) boot: Ensure DRYCC_DEBUG==true for debug output Please review the above changelog contents and ensure: 1. All intended commits are mentioned 2. The changes agree with the semver release tag (major, minor, or patch) Create release for Drycc Controller v2.8.2? [y/n]: y New release is available at https://github.com/drycc/controller/releases/tag/v2.8.2 Step 2: Verify the Component is Available \u00b6 Tagging the component (see Step 1 ) starts a CI job that eventually results in an artifact being made available for public download. Please see the CI flow diagrams for details. Double-check that the artifact is available, either by a docker pull command or by running the appropriate installer script. If the artifact can't be downloaded, ensure that its CI release jobs are still in progress, or fix whatever issue arose in the pipeline. For example, the master merge pipeline may have failed to promote the :git-abc1d23 candidate image and needs to be restarted with that component and commit. If the component has a correlating Kubernetes Helm chart, this chart will also be packaged, signed and uploaded to its production chart repo. Please verify it can be fetched (and verified): $ helm repo add controller https://charts.drycc.cc/stable \"controller\" has been added to your repositories $ helm fetch --verify drycc/controller --version v1.0.1 Verification: &{0xc4207ec870 sha256:026e766e918ff28d2a7041bc3d560d149ee7eb0cb84165c9d9d00a3045ff45c3 controller-v2.17.0.tgz} How to Release Workflow \u00b6 Drycc Workflow integrates multiple component releases together with a Kubernetes Helm chart deliverable. This section leads a maintainer through creating a Workflow release. Step 1: Set Environment Variables \u00b6 Export two environment variables that will be used in later steps: export WORKFLOW_RELEASE=v2.17.0 WORKFLOW_PREV_RELEASE=v2.16.0 # for example Step 2: Tag Supporting Repositories \u00b6 Some Workflow components not in the Helm chart must also be tagged in sync with the release. Follow the component release process above and ensure that these components are tagged: drycc/workflow-cli drycc/workflow-e2e The version number for drycc/workflow-cli should always match the overall Workflow version number. Step 3: Create Helm Chart \u00b6 To create and stage a release candidate chart for Workflow, we will build the workflow-chart-stage job with the following parameters: RELEASE_TAG=$WORKFLOW_RELEASE This job will gather all of the latest component release tags and use these to specify the versions of all component charts. It will then package the Workflow chart, upload it to the staging chart repo and kick off an e2e run against said chart. Step 4: Manual Testing \u00b6 Now it's time to go above and beyond current CI tests. Create a testing matrix spreadsheet (copying from the previous document is a good start) and sign up testers to cover all permutations. Testers should pay special attention to the overall user experience, make sure upgrading from earlier versions is smooth, and cover various storage configurations and Kubernetes versions and infrastructure providers. When showstopper-level bugs are found, the process is as follows: Create a component PR that fixes the bug. Once the PR passes and is reviewed, merge it and do a new component release Trigger the same workflow-chart-stage job as mentioned in Step 3 to upload the newly-generated Workflow release candidate chart to staging. Step 5: Release the Chart \u00b6 When testing has completed without uncovering any new showstopper bugs, kick off the workflow-chart-release job with the following parameter: RELEASE_TAG=$WORKFLOW_RELEASE This job will copy the release candidate chart (now approved by CI and manual testing) from the staging repo to the production repo, signing it if it has not done so already. Step 6: Assemble Master Changelog \u00b6 Each component already updated its release notes on GitHub with CHANGELOG content. We'll now generate the master changelog for the Workflow chart, consisting of all component and auxilliary repo changes. We'll employ the requirements.lock file from the WORKFLOW_PREV_RELEASE chart, as well as a repo-to-chart-name mapping file , this time invoking dryccrel changelog global to get all component changes between the chart versions existing in the WORKFLOW_PREV_RELEASE chart and the most recent releases existing in GitHub. (Therefore, if there are any unreleased commits in a component repo, they will not appear here): helm repo add drycc https://charts.drycc.cc/stable helm fetch --untar drycc/workflow --version $WORKFLOW_PREV_RELEASE dryccrel changelog global workflow/requirements.lock map.json > changelog-$WORKFLOW_RELEASE.md This master changelog should then be placed into a single gist. The file will also be added to the documentation update PR created in the next step. Step 7: Update Documentation \u00b6 Create a new pull request at drycc/workflow that updates version references to the new release. Use git grep $WORKFLOW_PREV_RELEASE to find any references, but be careful not to change CHANGELOG.md . Place the $WORKFLOW_RELEASE master changelog generated in Step 7 in the changelogs directory. Make sure to add a header to the page to make it clear that this is for a Workflow release, e.g.: ## Workflow v2.16.0 -> v2.17.0 Once the PR has been reviewed and merged, do a component release of drycc/workflow itself. The version number for drycc/workflow should always match the overall Workflow version number. Step 8: Close GitHub Milestones \u00b6 Create a pull request at seed-repo to close the release milestone and create the next one. When changes are merged to seed-repo, milestones on all relevant projects will be updated. If there are open issues attached to the milestone, move them to the next upcoming milestone before merging the pull request. Milestones map to Drycc Workflow releases in drycc/workflow . These milestones do not correspond to individual component release tags. Step 9: Release Workflow CLI Stable \u00b6 Now that the $WORKFLOW_RELEASE version of Workflow CLI has been vetted, we can push stable artifacts based on this version. Kick off https://ci.drycc.info/job/workflow-cli-build-stable/ with the TAG build parameter of $WORKFLOW_RELEASE and then verify stable artifacts are available and appropriately updated after the job completes: $ curl -sSL https://raw.githubusercontent.com/drycc/workflow-cli/master/install-v2.sh | bash -s v2.20.0 $ ./drycc version # (Should show $WORKFLOW_RELEASE) Step 10: Let Everyone Know \u00b6 Let the rest of the team know they can start blogging and tweeting about the new Workflow release. Post a message to the #company channel on Slack. Include a link to the released chart and to the master CHANGELOG: @here Drycc Workflow v2.17.0 is now live! Master CHANGELOG: https://drycc.info/docs/workflow/changelogs/v2.17.0/ You're done with the release. Nice job!","title":"Releases"},{"location":"roadmap/releases/#releases","text":"Drycc uses a continuous delivery approach for creating releases. Every merged commit that passes testing results in a deliverable that can be given a semantic version tag and shipped. The master git branch of a project should always work. Only changes considered ready to be released publicly are merged.","title":"Releases"},{"location":"roadmap/releases/#components-release-as-needed","text":"Drycc components release new versions as often as needed. Fixing a high priority bug requires the project maintainer to create a new patch release. Merging a backward-compatible feature implies a minor release. By releasing often, each component release becomes a safe and routine event. This makes it faster and easier for users to obtain specific fixes. Continuous delivery also reduces the work necessary to release a product such as Drycc Workflow, which integrates several components. \"Components\" applies not just to Drycc Workflow projects, but also to development and release tools, to Docker base images, and to other Drycc projects that do semantic version releases. See \" How to Release a Component \" for more detail.","title":"Components Release as Needed"},{"location":"roadmap/releases/#workflow-releases-each-month","text":"Drycc Workflow has a regular, public release cadence. From v2.8.0 onward, new Workflow feature releases arrive on the first Thursday of each month. Patch releases are created at any time, as needed. GitHub milestones are used to communicate the content and timing of major and minor releases, and longer-term planning is visible at the Roadmap . Workflow release timing is not linked to specific features. If a feature is merged before the release date, it is included in the next release. See \" How to Release Workflow \" for more detail.","title":"Workflow Releases Each Month"},{"location":"roadmap/releases/#semantic-versioning","text":"Drycc releases comply with semantic versioning , with the \"public API\" broadly defined as: REST, gRPC, or other API that is network-accessible Library or framework API intended for public use \"Pluggable\" socket-level protocols users can redirect CLI commands and output formats In general, changes to anything a user might reasonably link to, customize, or integrate with should be backward-compatible, or else require a major release. Drycc users can be confident that upgrading to a patch or to a minor release will not break anything.","title":"Semantic Versioning"},{"location":"roadmap/releases/#how-to-release-a-component","text":"Most Drycc projects are \"components\" which produce a Docker image or binary executable as a deliverable. This section leads a maintainer through creating a component release.","title":"How to Release a Component"},{"location":"roadmap/releases/#step-1-update-code-and-run-the-release-tool","text":"Major or minor releases should happen on the master branch. Patch releases should check out the previous release tag and cherry-pick specific commits from master. Note: if a patch release, the release artifact will have to be manually promoted by triggering the component-promote job with the following values: COMPONENT_NAME=<component name> COMPONENT_SHA=<patch commit sha> Make sure you have the dryccrel release tool in your search $PATH . Run dryccrel release once with a fake semver tag to proofread the changelog content. (If HEAD of master is not what is intended for the release, add the --sha flag as described in dryccrel release --help .) $ dryccrel release controller v0.0.0 Doing a dry run of the component release... skipping commit 943a49267eeb28546819a266654806cfcbae0e38 Creating changelog for controller with tag v2.8.1 through commit 943a49267eeb28546819a266654806cfcbae0e38 ### v2.8.1 -> v0.0.0 #### Fixes - [`615b834`](https://github.com/drycc/controller/commit/615b834f39cb68a854cc1f1e2f0f82d862ea2731) boot: Ensure DRYCC_DEBUG==true for debug output Based on the changelog content, determine whether the component deserves a minor or patch release. Run the command again with that semver tag and --dry-run=false . You will still be asked for confirmation before the release is created: $ dryccrel release controller v2.8.2 --dry-run=false skipping commit 943a49267eeb28546819a266654806cfcbae0e38 Creating changelog for controller with tag v2.8.1 through commit 943a49267eeb28546819a266654806cfcbae0e38 ### v2.8.1 -> v2.8.2 #### Fixes - [`615b834`](https://github.com/drycc/controller/commit/615b834f39cb68a854cc1f1e2f0f82d862ea2731) boot: Ensure DRYCC_DEBUG==true for debug output Please review the above changelog contents and ensure: 1. All intended commits are mentioned 2. The changes agree with the semver release tag (major, minor, or patch) Create release for Drycc Controller v2.8.2? [y/n]: y New release is available at https://github.com/drycc/controller/releases/tag/v2.8.2","title":"Step 1: Update Code and Run the Release Tool"},{"location":"roadmap/releases/#step-2-verify-the-component-is-available","text":"Tagging the component (see Step 1 ) starts a CI job that eventually results in an artifact being made available for public download. Please see the CI flow diagrams for details. Double-check that the artifact is available, either by a docker pull command or by running the appropriate installer script. If the artifact can't be downloaded, ensure that its CI release jobs are still in progress, or fix whatever issue arose in the pipeline. For example, the master merge pipeline may have failed to promote the :git-abc1d23 candidate image and needs to be restarted with that component and commit. If the component has a correlating Kubernetes Helm chart, this chart will also be packaged, signed and uploaded to its production chart repo. Please verify it can be fetched (and verified): $ helm repo add controller https://charts.drycc.cc/stable \"controller\" has been added to your repositories $ helm fetch --verify drycc/controller --version v1.0.1 Verification: &{0xc4207ec870 sha256:026e766e918ff28d2a7041bc3d560d149ee7eb0cb84165c9d9d00a3045ff45c3 controller-v2.17.0.tgz}","title":"Step 2: Verify the Component is Available"},{"location":"roadmap/releases/#how-to-release-workflow","text":"Drycc Workflow integrates multiple component releases together with a Kubernetes Helm chart deliverable. This section leads a maintainer through creating a Workflow release.","title":"How to Release Workflow"},{"location":"roadmap/releases/#step-1-set-environment-variables","text":"Export two environment variables that will be used in later steps: export WORKFLOW_RELEASE=v2.17.0 WORKFLOW_PREV_RELEASE=v2.16.0 # for example","title":"Step 1: Set Environment Variables"},{"location":"roadmap/releases/#step-2-tag-supporting-repositories","text":"Some Workflow components not in the Helm chart must also be tagged in sync with the release. Follow the component release process above and ensure that these components are tagged: drycc/workflow-cli drycc/workflow-e2e The version number for drycc/workflow-cli should always match the overall Workflow version number.","title":"Step 2: Tag Supporting Repositories"},{"location":"roadmap/releases/#step-3-create-helm-chart","text":"To create and stage a release candidate chart for Workflow, we will build the workflow-chart-stage job with the following parameters: RELEASE_TAG=$WORKFLOW_RELEASE This job will gather all of the latest component release tags and use these to specify the versions of all component charts. It will then package the Workflow chart, upload it to the staging chart repo and kick off an e2e run against said chart.","title":"Step 3: Create Helm Chart"},{"location":"roadmap/releases/#step-4-manual-testing","text":"Now it's time to go above and beyond current CI tests. Create a testing matrix spreadsheet (copying from the previous document is a good start) and sign up testers to cover all permutations. Testers should pay special attention to the overall user experience, make sure upgrading from earlier versions is smooth, and cover various storage configurations and Kubernetes versions and infrastructure providers. When showstopper-level bugs are found, the process is as follows: Create a component PR that fixes the bug. Once the PR passes and is reviewed, merge it and do a new component release Trigger the same workflow-chart-stage job as mentioned in Step 3 to upload the newly-generated Workflow release candidate chart to staging.","title":"Step 4: Manual Testing"},{"location":"roadmap/releases/#step-5-release-the-chart","text":"When testing has completed without uncovering any new showstopper bugs, kick off the workflow-chart-release job with the following parameter: RELEASE_TAG=$WORKFLOW_RELEASE This job will copy the release candidate chart (now approved by CI and manual testing) from the staging repo to the production repo, signing it if it has not done so already.","title":"Step 5: Release the Chart"},{"location":"roadmap/releases/#step-6-assemble-master-changelog","text":"Each component already updated its release notes on GitHub with CHANGELOG content. We'll now generate the master changelog for the Workflow chart, consisting of all component and auxilliary repo changes. We'll employ the requirements.lock file from the WORKFLOW_PREV_RELEASE chart, as well as a repo-to-chart-name mapping file , this time invoking dryccrel changelog global to get all component changes between the chart versions existing in the WORKFLOW_PREV_RELEASE chart and the most recent releases existing in GitHub. (Therefore, if there are any unreleased commits in a component repo, they will not appear here): helm repo add drycc https://charts.drycc.cc/stable helm fetch --untar drycc/workflow --version $WORKFLOW_PREV_RELEASE dryccrel changelog global workflow/requirements.lock map.json > changelog-$WORKFLOW_RELEASE.md This master changelog should then be placed into a single gist. The file will also be added to the documentation update PR created in the next step.","title":"Step 6: Assemble Master Changelog"},{"location":"roadmap/releases/#step-7-update-documentation","text":"Create a new pull request at drycc/workflow that updates version references to the new release. Use git grep $WORKFLOW_PREV_RELEASE to find any references, but be careful not to change CHANGELOG.md . Place the $WORKFLOW_RELEASE master changelog generated in Step 7 in the changelogs directory. Make sure to add a header to the page to make it clear that this is for a Workflow release, e.g.: ## Workflow v2.16.0 -> v2.17.0 Once the PR has been reviewed and merged, do a component release of drycc/workflow itself. The version number for drycc/workflow should always match the overall Workflow version number.","title":"Step 7: Update Documentation"},{"location":"roadmap/releases/#step-8-close-github-milestones","text":"Create a pull request at seed-repo to close the release milestone and create the next one. When changes are merged to seed-repo, milestones on all relevant projects will be updated. If there are open issues attached to the milestone, move them to the next upcoming milestone before merging the pull request. Milestones map to Drycc Workflow releases in drycc/workflow . These milestones do not correspond to individual component release tags.","title":"Step 8: Close GitHub Milestones"},{"location":"roadmap/releases/#step-9-release-workflow-cli-stable","text":"Now that the $WORKFLOW_RELEASE version of Workflow CLI has been vetted, we can push stable artifacts based on this version. Kick off https://ci.drycc.info/job/workflow-cli-build-stable/ with the TAG build parameter of $WORKFLOW_RELEASE and then verify stable artifacts are available and appropriately updated after the job completes: $ curl -sSL https://raw.githubusercontent.com/drycc/workflow-cli/master/install-v2.sh | bash -s v2.20.0 $ ./drycc version # (Should show $WORKFLOW_RELEASE)","title":"Step 9: Release Workflow CLI Stable"},{"location":"roadmap/releases/#step-10-let-everyone-know","text":"Let the rest of the team know they can start blogging and tweeting about the new Workflow release. Post a message to the #company channel on Slack. Include a link to the released chart and to the master CHANGELOG: @here Drycc Workflow v2.17.0 is now live! Master CHANGELOG: https://drycc.info/docs/workflow/changelogs/v2.17.0/ You're done with the release. Nice job!","title":"Step 10: Let Everyone Know"},{"location":"roadmap/roadmap/","text":"Drycc Workflow Roadmap \u00b6 The Drycc Workflow Roadmap is a community document created as part of the open Planning Process . Each roadmap item describes a high-level capability or grouping of features that are deemed important to the future of Drycc. Given the project's rapid Release Schedule , roadmap items are designed to provide a sense of direction over many releases. Interactive drycc run /bin/bash \u00b6 Provide the ability for developers to launch an interactive terminal session in their application environment. Related issues: https://github.com/drycc/workflow-cli/issues/28 https://github.com/drycc/drycc/issues/117 Log Streaming \u00b6 Stream application logs via drycc logs -f https://github.com/drycc/drycc/issues/465 Teams and Permissions \u00b6 Teams and Permissions represents a more flexible permissions model to allow more nuanced control to applications, capabilities and resources on the platform. There have been a number of proposals in this area which need to be reconciled for Drycc Workflow before we begin implementation. Related issues: Deploy Keys: https://github.com/drycc/drycc/issues/3875 Teams: https://github.com/drycc/drycc/issues/4173 Fine grained permissions: https://github.com/drycc/drycc/issues/4150 Admins create apps only: https://github.com/drycc/drycc/issues/4052 Admin Certificate Permissions: https://github.com/drycc/drycc/issues/4576#issuecomment-170987223 Monitoring \u00b6 Define and deliver alerts with Kapacitor: https://github.com/drycc/monitor/issues/44 Workflow Addons/Services \u00b6 Developers should be able to quickly and easily provision application dependencies using a services or addon abstraction. https://github.com/drycc/drycc/issues/231 Inbound/Outbound Webhooks \u00b6 Drycc Workflow should be able to send and receive webhooks from external systems. Facilitating integration with third party services like GitHub, Gitlab, Slack, Hipchat. Send webhook on platform events: https://github.com/drycc/drycc/issues/1486 (Workflow v2.10)","title":"Roadmap"},{"location":"roadmap/roadmap/#drycc-workflow-roadmap","text":"The Drycc Workflow Roadmap is a community document created as part of the open Planning Process . Each roadmap item describes a high-level capability or grouping of features that are deemed important to the future of Drycc. Given the project's rapid Release Schedule , roadmap items are designed to provide a sense of direction over many releases.","title":"Drycc Workflow Roadmap"},{"location":"roadmap/roadmap/#interactive-drycc-run-binbash","text":"Provide the ability for developers to launch an interactive terminal session in their application environment. Related issues: https://github.com/drycc/workflow-cli/issues/28 https://github.com/drycc/drycc/issues/117","title":"Interactive drycc run /bin/bash"},{"location":"roadmap/roadmap/#log-streaming","text":"Stream application logs via drycc logs -f https://github.com/drycc/drycc/issues/465","title":"Log Streaming"},{"location":"roadmap/roadmap/#teams-and-permissions","text":"Teams and Permissions represents a more flexible permissions model to allow more nuanced control to applications, capabilities and resources on the platform. There have been a number of proposals in this area which need to be reconciled for Drycc Workflow before we begin implementation. Related issues: Deploy Keys: https://github.com/drycc/drycc/issues/3875 Teams: https://github.com/drycc/drycc/issues/4173 Fine grained permissions: https://github.com/drycc/drycc/issues/4150 Admins create apps only: https://github.com/drycc/drycc/issues/4052 Admin Certificate Permissions: https://github.com/drycc/drycc/issues/4576#issuecomment-170987223","title":"Teams and Permissions"},{"location":"roadmap/roadmap/#monitoring","text":"Define and deliver alerts with Kapacitor: https://github.com/drycc/monitor/issues/44","title":"Monitoring"},{"location":"roadmap/roadmap/#workflow-addonsservices","text":"Developers should be able to quickly and easily provision application dependencies using a services or addon abstraction. https://github.com/drycc/drycc/issues/231","title":"Workflow Addons/Services"},{"location":"roadmap/roadmap/#inboundoutbound-webhooks","text":"Drycc Workflow should be able to send and receive webhooks from external systems. Facilitating integration with third party services like GitHub, Gitlab, Slack, Hipchat. Send webhook on platform events: https://github.com/drycc/drycc/issues/1486 (Workflow v2.10)","title":"Inbound/Outbound Webhooks"},{"location":"troubleshooting/","text":"Troubleshooting Workflow \u00b6 Common issues that users have run into when provisioning Workflow are detailed below. A Component Fails to Start \u00b6 For information on troubleshooting a failing component, see Troubleshooting with Kubectl . An Application Fails to Start \u00b6 For information on troubleshooting application deployment issues, see Troubleshooting Applications . Permission denied (publickey) \u00b6 The most common problem for this issue is the user forgetting to run drycc keys:add or add their private key to their SSH agent. To do so, run ssh-add ~/.ssh/id_rsa and try running git push drycc master again. If you happen get a Could not open a connection to your authentication agent error after trying to run ssh-add command above, you may need to load the SSH agent environment variables issuing the eval \"$(ssh-agent)\" command before. Other Issues \u00b6 Running into something not detailed here? Please open an issue or hop into #community on Slack for help!","title":"Troubleshooting Workflow"},{"location":"troubleshooting/#troubleshooting-workflow","text":"Common issues that users have run into when provisioning Workflow are detailed below.","title":"Troubleshooting Workflow"},{"location":"troubleshooting/#a-component-fails-to-start","text":"For information on troubleshooting a failing component, see Troubleshooting with Kubectl .","title":"A Component Fails to Start"},{"location":"troubleshooting/#an-application-fails-to-start","text":"For information on troubleshooting application deployment issues, see Troubleshooting Applications .","title":"An Application Fails to Start"},{"location":"troubleshooting/#permission-denied-publickey","text":"The most common problem for this issue is the user forgetting to run drycc keys:add or add their private key to their SSH agent. To do so, run ssh-add ~/.ssh/id_rsa and try running git push drycc master again. If you happen get a Could not open a connection to your authentication agent error after trying to run ssh-add command above, you may need to load the SSH agent environment variables issuing the eval \"$(ssh-agent)\" command before.","title":"Permission denied (publickey)"},{"location":"troubleshooting/#other-issues","text":"Running into something not detailed here? Please open an issue or hop into #community on Slack for help!","title":"Other Issues"},{"location":"troubleshooting/applications/","text":"Troubleshooting Applications \u00b6 This document describes how one can troubleshoot common issues when deploying or debugging an application that fails to start or deploy. Application has a Dockerfile, but a Buildpack Deployment Occurs \u00b6 When you deploy an application to Workflow using git push drycc master and the Builder attempts to deploy using the Buildpack workflow, check the following steps: Are you deploying the correct project? Are you pushing the correct git branch ( git push drycc <branch> )? Is the Dockerfile in the project's root directory? Have you committed the Dockerfile to the project? Application was Deployed, but is Failing to Start \u00b6 If you deployed your application but it is failing to start, you can use drycc logs to check why the application fails to boot. Sometimes, the application container may fail to boot without logging any information about the error. This typically occurs when the healthcheck configured for the application fails. In this case, you can start by troubleshooting using kubectl . You can inspect the application's current state by examining the pod deployed in the application's namespace. To do that, run $ kubectl --namespace=myapp get pods NAME READY STATUS RESTARTS AGE myapp-cmd-1585713350-3brbo 0/1 CrashLoopBackOff 2 43s We can then describe the pod and determine why it is failing to boot: Events: FirstSeen LastSeen Count From SubobjectPath Type Reason Message --------- -------- ----- ---- ------------- -------- ------ ------- 43s 43s 1 {default-scheduler } Normal Scheduled Successfully assigned myapp-cmd-1585713350-3brbo to kubernetes-node-1 41s 41s 1 {kubelet kubernetes-node-1} spec.containers{myapp-cmd} Normal Created Created container with docker id b86bd851a61f 41s 41s 1 {kubelet kubernetes-node-1} spec.containers{myapp-cmd} Normal Started Started container with docker id b86bd851a61f 37s 35s 1 {kubelet kubernetes-node-1} spec.containers{myapp-cmd} Warning Unhealthy Liveness probe failed: Get http://10.246.39.13:8000/healthz: dial tcp 10.246.39.13:8000: getsockopt: connection refused In this instance, we set the healthcheck initial delay timeout for the application at 1 second, which is too aggressive. The application needs some time to set up the API server after the container has booted. By increasing the healthcheck initial delay timeout to 10 seconds, the application is able to boot and is responding correctly. See Custom Health Checks for more information on how to customize the application's health checks to better suit the application's needs.","title":"Troubleshooting Applications"},{"location":"troubleshooting/applications/#troubleshooting-applications","text":"This document describes how one can troubleshoot common issues when deploying or debugging an application that fails to start or deploy.","title":"Troubleshooting Applications"},{"location":"troubleshooting/applications/#application-has-a-dockerfile-but-a-buildpack-deployment-occurs","text":"When you deploy an application to Workflow using git push drycc master and the Builder attempts to deploy using the Buildpack workflow, check the following steps: Are you deploying the correct project? Are you pushing the correct git branch ( git push drycc <branch> )? Is the Dockerfile in the project's root directory? Have you committed the Dockerfile to the project?","title":"Application has a Dockerfile, but a Buildpack Deployment Occurs"},{"location":"troubleshooting/applications/#application-was-deployed-but-is-failing-to-start","text":"If you deployed your application but it is failing to start, you can use drycc logs to check why the application fails to boot. Sometimes, the application container may fail to boot without logging any information about the error. This typically occurs when the healthcheck configured for the application fails. In this case, you can start by troubleshooting using kubectl . You can inspect the application's current state by examining the pod deployed in the application's namespace. To do that, run $ kubectl --namespace=myapp get pods NAME READY STATUS RESTARTS AGE myapp-cmd-1585713350-3brbo 0/1 CrashLoopBackOff 2 43s We can then describe the pod and determine why it is failing to boot: Events: FirstSeen LastSeen Count From SubobjectPath Type Reason Message --------- -------- ----- ---- ------------- -------- ------ ------- 43s 43s 1 {default-scheduler } Normal Scheduled Successfully assigned myapp-cmd-1585713350-3brbo to kubernetes-node-1 41s 41s 1 {kubelet kubernetes-node-1} spec.containers{myapp-cmd} Normal Created Created container with docker id b86bd851a61f 41s 41s 1 {kubelet kubernetes-node-1} spec.containers{myapp-cmd} Normal Started Started container with docker id b86bd851a61f 37s 35s 1 {kubelet kubernetes-node-1} spec.containers{myapp-cmd} Warning Unhealthy Liveness probe failed: Get http://10.246.39.13:8000/healthz: dial tcp 10.246.39.13:8000: getsockopt: connection refused In this instance, we set the healthcheck initial delay timeout for the application at 1 second, which is too aggressive. The application needs some time to set up the API server after the container has booted. By increasing the healthcheck initial delay timeout to 10 seconds, the application is able to boot and is responding correctly. See Custom Health Checks for more information on how to customize the application's health checks to better suit the application's needs.","title":"Application was Deployed, but is Failing to Start"},{"location":"troubleshooting/kubectl/","text":"Troubleshooting using Kubectl \u00b6 This document describes how one can use kubectl to debug any issues with the cluster. Diving into the Components \u00b6 Using kubectl , one can inspect the cluster's current state. When Workflow is installed with helm , Workflow is installed into the drycc namespace. To inspect if Workflow is running, run: $ kubectl --namespace=drycc get pods NAME READY STATUS RESTARTS AGE drycc-builder-gqum7 0/1 ContainerCreating 0 4s drycc-controller-h6lk6 0/1 ContainerCreating 0 4s drycc-database-56v39 0/1 ContainerCreating 0 4s drycc-logger-fluentd-xihr1 0/1 Pending 0 2s drycc-logger-grupg 0/1 ContainerCreating 0 3s drycc-minio-c2exb 0/1 Pending 0 3s drycc-monitor-grafana-9ccur 0/1 Pending 0 3s drycc-monitor-influxdb-f9ftm 0/1 Pending 0 3s drycc-monitor-stdout-novxs 0/1 Pending 0 3s drycc-monitor-telegraf-dc3y3 0/1 Pending 0 2s drycc-registry-5bor6 0/1 Pending 0 3s Tip To save precious keystrokes, alias kubectl --namespace=drycc to kd so it is easier to type in the future. To fetch the logs of a specific component, use kubectl logs : $ kubectl --namespace=drycc logs drycc-controller-h6lk6 system information: Django Version: 1.9.6 Python 3.5.1 addgroup: gid '0' in use Django checks: System check identified no issues (2 silenced). [...] To dive into a running container to inspect its environment, use kubectl exec : $ kubectl --namespace=drycc exec -it drycc-database-56v39 gosu postgres psql psql (9.4.7) Type \"help\" for help. postgres=# \\l List of databases Name | Owner | Encoding | Collate | Ctype | Access privileges ----------------------------------+----------+----------+------------+------------+----------------------- V7wckOHIAn3MZ7mO5du4q5IRq7yib1Oc | postgres | UTF8 | en_US.utf8 | en_US.utf8 | postgres | postgres | UTF8 | en_US.utf8 | en_US.utf8 | template0 | postgres | UTF8 | en_US.utf8 | en_US.utf8 | =c/postgres + | | | | | postgres=CTc/postgres template1 | postgres | UTF8 | en_US.utf8 | en_US.utf8 | =c/postgres + | | | | | postgres=CTc/postgres (4 rows) postgres=# \\connect V7wckOHIAn3MZ7mO5du4q5IRq7yib1Oc You are now connected to database \"V7wckOHIAn3MZ7mO5du4q5IRq7yib1Oc\" as user \"postgres\". V7wckOHIAn3MZ7mO5du4q5IRq7yib1Oc=# \\dt List of relations Schema | Name | Type | Owner --------+--------------------------------+-------+---------------------------------- public | api_app | table | V7wckOHIAn3MZ7mO5du4q5IRq7yib1Oc public | api_build | table | V7wckOHIAn3MZ7mO5du4q5IRq7yib1Oc public | api_certificate | table | V7wckOHIAn3MZ7mO5du4q5IRq7yib1Oc public | api_config | table | V7wckOHIAn3MZ7mO5du4q5IRq7yib1Oc public | api_domain | table | V7wckOHIAn3MZ7mO5du4q5IRq7yib1Oc public | api_key | table | V7wckOHIAn3MZ7mO5du4q5IRq7yib1Oc public | api_push | table | V7wckOHIAn3MZ7mO5du4q5IRq7yib1Oc public | api_release | table | V7wckOHIAn3MZ7mO5du4q5IRq7yib1Oc public | auth_group | table | V7wckOHIAn3MZ7mO5du4q5IRq7yib1Oc --More-- V7wckOHIAn3MZ7mO5du4q5IRq7yib1Oc=# SELECT COUNT(*) from api_app; count ------- 0 (1 row)","title":"Troubleshooting using Kubectl"},{"location":"troubleshooting/kubectl/#troubleshooting-using-kubectl","text":"This document describes how one can use kubectl to debug any issues with the cluster.","title":"Troubleshooting using Kubectl"},{"location":"troubleshooting/kubectl/#diving-into-the-components","text":"Using kubectl , one can inspect the cluster's current state. When Workflow is installed with helm , Workflow is installed into the drycc namespace. To inspect if Workflow is running, run: $ kubectl --namespace=drycc get pods NAME READY STATUS RESTARTS AGE drycc-builder-gqum7 0/1 ContainerCreating 0 4s drycc-controller-h6lk6 0/1 ContainerCreating 0 4s drycc-database-56v39 0/1 ContainerCreating 0 4s drycc-logger-fluentd-xihr1 0/1 Pending 0 2s drycc-logger-grupg 0/1 ContainerCreating 0 3s drycc-minio-c2exb 0/1 Pending 0 3s drycc-monitor-grafana-9ccur 0/1 Pending 0 3s drycc-monitor-influxdb-f9ftm 0/1 Pending 0 3s drycc-monitor-stdout-novxs 0/1 Pending 0 3s drycc-monitor-telegraf-dc3y3 0/1 Pending 0 2s drycc-registry-5bor6 0/1 Pending 0 3s Tip To save precious keystrokes, alias kubectl --namespace=drycc to kd so it is easier to type in the future. To fetch the logs of a specific component, use kubectl logs : $ kubectl --namespace=drycc logs drycc-controller-h6lk6 system information: Django Version: 1.9.6 Python 3.5.1 addgroup: gid '0' in use Django checks: System check identified no issues (2 silenced). [...] To dive into a running container to inspect its environment, use kubectl exec : $ kubectl --namespace=drycc exec -it drycc-database-56v39 gosu postgres psql psql (9.4.7) Type \"help\" for help. postgres=# \\l List of databases Name | Owner | Encoding | Collate | Ctype | Access privileges ----------------------------------+----------+----------+------------+------------+----------------------- V7wckOHIAn3MZ7mO5du4q5IRq7yib1Oc | postgres | UTF8 | en_US.utf8 | en_US.utf8 | postgres | postgres | UTF8 | en_US.utf8 | en_US.utf8 | template0 | postgres | UTF8 | en_US.utf8 | en_US.utf8 | =c/postgres + | | | | | postgres=CTc/postgres template1 | postgres | UTF8 | en_US.utf8 | en_US.utf8 | =c/postgres + | | | | | postgres=CTc/postgres (4 rows) postgres=# \\connect V7wckOHIAn3MZ7mO5du4q5IRq7yib1Oc You are now connected to database \"V7wckOHIAn3MZ7mO5du4q5IRq7yib1Oc\" as user \"postgres\". V7wckOHIAn3MZ7mO5du4q5IRq7yib1Oc=# \\dt List of relations Schema | Name | Type | Owner --------+--------------------------------+-------+---------------------------------- public | api_app | table | V7wckOHIAn3MZ7mO5du4q5IRq7yib1Oc public | api_build | table | V7wckOHIAn3MZ7mO5du4q5IRq7yib1Oc public | api_certificate | table | V7wckOHIAn3MZ7mO5du4q5IRq7yib1Oc public | api_config | table | V7wckOHIAn3MZ7mO5du4q5IRq7yib1Oc public | api_domain | table | V7wckOHIAn3MZ7mO5du4q5IRq7yib1Oc public | api_key | table | V7wckOHIAn3MZ7mO5du4q5IRq7yib1Oc public | api_push | table | V7wckOHIAn3MZ7mO5du4q5IRq7yib1Oc public | api_release | table | V7wckOHIAn3MZ7mO5du4q5IRq7yib1Oc public | auth_group | table | V7wckOHIAn3MZ7mO5du4q5IRq7yib1Oc --More-- V7wckOHIAn3MZ7mO5du4q5IRq7yib1Oc=# SELECT COUNT(*) from api_app; count ------- 0 (1 row)","title":"Diving into the Components"},{"location":"understanding-workflow/architecture/","text":"Architecture \u00b6 Drycc Workflow is built using a service oriented architecture. All components are published as a set of container images which can be deployed to any compliant Kubernetes cluster. Overview \u00b6 Operators use Helm to configure and install the Workflow components which interface directly with the underlying Kubernetes cluster. Service discovery, container availability and networking are all delegated to Kubernetes, while Workflow provides a clean and simple developer experience. Platform Services \u00b6 Drycc Workflow provides additional functionality to your Kubernetes cluster, including: Source to Image Builder which compiles your Application code via Buildpacks or Dockerfiles Cross-Pod Log Aggregation which gathers logs from all of your Application processes Simple REST API which powers the CLI and any external integrations Application release and rollback Authentication and Authorization to Application resources HTTP/HTTPS edge routing for your Applications Kubernetes-Native \u00b6 All platform components and applications deployed via Workflow expect to be running on an existing Kubernetes cluster. This means that you can happily run your Kubernetes-native workloads next to applications that are managed through Drycc Workflow. Application Layout and Edge Routing \u00b6 By default Workflow creates per-application Namespaces and Services so you can easily connect your applications to other on-cluster services through standard Kubernetes mechanisms. The router component is responsible for routing HTTP/s traffic to your Applications as well as proxying git push and platform API traffic. By default, the router component is deployed as a Kubernetes service with type LoadBalancer ; which, depending on your configuration, will provision a cloud-native load balancer automatically. The router automatically discovers routable Applications, SSL/TLS certificates and application-specific configurations through the use of Kubernetes annotations. Any changes to router configuration or certificates are applied within seconds. Topologies \u00b6 Drycc Workflow no longer dictates a specific topology or server count for your deployment. The platform components will happily run on single-server configurations as well as multi-server production clusters.","title":"Architecture"},{"location":"understanding-workflow/architecture/#architecture","text":"Drycc Workflow is built using a service oriented architecture. All components are published as a set of container images which can be deployed to any compliant Kubernetes cluster.","title":"Architecture"},{"location":"understanding-workflow/architecture/#overview","text":"Operators use Helm to configure and install the Workflow components which interface directly with the underlying Kubernetes cluster. Service discovery, container availability and networking are all delegated to Kubernetes, while Workflow provides a clean and simple developer experience.","title":"Overview"},{"location":"understanding-workflow/architecture/#platform-services","text":"Drycc Workflow provides additional functionality to your Kubernetes cluster, including: Source to Image Builder which compiles your Application code via Buildpacks or Dockerfiles Cross-Pod Log Aggregation which gathers logs from all of your Application processes Simple REST API which powers the CLI and any external integrations Application release and rollback Authentication and Authorization to Application resources HTTP/HTTPS edge routing for your Applications","title":"Platform Services"},{"location":"understanding-workflow/architecture/#kubernetes-native","text":"All platform components and applications deployed via Workflow expect to be running on an existing Kubernetes cluster. This means that you can happily run your Kubernetes-native workloads next to applications that are managed through Drycc Workflow.","title":"Kubernetes-Native"},{"location":"understanding-workflow/architecture/#application-layout-and-edge-routing","text":"By default Workflow creates per-application Namespaces and Services so you can easily connect your applications to other on-cluster services through standard Kubernetes mechanisms. The router component is responsible for routing HTTP/s traffic to your Applications as well as proxying git push and platform API traffic. By default, the router component is deployed as a Kubernetes service with type LoadBalancer ; which, depending on your configuration, will provision a cloud-native load balancer automatically. The router automatically discovers routable Applications, SSL/TLS certificates and application-specific configurations through the use of Kubernetes annotations. Any changes to router configuration or certificates are applied within seconds.","title":"Application Layout and Edge Routing"},{"location":"understanding-workflow/architecture/#topologies","text":"Drycc Workflow no longer dictates a specific topology or server count for your deployment. The platform components will happily run on single-server configurations as well as multi-server production clusters.","title":"Topologies"},{"location":"understanding-workflow/components/","text":"Components \u00b6 Workflow is comprised of a number of small, independent services that combine to create a distributed PaaS. All Workflow components are deployed as services (and associated controllers) in your Kubernetes cluster. If you are interested we have a more detailed exploration of the Workflow architecture . All of the componentry for Workflow is built with composability in mind. If you need to customize one of the components for your specific deployment or need the functionality in your own project we invite you to give it a shot! Controller \u00b6 Project Location: drycc/controller The controller component is an HTTP API server which serves as the endpoint for the drycc CLI. The controller provides all of the platform functionality as well as interfacing with your Kubernetes cluster. The controller persists all of its data to the database component. Database \u00b6 Project Location: drycc/postgres The database component is a managed instance of PostgreSQL which holds a majority of the platforms state. Backups and WAL files are pushed to object storage via WAL-E . When the database is restarted, backups are fetched and replayed from object storage so no data is lost. Builder \u00b6 Project Location: drycc/builder The builder component is responsible for accepting code pushes via Git and managing the build process of your Application . The builder process is: Receives incoming git push requests over SSH Authenticates the user via SSH key fingerprint Authorizes the user's access to push code to the Application Starts the Application Build phase (see below) Triggers a new Release via the Controller Builder currently supports both buildpack and Dockerfile based builds. Project Location: drycc/slugbuilder For Buildpack-based deploys, the builder component will launch a one-shot Pod in the drycc namespace. This pod runs slugbuilder component which handles default and custom buildpacks (specified by .buildpacks ). The \"compiled\" application results in a slug, consisting of your application code and all of its dependencies as determined by the buildpack. The slug is pushed to the cluster-configured object storage for later execution. For more information about buildpacks see using buildpacks . Project Location: drycc/dockerbuilder For Applications which contain a Dockerfile in the root of the repository, builder will instead launch the dockerbuilder to package your application. Instead of generating a slug, dockerbuilder generates a Docker image (using the underlying Docker engine). The completed image is pushed to the managed Docker registry on cluster. For more information see using Dockerfiles . Slugrunner \u00b6 Project Location: drycc/slugrunner Slugrunner is the component responsible for executing buildpack-based Applications. Slugrunner receives slug information from the controller and downloads the application slug just before launching your application processes. Object Storage \u00b6 Project Location: drycc/minio All of the Workflow components that need to persist data will ship them to the object storage that was configured for the cluster.For example, database ships its WAL files, registry stores Docker images, and slugbuilder stores slugs. Workflow supports either on or off-cluster storage. For production deployments we highly recommend that you configure off-cluster object storage . To facilitate experimentation, development and test environments, the default charts for Workflow include on-cluster object storage via minio . If you also feel comfortable using Kubernetes persistent volumes you may configure minio to use persistent storage available in your environment. Registry \u00b6 Project Location: drycc/registry The registry component is a managed docker registry which holds application images generated from the builder component. Registry persists the Docker image images to either local storage (in development mode) or to object storage configured for the cluster. Router \u00b6 Project Location: drycc/router The router component is based on Nginx and is responsible for routing inbound HTTP(S) traffic to your applications. The default workflow charts provision a Kubernetes service in the drycc namespace with a service type of LoadBalancer . Depending on your Kubernetes configuration, this may provision a cloud-based loadbalancer automatically. The router component uses Kubernetes annotations for both Application discovery as well as router configuration. For more detailed documentation and possible configuration view the router project documentation . Logger: fluentd, logger \u00b6 The logging subsystem consists of two components. Fluentd handles log shipping and logger maintains a ring-buffer of application logs. Project Location: drycc/fluentd Fluentd is deployed to your Kubernetes cluster via Daemon Sets. Fluentd subscribes to all container logs, decorates the output with Kubernetes metadata and can be configured to drain logs to multiple destinations. By default, fluentd ships logs to the logger component, which powers drycc logs . Project Location: drycc/logger The logger component receives log streams from fluentd , collating by Application name. Logger does not persist logs to disk, instead maintaining an in-memory ring buffer. For more information on logger see the project documentation . Monitor \u00b6 Project Location: drycc/monitor The monitoring subsystem consists of three components: Telegraf, InfluxDB and Grafana. Telegraf is the is the metrics collection agent that runs using the daemon set API. It runs on every worker node in the cluster, fetches information about the pods currently running and ships it to InfluxDB. InfluxDB is a database that stores the metrics collected by Telegraf. Out of the box, it does not persist to disk, but you can set it up to back it with a persisitent volume or swap this out with a more robust InfluxDB setup in a production setting. Grafana is a standalone graphing application. It natively supports InfluxDB as a datasource and provides a robust engine for creating dashboards on top of timeseries data. Workflow provides a few dashboards out of the box for monitoring Drycc Workflow and Kubernetes. The dashboards can be used as a starting point for creating more custom dashboards to suit a user's needs. See Also \u00b6 Workflow Concepts Workflow Architecture","title":"Components"},{"location":"understanding-workflow/components/#components","text":"Workflow is comprised of a number of small, independent services that combine to create a distributed PaaS. All Workflow components are deployed as services (and associated controllers) in your Kubernetes cluster. If you are interested we have a more detailed exploration of the Workflow architecture . All of the componentry for Workflow is built with composability in mind. If you need to customize one of the components for your specific deployment or need the functionality in your own project we invite you to give it a shot!","title":"Components"},{"location":"understanding-workflow/components/#controller","text":"Project Location: drycc/controller The controller component is an HTTP API server which serves as the endpoint for the drycc CLI. The controller provides all of the platform functionality as well as interfacing with your Kubernetes cluster. The controller persists all of its data to the database component.","title":"Controller"},{"location":"understanding-workflow/components/#database","text":"Project Location: drycc/postgres The database component is a managed instance of PostgreSQL which holds a majority of the platforms state. Backups and WAL files are pushed to object storage via WAL-E . When the database is restarted, backups are fetched and replayed from object storage so no data is lost.","title":"Database"},{"location":"understanding-workflow/components/#builder","text":"Project Location: drycc/builder The builder component is responsible for accepting code pushes via Git and managing the build process of your Application . The builder process is: Receives incoming git push requests over SSH Authenticates the user via SSH key fingerprint Authorizes the user's access to push code to the Application Starts the Application Build phase (see below) Triggers a new Release via the Controller Builder currently supports both buildpack and Dockerfile based builds. Project Location: drycc/slugbuilder For Buildpack-based deploys, the builder component will launch a one-shot Pod in the drycc namespace. This pod runs slugbuilder component which handles default and custom buildpacks (specified by .buildpacks ). The \"compiled\" application results in a slug, consisting of your application code and all of its dependencies as determined by the buildpack. The slug is pushed to the cluster-configured object storage for later execution. For more information about buildpacks see using buildpacks . Project Location: drycc/dockerbuilder For Applications which contain a Dockerfile in the root of the repository, builder will instead launch the dockerbuilder to package your application. Instead of generating a slug, dockerbuilder generates a Docker image (using the underlying Docker engine). The completed image is pushed to the managed Docker registry on cluster. For more information see using Dockerfiles .","title":"Builder"},{"location":"understanding-workflow/components/#slugrunner","text":"Project Location: drycc/slugrunner Slugrunner is the component responsible for executing buildpack-based Applications. Slugrunner receives slug information from the controller and downloads the application slug just before launching your application processes.","title":"Slugrunner"},{"location":"understanding-workflow/components/#object-storage","text":"Project Location: drycc/minio All of the Workflow components that need to persist data will ship them to the object storage that was configured for the cluster.For example, database ships its WAL files, registry stores Docker images, and slugbuilder stores slugs. Workflow supports either on or off-cluster storage. For production deployments we highly recommend that you configure off-cluster object storage . To facilitate experimentation, development and test environments, the default charts for Workflow include on-cluster object storage via minio . If you also feel comfortable using Kubernetes persistent volumes you may configure minio to use persistent storage available in your environment.","title":"Object Storage"},{"location":"understanding-workflow/components/#registry","text":"Project Location: drycc/registry The registry component is a managed docker registry which holds application images generated from the builder component. Registry persists the Docker image images to either local storage (in development mode) or to object storage configured for the cluster.","title":"Registry"},{"location":"understanding-workflow/components/#router","text":"Project Location: drycc/router The router component is based on Nginx and is responsible for routing inbound HTTP(S) traffic to your applications. The default workflow charts provision a Kubernetes service in the drycc namespace with a service type of LoadBalancer . Depending on your Kubernetes configuration, this may provision a cloud-based loadbalancer automatically. The router component uses Kubernetes annotations for both Application discovery as well as router configuration. For more detailed documentation and possible configuration view the router project documentation .","title":"Router"},{"location":"understanding-workflow/components/#logger-fluentd-logger","text":"The logging subsystem consists of two components. Fluentd handles log shipping and logger maintains a ring-buffer of application logs. Project Location: drycc/fluentd Fluentd is deployed to your Kubernetes cluster via Daemon Sets. Fluentd subscribes to all container logs, decorates the output with Kubernetes metadata and can be configured to drain logs to multiple destinations. By default, fluentd ships logs to the logger component, which powers drycc logs . Project Location: drycc/logger The logger component receives log streams from fluentd , collating by Application name. Logger does not persist logs to disk, instead maintaining an in-memory ring buffer. For more information on logger see the project documentation .","title":"Logger: fluentd, logger"},{"location":"understanding-workflow/components/#monitor","text":"Project Location: drycc/monitor The monitoring subsystem consists of three components: Telegraf, InfluxDB and Grafana. Telegraf is the is the metrics collection agent that runs using the daemon set API. It runs on every worker node in the cluster, fetches information about the pods currently running and ships it to InfluxDB. InfluxDB is a database that stores the metrics collected by Telegraf. Out of the box, it does not persist to disk, but you can set it up to back it with a persisitent volume or swap this out with a more robust InfluxDB setup in a production setting. Grafana is a standalone graphing application. It natively supports InfluxDB as a datasource and provides a robust engine for creating dashboards on top of timeseries data. Workflow provides a few dashboards out of the box for monitoring Drycc Workflow and Kubernetes. The dashboards can be used as a starting point for creating more custom dashboards to suit a user's needs.","title":"Monitor"},{"location":"understanding-workflow/components/#see-also","text":"Workflow Concepts Workflow Architecture","title":"See Also"},{"location":"understanding-workflow/concepts/","text":"Concepts \u00b6 Drycc Workflow is a lightweight application platform that deploys and scales Twelve-Factor apps as containers across a Kubernetes cluster. Twelve-Factor Applications \u00b6 The Twelve-Factor App is a methodology for building modern applications that can be scaled across a distributed system. Twelve-factor is a valuable synthesis of years of experience with software-as-a-service apps in the wild, particularly on the Heroku platform. Workflow is designed to run applications that adhere to the Twelve-Factor App methodology and best practices. Kubernetes \u00b6 Kubernetes is an open-source cluster manager developed by Google and donated to the Cloud Native Compute Foundation . Kubernetes manages all the activity on your cluster, including: desired state convergence, stable service addresses, health monitoring, service discovery, and DNS resolution. Workflow builds upon Kubernetes abstractions like Services, Deployments and Pods to provide a developer-friendly experience. Building containers directly from application source code, aggregating logs, and managing deployment configurations and app releases are just some of the features Workflow adds. Drycc Workflow is a set of Kubernetes-native components, installable via Helm . Systems engineers who are familiar with Kubernetes will feel right at home running Workflow. See the components overview for more detail. Docker \u00b6 Docker is an open source project to build, ship and run any application as a lightweight, portable, self-sufficient container. If you have not yet converted your application to containers, Workflow provides a simple and straightforward \"source to Docker image\" capability. Supporting multiple language runtimes via community buildpacks , building your application in a container can be as easy as git push drycc master . Applications which are packaged via a buildpack are run in Docker containers as part of the slugrunner process. View the slugrunner component for more information. Applications which use either a Dockerfile or reference external Docker images are launched unmodified. Applications \u00b6 Workflow is designed around the concept of an application , or app. Applications come in one of three forms: a collection of source files stored in a git repository a Dockerfile and associated source files stored in a git repository a reference to an existing image at a Docker repository Applications are identified by a unique name for easy reference. If you do not specify a name when creating your application, Workflow generates one for you. Workflow also manages related information, including domain names, SSL certificates, and developer-provided configuration. Build, Release, Run \u00b6 Build Stage \u00b6 The builder component processes incoming git push drycc master requests and manages your application packaging. If your application is using a buildpack , builder will launch an ephemeral job to extract and execute the packaging instructions. The resulting application artifact is stored by the platform for execution during the run stage. If instead builder finds a Dockerfile , it follows those instructions to create a Docker image. The resulting artifact is stored in a Drycc-managed registry which will be referenced during the run stage. If another system already builds and packages your application, that container artifact can be used directly. When referencing an external Docker image , the builder component doesn't attempt to repackage your app. Release Stage \u00b6 During the release stage, a build is combined with application configuration to create a new, numbered release . New releases are created any time a new build is created or application configuration is changed. Tracking releases as a \"write-only ledger\" this way makes it easy to rollback to any previous release. Run Stage \u00b6 The run stage deploys the new release to the underlying Kubernetes cluster by changing the Deployment object which references the new release. By managing the desired replica count, Workflow orchestrates a zero-downtime, rolling update of your application. Once successfully updated, Workflow removes the last reference to the old release. Note that during the deploy, your application will be running in a mixed mode. Backing Services \u00b6 Workflow treats all persistent services such as databases, caches, storage, messaging systems, and other backing services as resources managed separately from your application. This philosophy aligns with Twelve-Factor best practices. Applications attach to backing services using environment variables . Because apps are decoupled from backing services, they are free to scale up independently, to use services provided by other apps, or to switch to external or third-party vendor services. See Also \u00b6 Workflow Architecture Workflow Components","title":"Concepts"},{"location":"understanding-workflow/concepts/#concepts","text":"Drycc Workflow is a lightweight application platform that deploys and scales Twelve-Factor apps as containers across a Kubernetes cluster.","title":"Concepts"},{"location":"understanding-workflow/concepts/#twelve-factor-applications","text":"The Twelve-Factor App is a methodology for building modern applications that can be scaled across a distributed system. Twelve-factor is a valuable synthesis of years of experience with software-as-a-service apps in the wild, particularly on the Heroku platform. Workflow is designed to run applications that adhere to the Twelve-Factor App methodology and best practices.","title":"Twelve-Factor Applications"},{"location":"understanding-workflow/concepts/#kubernetes","text":"Kubernetes is an open-source cluster manager developed by Google and donated to the Cloud Native Compute Foundation . Kubernetes manages all the activity on your cluster, including: desired state convergence, stable service addresses, health monitoring, service discovery, and DNS resolution. Workflow builds upon Kubernetes abstractions like Services, Deployments and Pods to provide a developer-friendly experience. Building containers directly from application source code, aggregating logs, and managing deployment configurations and app releases are just some of the features Workflow adds. Drycc Workflow is a set of Kubernetes-native components, installable via Helm . Systems engineers who are familiar with Kubernetes will feel right at home running Workflow. See the components overview for more detail.","title":"Kubernetes"},{"location":"understanding-workflow/concepts/#docker","text":"Docker is an open source project to build, ship and run any application as a lightweight, portable, self-sufficient container. If you have not yet converted your application to containers, Workflow provides a simple and straightforward \"source to Docker image\" capability. Supporting multiple language runtimes via community buildpacks , building your application in a container can be as easy as git push drycc master . Applications which are packaged via a buildpack are run in Docker containers as part of the slugrunner process. View the slugrunner component for more information. Applications which use either a Dockerfile or reference external Docker images are launched unmodified.","title":"Docker"},{"location":"understanding-workflow/concepts/#applications","text":"Workflow is designed around the concept of an application , or app. Applications come in one of three forms: a collection of source files stored in a git repository a Dockerfile and associated source files stored in a git repository a reference to an existing image at a Docker repository Applications are identified by a unique name for easy reference. If you do not specify a name when creating your application, Workflow generates one for you. Workflow also manages related information, including domain names, SSL certificates, and developer-provided configuration.","title":"Applications"},{"location":"understanding-workflow/concepts/#build-release-run","text":"","title":"Build, Release, Run"},{"location":"understanding-workflow/concepts/#build-stage","text":"The builder component processes incoming git push drycc master requests and manages your application packaging. If your application is using a buildpack , builder will launch an ephemeral job to extract and execute the packaging instructions. The resulting application artifact is stored by the platform for execution during the run stage. If instead builder finds a Dockerfile , it follows those instructions to create a Docker image. The resulting artifact is stored in a Drycc-managed registry which will be referenced during the run stage. If another system already builds and packages your application, that container artifact can be used directly. When referencing an external Docker image , the builder component doesn't attempt to repackage your app.","title":"Build Stage"},{"location":"understanding-workflow/concepts/#release-stage","text":"During the release stage, a build is combined with application configuration to create a new, numbered release . New releases are created any time a new build is created or application configuration is changed. Tracking releases as a \"write-only ledger\" this way makes it easy to rollback to any previous release.","title":"Release Stage"},{"location":"understanding-workflow/concepts/#run-stage","text":"The run stage deploys the new release to the underlying Kubernetes cluster by changing the Deployment object which references the new release. By managing the desired replica count, Workflow orchestrates a zero-downtime, rolling update of your application. Once successfully updated, Workflow removes the last reference to the old release. Note that during the deploy, your application will be running in a mixed mode.","title":"Run Stage"},{"location":"understanding-workflow/concepts/#backing-services","text":"Workflow treats all persistent services such as databases, caches, storage, messaging systems, and other backing services as resources managed separately from your application. This philosophy aligns with Twelve-Factor best practices. Applications attach to backing services using environment variables . Because apps are decoupled from backing services, they are free to scale up independently, to use services provided by other apps, or to switch to external or third-party vendor services.","title":"Backing Services"},{"location":"understanding-workflow/concepts/#see-also","text":"Workflow Architecture Workflow Components","title":"See Also"},{"location":"users/cli/","text":"Drycc Workflow CLI \u00b6 The Drycc Workflow command-line interface (CLI), or client, allows you to interact with Drycc Workflow. Installation \u00b6 Install the latest drycc client for Linux or Mac OS X with: $ curl -sSL https://raw.githubusercontent.com/drycc/workflow-cli/master/install-v2.sh | bash -s v2.20.0 The installer puts drycc in your current directory, but you should move it somewhere in your $PATH: $ ln -fs $PWD/drycc /usr/local/bin/drycc Getting Help \u00b6 The Drycc client comes with comprehensive documentation for every command. Use drycc help to explore the commands available to you: $ drycc help The Drycc command-line client issues API calls to a Drycc controller. Usage: drycc <command> [<args>...] Auth commands:: register register a new user with a controller login login to a controller logout logout from the current controller Subcommands, use `drycc help [subcommand]` to learn more:: ... To get help on subcommands, use drycc help [subcommand] : $ drycc help apps Valid commands for apps: apps:create create a new application apps:list list accessible applications apps:info view info about an application apps:open open the application in a browser apps:logs view aggregated application logs apps:run run a command in an ephemeral app container apps:destroy destroy an application Use `drycc help [command]` to learn more Support for Multiple Profiles \u00b6 The CLI reads from the default client profile, which is located on your workstation at $HOME/.drycc/client.json . Easily switch between multiple Drycc Workflow installations or users by setting the $DRYCC_PROFILE environment variable or by using the -c flag. There are two ways to set the $DRYCC_PROFILE option. Path to a json configuration file. Profile name. If you set profile to just a name, it will be saved alongside the default profile, in $HOME/.drycc/<name>.json . Examples: $ DRYCC_PROFILE=production drycc login drycc.production.com ... Configuration saved to /home/testuser/.drycc/production.json $ DRYCC_PROFILE=~/config.json drycc login drycc.example.com ... Configuration saved to /home/testuser/config.json The configuration flag works identically to and overrides $DRYCC_PROFILE : $ drycc whoami -c ~/config.json You are drycc at drycc.example.com Proxy Support \u00b6 If your workstation uses a proxy to reach the network where the cluster lies, set the http_proxy or https_proxy environment variable to enable proxy support: $ export http_proxy=\"http://proxyip:port\" $ export https_proxy=\"http://proxyip:port\" Note Configuring a proxy is generally not necessary for local Minikube clusters. CLI Plugins \u00b6 Plugins allow developers to extend the functionality of the Drycc Client, adding new commands or features. If an unknown command is specified, the client will attempt to execute the command as a dash-separated command. In this case, drycc resource:command will execute drycc-resource with the argument list command . In full form: $ # these two are identical $ drycc accounts:list $ drycc-accounts list Any flags after the command will also be sent to the plugin as an argument: $ # these two are identical $ drycc accounts:list --debug $ drycc-accounts list --debug But flags preceding the command will not: $ # these two are identical $ drycc --debug accounts:list $ drycc-accounts list","title":"Command Line Interface"},{"location":"users/cli/#drycc-workflow-cli","text":"The Drycc Workflow command-line interface (CLI), or client, allows you to interact with Drycc Workflow.","title":"Drycc Workflow  CLI"},{"location":"users/cli/#installation","text":"Install the latest drycc client for Linux or Mac OS X with: $ curl -sSL https://raw.githubusercontent.com/drycc/workflow-cli/master/install-v2.sh | bash -s v2.20.0 The installer puts drycc in your current directory, but you should move it somewhere in your $PATH: $ ln -fs $PWD/drycc /usr/local/bin/drycc","title":"Installation"},{"location":"users/cli/#getting-help","text":"The Drycc client comes with comprehensive documentation for every command. Use drycc help to explore the commands available to you: $ drycc help The Drycc command-line client issues API calls to a Drycc controller. Usage: drycc <command> [<args>...] Auth commands:: register register a new user with a controller login login to a controller logout logout from the current controller Subcommands, use `drycc help [subcommand]` to learn more:: ... To get help on subcommands, use drycc help [subcommand] : $ drycc help apps Valid commands for apps: apps:create create a new application apps:list list accessible applications apps:info view info about an application apps:open open the application in a browser apps:logs view aggregated application logs apps:run run a command in an ephemeral app container apps:destroy destroy an application Use `drycc help [command]` to learn more","title":"Getting Help"},{"location":"users/cli/#support-for-multiple-profiles","text":"The CLI reads from the default client profile, which is located on your workstation at $HOME/.drycc/client.json . Easily switch between multiple Drycc Workflow installations or users by setting the $DRYCC_PROFILE environment variable or by using the -c flag. There are two ways to set the $DRYCC_PROFILE option. Path to a json configuration file. Profile name. If you set profile to just a name, it will be saved alongside the default profile, in $HOME/.drycc/<name>.json . Examples: $ DRYCC_PROFILE=production drycc login drycc.production.com ... Configuration saved to /home/testuser/.drycc/production.json $ DRYCC_PROFILE=~/config.json drycc login drycc.example.com ... Configuration saved to /home/testuser/config.json The configuration flag works identically to and overrides $DRYCC_PROFILE : $ drycc whoami -c ~/config.json You are drycc at drycc.example.com","title":"Support for Multiple Profiles"},{"location":"users/cli/#proxy-support","text":"If your workstation uses a proxy to reach the network where the cluster lies, set the http_proxy or https_proxy environment variable to enable proxy support: $ export http_proxy=\"http://proxyip:port\" $ export https_proxy=\"http://proxyip:port\" Note Configuring a proxy is generally not necessary for local Minikube clusters.","title":"Proxy Support"},{"location":"users/cli/#cli-plugins","text":"Plugins allow developers to extend the functionality of the Drycc Client, adding new commands or features. If an unknown command is specified, the client will attempt to execute the command as a dash-separated command. In this case, drycc resource:command will execute drycc-resource with the argument list command . In full form: $ # these two are identical $ drycc accounts:list $ drycc-accounts list Any flags after the command will also be sent to the plugin as an argument: $ # these two are identical $ drycc accounts:list --debug $ drycc-accounts list --debug But flags preceding the command will not: $ # these two are identical $ drycc --debug accounts:list $ drycc-accounts list","title":"CLI Plugins"},{"location":"users/registration/","text":"Users and Registration \u00b6 There are two classes of Workflow users: normal users and administrators. Users can use most of the features of Workflow - creating and deploying applications, adding/removing domains, etc. Administrators can perform all the actions that users can, but they also have owner access to all applications. The first user created on a Workflow installation is automatically an administrator. Register with a Controller \u00b6 Use drycc register with the Controller URL (supplied by your Drycc administrator) to create a new account. After successful registration you will be logged in as the new user. $ drycc register http://drycc.example.com username: myuser password: password (confirm): email: myuser@example.com Registered myuser Logged in as myuser Important The first user to register with Drycc Workflow automatically becomes an administrator. Additional users who register will be ordinary users. Login to Workflow \u00b6 If you already have an account, use drycc login to authenticate against the Drycc Workflow API. $ drycc login http://drycc.example.com username: drycc password: Logged in as drycc Logout from Workflow \u00b6 Logout of an existing controller session using drycc logout . $ drycc logout Logged out as drycc Verify Your Session \u00b6 You can verify your client configuration by running drycc whoami . $ drycc whoami You are drycc at http://drycc.example.com Note Session and client configuration is stored in the ~/.drycc/client.json file. Registering New Users \u00b6 By default, new users are not allowed to register after an initial user does. That initial user becomes the first \"admin\" user. Others will now receive an error when trying to register, but when logged in, an admin user can register new users: $ drycc register --login=false --username=newuser --password=changeme123 --email=newuser@drycc.cc Controlling Registration Modes \u00b6 After creating your first user, you may wish to change the registration mode for Drycc Workflow. Drycc Workflow supports three registration modes: Mode Description admin_only (default) Only existing admins may register new users enabled Registration is enabled and anyone can register disabled Does not allow anyone to register new users. To modify the registration mode for Workflow you may add or modify the REGISTRATION_MODE environment variable for the controller component. If Drycc Workflow is already running, use: kubectl --namespace=drycc patch deployments drycc-controller -p '{\"spec\":{\"template\":{\"spec\":{\"containers\":[{\"name\":\"drycc-controller\",\"env\":[{\"name\":\"REGISTRATION_MODE\",\"value\":\"disabled\"}]}]}}}}' Modify the value portion to match the desired mode. Kubernetes will automatically deploy a new ReplicaSet and corresponding Pod with the new environment variables set. Managing Administrative Permissions \u00b6 You can use the drycc perms command to promote a user to an admin: $ drycc perms:create john --admin Adding john to system administrators... done View current admins: $ drycc perms:list --admin === Administrators admin john Demote admins to normal users: $ drycc perms:delete john --admin Removing john from system administrators... done Re-issuing User Authentication Tokens \u00b6 The controller API uses a simple token-based HTTP Authentication scheme. Token authentication is appropriate for client-server setups, such as native desktop and mobile clients. Each user of the platform is issued a token the first time that they sign up on the platform. If this token is compromised, it will need to be regenerated. A user can regenerate their own token like this: $ drycc auth:regenerate An administrator can also regenerate the token of another user like this: $ drycc auth:regenerate -u test-user At this point, the user will no longer be able to authenticate against the controller with his auth token: $ drycc apps 401 UNAUTHORIZED Detail: Invalid token They will need to log back in to use their new auth token. If there is a cluster wide security breach, an administrator can regenerate everybody's auth token like this: $ drycc auth:regenerate --all=true Changing Account Password \u00b6 A user can change their own account's password like this: $ drycc auth:passwd current password: new password: new password (confirm): An administrator can change the password of another user's account like this: $ drycc auth:passwd --username=<username> new password: new password (confirm):","title":"Users and Registration"},{"location":"users/registration/#users-and-registration","text":"There are two classes of Workflow users: normal users and administrators. Users can use most of the features of Workflow - creating and deploying applications, adding/removing domains, etc. Administrators can perform all the actions that users can, but they also have owner access to all applications. The first user created on a Workflow installation is automatically an administrator.","title":"Users and Registration"},{"location":"users/registration/#register-with-a-controller","text":"Use drycc register with the Controller URL (supplied by your Drycc administrator) to create a new account. After successful registration you will be logged in as the new user. $ drycc register http://drycc.example.com username: myuser password: password (confirm): email: myuser@example.com Registered myuser Logged in as myuser Important The first user to register with Drycc Workflow automatically becomes an administrator. Additional users who register will be ordinary users.","title":"Register with a Controller"},{"location":"users/registration/#login-to-workflow","text":"If you already have an account, use drycc login to authenticate against the Drycc Workflow API. $ drycc login http://drycc.example.com username: drycc password: Logged in as drycc","title":"Login to Workflow"},{"location":"users/registration/#logout-from-workflow","text":"Logout of an existing controller session using drycc logout . $ drycc logout Logged out as drycc","title":"Logout from Workflow"},{"location":"users/registration/#verify-your-session","text":"You can verify your client configuration by running drycc whoami . $ drycc whoami You are drycc at http://drycc.example.com Note Session and client configuration is stored in the ~/.drycc/client.json file.","title":"Verify Your Session"},{"location":"users/registration/#registering-new-users","text":"By default, new users are not allowed to register after an initial user does. That initial user becomes the first \"admin\" user. Others will now receive an error when trying to register, but when logged in, an admin user can register new users: $ drycc register --login=false --username=newuser --password=changeme123 --email=newuser@drycc.cc","title":"Registering New Users"},{"location":"users/registration/#controlling-registration-modes","text":"After creating your first user, you may wish to change the registration mode for Drycc Workflow. Drycc Workflow supports three registration modes: Mode Description admin_only (default) Only existing admins may register new users enabled Registration is enabled and anyone can register disabled Does not allow anyone to register new users. To modify the registration mode for Workflow you may add or modify the REGISTRATION_MODE environment variable for the controller component. If Drycc Workflow is already running, use: kubectl --namespace=drycc patch deployments drycc-controller -p '{\"spec\":{\"template\":{\"spec\":{\"containers\":[{\"name\":\"drycc-controller\",\"env\":[{\"name\":\"REGISTRATION_MODE\",\"value\":\"disabled\"}]}]}}}}' Modify the value portion to match the desired mode. Kubernetes will automatically deploy a new ReplicaSet and corresponding Pod with the new environment variables set.","title":"Controlling Registration Modes"},{"location":"users/registration/#managing-administrative-permissions","text":"You can use the drycc perms command to promote a user to an admin: $ drycc perms:create john --admin Adding john to system administrators... done View current admins: $ drycc perms:list --admin === Administrators admin john Demote admins to normal users: $ drycc perms:delete john --admin Removing john from system administrators... done","title":"Managing Administrative Permissions"},{"location":"users/registration/#re-issuing-user-authentication-tokens","text":"The controller API uses a simple token-based HTTP Authentication scheme. Token authentication is appropriate for client-server setups, such as native desktop and mobile clients. Each user of the platform is issued a token the first time that they sign up on the platform. If this token is compromised, it will need to be regenerated. A user can regenerate their own token like this: $ drycc auth:regenerate An administrator can also regenerate the token of another user like this: $ drycc auth:regenerate -u test-user At this point, the user will no longer be able to authenticate against the controller with his auth token: $ drycc apps 401 UNAUTHORIZED Detail: Invalid token They will need to log back in to use their new auth token. If there is a cluster wide security breach, an administrator can regenerate everybody's auth token like this: $ drycc auth:regenerate --all=true","title":"Re-issuing User Authentication Tokens"},{"location":"users/registration/#changing-account-password","text":"A user can change their own account's password like this: $ drycc auth:passwd current password: new password: new password (confirm): An administrator can change the password of another user's account like this: $ drycc auth:passwd --username=<username> new password: new password (confirm):","title":"Changing Account Password"},{"location":"users/ssh-keys/","text":"Users and SSH Keys \u00b6 For Dockerfile and Buildpack based application deploys via git push , Drycc Workflow identifies users via SSH keys. SSH keys are pushed to the platform and must be unique to each user. Users may have multiple SSH keys as needed. Generate an SSH Key \u00b6 If you do not already have an SSH key or would like to create a new key for Drycc Workflow, generate a new key using ssh-keygen : $ ssh-keygen -f ~/.ssh/id_drycc -t rsa Generating public/private rsa key pair. Enter passphrase (empty for no passphrase): Enter same passphrase again: Your identification has been saved in /Users/admin/.ssh/id_drycc. Your public key has been saved in /Users/admin/.ssh/id_drycc.pub. The key fingerprint is: 3d:ac:1f:f4:83:f7:64:51:c1:7e:7f:80:b6:70:36:c9 admin@plinth-23437.local The key's randomart image is: +--[ RSA 2048]----+ | .. | | ..| | . o. .| | o. E .o.| | S == o..o| | o +. .o| | . o + o .| | . o = | | . . | +-----------------+ $ ssh-add ~/.ssh/id_drycc Identity added: /Users/admin/.ssh/id_drycc (/Users/admin/.ssh/id_drycc) Adding and Removing SSH Keys \u00b6 By publishing the public half of your SSH key to Drycc Workflow the component responsible for receiving git push will be able to authenticate the user and ensure that they have access to the destination application. $ drycc keys:add ~/.ssh/id_drycc.pub Uploading id_drycc.pub to drycc... done You can always view the keys associated with your user as well: $ drycc keys:list === admin Keys admin@plinth-23437.local ssh-rsa AAAAB3Nz...3437.local admin@subgenius.local ssh-rsa AAAAB3Nz...nius.local Remove keys by their name: $ drycc keys:remove admin@plinth-23437.local Removing admin@plinth-23437.local SSH Key... don","title":"SSH Keys"},{"location":"users/ssh-keys/#users-and-ssh-keys","text":"For Dockerfile and Buildpack based application deploys via git push , Drycc Workflow identifies users via SSH keys. SSH keys are pushed to the platform and must be unique to each user. Users may have multiple SSH keys as needed.","title":"Users and SSH Keys"},{"location":"users/ssh-keys/#generate-an-ssh-key","text":"If you do not already have an SSH key or would like to create a new key for Drycc Workflow, generate a new key using ssh-keygen : $ ssh-keygen -f ~/.ssh/id_drycc -t rsa Generating public/private rsa key pair. Enter passphrase (empty for no passphrase): Enter same passphrase again: Your identification has been saved in /Users/admin/.ssh/id_drycc. Your public key has been saved in /Users/admin/.ssh/id_drycc.pub. The key fingerprint is: 3d:ac:1f:f4:83:f7:64:51:c1:7e:7f:80:b6:70:36:c9 admin@plinth-23437.local The key's randomart image is: +--[ RSA 2048]----+ | .. | | ..| | . o. .| | o. E .o.| | S == o..o| | o +. .o| | . o + o .| | . o = | | . . | +-----------------+ $ ssh-add ~/.ssh/id_drycc Identity added: /Users/admin/.ssh/id_drycc (/Users/admin/.ssh/id_drycc)","title":"Generate an SSH Key"},{"location":"users/ssh-keys/#adding-and-removing-ssh-keys","text":"By publishing the public half of your SSH key to Drycc Workflow the component responsible for receiving git push will be able to authenticate the user and ensure that they have access to the destination application. $ drycc keys:add ~/.ssh/id_drycc.pub Uploading id_drycc.pub to drycc... done You can always view the keys associated with your user as well: $ drycc keys:list === admin Keys admin@plinth-23437.local ssh-rsa AAAAB3Nz...3437.local admin@subgenius.local ssh-rsa AAAAB3Nz...nius.local Remove keys by their name: $ drycc keys:remove admin@plinth-23437.local Removing admin@plinth-23437.local SSH Key... don","title":"Adding and Removing SSH Keys"}]}